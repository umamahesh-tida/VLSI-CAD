{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2hU5j_-jvPP"
      },
      "source": [
        "### Importing Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h70jf4C1JAHJ"
      },
      "outputs": [],
      "source": [
        "# !pip install torchprofile 1>/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iDYrz7qAJDhy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import copy\n",
        "import random\n",
        "import time\n",
        "from collections import OrderedDict, defaultdict\n",
        "from typing import Union, List\n",
        "import torch.nn.init as init\n",
        "import numpy as np\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.optim import *\n",
        "from torch.optim.lr_scheduler import *\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import *\n",
        "from torchvision.transforms import *\n",
        "from tqdm.auto import tqdm\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "\n",
        "#from torchprofile import profile_macs # Helps us to obtain mac calculations\n",
        "\n",
        "\n",
        "assert torch.cuda.is_available(), \\\n",
        "\"The current runtime does not have CUDA support.\" \\\n",
        "\"Please go to menu bar (Runtime - Change runtime type) and select GPU\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJW2Iw83JXo3"
      },
      "source": [
        "### DynamicConnectionLayer\n",
        "\n",
        "\n",
        "$h_j$ and $h_i$ are hidden states of the controller at anchor points which should be size of 35. We should consider $j<i$,\n",
        "$W_{prev}$, $W_{curr}$ and $v$ are trainable parameters. The choice of whether we concatenate the previous layers output or not determine the ground truth of sigmoid for training.\n",
        "\n",
        "\n",
        "$$P\\left(Layer\\ j\\ is\\ an\\ input\\ to\\ Layer\\ i\\right) = \\sigma\\left(v^T \\tanh\\left(W_{prev} \\star h_j + W_{curr} \\star h_i\\right)\\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Gdo0NxfYX_yq"
      },
      "outputs": [],
      "source": [
        "class DynamicConnectionLayer(nn.Module):\n",
        "\n",
        "    \"\"\"\n",
        "       This class is used to define anchor points in the controller network.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, num_input, hidden_size,intr_size=30):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_input (int): Number of input connections.\n",
        "            hidden_size (int): Size of the hidden layer.\n",
        "            intr_size (int, optional): Intermediate size. Defaults to 30.\n",
        "        \"\"\"\n",
        "        super(DynamicConnectionLayer, self).__init__()\n",
        "        self.num_input = num_input\n",
        "        self.hidden_size = hidden_size\n",
        "        self.intr_size=intr_size #intermeditate size\n",
        "        layers_array = []\n",
        "\n",
        "        for i in range(num_input):\n",
        "            # print(input_size)\n",
        "            layers_array.append(nn.Linear(hidden_size,intr_size, bias = False))  #W_prev parameter\n",
        "            layers_array.append(nn.Linear(hidden_size,intr_size, bias = False))   #W_curr parameter\n",
        "            layers_array.append(nn.Linear(intr_size,1, bias = False))  #v\n",
        "        self.layers = nn.ModuleList(layers_array)\n",
        "\n",
        "    def forward(self, prev_hidden_states, current_hidden_state):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            prev_hidden_states: previous states anchor points\n",
        "            current_hidden_state: current state anchor point\n",
        "\n",
        "        Returns:\n",
        "            probabilities: connection probability of previous layer is an input to current layer\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        probabilities=[]\n",
        "        for i in range(self.num_input):\n",
        "            prev_term = self.layers[3*i](prev_hidden_states[i])  # prev_term\n",
        "\n",
        "            curr_term = self.layers[3*i + 1](current_hidden_state)  # curr_term\n",
        "\n",
        "            connection_input = torch.tanh(prev_term + curr_term)\n",
        "            connection_probability = torch.sigmoid(self.layers[3*i + 2](connection_input))  # Apply sigmoid activation to get probabilities\n",
        "\n",
        "            probabilities.append(connection_probability)\n",
        "\n",
        "        return probabilities\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u7r9KEM1-zg"
      },
      "source": [
        "### Controller network\n",
        "\n",
        "Controller is a two - layer LSTM with 35 hidden units on each layer.\n",
        "\n",
        "It predicts filter height - $[1,3,5,7]$, filter width - $[1,3,5,7]$ ,number of filters - $[24, 36, 48, 64]$ , stride is (1,1) for each layer.\n",
        "\n",
        "Every prediction is carried out by a softmax classifier and then fed into the next time step as input.\n",
        "\n",
        "The controller uses skip connections as anchor points to decide what layers it wants as inputs to the current layer. here, every prediction is carried out by sigmoid classifier and then fed into the next time step as input.\n",
        "\n",
        "![controller.png](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0Bfy8DKmwwZf"
      },
      "outputs": [],
      "source": [
        "class Controller(nn.Module):\n",
        "    def __init__(self, conv_layers_num, input_size, hidden_size, lstm_num_layers, layers_num, layers_sizes):\n",
        "        \"\"\" Definition of the controller module\n",
        "        ---------\n",
        "        conv_layers_num is the total num of conv layers generating for the child architecture\n",
        "        input_size: the input size to the LSTM\n",
        "        hidden_size: the number of hidden units of the LSTM\n",
        "        lstm_num_layers: the number of layers in the lstm\n",
        "        layers_num :  the total number parameters used to define conv layer for prediction.\n",
        "        \"\"\"\n",
        "        super(Controller, self).__init__()\n",
        "        self.conv_layers_num =conv_layers_num\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm_num_layers = lstm_num_layers\n",
        "        self.layers_num = layers_num\n",
        "        self.layers_sizes = layers_sizes\n",
        "\n",
        "        # Define LSTM layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, lstm_num_layers, batch_first=True)\n",
        "\n",
        "        # Define dynamic connection layers\n",
        "        self.dynamic_layers = nn.ModuleList([DynamicConnectionLayer(_+1, hidden_size) for _ in range(conv_layers_num-1)])\n",
        "        # Create an linear layer\n",
        "\n",
        "        self.Embedding_softmax = nn.ModuleList([nn.Linear(size, input_size, bias=False) for size in layers_sizes])\n",
        "\n",
        "        self.Embedding_attn = nn.ModuleList([nn.Linear(hidden_size,input_size, bias=False)])\n",
        "        self.Embedding_attn.extend( [nn.Linear(size+1,input_size, bias=False) for size in range(conv_layers_num-2)])\n",
        "\n",
        "        # Define linear layers for predictions\n",
        "        self.prediction_layers = nn.ModuleList([nn.Linear(hidden_size, size) for size in layers_sizes])\n",
        "\n",
        "    def forward(self, inference=True,child_network_labels=None,child_network_skips=None):\n",
        "        \"\"\"\n",
        "        The code can operate in two modes: inference and training.\n",
        "\n",
        "        Inference Mode (Prediction):\n",
        "          In this mode, the code uses a pre-trained model to make predictions based on the input.\n",
        "          It doesn't involve any learning or updates to the system.\n",
        "\n",
        "        Training Mode:\n",
        "          In this mode, the code uses the input and potentially some\n",
        "          additional information (child_network_labels, child_network_skips) to train the model.\n",
        "          It refines the system based on the input and desired outcome.\n",
        "        Args:\n",
        "            child_network_labels : randomly generated labels as list of size(conv_layer_nums/len(vocab))\n",
        "            child_network_skips: randomly generated skip labels as a dict type of size(conv_layer_num)\n",
        "\n",
        "        Returns:\n",
        "            targets : Predicted probabilities of child_labels (output->list of Tensors)\n",
        "            skip_targets:Predicted probabilities of skip_labels (output -> dict consists of tensors)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        targets = []\n",
        "        anchor_points=[]\n",
        "        skip_targets={}\n",
        "        skip_input_index=0\n",
        "        threshold=torch.Tensor([0.5])\n",
        "        hidden, cell = torch.zeros(self.lstm_num_layers, self.hidden_size), torch.zeros(self.lstm_num_layers,self.hidden_size)\n",
        "        if inference:\n",
        "          num_forwards = 1\n",
        "        else:\n",
        "          num_forwards = len(child_network_labels)\n",
        "        input = torch.zeros(num_forwards,self.input_size)\n",
        "        input_test=torch.zeros(num_forwards,self.input_size)\n",
        "\n",
        "\n",
        "        for curr_conv_layer in range(self.conv_layers_num):\n",
        "                for i in range(self.layers_num+1):\n",
        "                    if i < self.layers_num:\n",
        "                        input, (hidden, cell) = self.lstm(input, (hidden, cell))\n",
        "                        # Flatten the input for linear layer\n",
        "                        input = self.prediction_layers[i](input.view(input.size(0),-1))\n",
        "                        targets.append(input)\n",
        "                        if inference:\n",
        "                            input = torch.nn.functional.one_hot(torch.argmax(input, dim=1).unsqueeze(1),num_classes=input.size(dim=1)).float()\n",
        "                        else:\n",
        "                            input_index = curr_conv_layer*self.layers_num+i\n",
        "                            childs_labels=[]\n",
        "                            for child_label in child_network_labels:\n",
        "                              childs_labels.append(child_network_labels[child_label][input_index])\n",
        "                            input = torch.nn.functional.one_hot(torch.tensor([childs_labels]),num_classes=input.size(dim=1)).float()\n",
        "                        input=self.Embedding_softmax[i](input).view(input_test.size())\n",
        "                    else:\n",
        "                    # Apply dynamic connections\n",
        "                      anchor_current,(hidden,cell)=self.lstm(input, (hidden, cell))\n",
        "                      if len(anchor_points)>0:\n",
        "                          input=self.dynamic_layers[curr_conv_layer-1](anchor_points,anchor_current)\n",
        "                          skip_targets[curr_conv_layer-1]=input\n",
        "                          if inference:\n",
        "                            input = (torch.tensor(input)>threshold).float()\n",
        "                          else:\n",
        "                            childs_skips=[]\n",
        "                            for child_skips in child_network_skips:\n",
        "                              childs_skips.append(child_network_skips[child_skips][skip_input_index])\n",
        "                            input =(torch.tensor([childs_skips])).float()\n",
        "                            skip_input_index =skip_input_index+1\n",
        "                          if(curr_conv_layer!=self.conv_layers_num-1):\n",
        "                            input = self.Embedding_attn[curr_conv_layer](input.float()).view(input_test.size())\n",
        "                      else:\n",
        "                          input=self.Embedding_attn[curr_conv_layer](anchor_current)\n",
        "                      anchor_points.append(anchor_current)\n",
        "\n",
        "        return targets,skip_targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Controller_Full(nn.Module):\n",
        "    def __init__(self, conv_layers_num, input_size, hidden_size, lstm_num_layers, layers_num, layers_sizes):\n",
        "        \"\"\" Definition of the controller module\n",
        "        ---------\n",
        "        conv_layers_num is the total num of conv layers generating for the child architecture\n",
        "        input_size: the input size to the LSTM\n",
        "        hidden_size: the number of hidden units of the LSTM\n",
        "        lstm_num_layers: the number of layers in the lstm\n",
        "        layers_num :  the total number parameters used to define conv layer for prediction.\n",
        "        \"\"\"\n",
        "        super(Controller, self).__init__()\n",
        "        self.conv_layers_num =conv_layers_num\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm_num_layers = lstm_num_layers\n",
        "        self.layers_num = layers_num\n",
        "        self.layers_sizes = layers_sizes\n",
        "        self.conv_layers_total=conv_layers_num\n",
        "\n",
        "        # Define LSTM layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, lstm_num_layers, batch_first=True)\n",
        "\n",
        "        # Define dynamic connection layers\n",
        "        self.dynamic_layers = nn.ModuleList([DynamicConnectionLayer(_+1, hidden_size) for _ in range(conv_layers_num-1)])\n",
        "        # Create an linear layer\n",
        "\n",
        "        self.Embedding_softmax = nn.ModuleList([nn.Linear(size, input_size, bias=False) for size in layers_sizes])\n",
        "\n",
        "        self.Embedding_attn = nn.ModuleList([nn.Linear(hidden_size,input_size, bias=False)])\n",
        "        self.Embedding_attn.extend( [nn.Linear(size+1,input_size, bias=False) for size in range(conv_layers_num-2)])\n",
        "\n",
        "        # Define linear layers for predictions\n",
        "        self.prediction_layers = nn.ModuleList([nn.Linear(hidden_size, size) for size in layers_sizes])\n",
        "    def extend_network(self, conv_layers_num):\n",
        "      self.conv_layers_num=conv_layers_num\n",
        "      if(self.conv_layers_total>conv_layers_num):\n",
        "         self.__init__(conv_layers_num, self.input_size,self.hidden_size,self.lstm_num_layers,self.layers_num, self.layers_sizes)\n",
        "\n",
        "    def forward(self, inference=True,child_network_labels=None,child_network_skips=None):\n",
        "        \"\"\"\n",
        "        The code can operate in two modes: inference and training.\n",
        "\n",
        "        Inference Mode (Prediction):\n",
        "          In this mode, the code uses a pre-trained model to make predictions based on the input.\n",
        "          It doesn't involve any learning or updates to the system.\n",
        "\n",
        "        Training Mode:\n",
        "          In this mode, the code uses the input and potentially some\n",
        "          additional information (child_network_labels, child_network_skips) to train the model.\n",
        "          It refines the system based on the input and desired outcome.\n",
        "        Args:\n",
        "            child_network_labels : randomly generated labels as list of size(conv_layer_nums/len(vocab))\n",
        "            child_network_skips: randomly generated skip labels as a dict type of size(conv_layer_num)\n",
        "\n",
        "        Returns:\n",
        "            targets : Predicted probabilities of child_labels (output->list of Tensors)\n",
        "            skip_targets:Predicted probabilities of skip_labels (output -> dict consists of tensors)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        targets = []\n",
        "        anchor_points=[]\n",
        "        skip_targets={}\n",
        "        skip_input_index=0\n",
        "        threshold=torch.Tensor([0.5])\n",
        "        hidden, cell = torch.zeros(self.lstm_num_layers, self.hidden_size), torch.zeros(self.lstm_num_layers,self.hidden_size)\n",
        "        if inference:\n",
        "          num_forwards = 1\n",
        "        else:\n",
        "          num_forwards = len(child_network_labels)\n",
        "        input = torch.zeros(num_forwards,self.input_size)\n",
        "        input_test=torch.zeros(num_forwards,self.input_size)\n",
        "\n",
        "\n",
        "        for curr_conv_layer in range(self.conv_layers_num):\n",
        "                for i in range(self.layers_num+1):\n",
        "                    if i < self.layers_num:\n",
        "                        input, (hidden, cell) = self.lstm(input, (hidden, cell))\n",
        "                        # Flatten the input for linear layer\n",
        "                        input = self.prediction_layers[i](input.view(input.size(0),-1))\n",
        "                        targets.append(input)\n",
        "                        if inference:\n",
        "                            input = torch.nn.functional.one_hot(torch.argmax(input, dim=1).unsqueeze(1),num_classes=input.size(dim=1)).float()\n",
        "                        else:\n",
        "                            input_index = curr_conv_layer*self.layers_num+i\n",
        "                            childs_labels=[]\n",
        "                            for child_label in child_network_labels:\n",
        "                              childs_labels.append(child_network_labels[child_label][input_index])\n",
        "                            input = torch.nn.functional.one_hot(torch.tensor([childs_labels]),num_classes=input.size(dim=1)).float()\n",
        "                        input=self.Embedding_softmax[i](input).view(input_test.size())\n",
        "                    else:\n",
        "                    # Apply dynamic connections\n",
        "                      anchor_current,(hidden,cell)=self.lstm(input, (hidden, cell))\n",
        "                      if len(anchor_points)>0:\n",
        "                          input=self.dynamic_layers[curr_conv_layer-1](anchor_points,anchor_current)\n",
        "                          skip_targets[curr_conv_layer-1]=input\n",
        "                          if inference:\n",
        "                            input = (torch.tensor(input)>threshold).float()\n",
        "                          else:\n",
        "                            childs_skips=[]\n",
        "                            for child_skips in child_network_skips:\n",
        "                              childs_skips.append(child_network_skips[child_skips][skip_input_index])\n",
        "                            input =(torch.tensor([childs_skips])).float()\n",
        "                            skip_input_index =skip_input_index+1\n",
        "                          if(curr_conv_layer!=self.conv_layers_num-1):\n",
        "                            input = self.Embedding_attn[curr_conv_layer](input.float()).view(input_test.size())\n",
        "                      else:\n",
        "                          input=self.Embedding_attn[curr_conv_layer](anchor_current)\n",
        "                      anchor_points.append(anchor_current)\n",
        "\n",
        "        return targets,skip_targets\n",
        "    \n",
        "             \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuFVy671OQ7i"
      },
      "source": [
        "##Child Network Class considering Child_labels and Child_skips\n",
        "\n",
        "\n",
        "Child network generate a sample architectures from randomly generated child_labels and child_skips.\n",
        "\n",
        "\n",
        "Sample Architectures will be in the form of:\n",
        "Conv2d ----> BatchNorm2d ----> ReLU\n",
        "\n",
        "Let's see example of 3 conv layers below sample child_model.\n",
        "![child.png](data:image/png;base64,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)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "59DdlKxiOQne"
      },
      "outputs": [],
      "source": [
        "class child_network(nn.Module):\n",
        "  def __init__(self, input_size, output_classes, conv_vocab, child_network_labels, child_network_skips):\n",
        "     \"\"\" Definition of the child network module\n",
        "        ---------\n",
        "        input_size: The input shape of the dataset we are evaluating our child network on\n",
        "        output_classes: The output classes number\n",
        "        conv_vocab: Contains information regarding the convolutional layer information such as # kernel size and # filters\n",
        "        child_network_labels: The labels corresponding to the conv layers of the child network\n",
        "        child_network_skips: The dictionary representation of the skip connection information\n",
        "        ---------\n",
        "        Dependent Parameters Drawn from the given information\n",
        "        ---------\n",
        "        layers_num : The total number of convolutional layers\n",
        "        \"\"\"\n",
        "     super(child_network,self).__init__()\n",
        "     layers_array=[]\n",
        "     conv_layers = len(child_network_skips)+1\n",
        "     layer_param_num = int(len(child_network_labels)/conv_layers)\n",
        "\n",
        "     conv_layer_dimensions = {}\n",
        "\n",
        "     \n",
        "\n",
        "\n",
        "     for conv_layer_num in range(conv_layers):\n",
        "\n",
        "        layers_array.append(nn.Conv2d(input_size[1], vocab[2][child_network_labels[conv_layer_num * layer_param_num + 2]],\n",
        "                                          kernel_size=tuple([vocab[0][child_network_labels[conv_layer_num * layer_param_num]],\n",
        "                                                             vocab[1][child_network_labels[conv_layer_num * layer_param_num + 1]]]),\n",
        "                                          stride=(1, 1)))\n",
        "        \n",
        "        \n",
        "\n",
        "        layers_array.append(nn.BatchNorm2d(vocab[2][child_network_labels[conv_layer_num * layer_param_num + 2]]))\n",
        "        layers_array.append(nn.ReLU())\n",
        "        \n",
        "        # Update height\n",
        "        input_size[2] = math.floor((input_size[2] - vocab[0][child_network_labels[conv_layer_num * layer_param_num]])) + 1\n",
        "        # Update width\n",
        "        input_size[3] = math.floor((input_size[3] - vocab[0][child_network_labels[conv_layer_num * layer_param_num + 1]])) + 1\n",
        "\n",
        "        # Update number of channels\n",
        "        if(conv_layer_num>0):\n",
        "          conv_check=0\n",
        "          input_size[1]= vocab[2][child_network_labels[conv_layer_num * layer_param_num + 2]]\n",
        "          for concat_info in child_network_skips[conv_layer_num-1]:\n",
        "            if(concat_info):\n",
        "              input_size[1] +=conv_layer_dimensions[conv_check][0]\n",
        "              input_size[2] = max(input_size[2],conv_layer_dimensions[conv_check][1])\n",
        "              input_size[3] = max(input_size[3],conv_layer_dimensions[conv_check][2])\n",
        "            conv_check+=1\n",
        "          layers_array.append(nn.Dropout(p=0.2, inplace=False))\n",
        "        else:\n",
        "          input_size[1]= vocab[2][child_network_labels[conv_layer_num * layer_param_num + 2]]\n",
        "        conv_layer_dimensions[conv_layer_num]=[input_size[1],input_size[2],input_size[3]]\n",
        "        # layers_array.append(nn.Dropout(p=0.2))\n",
        "        # layers_array.append(nn.Dropout(p=0.5, inplace=False))\n",
        "    \n",
        "\n",
        "    #  layers_array.append(nn.Dropout(0.5))\n",
        "     layers_array.append(nn.Linear(input_size[1] * input_size[2] * input_size[3], output_classes))\n",
        "     self.layers = nn.ModuleList(layers_array)\n",
        "     print(self.layers)\n",
        "     self.child_network_skips = child_network_skips\n",
        "     self.conv_layer_dimensions=conv_layer_dimensions\n",
        "  def forward(self, input):\n",
        "        '''\n",
        "          if:\n",
        "             layer 1 it forward pass through conv --> BatchNorm ---> Relu\n",
        "         else :\n",
        "          rest of layers it it perform forward pass through conv --> BatchNorm ---> Relu\n",
        "                after check for any skip conection if exist concat connection with padding\n",
        "         for every layer output is stored in 'outputs' dictionary\n",
        "\n",
        "        '''\n",
        "\n",
        "        outputs = {}\n",
        "        for conv_layer_num in range(len(self.child_network_skips) + 1):\n",
        "            # Initial layer without skip connections\n",
        "            if conv_layer_num == 0:\n",
        "                # Forward pass through the current convolutional layer with batchnorm and ReLU\n",
        "                for layer in self.layers[conv_layer_num * 3: conv_layer_num * 3 + 2]:\n",
        "                    input = layer(input)\n",
        "\n",
        "            else:\n",
        "                # Forward pass through the current convolutional layer with batchnorm and ReLU\n",
        "                for layer in self.layers[(conv_layer_num -1)* 4+3: (conv_layer_num -1)* 4+ 6]:\n",
        "                    input = layer(input)\n",
        "                # Concatenate skip connections with padding if necessary\n",
        "                conv_check=0\n",
        "                for concat_info in self.child_network_skips[conv_layer_num-1]:\n",
        "                  if(concat_info):\n",
        "                    out1=outputs[conv_check]\n",
        "                    out2=input\n",
        "\n",
        "                    padding = [abs((out2.size(dim) - out1.size(dim))) // 2 for dim in (2, 3)]\n",
        "                    padding_error=[abs((out2.size(dim) - out1.size(dim))) % 2 for dim in (2, 3)]\n",
        "\n",
        "\n",
        "                    if(out1.size(2)>out2.size(2)):\n",
        "                        if out1.size(3)>out2.size(3):\n",
        "                          out_padded1=out1\n",
        "                          out_padded2 = F.pad(F.pad(out2, (padding[1], padding[1], padding[0], padding[0])),(0,padding_error[1],0,padding_error[0]))\n",
        "                        else:\n",
        "                          out_padded1=F.pad(F.pad(out1, (padding[1], padding[1], 0, 0)),(0,padding_error[1],0,0))\n",
        "                          out_padded2=F.pad(F.pad(out2, (0,0, padding[0], padding[0])),(0,0,0,padding_error[0]))\n",
        "\n",
        "\n",
        "                    else:\n",
        "                        if(out1.size(3)>out2.size(3)):\n",
        "                          out_padded1=F.pad(F.pad(out1, (0,0, padding[0], padding[0])),(0,0,0,padding_error[0]))\n",
        "                          out_padded2=F.pad(F.pad(out2, (padding[1], padding[1], 0,0)),(0,padding_error[1],0,0))\n",
        "                        else:\n",
        "                          out_padded1 = F.pad(F.pad(out1, (padding[1], padding[1], padding[0], padding[0])),(padding_error[1],0,padding_error[0],0))\n",
        "                          out_padded2=out2\n",
        "                    input = torch.cat([out_padded1, out_padded2], dim=1)  # Concatenate the padded out1 with out2\n",
        "\n",
        "                  conv_check+=1\n",
        "\n",
        "            # Save the output for skip connections\n",
        "            outputs[conv_layer_num] = input.clone()\n",
        "\n",
        "\n",
        "        # Flatten and apply softmax to the final linear layer\n",
        "        input = input.view(-1, input.size(1) * input.size(2) * input.size(3))\n",
        "        input = self.layers[-1](input)\n",
        "\n",
        "\n",
        "        return input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egrmhzln2U1z"
      },
      "source": [
        "## Input values\n",
        "\n",
        "**num_childs:** Number of child nodes (possibly in a search space).\n",
        "\n",
        "**conv_layers_num:** Number of convolutional layers.\n",
        "\n",
        "**input_size:** Dimensionality of the input data to controller\n",
        "\n",
        "**hidden_size:** Dimensionality of the hidden state in the LSTM unit.\n",
        "\n",
        "**lstm_num_layers:** Number of LSTM layers stacked on top of each other.\n",
        "\n",
        "**FC_layers_num:** Number of fully-connected layers after the LSTM.\n",
        "\n",
        "**FC_layers_sizes:** A list specifying the number of units in each fully-connected layer.\n",
        "\n",
        "**Controller_Check:** it create instance of Controller Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QEZCqRIExFEB"
      },
      "outputs": [],
      "source": [
        "# Example usage:\n",
        "num_childs= 5000 # amount of architectures to be generated \n",
        "conv_layers_num =5\n",
        "input_size = 1\n",
        "hidden_size = 35\n",
        "lstm_num_layers = 1\n",
        "FC_layers_num = 3\n",
        "FC_layers_sizes = [4, 4, 4]\n",
        "controller_check = Controller(conv_layers_num, input_size, hidden_size, lstm_num_layers, FC_layers_num, FC_layers_sizes)\n",
        "targets, skip_targets=controller_check()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8ZpVAdjZVMCO"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Vocabulary:\n",
        "  vocab[0] and vocab[1] represent kernel sizes, both having values [1, 3, 5, 7].\n",
        "   vocab[2] represents convolutional layer choices, having values [24, 36,48, 64].\n",
        "Output Classes:\n",
        "  output_classes is set to 10, which is the number of classes in the final output.\n",
        "Input Shape\n",
        "  input is a random tensor with shape (1, 3, 32, 32). This is consistent with the typical shape of an input image with three color channels\n",
        "\"\"\"\n",
        "vocab={}\n",
        "vocab[0]=[1, 3, 5, 7]  #kernel height\n",
        "vocab[1]=[1, 3, 5, 7]     #kernel width\n",
        "vocab[2] = [24, 36, 48, 64]     #num of filters [24, 36, 48, 64]  \n",
        "output_classes = 10\n",
        "input = torch.randn(1,3,28,28)\n",
        "\n",
        "# vocab[2][[3,2,3,3,2,1,0,2,3,1,3,3,2,1,3][0 * 5]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5TbLvJIiP6d"
      },
      "source": [
        "## generate random child_ labels\n",
        "\n",
        "Randomly generate child_labels for each child.\n",
        "For Example,\n",
        "\n",
        "**Outer loop:** iterates num_child times.\n",
        "Let's assume num_childs is 2 (two child nodes).\n",
        "\n",
        "\n",
        "**Inner loop:** iterates num_layers times.Imagine num_layers is 5 (five conv layers for each child).\n",
        "\n",
        "**Innermost loop:**iterates size_predicts times.Let's say size_predict is 3 (three predictions[filter heigth,width,num of filters] per layer). Inside this loop, generates a random index within the vocabulary for a specific prediction.\n",
        "   \n",
        "   output (dict) : len(num_childs) and each key is of len(num_layers*size_predicts) ex:3x5=15\n",
        "\n",
        "   sample example:\n",
        "   \n",
        "   {0: array([2, 1, 1, 1, 1, 0, 0, 3, 1, 2, 2, 1, 0, 0, 0]), 1: array([3, 0, 3, 1, 3, 2, 0, 3, 1, 3, 1, 0, 1, 3, 3])}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-cW-iOilbxOV"
      },
      "outputs": [],
      "source": [
        "class child_network_generate_random:\n",
        "    \"\"\"\n",
        "     this class randomly generates the child labels\n",
        "      Args:\n",
        "          num_childs: number of childs\n",
        "          num_layers: number of conv layers\n",
        "          size_predict: number of layer parameter (kernel height,width, no of channels)\n",
        "          vocab: represents kernel sizes, conv layer choices\n",
        "      result:\n",
        "          randomly generated labels for each conv layer\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, num_childs, num_layers, size_predict, vocab):\n",
        "        self.labels = {}\n",
        "        for num_child in range(num_childs):\n",
        "            labels_num_child = []\n",
        "            for num_layer in range(num_layers):\n",
        "                labels_num_layer = []\n",
        "                for predict in range(size_predict):\n",
        "                    labels_num_layer.append(random.randrange(len(vocab[predict])))\n",
        "                labels_num_child.append(labels_num_layer)\n",
        "            self.labels[num_child] = np.concatenate(np.array(labels_num_child))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wd6o7KA2ceu"
      },
      "source": [
        "## child_network_skip_generate_random:\n",
        "\n",
        "Randomly generates skip connection for each layer.\n",
        "\n",
        "**Outer loop:** iterates num_child times.\n",
        "Let's assume num_childs is 2 (two child nodes).\n",
        "\n",
        "**Inner loop:** Intial layer has no skip connection.It iterates num_layers-1 times.Imagine num_layers is 5 (five conv layers for each child).\n",
        "\n",
        "For every layer, it randomly generates 0(no skip connection) or 1(skip connection) wrt to previous layer\n",
        "\n",
        "**Ex:** for 3rd layer it checks with 1,2 and\n",
        "  5th layer it checks with 1,2,3,4 layers generate a list.\n",
        "\n",
        "  Sample example:\n",
        "  \n",
        "   {0: {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 1: {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "53Jr7j37VQan"
      },
      "outputs": [],
      "source": [
        "class child_network_generate_skip_random:\n",
        "  \"\"\"\n",
        "  Args:\n",
        "     num_layers: number of conv layers\n",
        "  output:\n",
        "      skips: stores dictionary type of n-1 conv layer.\n",
        "             Each layer checks  with previous layers\n",
        "\n",
        "  \"\"\"\n",
        "  def __init__(self,num_layers,num_childs =1 ):\n",
        "      self.skips={}\n",
        "      for num_child in range(num_childs):\n",
        "        skip_child={}\n",
        "        for num_layer in range(num_layers-1):\n",
        "          labels_num_layer = []\n",
        "          for predict in range(num_layer+1):\n",
        "                    labels_num_layer.append(random.randrange(2))\n",
        "          skip_child[num_layer]=labels_num_layer\n",
        "        self.skips[num_child] = skip_child"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRQEzcS3ssvc",
        "outputId": "92fa7e41-888d-4df1-c23c-5fcc5a27d180"
      },
      "outputs": [],
      "source": [
        "\n",
        "child_skips = child_network_generate_skip_random(conv_layers_num,num_childs).skips\n",
        "child_labels = child_network_generate_random(num_childs, conv_layers_num, len(vocab), vocab).labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "\n",
        "# **** #  Create a dataset of the skips and label in preparation for training the controller #******#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, skips_values, label_values, reward_values):\n",
        "        self.skips_values = skips_values\n",
        "        self.label_values = label_values\n",
        "        self.reward_values = reward_values\n",
        "        # self.children = list(skips_values.keys())  # Assuming all dictionaries have the same keys\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reward_values)  # Assuming rewards define the number of samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # For each child, fetch the corresponding skip and label by index\n",
        "        # This example assumes the length of skips and labels matches the length of rewards for simplicity\n",
        "        skips = self.skips_values[idx]\n",
        "        labels = self.label_values[idx]\n",
        "        rewards = self.reward_values[idx]\n",
        "        return skips, labels, rewards\n",
        "\n",
        "  \n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    # 'batch' is a list of tuples returned by CustomDataset.__getitem__\n",
        "    skips_batch, labels_batch, rewards_batch = [], [], []\n",
        "    for skips, labels, rewards in batch:\n",
        "        skips_batch.append(skips)\n",
        "        labels_batch.append(labels)\n",
        "        rewards_batch.append(rewards)\n",
        "    # Return a dictionary of batches\n",
        "    \n",
        "    return  dict(skips_batch), dict(labels_batch), rewards_batch #{\"skips\": skips_batch, \"labels\": labels_batch, \"rewards\": rewards_batch}\n",
        "\n",
        "dataset = CustomDataset(child_skips_values, child_labels_values, rewards_values)\n",
        "\n",
        "# Create the DataLoader with the custom collate function\n",
        "data_loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=custom_collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preview random child models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPbt6p3hKv_p",
        "outputId": "b5eb3ba2-6f92-4691-fb0f-bc97f62e90b6"
      },
      "outputs": [],
      "source": [
        "# visualisation\n",
        "#%pip install torchview\n",
        "import torchvision\n",
        "from torchview import draw_graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRvCQ0hgPk0-"
      },
      "outputs": [],
      "source": [
        "controller_archi=Controller(conv_layers_num, input_size, hidden_size, lstm_num_layers, FC_layers_num, FC_layers_sizes)\n",
        "architecture = 'controller_archi'\n",
        "# model_graph = draw_graph(controller_archi,graph_dir ='TB' ,input_size=[input_size], roll=True, expand_nested=True, graph_name=f'self_{architecture}',save_graph=True,filename=f'self_{architecture}')\n",
        "# model_graph.visual_graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQpK4LONI-YD"
      },
      "outputs": [],
      "source": [
        "model=child_network([1,3,28,28],7,vocab,[2, 1, 1, 1, 1, 3, 2, 2, 0, 1, 0, 3, 3, 2, 1],{0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]})\n",
        "architecture = 'child_model'\n",
        "model_graph = draw_graph(model, input_size=(1,3,28,28),graph_dir ='TB' , roll=True, expand_nested=True, graph_name=f'self_{architecture}',save_graph=True,filename=f'self_{architecture}')\n",
        "model_graph.visual_graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BlV1A6IcyuL"
      },
      "source": [
        "**CIFAR-10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrIcSeVJU7It",
        "outputId": "7dbc1a40-34d2-4272-8737-da438ab8b3ab"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Assuming you have a CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "cifar10_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "cifar10_val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split the training set into Trainset45000 and Validationset5000\n",
        "train_size = 45000\n",
        "val_size = 5000\n",
        "train_dataset, val_dataset = random_split(cifar10_train_dataset, [train_size, val_size])\n",
        "\n",
        "# Define data loaders\n",
        "batch_size = 32\n",
        "num_epochs=20\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "cifar_batch = next(iter(train_loader)) \n",
        "\n",
        "print(cifar_batch[1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Dertaminist dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /home/ifedayo/.medmnist/dermamnist.npz\n",
            "Using downloaded and verified file: /home/ifedayo/.medmnist/dermamnist.npz\n",
            "tensor([[[[ 0.8980,  0.8980,  0.8980,  ...,  0.9765,  0.9608,  0.9529],\n",
            "          [ 0.8824,  0.8824,  0.8980,  ...,  0.9451,  0.9294,  0.9216],\n",
            "          [ 0.8667,  0.8745,  0.8980,  ...,  0.9294,  0.9137,  0.9137],\n",
            "          ...,\n",
            "          [ 0.8824,  0.8902,  0.9137,  ...,  0.8196,  0.8196,  0.8196],\n",
            "          [ 0.8588,  0.8824,  0.8980,  ...,  0.8118,  0.8118,  0.8118],\n",
            "          [ 0.8510,  0.8667,  0.8745,  ...,  0.7961,  0.8039,  0.8039]],\n",
            "\n",
            "         [[ 0.2941,  0.2941,  0.2941,  ...,  0.4196,  0.4275,  0.4353],\n",
            "          [ 0.2784,  0.2784,  0.2941,  ...,  0.3882,  0.3961,  0.4039],\n",
            "          [ 0.2627,  0.2706,  0.2941,  ...,  0.3804,  0.3804,  0.3804],\n",
            "          ...,\n",
            "          [ 0.3412,  0.3569,  0.3804,  ...,  0.3255,  0.3255,  0.3255],\n",
            "          [ 0.3255,  0.3490,  0.3647,  ...,  0.2941,  0.2941,  0.3020],\n",
            "          [ 0.3176,  0.3333,  0.3647,  ...,  0.2784,  0.2784,  0.2784]],\n",
            "\n",
            "         [[ 0.4353,  0.4353,  0.4353,  ...,  0.5294,  0.5451,  0.5451],\n",
            "          [ 0.4196,  0.4196,  0.4353,  ...,  0.4980,  0.5137,  0.5137],\n",
            "          [ 0.3882,  0.3961,  0.4196,  ...,  0.4667,  0.4824,  0.4824],\n",
            "          ...,\n",
            "          [ 0.3020,  0.3333,  0.3725,  ...,  0.3961,  0.3961,  0.3961],\n",
            "          [ 0.3020,  0.3255,  0.3569,  ...,  0.3725,  0.3725,  0.3647],\n",
            "          [ 0.2941,  0.3098,  0.3490,  ...,  0.3569,  0.3490,  0.3490]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9216,  0.9373,  0.9608,  ...,  0.9451,  0.9137,  0.8980],\n",
            "          [ 0.9373,  0.9686,  1.0000,  ...,  0.8980,  0.8745,  0.8588],\n",
            "          [ 1.0000,  1.0000,  1.0000,  ...,  0.9059,  0.8745,  0.8510],\n",
            "          ...,\n",
            "          [ 0.9765,  0.9843,  0.9686,  ...,  0.9529,  0.9529,  0.9529],\n",
            "          [ 0.9529,  0.9608,  0.9608,  ...,  0.9608,  0.9608,  0.9608],\n",
            "          [ 0.9137,  0.9216,  0.9216,  ...,  0.9608,  0.9608,  0.9608]],\n",
            "\n",
            "         [[ 0.4431,  0.4588,  0.4980,  ...,  0.5686,  0.5608,  0.5608],\n",
            "          [ 0.4745,  0.5059,  0.5451,  ...,  0.5216,  0.5216,  0.5216],\n",
            "          [ 0.5843,  0.6157,  0.6392,  ...,  0.5294,  0.5373,  0.5373],\n",
            "          ...,\n",
            "          [ 0.5686,  0.5765,  0.5451,  ...,  0.4196,  0.4196,  0.4196],\n",
            "          [ 0.5294,  0.5373,  0.5137,  ...,  0.4118,  0.4118,  0.4118],\n",
            "          [ 0.4902,  0.4980,  0.4745,  ...,  0.4118,  0.4118,  0.4118]],\n",
            "\n",
            "         [[ 0.4196,  0.4353,  0.4667,  ...,  0.5373,  0.5216,  0.5137],\n",
            "          [ 0.4431,  0.4745,  0.5137,  ...,  0.4902,  0.4824,  0.4745],\n",
            "          [ 0.5529,  0.5765,  0.6000,  ...,  0.4980,  0.4824,  0.4745],\n",
            "          ...,\n",
            "          [ 0.4667,  0.4745,  0.4510,  ...,  0.3961,  0.4118,  0.4118],\n",
            "          [ 0.4353,  0.4431,  0.4275,  ...,  0.4118,  0.4118,  0.4118],\n",
            "          [ 0.3961,  0.4039,  0.3882,  ...,  0.4118,  0.4118,  0.4118]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6471,  0.6549,  0.6706,  ...,  0.4196,  0.3490,  0.3098],\n",
            "          [ 0.6863,  0.6784,  0.6784,  ...,  0.4588,  0.3882,  0.3490],\n",
            "          [ 0.6706,  0.6627,  0.6549,  ...,  0.4510,  0.3804,  0.3490],\n",
            "          ...,\n",
            "          [ 0.0510,  0.0745,  0.1451,  ...,  0.2000,  0.1843,  0.1765],\n",
            "          [-0.0039,  0.0118,  0.0824,  ...,  0.1373,  0.1137,  0.1137],\n",
            "          [-0.0510, -0.0353,  0.0275,  ...,  0.0745,  0.0510,  0.0510]],\n",
            "\n",
            "         [[ 0.5059,  0.5137,  0.5373,  ...,  0.1765,  0.1059,  0.0667],\n",
            "          [ 0.5451,  0.5451,  0.5451,  ...,  0.2157,  0.1451,  0.1059],\n",
            "          [ 0.5451,  0.5451,  0.5373,  ...,  0.2078,  0.1529,  0.1216],\n",
            "          ...,\n",
            "          [-0.1922, -0.1686, -0.0980,  ..., -0.0353, -0.0510, -0.0588],\n",
            "          [-0.2392, -0.2235, -0.1686,  ..., -0.0980, -0.1137, -0.1137],\n",
            "          [-0.2863, -0.2706, -0.2235,  ..., -0.1608, -0.1765, -0.1765]],\n",
            "\n",
            "         [[ 0.6000,  0.6078,  0.6157,  ...,  0.2392,  0.1529,  0.1137],\n",
            "          [ 0.6392,  0.6235,  0.6235,  ...,  0.2784,  0.1922,  0.1529],\n",
            "          [ 0.6235,  0.6000,  0.5922,  ...,  0.2706,  0.1922,  0.1608],\n",
            "          ...,\n",
            "          [-0.1529, -0.1294, -0.0588,  ..., -0.0196, -0.0353, -0.0431],\n",
            "          [-0.2235, -0.2078, -0.1451,  ..., -0.0824, -0.0980, -0.0980],\n",
            "          [-0.2863, -0.2706, -0.2000,  ..., -0.1451, -0.1608, -0.1608]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.7804,  0.7804,  0.7882,  ...,  0.7961,  0.8275,  0.8431],\n",
            "          [ 0.7412,  0.7490,  0.7647,  ...,  0.7412,  0.7804,  0.7961],\n",
            "          [ 0.6941,  0.7020,  0.7176,  ...,  0.7176,  0.7490,  0.7725],\n",
            "          ...,\n",
            "          [ 0.6706,  0.6471,  0.5843,  ...,  0.5059,  0.5922,  0.6549],\n",
            "          [ 0.6314,  0.6549,  0.6235,  ...,  0.5137,  0.6000,  0.6627],\n",
            "          [ 0.6000,  0.6471,  0.6627,  ...,  0.5216,  0.6078,  0.6706]],\n",
            "\n",
            "         [[ 0.2078,  0.2078,  0.1843,  ...,  0.1608,  0.1922,  0.2078],\n",
            "          [ 0.1529,  0.1608,  0.1451,  ...,  0.1059,  0.1451,  0.1608],\n",
            "          [ 0.0745,  0.0824,  0.0745,  ...,  0.0745,  0.1059,  0.1294],\n",
            "          ...,\n",
            "          [ 0.1373,  0.0980,  0.0196,  ..., -0.1216, -0.0196,  0.0431],\n",
            "          [ 0.1294,  0.1373,  0.0902,  ..., -0.1137, -0.0118,  0.0431],\n",
            "          [ 0.1137,  0.1451,  0.1451,  ..., -0.1059, -0.0118,  0.0510]],\n",
            "\n",
            "         [[ 0.2784,  0.2627,  0.2314,  ...,  0.2078,  0.2627,  0.2784],\n",
            "          [ 0.2078,  0.2157,  0.1843,  ...,  0.1529,  0.2000,  0.2157],\n",
            "          [ 0.1216,  0.1216,  0.1059,  ...,  0.1216,  0.1529,  0.1765],\n",
            "          ...,\n",
            "          [ 0.0353,  0.0039, -0.0745,  ..., -0.2078, -0.0980, -0.0353],\n",
            "          [ 0.0353,  0.0275, -0.0118,  ..., -0.2000, -0.0902, -0.0118],\n",
            "          [ 0.0118,  0.0510,  0.0353,  ..., -0.1922, -0.0667, -0.0039]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6078,  0.5529,  0.5137,  ...,  0.7804,  0.8118,  0.7882],\n",
            "          [ 0.5686,  0.5373,  0.5216,  ...,  0.7020,  0.7333,  0.7490],\n",
            "          [ 0.6078,  0.6078,  0.6157,  ...,  0.6235,  0.6784,  0.6941],\n",
            "          ...,\n",
            "          [ 0.7412,  0.7255,  0.7098,  ...,  0.7412,  0.7020,  0.6706],\n",
            "          [ 0.7412,  0.7255,  0.7098,  ...,  0.7333,  0.7098,  0.6784],\n",
            "          [ 0.7020,  0.6941,  0.6784,  ...,  0.7647,  0.7333,  0.7020]],\n",
            "\n",
            "         [[ 0.0667,  0.0118, -0.0275,  ...,  0.2863,  0.3176,  0.3098],\n",
            "          [ 0.0275, -0.0039, -0.0196,  ...,  0.1686,  0.2235,  0.2392],\n",
            "          [ 0.0667,  0.0667,  0.0745,  ...,  0.0353,  0.0980,  0.1373],\n",
            "          ...,\n",
            "          [ 0.2784,  0.2627,  0.2471,  ...,  0.3020,  0.2627,  0.2314],\n",
            "          [ 0.2706,  0.2549,  0.2471,  ...,  0.2941,  0.2471,  0.2157],\n",
            "          [ 0.2314,  0.2235,  0.2157,  ...,  0.3255,  0.2706,  0.2392]],\n",
            "\n",
            "         [[ 0.0275, -0.0275, -0.0667,  ...,  0.2471,  0.2784,  0.2706],\n",
            "          [-0.0118, -0.0431, -0.0588,  ...,  0.1451,  0.1922,  0.2078],\n",
            "          [ 0.0118,  0.0118,  0.0196,  ...,  0.0118,  0.0745,  0.1059],\n",
            "          ...,\n",
            "          [ 0.2157,  0.2000,  0.1843,  ...,  0.3255,  0.2863,  0.2549],\n",
            "          [ 0.2078,  0.1922,  0.1843,  ...,  0.3176,  0.2784,  0.2471],\n",
            "          [ 0.1686,  0.1608,  0.1529,  ...,  0.3490,  0.3020,  0.2706]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4431,  0.5529,  0.5686,  ...,  0.5843,  0.5294,  0.4980],\n",
            "          [ 0.3961,  0.4824,  0.4980,  ...,  0.5373,  0.5686,  0.6078],\n",
            "          [ 0.4431,  0.4118,  0.3255,  ...,  0.2549,  0.2941,  0.3490],\n",
            "          ...,\n",
            "          [ 0.3098,  0.3647,  0.4353,  ...,  0.5294,  0.5216,  0.5373],\n",
            "          [ 0.4510,  0.4510,  0.4667,  ...,  0.5137,  0.4745,  0.4667],\n",
            "          [ 0.5294,  0.4980,  0.4745,  ...,  0.4745,  0.4196,  0.4118]],\n",
            "\n",
            "         [[ 0.0196,  0.1294,  0.1294,  ...,  0.1294,  0.0667,  0.0353],\n",
            "          [-0.0275,  0.0588,  0.0588,  ...,  0.0824,  0.1059,  0.1451],\n",
            "          [ 0.0196, -0.0118, -0.1137,  ..., -0.2000, -0.1608, -0.1059],\n",
            "          ...,\n",
            "          [-0.0667, -0.0118,  0.0588,  ...,  0.1137,  0.1216,  0.1373],\n",
            "          [ 0.0745,  0.0745,  0.0902,  ...,  0.1137,  0.0745,  0.0667],\n",
            "          [ 0.1529,  0.1216,  0.0980,  ...,  0.0745,  0.0196,  0.0118]],\n",
            "\n",
            "         [[ 0.2078,  0.3176,  0.3255,  ...,  0.3255,  0.2863,  0.2549],\n",
            "          [ 0.1608,  0.2471,  0.2549,  ...,  0.2784,  0.3255,  0.3647],\n",
            "          [ 0.2235,  0.1922,  0.0980,  ..., -0.0118,  0.0353,  0.0902],\n",
            "          ...,\n",
            "          [ 0.0588,  0.1137,  0.1843,  ...,  0.2549,  0.2549,  0.2706],\n",
            "          [ 0.2000,  0.2000,  0.2157,  ...,  0.2314,  0.1922,  0.1843],\n",
            "          [ 0.2784,  0.2471,  0.2235,  ...,  0.1922,  0.1373,  0.1294]]]])\n",
            "===================\n"
          ]
        }
      ],
      "source": [
        "from medmnist import DermaMNIST\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = DermaMNIST(split=\"train\", transform= data_transform, download=True)\n",
        "valida_dataset = DermaMNIST(split=\"val\", transform=data_transform, download=True)\n",
        "\n",
        "\n",
        "n_classes = 7\n",
        "num_epochs = 20\n",
        "\n",
        "# print(type(train_dataset))\n",
        "\n",
        "# pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "Mtrain_loader = DataLoader(dataset=train_dataset, batch_size= 32, shuffle=True)\n",
        "Mtrain_loader_at_eval = DataLoader(dataset=valida_dataset, batch_size= 32, shuffle=False)\n",
        "# Mtest_loader = DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "\n",
        "batch = next(iter(Mtrain_loader))\n",
        "input = batch[0].float()\n",
        "print(input)\n",
        "print(\"===================\")\n",
        "# print(test_dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK7AMrdS16q9"
      },
      "source": [
        "## Generating child_models and training each Child model with CIFAR-10 dataset\n",
        "\n",
        "Generate n number of child models where,\n",
        "each Child Model is trained with the **ADAM optimizer**  with a learning rate of **0.1**.\n",
        "\n",
        "The **reward** used for updating the controller is the maximum validation accuracy of the last 5 epochs cubed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 64, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(88, 36, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(36, 24, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(112, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=34560, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 24, 26]           1,104\n",
            "       BatchNorm2d-2           [-1, 24, 24, 26]              48\n",
            "            Conv2d-3           [-1, 64, 24, 20]          10,816\n",
            "       BatchNorm2d-4           [-1, 64, 24, 20]             128\n",
            "              ReLU-5           [-1, 64, 24, 20]               0\n",
            "            Conv2d-6           [-1, 36, 18, 20]         155,268\n",
            "       BatchNorm2d-7           [-1, 36, 18, 20]              72\n",
            "              ReLU-8           [-1, 36, 18, 20]               0\n",
            "            Conv2d-9           [-1, 24, 18, 16]           4,344\n",
            "      BatchNorm2d-10           [-1, 24, 18, 16]              48\n",
            "             ReLU-11           [-1, 24, 18, 16]               0\n",
            "           Conv2d-12           [-1, 36, 24, 20]          28,260\n",
            "      BatchNorm2d-13           [-1, 36, 24, 20]              72\n",
            "             ReLU-14           [-1, 36, 24, 20]               0\n",
            "           Linear-15                    [-1, 7]         241,927\n",
            "================================================================\n",
            "Total params: 442,087\n",
            "Trainable params: 442,087\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.78\n",
            "Params size (MB): 1.69\n",
            "Estimated Total Size (MB): 3.48\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 0.9497, Validation Accuracy: 0.6690\n",
            "Epoch 2/100, Loss: 1.0330, Validation Accuracy: 0.6690\n",
            "Epoch 3/100, Loss: 1.4390, Validation Accuracy: 0.6690\n",
            "Epoch 4/100, Loss: 1.2958, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 0.9226, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 1.1709, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 1.0118, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 0.9518, Validation Accuracy: 0.6690\n",
            "Epoch 9/100, Loss: 1.3519, Validation Accuracy: 0.6690\n",
            "Epoch 10/100, Loss: 1.4249, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 1.4008, Validation Accuracy: 0.6690\n",
            "Epoch 12/100, Loss: 1.0662, Validation Accuracy: 0.6690\n",
            "Epoch 13/100, Loss: 0.9182, Validation Accuracy: 0.6690\n",
            "Epoch 14/100, Loss: 1.2810, Validation Accuracy: 0.6690\n",
            "Epoch 15/100, Loss: 1.2634, Validation Accuracy: 0.6690\n",
            "Epoch 16/100, Loss: 1.3672, Validation Accuracy: 0.6690\n",
            "Epoch 17/100, Loss: 0.7294, Validation Accuracy: 0.6690\n",
            "Epoch 18/100, Loss: 0.9754, Validation Accuracy: 0.6690\n",
            "Epoch 19/100, Loss: 1.0276, Validation Accuracy: 0.6690\n",
            "Epoch 20/100, Loss: 0.8359, Validation Accuracy: 0.6690\n",
            "Epoch 21/100, Loss: 1.1806, Validation Accuracy: 0.6690\n",
            "Epoch 22/100, Loss: 0.7959, Validation Accuracy: 0.6690\n",
            "Epoch 23/100, Loss: 0.9870, Validation Accuracy: 0.6690\n",
            "Epoch 24/100, Loss: 1.0250, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 1.2498, Validation Accuracy: 0.6690\n",
            "Epoch 26/100, Loss: 1.1708, Validation Accuracy: 0.6690\n",
            "Epoch 27/100, Loss: 1.0437, Validation Accuracy: 0.6690\n",
            "Epoch 28/100, Loss: 0.9150, Validation Accuracy: 0.6690\n",
            "Epoch 29/100, Loss: 1.2426, Validation Accuracy: 0.6690\n",
            "Epoch 30/100, Loss: 1.3166, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 0.9992, Validation Accuracy: 0.6690\n",
            "Epoch 32/100, Loss: 1.2487, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 1.0029, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 0.8671, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 1.2110, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 1.1859, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 1.7447, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 1.1325, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 0.6817, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 0.8004, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 1.4219, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 1.6020, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 1.1322, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 0.8200, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 0.9300, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 0.9934, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 1.2617, Validation Accuracy: 0.6690\n",
            "Epoch 48/100, Loss: 1.4632, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 1.4004, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 1.0552, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 1.4605, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 1.0732, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 1.5004, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 1.1250, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 1.3854, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 0.7455, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 0.9804, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 1.0556, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 1.2898, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 1.1200, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 1.3677, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 1.2373, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 1.0853, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 1.0507, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 1.2043, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 1.1625, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 0.9100, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 1.2550, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 0.9823, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 1.2583, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 1.3795, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 1.0959, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 0.9529, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 1.0137, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 0.9924, Validation Accuracy: 0.6690\n",
            "Epoch 76/100, Loss: 1.1497, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 0.7820, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 0.7909, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 1.0098, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 1.1503, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 0.8697, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 0.8474, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 0.8776, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 1.4152, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 1.0056, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 0.9527, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 0.9056, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 1.1251, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 1.0870, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 1.0672, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 1.4054, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 0.9237, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 1.2327, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 1.1981, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 1.6974, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 1.1155, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 1.0529, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 1.0285, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 1.4653, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 1.3925, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 1.6964, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 1.1147, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 0.8961, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 1.1391, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 1.1678, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 1.1672, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 1.0861, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 1.1554, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 0.9736, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 0.9263, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.3178, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 1.4502, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 0.8568, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 1.0576, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 1.1620, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 1.2588, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 0.9904, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 0.7427, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 0.8857, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 1.3568, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 1.0658, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.4897, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 1.0329, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 0.6928, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 1.6514, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 0.8167, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 0.8434, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 1.0276, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 1.2041, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 1.0249, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 0.7867, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 1.3010, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 1.3497, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 1.2086, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 1.6826, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 1.2630, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 0.7426, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 1.0359, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 1.3493, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 1.2029, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 1.3717, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 1.2892, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 0.9808, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 0.7263, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 1.1389, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 0.8439, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 0.9166, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 1.2275, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 0.9858, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 1.3161, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 1.3378, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 1.5027, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 1.6166, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 1.4200, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 1.1784, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 0.8669, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 1.3641, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 0.8625, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 1.4343, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 1.2896, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 1.1136, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 1.1687, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 1.4125, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 1.1391, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 1.1008, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 1.4022, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 1.1644, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 1.1430, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 1.2803, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 1.2549, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 1.2526, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 1.4438, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 0.9802, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 0.5382, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 1.4411, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 1.1623, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 1.0110, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 0.9532, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 0.7035, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 0.9057, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 1.0644, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 1.3081, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 1.2748, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 1.0047, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 1.4807, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 1.3352, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 1.2965, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 0.9830, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 0.6483, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 1.0259, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 1.1671, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 1.1193, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 1.4404, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 1.2219, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 1.1477, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 1.1963, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 1.0979, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 1.2519, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 1.2451, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 0.9978, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_0:  {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, [2, 1, 0, 0, 3, 3, 3, 3, 1, 0, 2, 0, 0, 3, 1], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 36, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 48, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(48, 36, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(120, 64, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=169312, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 26, 22]           4,096\n",
            "       BatchNorm2d-2           [-1, 64, 26, 22]             128\n",
            "            Conv2d-3           [-1, 36, 24, 22]           6,948\n",
            "       BatchNorm2d-4           [-1, 36, 24, 22]              72\n",
            "              ReLU-5           [-1, 36, 24, 22]               0\n",
            "            Conv2d-6           [-1, 48, 24, 20]           5,232\n",
            "       BatchNorm2d-7           [-1, 48, 24, 20]              96\n",
            "              ReLU-8           [-1, 48, 24, 20]               0\n",
            "            Conv2d-9           [-1, 36, 22, 20]           5,220\n",
            "      BatchNorm2d-10           [-1, 36, 22, 20]              72\n",
            "             ReLU-11           [-1, 36, 22, 20]               0\n",
            "           Conv2d-12           [-1, 64, 20, 16]         268,864\n",
            "      BatchNorm2d-13           [-1, 64, 20, 16]             128\n",
            "             ReLU-14           [-1, 64, 20, 16]               0\n",
            "           Linear-15                    [-1, 7]       1,185,191\n",
            "================================================================\n",
            "Total params: 1,476,047\n",
            "Trainable params: 1,476,047\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.35\n",
            "Params size (MB): 5.63\n",
            "Estimated Total Size (MB): 7.99\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 23.9013, Validation Accuracy: 0.3958\n",
            "Epoch 2/100, Loss: 43.2815, Validation Accuracy: 0.4955\n",
            "Epoch 3/100, Loss: 21.9866, Validation Accuracy: 0.6680\n",
            "Epoch 4/100, Loss: 18.4098, Validation Accuracy: 0.6082\n",
            "Epoch 5/100, Loss: 72.4248, Validation Accuracy: 0.5703\n",
            "Epoch 6/100, Loss: 51.6615, Validation Accuracy: 0.6570\n",
            "Epoch 7/100, Loss: 80.3536, Validation Accuracy: 0.6590\n",
            "Epoch 8/100, Loss: 428.8133, Validation Accuracy: 0.6152\n",
            "Epoch 9/100, Loss: 31.0861, Validation Accuracy: 0.6630\n",
            "Epoch 10/100, Loss: 14.0520, Validation Accuracy: 0.5882\n",
            "Epoch 11/100, Loss: 10.5717, Validation Accuracy: 0.4995\n",
            "Epoch 12/100, Loss: 62.1903, Validation Accuracy: 0.6720\n",
            "Epoch 13/100, Loss: 18.4665, Validation Accuracy: 0.6451\n",
            "Epoch 14/100, Loss: 26.0653, Validation Accuracy: 0.5304\n",
            "Epoch 15/100, Loss: 36.0688, Validation Accuracy: 0.6520\n",
            "Epoch 16/100, Loss: 35.3010, Validation Accuracy: 0.6042\n",
            "Epoch 17/100, Loss: 37.7375, Validation Accuracy: 0.5972\n",
            "Epoch 18/100, Loss: 82.9786, Validation Accuracy: 0.6471\n",
            "Epoch 19/100, Loss: 13.7896, Validation Accuracy: 0.5274\n",
            "Epoch 20/100, Loss: 37.6116, Validation Accuracy: 0.4736\n",
            "Epoch 21/100, Loss: 10.1262, Validation Accuracy: 0.5145\n",
            "Epoch 22/100, Loss: 45.6868, Validation Accuracy: 0.7059\n",
            "Epoch 23/100, Loss: 15.4123, Validation Accuracy: 0.6371\n",
            "Epoch 24/100, Loss: 82.8640, Validation Accuracy: 0.6660\n",
            "Epoch 25/100, Loss: 54.3440, Validation Accuracy: 0.5394\n",
            "Epoch 26/100, Loss: 73.1922, Validation Accuracy: 0.5085\n",
            "Epoch 27/100, Loss: 60.2431, Validation Accuracy: 0.6839\n",
            "Epoch 28/100, Loss: 43.3323, Validation Accuracy: 0.6321\n",
            "Epoch 29/100, Loss: 47.8293, Validation Accuracy: 0.5803\n",
            "Epoch 30/100, Loss: 58.1587, Validation Accuracy: 0.4158\n",
            "Epoch 31/100, Loss: 148.5121, Validation Accuracy: 0.6241\n",
            "Epoch 32/100, Loss: 25.9336, Validation Accuracy: 0.6152\n",
            "Epoch 33/100, Loss: 26.4624, Validation Accuracy: 0.5743\n",
            "Epoch 34/100, Loss: 31.9563, Validation Accuracy: 0.5952\n",
            "Epoch 35/100, Loss: 23.0908, Validation Accuracy: 0.6092\n",
            "Epoch 36/100, Loss: 21.2767, Validation Accuracy: 0.5703\n",
            "Epoch 37/100, Loss: 5.4112, Validation Accuracy: 0.5653\n",
            "Epoch 38/100, Loss: 12.8286, Validation Accuracy: 0.5464\n",
            "Epoch 39/100, Loss: 26.3648, Validation Accuracy: 0.6092\n",
            "Epoch 40/100, Loss: 32.8782, Validation Accuracy: 0.4835\n",
            "Epoch 41/100, Loss: 32.7476, Validation Accuracy: 0.3898\n",
            "Epoch 42/100, Loss: 39.3250, Validation Accuracy: 0.6142\n",
            "Epoch 43/100, Loss: 21.5734, Validation Accuracy: 0.6391\n",
            "Epoch 44/100, Loss: 42.0688, Validation Accuracy: 0.6152\n",
            "Epoch 45/100, Loss: 152.9180, Validation Accuracy: 0.6820\n",
            "Epoch 46/100, Loss: 38.2475, Validation Accuracy: 0.6341\n",
            "Epoch 47/100, Loss: 44.6657, Validation Accuracy: 0.4367\n",
            "Epoch 48/100, Loss: 25.2210, Validation Accuracy: 0.6550\n",
            "Epoch 49/100, Loss: 30.6527, Validation Accuracy: 0.6171\n",
            "Epoch 50/100, Loss: 22.1747, Validation Accuracy: 0.6730\n",
            "Epoch 51/100, Loss: 52.4748, Validation Accuracy: 0.6301\n",
            "Epoch 52/100, Loss: 58.9511, Validation Accuracy: 0.6411\n",
            "Epoch 53/100, Loss: 40.9659, Validation Accuracy: 0.5194\n",
            "Epoch 54/100, Loss: 74.0332, Validation Accuracy: 0.5723\n",
            "Epoch 55/100, Loss: 25.7915, Validation Accuracy: 0.6152\n",
            "Epoch 56/100, Loss: 39.0667, Validation Accuracy: 0.3450\n",
            "Epoch 57/100, Loss: 31.1832, Validation Accuracy: 0.6650\n",
            "Epoch 58/100, Loss: 13.0523, Validation Accuracy: 0.5364\n",
            "Epoch 59/100, Loss: 42.2244, Validation Accuracy: 0.6879\n",
            "Epoch 60/100, Loss: 120.4277, Validation Accuracy: 0.5793\n",
            "Epoch 61/100, Loss: 112.5593, Validation Accuracy: 0.6510\n",
            "Epoch 62/100, Loss: 141.3915, Validation Accuracy: 0.6740\n",
            "Epoch 63/100, Loss: 22.2539, Validation Accuracy: 0.4736\n",
            "Epoch 64/100, Loss: 23.4938, Validation Accuracy: 0.5384\n",
            "Epoch 65/100, Loss: 65.2406, Validation Accuracy: 0.6072\n",
            "Epoch 66/100, Loss: 41.6298, Validation Accuracy: 0.5912\n",
            "Epoch 67/100, Loss: 30.0253, Validation Accuracy: 0.6760\n",
            "Epoch 68/100, Loss: 68.4553, Validation Accuracy: 0.4965\n",
            "Epoch 69/100, Loss: 25.3833, Validation Accuracy: 0.5813\n",
            "Epoch 70/100, Loss: 40.6186, Validation Accuracy: 0.3470\n",
            "Epoch 71/100, Loss: 52.8261, Validation Accuracy: 0.5813\n",
            "Epoch 72/100, Loss: 37.0401, Validation Accuracy: 0.6849\n",
            "Epoch 73/100, Loss: 59.1342, Validation Accuracy: 0.6271\n",
            "Epoch 74/100, Loss: 66.1021, Validation Accuracy: 0.4646\n",
            "Epoch 75/100, Loss: 45.9915, Validation Accuracy: 0.6680\n",
            "Epoch 76/100, Loss: 9.2974, Validation Accuracy: 0.5384\n",
            "Epoch 77/100, Loss: 87.4330, Validation Accuracy: 0.6560\n",
            "Epoch 78/100, Loss: 55.8934, Validation Accuracy: 0.5494\n",
            "Epoch 79/100, Loss: 32.9926, Validation Accuracy: 0.6271\n",
            "Epoch 80/100, Loss: 17.2521, Validation Accuracy: 0.6600\n",
            "Epoch 81/100, Loss: 114.8905, Validation Accuracy: 0.6431\n",
            "Epoch 82/100, Loss: 33.0552, Validation Accuracy: 0.6700\n",
            "Epoch 83/100, Loss: 62.4773, Validation Accuracy: 0.6510\n",
            "Epoch 84/100, Loss: 76.1030, Validation Accuracy: 0.6032\n",
            "Epoch 85/100, Loss: 14.5834, Validation Accuracy: 0.6550\n",
            "Epoch 86/100, Loss: 109.3903, Validation Accuracy: 0.6042\n",
            "Epoch 87/100, Loss: 30.6184, Validation Accuracy: 0.5862\n",
            "Epoch 88/100, Loss: 27.0342, Validation Accuracy: 0.5075\n",
            "Epoch 89/100, Loss: 19.4744, Validation Accuracy: 0.5304\n",
            "Epoch 90/100, Loss: 32.5255, Validation Accuracy: 0.5105\n",
            "Epoch 91/100, Loss: 93.6039, Validation Accuracy: 0.6570\n",
            "Epoch 92/100, Loss: 23.5138, Validation Accuracy: 0.6291\n",
            "Epoch 93/100, Loss: 24.6816, Validation Accuracy: 0.6680\n",
            "Epoch 94/100, Loss: 95.9902, Validation Accuracy: 0.4207\n",
            "Epoch 95/100, Loss: 32.9594, Validation Accuracy: 0.6750\n",
            "Epoch 96/100, Loss: 106.9998, Validation Accuracy: 0.6112\n",
            "Epoch 97/100, Loss: 98.1051, Validation Accuracy: 0.6451\n",
            "Epoch 98/100, Loss: 46.0827, Validation Accuracy: 0.6680\n",
            "Epoch 99/100, Loss: 101.6056, Validation Accuracy: 0.6810\n",
            "Epoch 100/100, Loss: 84.2552, Validation Accuracy: 0.6261\n",
            "Epoch 101/100, Loss: 31.5491, Validation Accuracy: 0.5115\n",
            "Epoch 102/100, Loss: 69.2583, Validation Accuracy: 0.6162\n",
            "Epoch 103/100, Loss: 35.3887, Validation Accuracy: 0.6780\n",
            "Epoch 104/100, Loss: 52.6228, Validation Accuracy: 0.5294\n",
            "Epoch 105/100, Loss: 79.9217, Validation Accuracy: 0.6650\n",
            "Epoch 106/100, Loss: 77.4087, Validation Accuracy: 0.6221\n",
            "Epoch 107/100, Loss: 23.2342, Validation Accuracy: 0.4726\n",
            "Epoch 108/100, Loss: 45.8811, Validation Accuracy: 0.6481\n",
            "Epoch 109/100, Loss: 1.0987, Validation Accuracy: 0.6371\n",
            "Epoch 110/100, Loss: 15.0047, Validation Accuracy: 0.6939\n",
            "Epoch 111/100, Loss: 31.4377, Validation Accuracy: 0.6530\n",
            "Epoch 112/100, Loss: 124.9738, Validation Accuracy: 0.6820\n",
            "Epoch 113/100, Loss: 126.8837, Validation Accuracy: 0.6012\n",
            "Epoch 114/100, Loss: 79.5357, Validation Accuracy: 0.6171\n",
            "Epoch 115/100, Loss: 78.3730, Validation Accuracy: 0.5494\n",
            "Epoch 116/100, Loss: 27.6407, Validation Accuracy: 0.6481\n",
            "Epoch 117/100, Loss: 56.1382, Validation Accuracy: 0.5703\n",
            "Epoch 118/100, Loss: 26.5322, Validation Accuracy: 0.4995\n",
            "Epoch 119/100, Loss: 63.4262, Validation Accuracy: 0.6122\n",
            "Epoch 120/100, Loss: 35.8000, Validation Accuracy: 0.6620\n",
            "Epoch 121/100, Loss: 22.6547, Validation Accuracy: 0.6600\n",
            "Epoch 122/100, Loss: 28.8390, Validation Accuracy: 0.5972\n",
            "Epoch 123/100, Loss: 125.8622, Validation Accuracy: 0.5882\n",
            "Epoch 124/100, Loss: 28.6619, Validation Accuracy: 0.6491\n",
            "Epoch 125/100, Loss: 32.8833, Validation Accuracy: 0.6082\n",
            "Epoch 126/100, Loss: 54.9681, Validation Accuracy: 0.5623\n",
            "Epoch 127/100, Loss: 61.9935, Validation Accuracy: 0.6381\n",
            "Epoch 128/100, Loss: 50.4899, Validation Accuracy: 0.6271\n",
            "Epoch 129/100, Loss: 50.4612, Validation Accuracy: 0.6291\n",
            "Epoch 130/100, Loss: 82.4552, Validation Accuracy: 0.6929\n",
            "Epoch 131/100, Loss: 61.7861, Validation Accuracy: 0.5703\n",
            "Epoch 132/100, Loss: 105.0179, Validation Accuracy: 0.3370\n",
            "Epoch 133/100, Loss: 47.6846, Validation Accuracy: 0.5464\n",
            "Epoch 134/100, Loss: 39.7893, Validation Accuracy: 0.5852\n",
            "Epoch 135/100, Loss: 46.4687, Validation Accuracy: 0.6241\n",
            "Epoch 136/100, Loss: 63.0318, Validation Accuracy: 0.6142\n",
            "Epoch 137/100, Loss: 222.6917, Validation Accuracy: 0.6650\n",
            "Epoch 138/100, Loss: 56.3304, Validation Accuracy: 0.6451\n",
            "Epoch 139/100, Loss: 107.8887, Validation Accuracy: 0.6610\n",
            "Epoch 140/100, Loss: 42.2006, Validation Accuracy: 0.6012\n",
            "Epoch 141/100, Loss: 54.9815, Validation Accuracy: 0.5813\n",
            "Epoch 142/100, Loss: 28.6300, Validation Accuracy: 0.6441\n",
            "Epoch 143/100, Loss: 27.4207, Validation Accuracy: 0.6251\n",
            "Epoch 144/100, Loss: 35.5337, Validation Accuracy: 0.6610\n",
            "Epoch 145/100, Loss: 45.8520, Validation Accuracy: 0.5085\n",
            "Epoch 146/100, Loss: 21.2619, Validation Accuracy: 0.5484\n",
            "Epoch 147/100, Loss: 155.4861, Validation Accuracy: 0.4816\n",
            "Epoch 148/100, Loss: 71.4546, Validation Accuracy: 0.6550\n",
            "Epoch 149/100, Loss: 48.8166, Validation Accuracy: 0.6540\n",
            "Epoch 150/100, Loss: 26.9521, Validation Accuracy: 0.6500\n",
            "Epoch 151/100, Loss: 58.2188, Validation Accuracy: 0.6481\n",
            "Epoch 152/100, Loss: 164.1013, Validation Accuracy: 0.6311\n",
            "Epoch 153/100, Loss: 29.5645, Validation Accuracy: 0.6351\n",
            "Epoch 154/100, Loss: 59.5280, Validation Accuracy: 0.6152\n",
            "Epoch 155/100, Loss: 9.7392, Validation Accuracy: 0.5872\n",
            "Epoch 156/100, Loss: 75.7800, Validation Accuracy: 0.3948\n",
            "Epoch 157/100, Loss: 103.6550, Validation Accuracy: 0.5095\n",
            "Epoch 158/100, Loss: 51.6162, Validation Accuracy: 0.6520\n",
            "Epoch 159/100, Loss: 67.0007, Validation Accuracy: 0.6231\n",
            "Epoch 160/100, Loss: 28.8502, Validation Accuracy: 0.6670\n",
            "Epoch 161/100, Loss: 75.1492, Validation Accuracy: 0.6481\n",
            "Epoch 162/100, Loss: 33.8717, Validation Accuracy: 0.6550\n",
            "Epoch 163/100, Loss: 21.2582, Validation Accuracy: 0.5474\n",
            "Epoch 164/100, Loss: 55.6405, Validation Accuracy: 0.6062\n",
            "Epoch 165/100, Loss: 47.8933, Validation Accuracy: 0.5982\n",
            "Epoch 166/100, Loss: 53.8727, Validation Accuracy: 0.5673\n",
            "Epoch 167/100, Loss: 60.4318, Validation Accuracy: 0.6590\n",
            "Epoch 168/100, Loss: 16.8987, Validation Accuracy: 0.4616\n",
            "Epoch 169/100, Loss: 53.3633, Validation Accuracy: 0.6839\n",
            "Epoch 170/100, Loss: 65.3140, Validation Accuracy: 0.6181\n",
            "Epoch 171/100, Loss: 61.7515, Validation Accuracy: 0.6062\n",
            "Epoch 172/100, Loss: 77.1077, Validation Accuracy: 0.6859\n",
            "Epoch 173/100, Loss: 32.5503, Validation Accuracy: 0.6640\n",
            "Epoch 174/100, Loss: 82.6157, Validation Accuracy: 0.6461\n",
            "Epoch 175/100, Loss: 65.7282, Validation Accuracy: 0.6102\n",
            "Epoch 176/100, Loss: 27.3195, Validation Accuracy: 0.6361\n",
            "Epoch 177/100, Loss: 48.3515, Validation Accuracy: 0.5703\n",
            "Epoch 178/100, Loss: 220.3751, Validation Accuracy: 0.6221\n",
            "Epoch 179/100, Loss: 132.9125, Validation Accuracy: 0.5942\n",
            "Epoch 180/100, Loss: 29.6533, Validation Accuracy: 0.6381\n",
            "Epoch 181/100, Loss: 67.3801, Validation Accuracy: 0.6231\n",
            "Epoch 182/100, Loss: 82.0579, Validation Accuracy: 0.6421\n",
            "Epoch 183/100, Loss: 10.1423, Validation Accuracy: 0.5902\n",
            "Epoch 184/100, Loss: 49.6997, Validation Accuracy: 0.5264\n",
            "Epoch 185/100, Loss: 20.4724, Validation Accuracy: 0.6560\n",
            "Epoch 186/100, Loss: 2.3369, Validation Accuracy: 0.6291\n",
            "Epoch 187/100, Loss: 58.0692, Validation Accuracy: 0.5254\n",
            "Epoch 188/100, Loss: 48.1850, Validation Accuracy: 0.4387\n",
            "Epoch 189/100, Loss: 50.7338, Validation Accuracy: 0.5454\n",
            "Epoch 190/100, Loss: 62.2341, Validation Accuracy: 0.5723\n",
            "Epoch 191/100, Loss: 61.5296, Validation Accuracy: 0.6770\n",
            "Epoch 192/100, Loss: 29.6051, Validation Accuracy: 0.6251\n",
            "Epoch 193/100, Loss: 197.0335, Validation Accuracy: 0.6381\n",
            "Epoch 194/100, Loss: 45.5248, Validation Accuracy: 0.5743\n",
            "Epoch 195/100, Loss: 40.9227, Validation Accuracy: 0.6251\n",
            "Epoch 196/100, Loss: 52.7717, Validation Accuracy: 0.5085\n",
            "Epoch 197/100, Loss: 73.4967, Validation Accuracy: 0.6181\n",
            "Epoch 198/100, Loss: 12.1255, Validation Accuracy: 0.6092\n",
            "Epoch 199/100, Loss: 98.1341, Validation Accuracy: 0.6540\n",
            "Epoch 200/100, Loss: 65.9548, Validation Accuracy: 0.6261\n",
            "Reward for Child Model: 0.2797748805989118\n",
            "Child_1:  {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, [1, 3, 3, 1, 0, 1, 0, 1, 2, 1, 0, 1, 2, 3, 3], 0.2797748805989118\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 24, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(88, 48, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(112, 64, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(240, 24, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=313664, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 26, 26]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 26, 26]             128\n",
            "            Conv2d-3           [-1, 24, 26, 22]           7,704\n",
            "       BatchNorm2d-4           [-1, 24, 26, 22]              48\n",
            "              ReLU-5           [-1, 24, 26, 22]               0\n",
            "            Conv2d-6           [-1, 48, 20, 20]         207,024\n",
            "       BatchNorm2d-7           [-1, 48, 20, 20]              96\n",
            "              ReLU-8           [-1, 48, 20, 20]               0\n",
            "            Conv2d-9           [-1, 64, 20, 24]         150,592\n",
            "      BatchNorm2d-10           [-1, 64, 20, 24]             128\n",
            "             ReLU-11           [-1, 64, 20, 24]               0\n",
            "           Conv2d-12           [-1, 24, 24, 26]          17,304\n",
            "      BatchNorm2d-13           [-1, 24, 24, 26]              48\n",
            "             ReLU-14           [-1, 24, 24, 26]               0\n",
            "           Linear-15                    [-1, 7]       2,195,655\n",
            "================================================================\n",
            "Total params: 2,580,519\n",
            "Trainable params: 2,580,519\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.46\n",
            "Params size (MB): 9.84\n",
            "Estimated Total Size (MB): 12.31\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 156.5505, Validation Accuracy: 0.4676\n",
            "Epoch 2/100, Loss: 66.9059, Validation Accuracy: 0.6550\n",
            "Epoch 3/100, Loss: 47.2934, Validation Accuracy: 0.6411\n",
            "Epoch 4/100, Loss: 364.0802, Validation Accuracy: 0.5174\n",
            "Epoch 5/100, Loss: 63.9411, Validation Accuracy: 0.6720\n",
            "Epoch 6/100, Loss: 58.5157, Validation Accuracy: 0.6241\n",
            "Epoch 7/100, Loss: 68.6982, Validation Accuracy: 0.6211\n",
            "Epoch 8/100, Loss: 69.9198, Validation Accuracy: 0.6331\n",
            "Epoch 9/100, Loss: 121.9221, Validation Accuracy: 0.6790\n",
            "Epoch 10/100, Loss: 304.5974, Validation Accuracy: 0.6750\n",
            "Epoch 11/100, Loss: 549.4720, Validation Accuracy: 0.6092\n",
            "Epoch 12/100, Loss: 134.4398, Validation Accuracy: 0.6082\n",
            "Epoch 13/100, Loss: 133.3751, Validation Accuracy: 0.6351\n",
            "Epoch 14/100, Loss: 212.1454, Validation Accuracy: 0.6022\n",
            "Epoch 15/100, Loss: 69.5854, Validation Accuracy: 0.4217\n",
            "Epoch 16/100, Loss: 418.4569, Validation Accuracy: 0.6261\n",
            "Epoch 17/100, Loss: 161.5824, Validation Accuracy: 0.6291\n",
            "Epoch 18/100, Loss: 473.2513, Validation Accuracy: 0.6291\n",
            "Epoch 19/100, Loss: 129.0155, Validation Accuracy: 0.6500\n",
            "Epoch 20/100, Loss: 117.6171, Validation Accuracy: 0.5194\n",
            "Epoch 21/100, Loss: 199.8195, Validation Accuracy: 0.2293\n",
            "Epoch 22/100, Loss: 350.3609, Validation Accuracy: 0.5115\n",
            "Epoch 23/100, Loss: 138.1557, Validation Accuracy: 0.6820\n",
            "Epoch 24/100, Loss: 141.7197, Validation Accuracy: 0.6670\n",
            "Epoch 25/100, Loss: 121.8888, Validation Accuracy: 0.6590\n",
            "Epoch 26/100, Loss: 34.6649, Validation Accuracy: 0.6800\n",
            "Epoch 27/100, Loss: 199.2967, Validation Accuracy: 0.6730\n",
            "Epoch 28/100, Loss: 267.8524, Validation Accuracy: 0.5005\n",
            "Epoch 29/100, Loss: 483.1521, Validation Accuracy: 0.5015\n",
            "Epoch 30/100, Loss: 343.4941, Validation Accuracy: 0.4995\n",
            "Epoch 31/100, Loss: 308.2908, Validation Accuracy: 0.6810\n",
            "Epoch 32/100, Loss: 85.8333, Validation Accuracy: 0.6321\n",
            "Epoch 33/100, Loss: 174.3573, Validation Accuracy: 0.6132\n",
            "Epoch 34/100, Loss: 258.5250, Validation Accuracy: 0.6421\n",
            "Epoch 35/100, Loss: 346.5035, Validation Accuracy: 0.5723\n",
            "Epoch 36/100, Loss: 112.3581, Validation Accuracy: 0.5902\n",
            "Epoch 37/100, Loss: 177.6373, Validation Accuracy: 0.6451\n",
            "Epoch 38/100, Loss: 184.3571, Validation Accuracy: 0.6720\n",
            "Epoch 39/100, Loss: 252.2320, Validation Accuracy: 0.6261\n",
            "Epoch 40/100, Loss: 171.7445, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 585.8267, Validation Accuracy: 0.6481\n",
            "Epoch 42/100, Loss: 491.1605, Validation Accuracy: 0.5214\n",
            "Epoch 43/100, Loss: 250.2405, Validation Accuracy: 0.6660\n",
            "Epoch 44/100, Loss: 321.8077, Validation Accuracy: 0.6740\n",
            "Epoch 45/100, Loss: 267.8588, Validation Accuracy: 0.5224\n",
            "Epoch 46/100, Loss: 252.3305, Validation Accuracy: 0.5962\n",
            "Epoch 47/100, Loss: 303.5930, Validation Accuracy: 0.5444\n",
            "Epoch 48/100, Loss: 112.5052, Validation Accuracy: 0.6530\n",
            "Epoch 49/100, Loss: 236.8615, Validation Accuracy: 0.5145\n",
            "Epoch 50/100, Loss: 249.5306, Validation Accuracy: 0.6500\n",
            "Epoch 51/100, Loss: 509.3918, Validation Accuracy: 0.6092\n",
            "Epoch 52/100, Loss: 253.6978, Validation Accuracy: 0.6301\n",
            "Epoch 53/100, Loss: 478.7175, Validation Accuracy: 0.6221\n",
            "Epoch 54/100, Loss: 315.3785, Validation Accuracy: 0.6670\n",
            "Epoch 55/100, Loss: 179.5259, Validation Accuracy: 0.6441\n",
            "Epoch 56/100, Loss: 315.1252, Validation Accuracy: 0.6700\n",
            "Epoch 57/100, Loss: 174.6606, Validation Accuracy: 0.6431\n",
            "Epoch 58/100, Loss: 197.1564, Validation Accuracy: 0.5952\n",
            "Epoch 59/100, Loss: 330.5034, Validation Accuracy: 0.6032\n",
            "Epoch 60/100, Loss: 435.4175, Validation Accuracy: 0.5872\n",
            "Epoch 61/100, Loss: 235.2327, Validation Accuracy: 0.6510\n",
            "Epoch 62/100, Loss: 523.7991, Validation Accuracy: 0.4497\n",
            "Epoch 63/100, Loss: 813.4905, Validation Accuracy: 0.6540\n",
            "Epoch 64/100, Loss: 362.2575, Validation Accuracy: 0.6580\n",
            "Epoch 65/100, Loss: 265.1873, Validation Accuracy: 0.5733\n",
            "Epoch 66/100, Loss: 371.5201, Validation Accuracy: 0.5663\n",
            "Epoch 67/100, Loss: 229.0198, Validation Accuracy: 0.6411\n",
            "Epoch 68/100, Loss: 138.6015, Validation Accuracy: 0.6152\n",
            "Epoch 69/100, Loss: 282.8150, Validation Accuracy: 0.6929\n",
            "Epoch 70/100, Loss: 80.7248, Validation Accuracy: 0.6361\n",
            "Epoch 71/100, Loss: 203.8873, Validation Accuracy: 0.6391\n",
            "Epoch 72/100, Loss: 625.9219, Validation Accuracy: 0.5922\n",
            "Epoch 73/100, Loss: 324.0951, Validation Accuracy: 0.6560\n",
            "Epoch 74/100, Loss: 224.4698, Validation Accuracy: 0.4885\n",
            "Epoch 75/100, Loss: 261.1866, Validation Accuracy: 0.6839\n",
            "Epoch 76/100, Loss: 103.2863, Validation Accuracy: 0.6231\n",
            "Epoch 77/100, Loss: 150.6569, Validation Accuracy: 0.5842\n",
            "Epoch 78/100, Loss: 437.7432, Validation Accuracy: 0.5523\n",
            "Epoch 79/100, Loss: 50.6644, Validation Accuracy: 0.2483\n",
            "Epoch 80/100, Loss: 299.9692, Validation Accuracy: 0.6491\n",
            "Epoch 81/100, Loss: 262.6963, Validation Accuracy: 0.5942\n",
            "Epoch 82/100, Loss: 111.3984, Validation Accuracy: 0.6481\n",
            "Epoch 83/100, Loss: 448.5205, Validation Accuracy: 0.6540\n",
            "Epoch 84/100, Loss: 349.4194, Validation Accuracy: 0.5593\n",
            "Epoch 85/100, Loss: 288.3247, Validation Accuracy: 0.6331\n",
            "Epoch 86/100, Loss: 110.8980, Validation Accuracy: 0.6620\n",
            "Epoch 87/100, Loss: 183.1544, Validation Accuracy: 0.5693\n",
            "Epoch 88/100, Loss: 244.0929, Validation Accuracy: 0.6500\n",
            "Epoch 89/100, Loss: 214.8864, Validation Accuracy: 0.5165\n",
            "Epoch 90/100, Loss: 358.0063, Validation Accuracy: 0.3739\n",
            "Epoch 91/100, Loss: 479.6222, Validation Accuracy: 0.5513\n",
            "Epoch 92/100, Loss: 209.6851, Validation Accuracy: 0.6291\n",
            "Epoch 93/100, Loss: 488.3959, Validation Accuracy: 0.6620\n",
            "Epoch 94/100, Loss: 235.7550, Validation Accuracy: 0.6710\n",
            "Epoch 95/100, Loss: 475.4741, Validation Accuracy: 0.5344\n",
            "Epoch 96/100, Loss: 266.2164, Validation Accuracy: 0.6351\n",
            "Epoch 97/100, Loss: 184.2578, Validation Accuracy: 0.6241\n",
            "Epoch 98/100, Loss: 168.2446, Validation Accuracy: 0.5583\n",
            "Epoch 99/100, Loss: 833.4163, Validation Accuracy: 0.6550\n",
            "Epoch 100/100, Loss: 257.9710, Validation Accuracy: 0.6271\n",
            "Epoch 101/100, Loss: 273.2435, Validation Accuracy: 0.4546\n",
            "Epoch 102/100, Loss: 339.4431, Validation Accuracy: 0.5972\n",
            "Epoch 103/100, Loss: 378.1404, Validation Accuracy: 0.6201\n",
            "Epoch 104/100, Loss: 223.0606, Validation Accuracy: 0.5045\n",
            "Epoch 105/100, Loss: 425.0900, Validation Accuracy: 0.6461\n",
            "Epoch 106/100, Loss: 357.5868, Validation Accuracy: 0.6321\n",
            "Epoch 107/100, Loss: 129.5625, Validation Accuracy: 0.5593\n",
            "Epoch 108/100, Loss: 220.1196, Validation Accuracy: 0.6072\n",
            "Epoch 109/100, Loss: 176.7550, Validation Accuracy: 0.6650\n",
            "Epoch 110/100, Loss: 255.5501, Validation Accuracy: 0.6590\n",
            "Epoch 111/100, Loss: 414.5642, Validation Accuracy: 0.5055\n",
            "Epoch 112/100, Loss: 692.0380, Validation Accuracy: 0.5474\n",
            "Epoch 113/100, Loss: 444.5168, Validation Accuracy: 0.4616\n",
            "Epoch 114/100, Loss: 290.4891, Validation Accuracy: 0.5992\n",
            "Epoch 115/100, Loss: 336.7020, Validation Accuracy: 0.6201\n",
            "Epoch 116/100, Loss: 161.3730, Validation Accuracy: 0.5922\n",
            "Epoch 117/100, Loss: 97.4101, Validation Accuracy: 0.6421\n",
            "Epoch 118/100, Loss: 577.5854, Validation Accuracy: 0.6301\n",
            "Epoch 119/100, Loss: 317.2501, Validation Accuracy: 0.5454\n",
            "Epoch 120/100, Loss: 118.6209, Validation Accuracy: 0.6361\n",
            "Epoch 121/100, Loss: 149.8651, Validation Accuracy: 0.6241\n",
            "Epoch 122/100, Loss: 44.7742, Validation Accuracy: 0.5833\n",
            "Epoch 123/100, Loss: 115.4018, Validation Accuracy: 0.5434\n",
            "Epoch 124/100, Loss: 303.8983, Validation Accuracy: 0.6600\n",
            "Epoch 125/100, Loss: 281.6295, Validation Accuracy: 0.6102\n",
            "Epoch 126/100, Loss: 474.0832, Validation Accuracy: 0.5763\n",
            "Epoch 127/100, Loss: 358.7566, Validation Accuracy: 0.5125\n",
            "Epoch 128/100, Loss: 176.6552, Validation Accuracy: 0.5434\n",
            "Epoch 129/100, Loss: 455.8766, Validation Accuracy: 0.6301\n",
            "Epoch 130/100, Loss: 398.0104, Validation Accuracy: 0.5573\n",
            "Epoch 131/100, Loss: 223.9199, Validation Accuracy: 0.5503\n",
            "Epoch 132/100, Loss: 181.0931, Validation Accuracy: 0.6201\n",
            "Epoch 133/100, Loss: 69.1008, Validation Accuracy: 0.6341\n",
            "Epoch 134/100, Loss: 337.5364, Validation Accuracy: 0.4526\n",
            "Epoch 135/100, Loss: 160.7112, Validation Accuracy: 0.5623\n",
            "Epoch 136/100, Loss: 207.6391, Validation Accuracy: 0.4716\n",
            "Epoch 137/100, Loss: 241.2709, Validation Accuracy: 0.5992\n",
            "Epoch 138/100, Loss: 283.2422, Validation Accuracy: 0.5533\n",
            "Epoch 139/100, Loss: 327.7643, Validation Accuracy: 0.5424\n",
            "Epoch 140/100, Loss: 360.1198, Validation Accuracy: 0.6251\n",
            "Epoch 141/100, Loss: 555.8647, Validation Accuracy: 0.4008\n",
            "Epoch 142/100, Loss: 132.3255, Validation Accuracy: 0.4536\n",
            "Epoch 143/100, Loss: 157.9270, Validation Accuracy: 0.6162\n",
            "Epoch 144/100, Loss: 237.4293, Validation Accuracy: 0.5823\n",
            "Epoch 145/100, Loss: 515.7225, Validation Accuracy: 0.6331\n",
            "Epoch 146/100, Loss: 165.4690, Validation Accuracy: 0.6092\n",
            "Epoch 147/100, Loss: 432.9623, Validation Accuracy: 0.6042\n",
            "Epoch 148/100, Loss: 156.4651, Validation Accuracy: 0.5543\n",
            "Epoch 149/100, Loss: 283.8380, Validation Accuracy: 0.6391\n",
            "Epoch 150/100, Loss: 328.2849, Validation Accuracy: 0.5852\n",
            "Epoch 151/100, Loss: 140.3252, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 897.0417, Validation Accuracy: 0.6620\n",
            "Epoch 153/100, Loss: 299.1878, Validation Accuracy: 0.6072\n",
            "Epoch 154/100, Loss: 169.7250, Validation Accuracy: 0.5035\n",
            "Epoch 155/100, Loss: 310.0302, Validation Accuracy: 0.5484\n",
            "Epoch 156/100, Loss: 324.5228, Validation Accuracy: 0.6620\n",
            "Epoch 157/100, Loss: 317.4770, Validation Accuracy: 0.6421\n",
            "Epoch 158/100, Loss: 183.0869, Validation Accuracy: 0.5972\n",
            "Epoch 159/100, Loss: 244.2574, Validation Accuracy: 0.5942\n",
            "Epoch 160/100, Loss: 567.2662, Validation Accuracy: 0.6411\n",
            "Epoch 161/100, Loss: 157.7867, Validation Accuracy: 0.6032\n",
            "Epoch 162/100, Loss: 76.6501, Validation Accuracy: 0.6181\n",
            "Epoch 163/100, Loss: 593.2633, Validation Accuracy: 0.5633\n",
            "Epoch 164/100, Loss: 326.0328, Validation Accuracy: 0.5474\n",
            "Epoch 165/100, Loss: 302.4607, Validation Accuracy: 0.5693\n",
            "Epoch 166/100, Loss: 186.0721, Validation Accuracy: 0.6181\n",
            "Epoch 167/100, Loss: 250.7164, Validation Accuracy: 0.5962\n",
            "Epoch 168/100, Loss: 384.3047, Validation Accuracy: 0.5184\n",
            "Epoch 169/100, Loss: 362.4808, Validation Accuracy: 0.6700\n",
            "Epoch 170/100, Loss: 273.1735, Validation Accuracy: 0.5693\n",
            "Epoch 171/100, Loss: 62.8672, Validation Accuracy: 0.5902\n",
            "Epoch 172/100, Loss: 396.2291, Validation Accuracy: 0.6251\n",
            "Epoch 173/100, Loss: 209.3392, Validation Accuracy: 0.4845\n",
            "Epoch 174/100, Loss: 327.0338, Validation Accuracy: 0.5444\n",
            "Epoch 175/100, Loss: 597.2427, Validation Accuracy: 0.5663\n",
            "Epoch 176/100, Loss: 198.2046, Validation Accuracy: 0.5613\n",
            "Epoch 177/100, Loss: 97.2992, Validation Accuracy: 0.6221\n",
            "Epoch 178/100, Loss: 92.1018, Validation Accuracy: 0.6550\n",
            "Epoch 179/100, Loss: 154.5492, Validation Accuracy: 0.4875\n",
            "Epoch 180/100, Loss: 263.3454, Validation Accuracy: 0.5314\n",
            "Epoch 181/100, Loss: 308.8658, Validation Accuracy: 0.6520\n",
            "Epoch 182/100, Loss: 367.3465, Validation Accuracy: 0.6291\n",
            "Epoch 183/100, Loss: 189.0502, Validation Accuracy: 0.5902\n",
            "Epoch 184/100, Loss: 576.9920, Validation Accuracy: 0.6042\n",
            "Epoch 185/100, Loss: 321.5393, Validation Accuracy: 0.5444\n",
            "Epoch 186/100, Loss: 622.6360, Validation Accuracy: 0.6231\n",
            "Epoch 187/100, Loss: 175.3834, Validation Accuracy: 0.6092\n",
            "Epoch 188/100, Loss: 273.9422, Validation Accuracy: 0.6072\n",
            "Epoch 189/100, Loss: 209.0801, Validation Accuracy: 0.6331\n",
            "Epoch 190/100, Loss: 266.1426, Validation Accuracy: 0.4666\n",
            "Epoch 191/100, Loss: 387.7800, Validation Accuracy: 0.5833\n",
            "Epoch 192/100, Loss: 82.4933, Validation Accuracy: 0.5743\n",
            "Epoch 193/100, Loss: 276.7755, Validation Accuracy: 0.5763\n",
            "Epoch 194/100, Loss: 755.6002, Validation Accuracy: 0.6810\n",
            "Epoch 195/100, Loss: 182.0943, Validation Accuracy: 0.5823\n",
            "Epoch 196/100, Loss: 545.4803, Validation Accuracy: 0.6650\n",
            "Epoch 197/100, Loss: 403.0047, Validation Accuracy: 0.6012\n",
            "Epoch 198/100, Loss: 122.0316, Validation Accuracy: 0.6351\n",
            "Epoch 199/100, Loss: 152.5475, Validation Accuracy: 0.6132\n",
            "Epoch 200/100, Loss: 44.3546, Validation Accuracy: 0.6431\n",
            "Reward for Child Model: 0.294086238583974\n",
            "Child_2:  {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, [1, 1, 3, 0, 2, 0, 3, 3, 2, 3, 1, 3, 1, 0, 0], 0.294086238583974\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 24, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 24, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(48, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(72, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=91520, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 22, 26]           4,096\n",
            "       BatchNorm2d-2           [-1, 64, 22, 26]             128\n",
            "            Conv2d-3           [-1, 24, 16, 20]          75,288\n",
            "       BatchNorm2d-4           [-1, 24, 16, 20]              48\n",
            "              ReLU-5           [-1, 24, 16, 20]               0\n",
            "            Conv2d-6           [-1, 24, 10, 18]          12,120\n",
            "       BatchNorm2d-7           [-1, 24, 10, 18]              48\n",
            "              ReLU-8           [-1, 24, 10, 18]               0\n",
            "            Conv2d-9           [-1, 48, 10, 18]          48,432\n",
            "      BatchNorm2d-10           [-1, 48, 10, 18]              96\n",
            "             ReLU-11           [-1, 48, 10, 18]               0\n",
            "           Conv2d-12           [-1, 48, 10, 18]          72,624\n",
            "      BatchNorm2d-13           [-1, 48, 10, 18]              96\n",
            "             ReLU-14           [-1, 48, 10, 18]               0\n",
            "           Linear-15                    [-1, 7]         640,647\n",
            "================================================================\n",
            "Total params: 853,623\n",
            "Trainable params: 853,623\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.23\n",
            "Params size (MB): 3.26\n",
            "Estimated Total Size (MB): 4.49\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 16.6306, Validation Accuracy: 0.4826\n",
            "Epoch 2/100, Loss: 40.2173, Validation Accuracy: 0.6520\n",
            "Epoch 3/100, Loss: 18.9788, Validation Accuracy: 0.4756\n",
            "Epoch 4/100, Loss: 32.7061, Validation Accuracy: 0.6341\n",
            "Epoch 5/100, Loss: 181.8716, Validation Accuracy: 0.5673\n",
            "Epoch 6/100, Loss: 352.8349, Validation Accuracy: 0.5623\n",
            "Epoch 7/100, Loss: 35.8269, Validation Accuracy: 0.6530\n",
            "Epoch 8/100, Loss: 19.3385, Validation Accuracy: 0.4536\n",
            "Epoch 9/100, Loss: 46.5150, Validation Accuracy: 0.5484\n",
            "Epoch 10/100, Loss: 46.6024, Validation Accuracy: 0.5922\n",
            "Epoch 11/100, Loss: 105.5325, Validation Accuracy: 0.6540\n",
            "Epoch 12/100, Loss: 30.0833, Validation Accuracy: 0.6431\n",
            "Epoch 13/100, Loss: 47.0583, Validation Accuracy: 0.5284\n",
            "Epoch 14/100, Loss: 65.0760, Validation Accuracy: 0.6590\n",
            "Epoch 15/100, Loss: 109.4909, Validation Accuracy: 0.4237\n",
            "Epoch 16/100, Loss: 92.8667, Validation Accuracy: 0.5962\n",
            "Epoch 17/100, Loss: 16.7100, Validation Accuracy: 0.5882\n",
            "Epoch 18/100, Loss: 87.5556, Validation Accuracy: 0.5155\n",
            "Epoch 19/100, Loss: 23.6548, Validation Accuracy: 0.6760\n",
            "Epoch 20/100, Loss: 48.2897, Validation Accuracy: 0.6560\n",
            "Epoch 21/100, Loss: 86.5354, Validation Accuracy: 0.6371\n",
            "Epoch 22/100, Loss: 68.6652, Validation Accuracy: 0.4716\n",
            "Epoch 23/100, Loss: 84.5521, Validation Accuracy: 0.6969\n",
            "Epoch 24/100, Loss: 72.8979, Validation Accuracy: 0.4975\n",
            "Epoch 25/100, Loss: 48.2581, Validation Accuracy: 0.6510\n",
            "Epoch 26/100, Loss: 33.2896, Validation Accuracy: 0.6371\n",
            "Epoch 27/100, Loss: 66.8350, Validation Accuracy: 0.5862\n",
            "Epoch 28/100, Loss: 76.7132, Validation Accuracy: 0.5174\n",
            "Epoch 29/100, Loss: 33.6929, Validation Accuracy: 0.6780\n",
            "Epoch 30/100, Loss: 50.8126, Validation Accuracy: 0.6560\n",
            "Epoch 31/100, Loss: 57.6033, Validation Accuracy: 0.6690\n",
            "Epoch 32/100, Loss: 34.5363, Validation Accuracy: 0.5723\n",
            "Epoch 33/100, Loss: 126.0394, Validation Accuracy: 0.6530\n",
            "Epoch 34/100, Loss: 27.1376, Validation Accuracy: 0.5454\n",
            "Epoch 35/100, Loss: 67.6833, Validation Accuracy: 0.6520\n",
            "Epoch 36/100, Loss: 79.6438, Validation Accuracy: 0.6660\n",
            "Epoch 37/100, Loss: 10.0531, Validation Accuracy: 0.6730\n",
            "Epoch 38/100, Loss: 21.6534, Validation Accuracy: 0.5882\n",
            "Epoch 39/100, Loss: 21.9284, Validation Accuracy: 0.5823\n",
            "Epoch 40/100, Loss: 60.1999, Validation Accuracy: 0.6620\n",
            "Epoch 41/100, Loss: 68.6331, Validation Accuracy: 0.6750\n",
            "Epoch 42/100, Loss: 36.4875, Validation Accuracy: 0.4546\n",
            "Epoch 43/100, Loss: 81.4935, Validation Accuracy: 0.6301\n",
            "Epoch 44/100, Loss: 29.8906, Validation Accuracy: 0.6800\n",
            "Epoch 45/100, Loss: 38.7420, Validation Accuracy: 0.5982\n",
            "Epoch 46/100, Loss: 35.4378, Validation Accuracy: 0.5005\n",
            "Epoch 47/100, Loss: 96.6767, Validation Accuracy: 0.5244\n",
            "Epoch 48/100, Loss: 42.6056, Validation Accuracy: 0.5613\n",
            "Epoch 49/100, Loss: 192.2983, Validation Accuracy: 0.6730\n",
            "Epoch 50/100, Loss: 107.1033, Validation Accuracy: 0.6271\n",
            "Epoch 51/100, Loss: 67.5303, Validation Accuracy: 0.6600\n",
            "Epoch 52/100, Loss: 23.9348, Validation Accuracy: 0.6869\n",
            "Epoch 53/100, Loss: 43.2239, Validation Accuracy: 0.6132\n",
            "Epoch 54/100, Loss: 37.3277, Validation Accuracy: 0.6640\n",
            "Epoch 55/100, Loss: 107.9522, Validation Accuracy: 0.6451\n",
            "Epoch 56/100, Loss: 45.9826, Validation Accuracy: 0.6580\n",
            "Epoch 57/100, Loss: 56.1604, Validation Accuracy: 0.6072\n",
            "Epoch 58/100, Loss: 61.4827, Validation Accuracy: 0.6879\n",
            "Epoch 59/100, Loss: 23.2828, Validation Accuracy: 0.6012\n",
            "Epoch 60/100, Loss: 42.6541, Validation Accuracy: 0.6570\n",
            "Epoch 61/100, Loss: 42.1721, Validation Accuracy: 0.6650\n",
            "Epoch 62/100, Loss: 53.6733, Validation Accuracy: 0.6112\n",
            "Epoch 63/100, Loss: 29.0663, Validation Accuracy: 0.6261\n",
            "Epoch 64/100, Loss: 91.7503, Validation Accuracy: 0.6411\n",
            "Epoch 65/100, Loss: 51.2851, Validation Accuracy: 0.6640\n",
            "Epoch 66/100, Loss: 46.4020, Validation Accuracy: 0.6122\n",
            "Epoch 67/100, Loss: 37.4727, Validation Accuracy: 0.5922\n",
            "Epoch 68/100, Loss: 24.7804, Validation Accuracy: 0.6660\n",
            "Epoch 69/100, Loss: 16.4771, Validation Accuracy: 0.6251\n",
            "Epoch 70/100, Loss: 32.3488, Validation Accuracy: 0.6510\n",
            "Epoch 71/100, Loss: 10.4062, Validation Accuracy: 0.6491\n",
            "Epoch 72/100, Loss: 127.2592, Validation Accuracy: 0.6540\n",
            "Epoch 73/100, Loss: 46.8685, Validation Accuracy: 0.5115\n",
            "Epoch 74/100, Loss: 67.6060, Validation Accuracy: 0.3579\n",
            "Epoch 75/100, Loss: 59.6624, Validation Accuracy: 0.6550\n",
            "Epoch 76/100, Loss: 21.8808, Validation Accuracy: 0.5503\n",
            "Epoch 77/100, Loss: 25.8270, Validation Accuracy: 0.6790\n",
            "Epoch 78/100, Loss: 70.6627, Validation Accuracy: 0.6092\n",
            "Epoch 79/100, Loss: 65.0299, Validation Accuracy: 0.4816\n",
            "Epoch 80/100, Loss: 28.9049, Validation Accuracy: 0.5075\n",
            "Epoch 81/100, Loss: 74.8671, Validation Accuracy: 0.6630\n",
            "Epoch 82/100, Loss: 41.9363, Validation Accuracy: 0.6301\n",
            "Epoch 83/100, Loss: 27.6781, Validation Accuracy: 0.6650\n",
            "Epoch 84/100, Loss: 19.5292, Validation Accuracy: 0.6620\n",
            "Epoch 85/100, Loss: 40.9307, Validation Accuracy: 0.5912\n",
            "Epoch 86/100, Loss: 58.5398, Validation Accuracy: 0.6590\n",
            "Epoch 87/100, Loss: 115.5654, Validation Accuracy: 0.6451\n",
            "Epoch 88/100, Loss: 53.7529, Validation Accuracy: 0.6700\n",
            "Epoch 89/100, Loss: 72.6997, Validation Accuracy: 0.6351\n",
            "Epoch 90/100, Loss: 73.2190, Validation Accuracy: 0.6481\n",
            "Epoch 91/100, Loss: 155.1302, Validation Accuracy: 0.6820\n",
            "Epoch 92/100, Loss: 47.6292, Validation Accuracy: 0.6381\n",
            "Epoch 93/100, Loss: 63.8505, Validation Accuracy: 0.5902\n",
            "Epoch 94/100, Loss: 17.3059, Validation Accuracy: 0.6700\n",
            "Epoch 95/100, Loss: 11.1809, Validation Accuracy: 0.6491\n",
            "Epoch 96/100, Loss: 25.7203, Validation Accuracy: 0.6760\n",
            "Epoch 97/100, Loss: 37.5593, Validation Accuracy: 0.6620\n",
            "Epoch 98/100, Loss: 40.0532, Validation Accuracy: 0.5753\n",
            "Epoch 99/100, Loss: 82.0066, Validation Accuracy: 0.6720\n",
            "Epoch 100/100, Loss: 89.9050, Validation Accuracy: 0.5743\n",
            "Epoch 101/100, Loss: 30.8161, Validation Accuracy: 0.5753\n",
            "Epoch 102/100, Loss: 77.2903, Validation Accuracy: 0.3998\n",
            "Epoch 103/100, Loss: 35.4542, Validation Accuracy: 0.5354\n",
            "Epoch 104/100, Loss: 48.8559, Validation Accuracy: 0.6899\n",
            "Epoch 105/100, Loss: 43.7436, Validation Accuracy: 0.6012\n",
            "Epoch 106/100, Loss: 34.3163, Validation Accuracy: 0.4696\n",
            "Epoch 107/100, Loss: 63.5749, Validation Accuracy: 0.6550\n",
            "Epoch 108/100, Loss: 12.3029, Validation Accuracy: 0.6361\n",
            "Epoch 109/100, Loss: 19.2708, Validation Accuracy: 0.6321\n",
            "Epoch 110/100, Loss: 77.3585, Validation Accuracy: 0.6381\n",
            "Epoch 111/100, Loss: 19.8726, Validation Accuracy: 0.6680\n",
            "Epoch 112/100, Loss: 46.6103, Validation Accuracy: 0.6132\n",
            "Epoch 113/100, Loss: 47.9823, Validation Accuracy: 0.6361\n",
            "Epoch 114/100, Loss: 87.8566, Validation Accuracy: 0.6321\n",
            "Epoch 115/100, Loss: 55.1563, Validation Accuracy: 0.5743\n",
            "Epoch 116/100, Loss: 40.5688, Validation Accuracy: 0.6391\n",
            "Epoch 117/100, Loss: 23.1862, Validation Accuracy: 0.5553\n",
            "Epoch 118/100, Loss: 57.6779, Validation Accuracy: 0.6640\n",
            "Epoch 119/100, Loss: 31.0821, Validation Accuracy: 0.5434\n",
            "Epoch 120/100, Loss: 29.8752, Validation Accuracy: 0.6251\n",
            "Epoch 121/100, Loss: 38.4128, Validation Accuracy: 0.6171\n",
            "Epoch 122/100, Loss: 17.6259, Validation Accuracy: 0.6580\n",
            "Epoch 123/100, Loss: 31.3378, Validation Accuracy: 0.6550\n",
            "Epoch 124/100, Loss: 58.1246, Validation Accuracy: 0.5494\n",
            "Epoch 125/100, Loss: 27.2987, Validation Accuracy: 0.6261\n",
            "Epoch 126/100, Loss: 15.7796, Validation Accuracy: 0.5244\n",
            "Epoch 127/100, Loss: 33.0799, Validation Accuracy: 0.6351\n",
            "Epoch 128/100, Loss: 74.1272, Validation Accuracy: 0.5174\n",
            "Epoch 129/100, Loss: 43.3492, Validation Accuracy: 0.5693\n",
            "Epoch 130/100, Loss: 23.7258, Validation Accuracy: 0.6211\n",
            "Epoch 131/100, Loss: 107.6438, Validation Accuracy: 0.6530\n",
            "Epoch 132/100, Loss: 31.5766, Validation Accuracy: 0.5264\n",
            "Epoch 133/100, Loss: 102.4473, Validation Accuracy: 0.6530\n",
            "Epoch 134/100, Loss: 62.6090, Validation Accuracy: 0.5583\n",
            "Epoch 135/100, Loss: 46.9752, Validation Accuracy: 0.6261\n",
            "Epoch 136/100, Loss: 50.8934, Validation Accuracy: 0.5035\n",
            "Epoch 137/100, Loss: 47.8084, Validation Accuracy: 0.4985\n",
            "Epoch 138/100, Loss: 50.0342, Validation Accuracy: 0.6830\n",
            "Epoch 139/100, Loss: 68.2812, Validation Accuracy: 0.6600\n",
            "Epoch 140/100, Loss: 57.8643, Validation Accuracy: 0.3819\n",
            "Epoch 141/100, Loss: 17.2716, Validation Accuracy: 0.6122\n",
            "Epoch 142/100, Loss: 8.2350, Validation Accuracy: 0.6859\n",
            "Epoch 143/100, Loss: 53.3145, Validation Accuracy: 0.5793\n",
            "Epoch 144/100, Loss: 40.5716, Validation Accuracy: 0.6660\n",
            "Epoch 145/100, Loss: 54.0306, Validation Accuracy: 0.5234\n",
            "Epoch 146/100, Loss: 69.2959, Validation Accuracy: 0.6261\n",
            "Epoch 147/100, Loss: 29.5169, Validation Accuracy: 0.6221\n",
            "Epoch 148/100, Loss: 22.3629, Validation Accuracy: 0.6351\n",
            "Epoch 149/100, Loss: 24.1793, Validation Accuracy: 0.5962\n",
            "Epoch 150/100, Loss: 94.7974, Validation Accuracy: 0.5394\n",
            "Epoch 151/100, Loss: 65.1131, Validation Accuracy: 0.6211\n",
            "Epoch 152/100, Loss: 36.2606, Validation Accuracy: 0.5404\n",
            "Epoch 153/100, Loss: 31.7394, Validation Accuracy: 0.6680\n",
            "Epoch 154/100, Loss: 41.5263, Validation Accuracy: 0.5982\n",
            "Epoch 155/100, Loss: 84.8619, Validation Accuracy: 0.6500\n",
            "Epoch 156/100, Loss: 30.0881, Validation Accuracy: 0.6441\n",
            "Epoch 157/100, Loss: 110.9603, Validation Accuracy: 0.6600\n",
            "Epoch 158/100, Loss: 18.5258, Validation Accuracy: 0.5394\n",
            "Epoch 159/100, Loss: 25.4596, Validation Accuracy: 0.5713\n",
            "Epoch 160/100, Loss: 52.3708, Validation Accuracy: 0.5952\n",
            "Epoch 161/100, Loss: 45.0234, Validation Accuracy: 0.5942\n",
            "Epoch 162/100, Loss: 54.3128, Validation Accuracy: 0.6919\n",
            "Epoch 163/100, Loss: 24.9074, Validation Accuracy: 0.6600\n",
            "Epoch 164/100, Loss: 83.4824, Validation Accuracy: 0.4776\n",
            "Epoch 165/100, Loss: 110.9955, Validation Accuracy: 0.6570\n",
            "Epoch 166/100, Loss: 52.6833, Validation Accuracy: 0.5533\n",
            "Epoch 167/100, Loss: 66.4558, Validation Accuracy: 0.6122\n",
            "Epoch 168/100, Loss: 29.5429, Validation Accuracy: 0.5334\n",
            "Epoch 169/100, Loss: 63.8118, Validation Accuracy: 0.5454\n",
            "Epoch 170/100, Loss: 77.0548, Validation Accuracy: 0.6421\n",
            "Epoch 171/100, Loss: 47.7823, Validation Accuracy: 0.5693\n",
            "Epoch 172/100, Loss: 20.7638, Validation Accuracy: 0.5414\n",
            "Epoch 173/100, Loss: 16.4059, Validation Accuracy: 0.5882\n",
            "Epoch 174/100, Loss: 68.8534, Validation Accuracy: 0.6570\n",
            "Epoch 175/100, Loss: 17.8524, Validation Accuracy: 0.6191\n",
            "Epoch 176/100, Loss: 54.4573, Validation Accuracy: 0.6012\n",
            "Epoch 177/100, Loss: 23.0002, Validation Accuracy: 0.6171\n",
            "Epoch 178/100, Loss: 53.0065, Validation Accuracy: 0.5444\n",
            "Epoch 179/100, Loss: 45.8826, Validation Accuracy: 0.6750\n",
            "Epoch 180/100, Loss: 86.3592, Validation Accuracy: 0.6331\n",
            "Epoch 181/100, Loss: 69.0301, Validation Accuracy: 0.5882\n",
            "Epoch 182/100, Loss: 70.0791, Validation Accuracy: 0.5394\n",
            "Epoch 183/100, Loss: 28.4010, Validation Accuracy: 0.6401\n",
            "Epoch 184/100, Loss: 39.1244, Validation Accuracy: 0.6032\n",
            "Epoch 185/100, Loss: 30.9518, Validation Accuracy: 0.6231\n",
            "Epoch 186/100, Loss: 76.9290, Validation Accuracy: 0.6520\n",
            "Epoch 187/100, Loss: 12.1468, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 87.6936, Validation Accuracy: 0.5553\n",
            "Epoch 189/100, Loss: 36.1786, Validation Accuracy: 0.5633\n",
            "Epoch 190/100, Loss: 114.0450, Validation Accuracy: 0.6251\n",
            "Epoch 191/100, Loss: 112.5054, Validation Accuracy: 0.6411\n",
            "Epoch 192/100, Loss: 56.3430, Validation Accuracy: 0.5992\n",
            "Epoch 193/100, Loss: 56.3965, Validation Accuracy: 0.6181\n",
            "Epoch 194/100, Loss: 41.9053, Validation Accuracy: 0.6072\n",
            "Epoch 195/100, Loss: 57.2959, Validation Accuracy: 0.6301\n",
            "Epoch 196/100, Loss: 40.5381, Validation Accuracy: 0.6271\n",
            "Epoch 197/100, Loss: 43.2816, Validation Accuracy: 0.6600\n",
            "Epoch 198/100, Loss: 37.3004, Validation Accuracy: 0.6441\n",
            "Epoch 199/100, Loss: 86.8162, Validation Accuracy: 0.6570\n",
            "Epoch 200/100, Loss: 28.4224, Validation Accuracy: 0.6660\n",
            "Reward for Child Model: 0.2954109493838166\n",
            "Child_3:  {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, [3, 1, 3, 3, 3, 0, 3, 1, 0, 3, 1, 2, 3, 1, 2], 0.2954109493838166\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 64, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(64, 36, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(100, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=125216, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 26, 28]             240\n",
            "       BatchNorm2d-2           [-1, 24, 26, 28]              48\n",
            "            Conv2d-3           [-1, 24, 20, 22]          28,248\n",
            "       BatchNorm2d-4           [-1, 24, 20, 22]              48\n",
            "              ReLU-5           [-1, 24, 20, 22]               0\n",
            "            Conv2d-6           [-1, 64, 22, 22]         107,584\n",
            "       BatchNorm2d-7           [-1, 64, 22, 22]             128\n",
            "              ReLU-8           [-1, 64, 22, 22]               0\n",
            "            Conv2d-9           [-1, 36, 20, 18]          34,596\n",
            "      BatchNorm2d-10           [-1, 36, 20, 18]              72\n",
            "             ReLU-11           [-1, 36, 20, 18]               0\n",
            "           Conv2d-12           [-1, 48, 22, 18]          24,048\n",
            "      BatchNorm2d-13           [-1, 48, 22, 18]              96\n",
            "             ReLU-14           [-1, 48, 22, 18]               0\n",
            "           Linear-15                    [-1, 7]         876,519\n",
            "================================================================\n",
            "Total params: 1,071,627\n",
            "Trainable params: 1,071,627\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.95\n",
            "Params size (MB): 4.09\n",
            "Estimated Total Size (MB): 6.05\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 60.0294, Validation Accuracy: 0.4955\n",
            "Epoch 2/100, Loss: 17.8556, Validation Accuracy: 0.2941\n",
            "Epoch 3/100, Loss: 16.3948, Validation Accuracy: 0.2702\n",
            "Epoch 4/100, Loss: 12.3972, Validation Accuracy: 0.6620\n",
            "Epoch 5/100, Loss: 34.2597, Validation Accuracy: 0.6072\n",
            "Epoch 6/100, Loss: 9.3744, Validation Accuracy: 0.6481\n",
            "Epoch 7/100, Loss: 1819.0769, Validation Accuracy: 0.6451\n",
            "Epoch 8/100, Loss: 81.2354, Validation Accuracy: 0.6540\n",
            "Epoch 9/100, Loss: 22.2483, Validation Accuracy: 0.5643\n",
            "Epoch 10/100, Loss: 45.5932, Validation Accuracy: 0.6520\n",
            "Epoch 11/100, Loss: 6.3321, Validation Accuracy: 0.6550\n",
            "Epoch 12/100, Loss: 9.1074, Validation Accuracy: 0.5683\n",
            "Epoch 13/100, Loss: 2.0553, Validation Accuracy: 0.6540\n",
            "Epoch 14/100, Loss: 3.5431, Validation Accuracy: 0.6780\n",
            "Epoch 15/100, Loss: 2.1946, Validation Accuracy: 0.6500\n",
            "Epoch 16/100, Loss: 5.0246, Validation Accuracy: 0.6989\n",
            "Epoch 17/100, Loss: 14.1159, Validation Accuracy: 0.6760\n",
            "Epoch 18/100, Loss: 9.1085, Validation Accuracy: 0.6122\n",
            "Epoch 19/100, Loss: 6.5093, Validation Accuracy: 0.6510\n",
            "Epoch 20/100, Loss: 6.8437, Validation Accuracy: 0.6740\n",
            "Epoch 21/100, Loss: 6.0409, Validation Accuracy: 0.6371\n",
            "Epoch 22/100, Loss: 7.0313, Validation Accuracy: 0.2423\n",
            "Epoch 23/100, Loss: 29.6427, Validation Accuracy: 0.6361\n",
            "Epoch 24/100, Loss: 7.4211, Validation Accuracy: 0.4816\n",
            "Epoch 25/100, Loss: 4.4833, Validation Accuracy: 0.5693\n",
            "Epoch 26/100, Loss: 6.3062, Validation Accuracy: 0.5105\n",
            "Epoch 27/100, Loss: 81.8082, Validation Accuracy: 0.2024\n",
            "Epoch 28/100, Loss: 23.8686, Validation Accuracy: 0.6820\n",
            "Epoch 29/100, Loss: 12.2321, Validation Accuracy: 0.6720\n",
            "Epoch 30/100, Loss: 96.1665, Validation Accuracy: 0.6750\n",
            "Epoch 31/100, Loss: 17.5886, Validation Accuracy: 0.6251\n",
            "Epoch 32/100, Loss: 11.6260, Validation Accuracy: 0.6670\n",
            "Epoch 33/100, Loss: 3.1245, Validation Accuracy: 0.5464\n",
            "Epoch 34/100, Loss: 14.3518, Validation Accuracy: 0.6341\n",
            "Epoch 35/100, Loss: 11.8966, Validation Accuracy: 0.6670\n",
            "Epoch 36/100, Loss: 5.4838, Validation Accuracy: 0.6720\n",
            "Epoch 37/100, Loss: 7.6379, Validation Accuracy: 0.6092\n",
            "Epoch 38/100, Loss: 9.2814, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 18.9682, Validation Accuracy: 0.5882\n",
            "Epoch 40/100, Loss: 34.4806, Validation Accuracy: 0.6211\n",
            "Epoch 41/100, Loss: 2.2085, Validation Accuracy: 0.6869\n",
            "Epoch 42/100, Loss: 10.8636, Validation Accuracy: 0.6431\n",
            "Epoch 43/100, Loss: 6.3188, Validation Accuracy: 0.5823\n",
            "Epoch 44/100, Loss: 14.3636, Validation Accuracy: 0.5075\n",
            "Epoch 45/100, Loss: 13.4187, Validation Accuracy: 0.4606\n",
            "Epoch 46/100, Loss: 27.2656, Validation Accuracy: 0.4536\n",
            "Epoch 47/100, Loss: 7.4355, Validation Accuracy: 0.6241\n",
            "Epoch 48/100, Loss: 26.0098, Validation Accuracy: 0.6082\n",
            "Epoch 49/100, Loss: 14.2183, Validation Accuracy: 0.6580\n",
            "Epoch 50/100, Loss: 40.7349, Validation Accuracy: 0.3978\n",
            "Epoch 51/100, Loss: 17.2339, Validation Accuracy: 0.5992\n",
            "Epoch 52/100, Loss: 100.1235, Validation Accuracy: 0.5553\n",
            "Epoch 53/100, Loss: 34.4684, Validation Accuracy: 0.6610\n",
            "Epoch 54/100, Loss: 8.7429, Validation Accuracy: 0.6142\n",
            "Epoch 55/100, Loss: 11.8937, Validation Accuracy: 0.6949\n",
            "Epoch 56/100, Loss: 7.7758, Validation Accuracy: 0.6321\n",
            "Epoch 57/100, Loss: 15.5555, Validation Accuracy: 0.5852\n",
            "Epoch 58/100, Loss: 25.5767, Validation Accuracy: 0.5773\n",
            "Epoch 59/100, Loss: 49.1335, Validation Accuracy: 0.3998\n",
            "Epoch 60/100, Loss: 43.8576, Validation Accuracy: 0.5872\n",
            "Epoch 61/100, Loss: 10.7034, Validation Accuracy: 0.3739\n",
            "Epoch 62/100, Loss: 12.9011, Validation Accuracy: 0.6680\n",
            "Epoch 63/100, Loss: 13.2563, Validation Accuracy: 0.5922\n",
            "Epoch 64/100, Loss: 13.6358, Validation Accuracy: 0.6241\n",
            "Epoch 65/100, Loss: 7.6336, Validation Accuracy: 0.6710\n",
            "Epoch 66/100, Loss: 13.8892, Validation Accuracy: 0.5474\n",
            "Epoch 67/100, Loss: 134.1782, Validation Accuracy: 0.6251\n",
            "Epoch 68/100, Loss: 23.0306, Validation Accuracy: 0.6132\n",
            "Epoch 69/100, Loss: 5.9492, Validation Accuracy: 0.6879\n",
            "Epoch 70/100, Loss: 12.3944, Validation Accuracy: 0.6331\n",
            "Epoch 71/100, Loss: 4.9067, Validation Accuracy: 0.6461\n",
            "Epoch 72/100, Loss: 16.2082, Validation Accuracy: 0.6241\n",
            "Epoch 73/100, Loss: 29.2844, Validation Accuracy: 0.6311\n",
            "Epoch 74/100, Loss: 66.5164, Validation Accuracy: 0.6052\n",
            "Epoch 75/100, Loss: 8.8139, Validation Accuracy: 0.6341\n",
            "Epoch 76/100, Loss: 19.2021, Validation Accuracy: 0.5125\n",
            "Epoch 77/100, Loss: 15.0597, Validation Accuracy: 0.6750\n",
            "Epoch 78/100, Loss: 28.9163, Validation Accuracy: 0.5753\n",
            "Epoch 79/100, Loss: 48.1475, Validation Accuracy: 0.5982\n",
            "Epoch 80/100, Loss: 14.5530, Validation Accuracy: 0.6740\n",
            "Epoch 81/100, Loss: 10.2598, Validation Accuracy: 0.4367\n",
            "Epoch 82/100, Loss: 12.0746, Validation Accuracy: 0.6152\n",
            "Epoch 83/100, Loss: 12.9810, Validation Accuracy: 0.6869\n",
            "Epoch 84/100, Loss: 18.4008, Validation Accuracy: 0.6201\n",
            "Epoch 85/100, Loss: 16.9571, Validation Accuracy: 0.3589\n",
            "Epoch 86/100, Loss: 6.6040, Validation Accuracy: 0.6421\n",
            "Epoch 87/100, Loss: 18.9528, Validation Accuracy: 0.6421\n",
            "Epoch 88/100, Loss: 13.5777, Validation Accuracy: 0.6650\n",
            "Epoch 89/100, Loss: 13.9652, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 28.0227, Validation Accuracy: 0.6790\n",
            "Epoch 91/100, Loss: 15.8863, Validation Accuracy: 0.4118\n",
            "Epoch 92/100, Loss: 43.6699, Validation Accuracy: 0.6042\n",
            "Epoch 93/100, Loss: 10.5368, Validation Accuracy: 0.6640\n",
            "Epoch 94/100, Loss: 12.1636, Validation Accuracy: 0.6132\n",
            "Epoch 95/100, Loss: 12.9221, Validation Accuracy: 0.5643\n",
            "Epoch 96/100, Loss: 19.7149, Validation Accuracy: 0.4845\n",
            "Epoch 97/100, Loss: 8.5276, Validation Accuracy: 0.4885\n",
            "Epoch 98/100, Loss: 5.2115, Validation Accuracy: 0.3669\n",
            "Epoch 99/100, Loss: 12.1590, Validation Accuracy: 0.4925\n",
            "Epoch 100/100, Loss: 36.0484, Validation Accuracy: 0.5743\n",
            "Epoch 101/100, Loss: 5.7231, Validation Accuracy: 0.5663\n",
            "Epoch 102/100, Loss: 11.1944, Validation Accuracy: 0.5573\n",
            "Epoch 103/100, Loss: 27.3785, Validation Accuracy: 0.6600\n",
            "Epoch 104/100, Loss: 10.0076, Validation Accuracy: 0.6221\n",
            "Epoch 105/100, Loss: 24.4151, Validation Accuracy: 0.6500\n",
            "Epoch 106/100, Loss: 13.6812, Validation Accuracy: 0.6311\n",
            "Epoch 107/100, Loss: 75.3795, Validation Accuracy: 0.5583\n",
            "Epoch 108/100, Loss: 25.9249, Validation Accuracy: 0.6740\n",
            "Epoch 109/100, Loss: 6.0045, Validation Accuracy: 0.6500\n",
            "Epoch 110/100, Loss: 11.1224, Validation Accuracy: 0.1924\n",
            "Epoch 111/100, Loss: 15.3822, Validation Accuracy: 0.5713\n",
            "Epoch 112/100, Loss: 11.1388, Validation Accuracy: 0.4247\n",
            "Epoch 113/100, Loss: 27.6566, Validation Accuracy: 0.5234\n",
            "Epoch 114/100, Loss: 16.7995, Validation Accuracy: 0.6221\n",
            "Epoch 115/100, Loss: 14.5772, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 14.1785, Validation Accuracy: 0.6610\n",
            "Epoch 117/100, Loss: 5.7434, Validation Accuracy: 0.6391\n",
            "Epoch 118/100, Loss: 34.8547, Validation Accuracy: 0.6231\n",
            "Epoch 119/100, Loss: 18.7778, Validation Accuracy: 0.6889\n",
            "Epoch 120/100, Loss: 20.5399, Validation Accuracy: 0.6750\n",
            "Epoch 121/100, Loss: 16.7042, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 19.8242, Validation Accuracy: 0.5304\n",
            "Epoch 123/100, Loss: 15.5123, Validation Accuracy: 0.6570\n",
            "Epoch 124/100, Loss: 10.1101, Validation Accuracy: 0.6082\n",
            "Epoch 125/100, Loss: 14.9869, Validation Accuracy: 0.6052\n",
            "Epoch 126/100, Loss: 33.4839, Validation Accuracy: 0.6481\n",
            "Epoch 127/100, Loss: 19.7224, Validation Accuracy: 0.6610\n",
            "Epoch 128/100, Loss: 25.9627, Validation Accuracy: 0.6680\n",
            "Epoch 129/100, Loss: 34.4969, Validation Accuracy: 0.6331\n",
            "Epoch 130/100, Loss: 5.7003, Validation Accuracy: 0.6231\n",
            "Epoch 131/100, Loss: 15.7773, Validation Accuracy: 0.6660\n",
            "Epoch 132/100, Loss: 16.1382, Validation Accuracy: 0.6899\n",
            "Epoch 133/100, Loss: 20.4352, Validation Accuracy: 0.6012\n",
            "Epoch 134/100, Loss: 20.3387, Validation Accuracy: 0.6102\n",
            "Epoch 135/100, Loss: 29.2684, Validation Accuracy: 0.6401\n",
            "Epoch 136/100, Loss: 12.4624, Validation Accuracy: 0.6590\n",
            "Epoch 137/100, Loss: 19.4201, Validation Accuracy: 0.6042\n",
            "Epoch 138/100, Loss: 24.6709, Validation Accuracy: 0.5174\n",
            "Epoch 139/100, Loss: 15.9167, Validation Accuracy: 0.6859\n",
            "Epoch 140/100, Loss: 7.4310, Validation Accuracy: 0.6859\n",
            "Epoch 141/100, Loss: 13.1166, Validation Accuracy: 0.6830\n",
            "Epoch 142/100, Loss: 147.1638, Validation Accuracy: 0.6740\n",
            "Epoch 143/100, Loss: 24.0054, Validation Accuracy: 0.6381\n",
            "Epoch 144/100, Loss: 18.9671, Validation Accuracy: 0.6112\n",
            "Epoch 145/100, Loss: 20.2485, Validation Accuracy: 0.6660\n",
            "Epoch 146/100, Loss: 14.6667, Validation Accuracy: 0.5922\n",
            "Epoch 147/100, Loss: 19.7309, Validation Accuracy: 0.4576\n",
            "Epoch 148/100, Loss: 40.6265, Validation Accuracy: 0.5434\n",
            "Epoch 149/100, Loss: 6.6622, Validation Accuracy: 0.3938\n",
            "Epoch 150/100, Loss: 6.6705, Validation Accuracy: 0.6750\n",
            "Epoch 151/100, Loss: 10.6461, Validation Accuracy: 0.5454\n",
            "Epoch 152/100, Loss: 23.3715, Validation Accuracy: 0.2164\n",
            "Epoch 153/100, Loss: 22.0701, Validation Accuracy: 0.6391\n",
            "Epoch 154/100, Loss: 13.0188, Validation Accuracy: 0.6421\n",
            "Epoch 155/100, Loss: 4.7835, Validation Accuracy: 0.5902\n",
            "Epoch 156/100, Loss: 62.3144, Validation Accuracy: 0.6700\n",
            "Epoch 157/100, Loss: 13.7442, Validation Accuracy: 0.6590\n",
            "Epoch 158/100, Loss: 51.7588, Validation Accuracy: 0.6411\n",
            "Epoch 159/100, Loss: 9.4599, Validation Accuracy: 0.6331\n",
            "Epoch 160/100, Loss: 5.5422, Validation Accuracy: 0.5912\n",
            "Epoch 161/100, Loss: 27.5913, Validation Accuracy: 0.6481\n",
            "Epoch 162/100, Loss: 22.7204, Validation Accuracy: 0.6650\n",
            "Epoch 163/100, Loss: 16.3725, Validation Accuracy: 0.6710\n",
            "Epoch 164/100, Loss: 15.3019, Validation Accuracy: 0.5434\n",
            "Epoch 165/100, Loss: 15.1353, Validation Accuracy: 0.4835\n",
            "Epoch 166/100, Loss: 8.7641, Validation Accuracy: 0.6770\n",
            "Epoch 167/100, Loss: 11.5508, Validation Accuracy: 0.6082\n",
            "Epoch 168/100, Loss: 20.6546, Validation Accuracy: 0.6700\n",
            "Epoch 169/100, Loss: 40.5454, Validation Accuracy: 0.6620\n",
            "Epoch 170/100, Loss: 32.8071, Validation Accuracy: 0.6431\n",
            "Epoch 171/100, Loss: 10.8782, Validation Accuracy: 0.6879\n",
            "Epoch 172/100, Loss: 28.9389, Validation Accuracy: 0.6590\n",
            "Epoch 173/100, Loss: 32.5538, Validation Accuracy: 0.6600\n",
            "Epoch 174/100, Loss: 9.3481, Validation Accuracy: 0.6032\n",
            "Epoch 175/100, Loss: 72.3867, Validation Accuracy: 0.6780\n",
            "Epoch 176/100, Loss: 13.6421, Validation Accuracy: 0.6820\n",
            "Epoch 177/100, Loss: 36.3422, Validation Accuracy: 0.6550\n",
            "Epoch 178/100, Loss: 26.3911, Validation Accuracy: 0.6790\n",
            "Epoch 179/100, Loss: 15.2276, Validation Accuracy: 0.6142\n",
            "Epoch 180/100, Loss: 13.6204, Validation Accuracy: 0.6311\n",
            "Epoch 181/100, Loss: 25.3979, Validation Accuracy: 0.6660\n",
            "Epoch 182/100, Loss: 37.2305, Validation Accuracy: 0.5733\n",
            "Epoch 183/100, Loss: 78.0033, Validation Accuracy: 0.6441\n",
            "Epoch 184/100, Loss: 20.2135, Validation Accuracy: 0.6351\n",
            "Epoch 185/100, Loss: 66.1477, Validation Accuracy: 0.6122\n",
            "Epoch 186/100, Loss: 11.2522, Validation Accuracy: 0.5324\n",
            "Epoch 187/100, Loss: 11.4458, Validation Accuracy: 0.6530\n",
            "Epoch 188/100, Loss: 9.7889, Validation Accuracy: 0.6560\n",
            "Epoch 189/100, Loss: 7.7621, Validation Accuracy: 0.6002\n",
            "Epoch 190/100, Loss: 22.0292, Validation Accuracy: 0.5484\n",
            "Epoch 191/100, Loss: 5.7040, Validation Accuracy: 0.6939\n",
            "Epoch 192/100, Loss: 18.8615, Validation Accuracy: 0.5723\n",
            "Epoch 193/100, Loss: 9.9294, Validation Accuracy: 0.5872\n",
            "Epoch 194/100, Loss: 12.6708, Validation Accuracy: 0.6800\n",
            "Epoch 195/100, Loss: 13.6959, Validation Accuracy: 0.6211\n",
            "Epoch 196/100, Loss: 3.7714, Validation Accuracy: 0.6291\n",
            "Epoch 197/100, Loss: 29.3654, Validation Accuracy: 0.6680\n",
            "Epoch 198/100, Loss: 26.3243, Validation Accuracy: 0.6092\n",
            "Epoch 199/100, Loss: 31.2271, Validation Accuracy: 0.6291\n",
            "Epoch 200/100, Loss: 18.8694, Validation Accuracy: 0.6630\n",
            "Reward for Child Model: 0.2980722933598883\n",
            "Child_4:  {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, [1, 0, 0, 3, 3, 0, 2, 3, 3, 1, 2, 1, 0, 2, 2], 0.2980722933598883\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(88, 36, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(148, 48, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(72, 64, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=78336, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 24, 24]           1,824\n",
            "       BatchNorm2d-2           [-1, 24, 24, 24]              48\n",
            "            Conv2d-3           [-1, 64, 24, 24]           1,600\n",
            "       BatchNorm2d-4           [-1, 64, 24, 24]             128\n",
            "              ReLU-5           [-1, 64, 24, 24]               0\n",
            "            Conv2d-6           [-1, 36, 24, 20]          15,876\n",
            "       BatchNorm2d-7           [-1, 36, 24, 20]              72\n",
            "              ReLU-8           [-1, 36, 24, 20]               0\n",
            "            Conv2d-9           [-1, 48, 20, 24]          35,568\n",
            "      BatchNorm2d-10           [-1, 48, 20, 24]              96\n",
            "             ReLU-11           [-1, 48, 20, 24]               0\n",
            "           Conv2d-12           [-1, 64, 20, 22]          69,184\n",
            "      BatchNorm2d-13           [-1, 64, 20, 22]             128\n",
            "             ReLU-14           [-1, 64, 20, 22]               0\n",
            "           Linear-15                    [-1, 7]         548,359\n",
            "================================================================\n",
            "Total params: 672,883\n",
            "Trainable params: 672,883\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.62\n",
            "Params size (MB): 2.57\n",
            "Estimated Total Size (MB): 5.20\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 7.1994, Validation Accuracy: 0.3101\n",
            "Epoch 2/100, Loss: 57.8358, Validation Accuracy: 0.6221\n",
            "Epoch 3/100, Loss: 4.9525, Validation Accuracy: 0.5613\n",
            "Epoch 4/100, Loss: 1.4331, Validation Accuracy: 0.6231\n",
            "Epoch 5/100, Loss: 2.0962, Validation Accuracy: 0.6072\n",
            "Epoch 6/100, Loss: 5.6614, Validation Accuracy: 0.5902\n",
            "Epoch 7/100, Loss: 14.7667, Validation Accuracy: 0.6171\n",
            "Epoch 8/100, Loss: 4.6781, Validation Accuracy: 0.5434\n",
            "Epoch 9/100, Loss: 1.6173, Validation Accuracy: 0.6152\n",
            "Epoch 10/100, Loss: 3.7058, Validation Accuracy: 0.6640\n",
            "Epoch 11/100, Loss: 2.2480, Validation Accuracy: 0.5763\n",
            "Epoch 12/100, Loss: 2.7618, Validation Accuracy: 0.6002\n",
            "Epoch 13/100, Loss: 2.9053, Validation Accuracy: 0.6112\n",
            "Epoch 14/100, Loss: 2.9328, Validation Accuracy: 0.5872\n",
            "Epoch 15/100, Loss: 1.7922, Validation Accuracy: 0.5693\n",
            "Epoch 16/100, Loss: 3.6874, Validation Accuracy: 0.3579\n",
            "Epoch 17/100, Loss: 131.3368, Validation Accuracy: 0.6241\n",
            "Epoch 18/100, Loss: 13.4139, Validation Accuracy: 0.6032\n",
            "Epoch 19/100, Loss: 9.3610, Validation Accuracy: 0.6072\n",
            "Epoch 20/100, Loss: 2.8694, Validation Accuracy: 0.5793\n",
            "Epoch 21/100, Loss: 6.8523, Validation Accuracy: 0.4945\n",
            "Epoch 22/100, Loss: 3.9890, Validation Accuracy: 0.4596\n",
            "Epoch 23/100, Loss: 113.3557, Validation Accuracy: 0.6441\n",
            "Epoch 24/100, Loss: 27.5044, Validation Accuracy: 0.4357\n",
            "Epoch 25/100, Loss: 17.0284, Validation Accuracy: 0.6052\n",
            "Epoch 26/100, Loss: 1.8375, Validation Accuracy: 0.6221\n",
            "Epoch 27/100, Loss: 2.9630, Validation Accuracy: 0.6520\n",
            "Epoch 28/100, Loss: 5.2649, Validation Accuracy: 0.5793\n",
            "Epoch 29/100, Loss: 5.9881, Validation Accuracy: 0.4696\n",
            "Epoch 30/100, Loss: 40.2832, Validation Accuracy: 0.5513\n",
            "Epoch 31/100, Loss: 37.4170, Validation Accuracy: 0.6251\n",
            "Epoch 32/100, Loss: 3.5811, Validation Accuracy: 0.5224\n",
            "Epoch 33/100, Loss: 4.0467, Validation Accuracy: 0.6550\n",
            "Epoch 34/100, Loss: 8.4373, Validation Accuracy: 0.5783\n",
            "Epoch 35/100, Loss: 3.1114, Validation Accuracy: 0.5553\n",
            "Epoch 36/100, Loss: 6.2100, Validation Accuracy: 0.6620\n",
            "Epoch 37/100, Loss: 2.8716, Validation Accuracy: 0.6152\n",
            "Epoch 38/100, Loss: 5.5649, Validation Accuracy: 0.3559\n",
            "Epoch 39/100, Loss: 49.8349, Validation Accuracy: 0.2004\n",
            "Epoch 40/100, Loss: 6.8782, Validation Accuracy: 0.6132\n",
            "Epoch 41/100, Loss: 5.0872, Validation Accuracy: 0.5563\n",
            "Epoch 42/100, Loss: 9.0837, Validation Accuracy: 0.5553\n",
            "Epoch 43/100, Loss: 6.1201, Validation Accuracy: 0.6241\n",
            "Epoch 44/100, Loss: 15.3321, Validation Accuracy: 0.5513\n",
            "Epoch 45/100, Loss: 95.3075, Validation Accuracy: 0.5623\n",
            "Epoch 46/100, Loss: 15.5273, Validation Accuracy: 0.6570\n",
            "Epoch 47/100, Loss: 5.6113, Validation Accuracy: 0.2822\n",
            "Epoch 48/100, Loss: 9.6387, Validation Accuracy: 0.5872\n",
            "Epoch 49/100, Loss: 13.2338, Validation Accuracy: 0.6311\n",
            "Epoch 50/100, Loss: 6.7258, Validation Accuracy: 0.6810\n",
            "Epoch 51/100, Loss: 26.7176, Validation Accuracy: 0.5145\n",
            "Epoch 52/100, Loss: 72.8401, Validation Accuracy: 0.5673\n",
            "Epoch 53/100, Loss: 5.6397, Validation Accuracy: 0.5922\n",
            "Epoch 54/100, Loss: 5.8269, Validation Accuracy: 0.4746\n",
            "Epoch 55/100, Loss: 5.5983, Validation Accuracy: 0.6291\n",
            "Epoch 56/100, Loss: 3.6587, Validation Accuracy: 0.6072\n",
            "Epoch 57/100, Loss: 23.8631, Validation Accuracy: 0.6451\n",
            "Epoch 58/100, Loss: 25.8997, Validation Accuracy: 0.6311\n",
            "Epoch 59/100, Loss: 7.2842, Validation Accuracy: 0.5364\n",
            "Epoch 60/100, Loss: 2.7657, Validation Accuracy: 0.6680\n",
            "Epoch 61/100, Loss: 19.1161, Validation Accuracy: 0.5424\n",
            "Epoch 62/100, Loss: 13.5460, Validation Accuracy: 0.6351\n",
            "Epoch 63/100, Loss: 7.7877, Validation Accuracy: 0.6510\n",
            "Epoch 64/100, Loss: 13.0957, Validation Accuracy: 0.4875\n",
            "Epoch 65/100, Loss: 9.2208, Validation Accuracy: 0.6291\n",
            "Epoch 66/100, Loss: 35.8570, Validation Accuracy: 0.5783\n",
            "Epoch 67/100, Loss: 25.6422, Validation Accuracy: 0.5424\n",
            "Epoch 68/100, Loss: 12.8463, Validation Accuracy: 0.6630\n",
            "Epoch 69/100, Loss: 6.3686, Validation Accuracy: 0.6201\n",
            "Epoch 70/100, Loss: 7.3227, Validation Accuracy: 0.5823\n",
            "Epoch 71/100, Loss: 6.5595, Validation Accuracy: 0.6730\n",
            "Epoch 72/100, Loss: 14.5328, Validation Accuracy: 0.6132\n",
            "Epoch 73/100, Loss: 74.1992, Validation Accuracy: 0.5593\n",
            "Epoch 74/100, Loss: 15.2982, Validation Accuracy: 0.6181\n",
            "Epoch 75/100, Loss: 8.6123, Validation Accuracy: 0.6630\n",
            "Epoch 76/100, Loss: 1.7029, Validation Accuracy: 0.5833\n",
            "Epoch 77/100, Loss: 10.7325, Validation Accuracy: 0.4895\n",
            "Epoch 78/100, Loss: 43.4215, Validation Accuracy: 0.4706\n",
            "Epoch 79/100, Loss: 17.1441, Validation Accuracy: 0.5912\n",
            "Epoch 80/100, Loss: 11.7425, Validation Accuracy: 0.4487\n",
            "Epoch 81/100, Loss: 86.6759, Validation Accuracy: 0.6461\n",
            "Epoch 82/100, Loss: 5.0226, Validation Accuracy: 0.5962\n",
            "Epoch 83/100, Loss: 2.9665, Validation Accuracy: 0.6381\n",
            "Epoch 84/100, Loss: 9.3190, Validation Accuracy: 0.4596\n",
            "Epoch 85/100, Loss: 7.0569, Validation Accuracy: 0.5045\n",
            "Epoch 86/100, Loss: 25.1053, Validation Accuracy: 0.5633\n",
            "Epoch 87/100, Loss: 14.4237, Validation Accuracy: 0.6321\n",
            "Epoch 88/100, Loss: 5.7806, Validation Accuracy: 0.5842\n",
            "Epoch 89/100, Loss: 4.9024, Validation Accuracy: 0.5932\n",
            "Epoch 90/100, Loss: 13.6495, Validation Accuracy: 0.6570\n",
            "Epoch 91/100, Loss: 50.1626, Validation Accuracy: 0.6590\n",
            "Epoch 92/100, Loss: 7.3362, Validation Accuracy: 0.6630\n",
            "Epoch 93/100, Loss: 13.3752, Validation Accuracy: 0.6142\n",
            "Epoch 94/100, Loss: 14.2255, Validation Accuracy: 0.5653\n",
            "Epoch 95/100, Loss: 5.6603, Validation Accuracy: 0.6580\n",
            "Epoch 96/100, Loss: 20.2411, Validation Accuracy: 0.5135\n",
            "Epoch 97/100, Loss: 80.2688, Validation Accuracy: 0.4148\n",
            "Epoch 98/100, Loss: 37.8126, Validation Accuracy: 0.5294\n",
            "Epoch 99/100, Loss: 26.1988, Validation Accuracy: 0.4636\n",
            "Epoch 100/100, Loss: 7.2002, Validation Accuracy: 0.6281\n",
            "Epoch 101/100, Loss: 20.3586, Validation Accuracy: 0.6152\n",
            "Epoch 102/100, Loss: 9.2094, Validation Accuracy: 0.5663\n",
            "Epoch 103/100, Loss: 7.7898, Validation Accuracy: 0.6720\n",
            "Epoch 104/100, Loss: 14.1995, Validation Accuracy: 0.5503\n",
            "Epoch 105/100, Loss: 18.9566, Validation Accuracy: 0.5823\n",
            "Epoch 106/100, Loss: 58.4903, Validation Accuracy: 0.4377\n",
            "Epoch 107/100, Loss: 9.7908, Validation Accuracy: 0.5922\n",
            "Epoch 108/100, Loss: 5.3741, Validation Accuracy: 0.6481\n",
            "Epoch 109/100, Loss: 2.7501, Validation Accuracy: 0.6221\n",
            "Epoch 110/100, Loss: 5.8058, Validation Accuracy: 0.6461\n",
            "Epoch 111/100, Loss: 13.1174, Validation Accuracy: 0.6191\n",
            "Epoch 112/100, Loss: 32.5304, Validation Accuracy: 0.5583\n",
            "Epoch 113/100, Loss: 8.1336, Validation Accuracy: 0.6181\n",
            "Epoch 114/100, Loss: 4.0902, Validation Accuracy: 0.6570\n",
            "Epoch 115/100, Loss: 19.5372, Validation Accuracy: 0.6371\n",
            "Epoch 116/100, Loss: 17.7218, Validation Accuracy: 0.6610\n",
            "Epoch 117/100, Loss: 10.0578, Validation Accuracy: 0.6421\n",
            "Epoch 118/100, Loss: 7.0450, Validation Accuracy: 0.6052\n",
            "Epoch 119/100, Loss: 9.7426, Validation Accuracy: 0.6510\n",
            "Epoch 120/100, Loss: 47.5234, Validation Accuracy: 0.4845\n",
            "Epoch 121/100, Loss: 34.4509, Validation Accuracy: 0.6361\n",
            "Epoch 122/100, Loss: 10.6378, Validation Accuracy: 0.5593\n",
            "Epoch 123/100, Loss: 24.7366, Validation Accuracy: 0.6231\n",
            "Epoch 124/100, Loss: 6.2980, Validation Accuracy: 0.5444\n",
            "Epoch 125/100, Loss: 18.7754, Validation Accuracy: 0.4686\n",
            "Epoch 126/100, Loss: 5.5230, Validation Accuracy: 0.6381\n",
            "Epoch 127/100, Loss: 183.1214, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 6.4629, Validation Accuracy: 0.6481\n",
            "Epoch 129/100, Loss: 6.8152, Validation Accuracy: 0.6610\n",
            "Epoch 130/100, Loss: 8.7722, Validation Accuracy: 0.6181\n",
            "Epoch 131/100, Loss: 5.1720, Validation Accuracy: 0.6281\n",
            "Epoch 132/100, Loss: 9.2600, Validation Accuracy: 0.3051\n",
            "Epoch 133/100, Loss: 25.8113, Validation Accuracy: 0.6261\n",
            "Epoch 134/100, Loss: 22.8845, Validation Accuracy: 0.6700\n",
            "Epoch 135/100, Loss: 13.0647, Validation Accuracy: 0.5155\n",
            "Epoch 136/100, Loss: 5.4789, Validation Accuracy: 0.6660\n",
            "Epoch 137/100, Loss: 9.1953, Validation Accuracy: 0.6122\n",
            "Epoch 138/100, Loss: 19.0517, Validation Accuracy: 0.5882\n",
            "Epoch 139/100, Loss: 4.0306, Validation Accuracy: 0.6401\n",
            "Epoch 140/100, Loss: 36.9315, Validation Accuracy: 0.6700\n",
            "Epoch 141/100, Loss: 23.1455, Validation Accuracy: 0.5723\n",
            "Epoch 142/100, Loss: 12.4582, Validation Accuracy: 0.6331\n",
            "Epoch 143/100, Loss: 5.7620, Validation Accuracy: 0.5464\n",
            "Epoch 144/100, Loss: 8.0317, Validation Accuracy: 0.5364\n",
            "Epoch 145/100, Loss: 11.8420, Validation Accuracy: 0.6560\n",
            "Epoch 146/100, Loss: 9.9112, Validation Accuracy: 0.6839\n",
            "Epoch 147/100, Loss: 12.1523, Validation Accuracy: 0.5723\n",
            "Epoch 148/100, Loss: 68.1312, Validation Accuracy: 0.4626\n",
            "Epoch 149/100, Loss: 34.0570, Validation Accuracy: 0.6610\n",
            "Epoch 150/100, Loss: 7.2578, Validation Accuracy: 0.6510\n",
            "Epoch 151/100, Loss: 12.8707, Validation Accuracy: 0.5583\n",
            "Epoch 152/100, Loss: 4.4156, Validation Accuracy: 0.6022\n",
            "Epoch 153/100, Loss: 9.0593, Validation Accuracy: 0.5942\n",
            "Epoch 154/100, Loss: 14.8432, Validation Accuracy: 0.6800\n",
            "Epoch 155/100, Loss: 14.7793, Validation Accuracy: 0.5085\n",
            "Epoch 156/100, Loss: 8.5897, Validation Accuracy: 0.5194\n",
            "Epoch 157/100, Loss: 7.0907, Validation Accuracy: 0.6520\n",
            "Epoch 158/100, Loss: 7.3167, Validation Accuracy: 0.4826\n",
            "Epoch 159/100, Loss: 6.4750, Validation Accuracy: 0.6590\n",
            "Epoch 160/100, Loss: 15.6493, Validation Accuracy: 0.5005\n",
            "Epoch 161/100, Loss: 41.6986, Validation Accuracy: 0.6052\n",
            "Epoch 162/100, Loss: 28.1043, Validation Accuracy: 0.5324\n",
            "Epoch 163/100, Loss: 15.5941, Validation Accuracy: 0.5803\n",
            "Epoch 164/100, Loss: 20.0417, Validation Accuracy: 0.5394\n",
            "Epoch 165/100, Loss: 26.6533, Validation Accuracy: 0.6760\n",
            "Epoch 166/100, Loss: 14.2814, Validation Accuracy: 0.4676\n",
            "Epoch 167/100, Loss: 26.3062, Validation Accuracy: 0.5264\n",
            "Epoch 168/100, Loss: 48.0098, Validation Accuracy: 0.5793\n",
            "Epoch 169/100, Loss: 11.0880, Validation Accuracy: 0.5404\n",
            "Epoch 170/100, Loss: 10.6848, Validation Accuracy: 0.6381\n",
            "Epoch 171/100, Loss: 14.6861, Validation Accuracy: 0.4995\n",
            "Epoch 172/100, Loss: 11.1256, Validation Accuracy: 0.6351\n",
            "Epoch 173/100, Loss: 6.2536, Validation Accuracy: 0.6152\n",
            "Epoch 174/100, Loss: 28.9615, Validation Accuracy: 0.6311\n",
            "Epoch 175/100, Loss: 36.4360, Validation Accuracy: 0.6321\n",
            "Epoch 176/100, Loss: 21.3065, Validation Accuracy: 0.6371\n",
            "Epoch 177/100, Loss: 30.8216, Validation Accuracy: 0.5753\n",
            "Epoch 178/100, Loss: 12.0174, Validation Accuracy: 0.6560\n",
            "Epoch 179/100, Loss: 12.3125, Validation Accuracy: 0.6381\n",
            "Epoch 180/100, Loss: 8.2009, Validation Accuracy: 0.6371\n",
            "Epoch 181/100, Loss: 23.8677, Validation Accuracy: 0.5653\n",
            "Epoch 182/100, Loss: 13.2750, Validation Accuracy: 0.6361\n",
            "Epoch 183/100, Loss: 35.5339, Validation Accuracy: 0.4965\n",
            "Epoch 184/100, Loss: 8.9678, Validation Accuracy: 0.5264\n",
            "Epoch 185/100, Loss: 28.6625, Validation Accuracy: 0.5374\n",
            "Epoch 186/100, Loss: 13.0763, Validation Accuracy: 0.6191\n",
            "Epoch 187/100, Loss: 19.4473, Validation Accuracy: 0.5344\n",
            "Epoch 188/100, Loss: 28.6914, Validation Accuracy: 0.5294\n",
            "Epoch 189/100, Loss: 11.7803, Validation Accuracy: 0.6630\n",
            "Epoch 190/100, Loss: 12.7168, Validation Accuracy: 0.6142\n",
            "Epoch 191/100, Loss: 65.5732, Validation Accuracy: 0.6132\n",
            "Epoch 192/100, Loss: 13.8506, Validation Accuracy: 0.6361\n",
            "Epoch 193/100, Loss: 8.5744, Validation Accuracy: 0.6391\n",
            "Epoch 194/100, Loss: 15.4035, Validation Accuracy: 0.6321\n",
            "Epoch 195/100, Loss: 9.8904, Validation Accuracy: 0.5135\n",
            "Epoch 196/100, Loss: 17.0275, Validation Accuracy: 0.6082\n",
            "Epoch 197/100, Loss: 7.4398, Validation Accuracy: 0.6062\n",
            "Epoch 198/100, Loss: 49.9226, Validation Accuracy: 0.5603\n",
            "Epoch 199/100, Loss: 11.3754, Validation Accuracy: 0.6211\n",
            "Epoch 200/100, Loss: 4.7407, Validation Accuracy: 0.4666\n",
            "Reward for Child Model: 0.23964112013820227\n",
            "Child_5:  {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, [2, 2, 0, 0, 0, 3, 0, 2, 1, 2, 0, 2, 2, 1, 3], 0.23964112013820227\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 64, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(152, 36, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(252, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=151008, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 26, 22]           4,096\n",
            "       BatchNorm2d-2           [-1, 64, 26, 22]             128\n",
            "            Conv2d-3           [-1, 24, 26, 16]          10,776\n",
            "       BatchNorm2d-4           [-1, 24, 26, 16]              48\n",
            "              ReLU-5           [-1, 24, 26, 16]               0\n",
            "            Conv2d-6           [-1, 64, 24, 12]          23,104\n",
            "       BatchNorm2d-7           [-1, 64, 24, 12]             128\n",
            "              ReLU-8           [-1, 64, 24, 12]               0\n",
            "            Conv2d-9           [-1, 36, 26, 18]          27,396\n",
            "      BatchNorm2d-10           [-1, 36, 26, 18]              72\n",
            "             ReLU-11           [-1, 36, 26, 18]               0\n",
            "           Conv2d-12           [-1, 24, 26, 16]          42,360\n",
            "      BatchNorm2d-13           [-1, 24, 26, 16]              48\n",
            "             ReLU-14           [-1, 24, 26, 16]               0\n",
            "           Linear-15                    [-1, 7]       1,057,063\n",
            "================================================================\n",
            "Total params: 1,165,219\n",
            "Trainable params: 1,165,219\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.82\n",
            "Params size (MB): 4.44\n",
            "Estimated Total Size (MB): 6.28\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 50.7368, Validation Accuracy: 0.5145\n",
            "Epoch 2/100, Loss: 27.9059, Validation Accuracy: 0.3340\n",
            "Epoch 3/100, Loss: 185.0990, Validation Accuracy: 0.6022\n",
            "Epoch 4/100, Loss: 24.7649, Validation Accuracy: 0.3011\n",
            "Epoch 5/100, Loss: 33.4385, Validation Accuracy: 0.5174\n",
            "Epoch 6/100, Loss: 36.0991, Validation Accuracy: 0.5653\n",
            "Epoch 7/100, Loss: 56.2673, Validation Accuracy: 0.6510\n",
            "Epoch 8/100, Loss: 78.6470, Validation Accuracy: 0.5703\n",
            "Epoch 9/100, Loss: 148.1986, Validation Accuracy: 0.6411\n",
            "Epoch 10/100, Loss: 86.8159, Validation Accuracy: 0.1665\n",
            "Epoch 11/100, Loss: 174.1712, Validation Accuracy: 0.6122\n",
            "Epoch 12/100, Loss: 372.0020, Validation Accuracy: 0.6481\n",
            "Epoch 13/100, Loss: 67.2121, Validation Accuracy: 0.6122\n",
            "Epoch 14/100, Loss: 23.8644, Validation Accuracy: 0.5354\n",
            "Epoch 15/100, Loss: 35.3280, Validation Accuracy: 0.6082\n",
            "Epoch 16/100, Loss: 44.9185, Validation Accuracy: 0.5414\n",
            "Epoch 17/100, Loss: 223.1048, Validation Accuracy: 0.3430\n",
            "Epoch 18/100, Loss: 23.9119, Validation Accuracy: 0.6321\n",
            "Epoch 19/100, Loss: 35.8627, Validation Accuracy: 0.5214\n",
            "Epoch 20/100, Loss: 79.1385, Validation Accuracy: 0.4028\n",
            "Epoch 21/100, Loss: 44.0137, Validation Accuracy: 0.4905\n",
            "Epoch 22/100, Loss: 27.2916, Validation Accuracy: 0.5653\n",
            "Epoch 23/100, Loss: 67.2966, Validation Accuracy: 0.6132\n",
            "Epoch 24/100, Loss: 152.1417, Validation Accuracy: 0.6471\n",
            "Epoch 25/100, Loss: 97.3764, Validation Accuracy: 0.5932\n",
            "Epoch 26/100, Loss: 42.0110, Validation Accuracy: 0.6580\n",
            "Epoch 27/100, Loss: 120.4205, Validation Accuracy: 0.5743\n",
            "Epoch 28/100, Loss: 204.3556, Validation Accuracy: 0.5962\n",
            "Epoch 29/100, Loss: 75.9711, Validation Accuracy: 0.3579\n",
            "Epoch 30/100, Loss: 146.0139, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 107.7285, Validation Accuracy: 0.6939\n",
            "Epoch 32/100, Loss: 123.6409, Validation Accuracy: 0.5244\n",
            "Epoch 33/100, Loss: 59.9403, Validation Accuracy: 0.6660\n",
            "Epoch 34/100, Loss: 64.7207, Validation Accuracy: 0.5743\n",
            "Epoch 35/100, Loss: 99.5055, Validation Accuracy: 0.5314\n",
            "Epoch 36/100, Loss: 408.6408, Validation Accuracy: 0.6680\n",
            "Epoch 37/100, Loss: 142.6602, Validation Accuracy: 0.5174\n",
            "Epoch 38/100, Loss: 109.3267, Validation Accuracy: 0.4816\n",
            "Epoch 39/100, Loss: 89.0537, Validation Accuracy: 0.6351\n",
            "Epoch 40/100, Loss: 105.5299, Validation Accuracy: 0.6211\n",
            "Epoch 41/100, Loss: 131.9620, Validation Accuracy: 0.5892\n",
            "Epoch 42/100, Loss: 109.7661, Validation Accuracy: 0.4536\n",
            "Epoch 43/100, Loss: 150.4668, Validation Accuracy: 0.6650\n",
            "Epoch 44/100, Loss: 243.6095, Validation Accuracy: 0.5284\n",
            "Epoch 45/100, Loss: 44.0211, Validation Accuracy: 0.5533\n",
            "Epoch 46/100, Loss: 37.3020, Validation Accuracy: 0.6062\n",
            "Epoch 47/100, Loss: 36.3261, Validation Accuracy: 0.6520\n",
            "Epoch 48/100, Loss: 85.1804, Validation Accuracy: 0.6371\n",
            "Epoch 49/100, Loss: 108.3709, Validation Accuracy: 0.5533\n",
            "Epoch 50/100, Loss: 206.3405, Validation Accuracy: 0.6381\n",
            "Epoch 51/100, Loss: 204.6258, Validation Accuracy: 0.5354\n",
            "Epoch 52/100, Loss: 35.3354, Validation Accuracy: 0.5344\n",
            "Epoch 53/100, Loss: 91.9594, Validation Accuracy: 0.5464\n",
            "Epoch 54/100, Loss: 109.0240, Validation Accuracy: 0.6560\n",
            "Epoch 55/100, Loss: 203.0712, Validation Accuracy: 0.5962\n",
            "Epoch 56/100, Loss: 68.7043, Validation Accuracy: 0.6830\n",
            "Epoch 57/100, Loss: 50.9130, Validation Accuracy: 0.5673\n",
            "Epoch 58/100, Loss: 175.4579, Validation Accuracy: 0.5992\n",
            "Epoch 59/100, Loss: 143.4496, Validation Accuracy: 0.6241\n",
            "Epoch 60/100, Loss: 186.5403, Validation Accuracy: 0.6660\n",
            "Epoch 61/100, Loss: 120.3432, Validation Accuracy: 0.6790\n",
            "Epoch 62/100, Loss: 302.8486, Validation Accuracy: 0.6181\n",
            "Epoch 63/100, Loss: 89.6392, Validation Accuracy: 0.6271\n",
            "Epoch 64/100, Loss: 236.2274, Validation Accuracy: 0.6451\n",
            "Epoch 65/100, Loss: 118.1504, Validation Accuracy: 0.5703\n",
            "Epoch 66/100, Loss: 185.1958, Validation Accuracy: 0.5922\n",
            "Epoch 67/100, Loss: 167.5078, Validation Accuracy: 0.6580\n",
            "Epoch 68/100, Loss: 91.4865, Validation Accuracy: 0.5882\n",
            "Epoch 69/100, Loss: 168.3199, Validation Accuracy: 0.6052\n",
            "Epoch 70/100, Loss: 130.1826, Validation Accuracy: 0.6321\n",
            "Epoch 71/100, Loss: 65.4881, Validation Accuracy: 0.6411\n",
            "Epoch 72/100, Loss: 177.2023, Validation Accuracy: 0.6770\n",
            "Epoch 73/100, Loss: 307.6935, Validation Accuracy: 0.5364\n",
            "Epoch 74/100, Loss: 87.6883, Validation Accuracy: 0.5055\n",
            "Epoch 75/100, Loss: 190.6592, Validation Accuracy: 0.6451\n",
            "Epoch 76/100, Loss: 114.6956, Validation Accuracy: 0.6760\n",
            "Epoch 77/100, Loss: 100.3225, Validation Accuracy: 0.4806\n",
            "Epoch 78/100, Loss: 177.0593, Validation Accuracy: 0.6540\n",
            "Epoch 79/100, Loss: 96.1928, Validation Accuracy: 0.5045\n",
            "Epoch 80/100, Loss: 75.4934, Validation Accuracy: 0.5573\n",
            "Epoch 81/100, Loss: 117.3061, Validation Accuracy: 0.4327\n",
            "Epoch 82/100, Loss: 222.9726, Validation Accuracy: 0.6570\n",
            "Epoch 83/100, Loss: 105.1752, Validation Accuracy: 0.6112\n",
            "Epoch 84/100, Loss: 102.6784, Validation Accuracy: 0.6720\n",
            "Epoch 85/100, Loss: 38.1583, Validation Accuracy: 0.5942\n",
            "Epoch 86/100, Loss: 54.0090, Validation Accuracy: 0.6381\n",
            "Epoch 87/100, Loss: 57.0898, Validation Accuracy: 0.5793\n",
            "Epoch 88/100, Loss: 57.4986, Validation Accuracy: 0.5384\n",
            "Epoch 89/100, Loss: 146.6599, Validation Accuracy: 0.5683\n",
            "Epoch 90/100, Loss: 156.5376, Validation Accuracy: 0.6421\n",
            "Epoch 91/100, Loss: 195.9897, Validation Accuracy: 0.6879\n",
            "Epoch 92/100, Loss: 233.1261, Validation Accuracy: 0.6032\n",
            "Epoch 93/100, Loss: 48.8888, Validation Accuracy: 0.6760\n",
            "Epoch 94/100, Loss: 102.5696, Validation Accuracy: 0.6650\n",
            "Epoch 95/100, Loss: 97.3470, Validation Accuracy: 0.4187\n",
            "Epoch 96/100, Loss: 174.8821, Validation Accuracy: 0.6800\n",
            "Epoch 97/100, Loss: 79.1340, Validation Accuracy: 0.6062\n",
            "Epoch 98/100, Loss: 60.3976, Validation Accuracy: 0.6152\n",
            "Epoch 99/100, Loss: 274.8812, Validation Accuracy: 0.4616\n",
            "Epoch 100/100, Loss: 50.8491, Validation Accuracy: 0.6092\n",
            "Epoch 101/100, Loss: 136.4583, Validation Accuracy: 0.5204\n",
            "Epoch 102/100, Loss: 93.8656, Validation Accuracy: 0.5703\n",
            "Epoch 103/100, Loss: 189.1194, Validation Accuracy: 0.5773\n",
            "Epoch 104/100, Loss: 288.5444, Validation Accuracy: 0.5922\n",
            "Epoch 105/100, Loss: 229.5864, Validation Accuracy: 0.5563\n",
            "Epoch 106/100, Loss: 81.4898, Validation Accuracy: 0.5214\n",
            "Epoch 107/100, Loss: 68.4324, Validation Accuracy: 0.5523\n",
            "Epoch 108/100, Loss: 98.5180, Validation Accuracy: 0.6142\n",
            "Epoch 109/100, Loss: 118.7965, Validation Accuracy: 0.6570\n",
            "Epoch 110/100, Loss: 77.3220, Validation Accuracy: 0.5603\n",
            "Epoch 111/100, Loss: 106.7719, Validation Accuracy: 0.6530\n",
            "Epoch 112/100, Loss: 198.5216, Validation Accuracy: 0.5015\n",
            "Epoch 113/100, Loss: 101.3916, Validation Accuracy: 0.4307\n",
            "Epoch 114/100, Loss: 138.1908, Validation Accuracy: 0.3559\n",
            "Epoch 115/100, Loss: 88.3761, Validation Accuracy: 0.6271\n",
            "Epoch 116/100, Loss: 94.1637, Validation Accuracy: 0.5723\n",
            "Epoch 117/100, Loss: 91.0028, Validation Accuracy: 0.6859\n",
            "Epoch 118/100, Loss: 53.5765, Validation Accuracy: 0.6381\n",
            "Epoch 119/100, Loss: 24.1561, Validation Accuracy: 0.6022\n",
            "Epoch 120/100, Loss: 213.5348, Validation Accuracy: 0.6491\n",
            "Epoch 121/100, Loss: 253.1152, Validation Accuracy: 0.6142\n",
            "Epoch 122/100, Loss: 158.0811, Validation Accuracy: 0.5842\n",
            "Epoch 123/100, Loss: 115.4625, Validation Accuracy: 0.6221\n",
            "Epoch 124/100, Loss: 162.2052, Validation Accuracy: 0.6620\n",
            "Epoch 125/100, Loss: 89.8191, Validation Accuracy: 0.5872\n",
            "Epoch 126/100, Loss: 20.4433, Validation Accuracy: 0.5065\n",
            "Epoch 127/100, Loss: 38.7137, Validation Accuracy: 0.6590\n",
            "Epoch 128/100, Loss: 146.4787, Validation Accuracy: 0.6630\n",
            "Epoch 129/100, Loss: 239.9278, Validation Accuracy: 0.6869\n",
            "Epoch 130/100, Loss: 58.1647, Validation Accuracy: 0.4756\n",
            "Epoch 131/100, Loss: 124.7468, Validation Accuracy: 0.6241\n",
            "Epoch 132/100, Loss: 139.6017, Validation Accuracy: 0.5174\n",
            "Epoch 133/100, Loss: 71.9735, Validation Accuracy: 0.6291\n",
            "Epoch 134/100, Loss: 109.7462, Validation Accuracy: 0.6112\n",
            "Epoch 135/100, Loss: 198.5628, Validation Accuracy: 0.6251\n",
            "Epoch 136/100, Loss: 167.2311, Validation Accuracy: 0.6191\n",
            "Epoch 137/100, Loss: 32.9006, Validation Accuracy: 0.5703\n",
            "Epoch 138/100, Loss: 127.3043, Validation Accuracy: 0.5813\n",
            "Epoch 139/100, Loss: 132.4768, Validation Accuracy: 0.6630\n",
            "Epoch 140/100, Loss: 96.0715, Validation Accuracy: 0.4526\n",
            "Epoch 141/100, Loss: 105.2587, Validation Accuracy: 0.6201\n",
            "Epoch 142/100, Loss: 234.2162, Validation Accuracy: 0.5613\n",
            "Epoch 143/100, Loss: 244.2242, Validation Accuracy: 0.5583\n",
            "Epoch 144/100, Loss: 44.7569, Validation Accuracy: 0.5145\n",
            "Epoch 145/100, Loss: 96.3673, Validation Accuracy: 0.6062\n",
            "Epoch 146/100, Loss: 142.3960, Validation Accuracy: 0.6271\n",
            "Epoch 147/100, Loss: 139.3405, Validation Accuracy: 0.5743\n",
            "Epoch 148/100, Loss: 184.2408, Validation Accuracy: 0.5314\n",
            "Epoch 149/100, Loss: 76.7522, Validation Accuracy: 0.5882\n",
            "Epoch 150/100, Loss: 83.4042, Validation Accuracy: 0.6261\n",
            "Epoch 151/100, Loss: 313.2843, Validation Accuracy: 0.6421\n",
            "Epoch 152/100, Loss: 91.0993, Validation Accuracy: 0.6072\n",
            "Epoch 153/100, Loss: 88.0938, Validation Accuracy: 0.6540\n",
            "Epoch 154/100, Loss: 49.9912, Validation Accuracy: 0.4985\n",
            "Epoch 155/100, Loss: 129.4899, Validation Accuracy: 0.5813\n",
            "Epoch 156/100, Loss: 133.4449, Validation Accuracy: 0.6740\n",
            "Epoch 157/100, Loss: 197.2739, Validation Accuracy: 0.4487\n",
            "Epoch 158/100, Loss: 256.8666, Validation Accuracy: 0.5105\n",
            "Epoch 159/100, Loss: 42.9694, Validation Accuracy: 0.6780\n",
            "Epoch 160/100, Loss: 54.7115, Validation Accuracy: 0.6381\n",
            "Epoch 161/100, Loss: 131.3447, Validation Accuracy: 0.6481\n",
            "Epoch 162/100, Loss: 77.3850, Validation Accuracy: 0.6221\n",
            "Epoch 163/100, Loss: 251.2233, Validation Accuracy: 0.6261\n",
            "Epoch 164/100, Loss: 137.4669, Validation Accuracy: 0.6770\n",
            "Epoch 165/100, Loss: 109.9592, Validation Accuracy: 0.6421\n",
            "Epoch 166/100, Loss: 149.8852, Validation Accuracy: 0.6461\n",
            "Epoch 167/100, Loss: 97.7022, Validation Accuracy: 0.6740\n",
            "Epoch 168/100, Loss: 70.1435, Validation Accuracy: 0.6411\n",
            "Epoch 169/100, Loss: 212.7630, Validation Accuracy: 0.6730\n",
            "Epoch 170/100, Loss: 120.4890, Validation Accuracy: 0.5125\n",
            "Epoch 171/100, Loss: 94.7284, Validation Accuracy: 0.6580\n",
            "Epoch 172/100, Loss: 83.8398, Validation Accuracy: 0.6790\n",
            "Epoch 173/100, Loss: 76.1742, Validation Accuracy: 0.5095\n",
            "Epoch 174/100, Loss: 104.5916, Validation Accuracy: 0.6461\n",
            "Epoch 175/100, Loss: 213.3508, Validation Accuracy: 0.5603\n",
            "Epoch 176/100, Loss: 202.5281, Validation Accuracy: 0.6481\n",
            "Epoch 177/100, Loss: 67.6041, Validation Accuracy: 0.6491\n",
            "Epoch 178/100, Loss: 108.7942, Validation Accuracy: 0.5942\n",
            "Epoch 179/100, Loss: 116.0824, Validation Accuracy: 0.5932\n",
            "Epoch 180/100, Loss: 73.2069, Validation Accuracy: 0.5982\n",
            "Epoch 181/100, Loss: 170.7239, Validation Accuracy: 0.5155\n",
            "Epoch 182/100, Loss: 121.9239, Validation Accuracy: 0.6281\n",
            "Epoch 183/100, Loss: 62.7957, Validation Accuracy: 0.5932\n",
            "Epoch 184/100, Loss: 141.6561, Validation Accuracy: 0.6610\n",
            "Epoch 185/100, Loss: 95.5114, Validation Accuracy: 0.6181\n",
            "Epoch 186/100, Loss: 75.3201, Validation Accuracy: 0.6381\n",
            "Epoch 187/100, Loss: 191.6058, Validation Accuracy: 0.6570\n",
            "Epoch 188/100, Loss: 182.8327, Validation Accuracy: 0.5763\n",
            "Epoch 189/100, Loss: 100.9615, Validation Accuracy: 0.4985\n",
            "Epoch 190/100, Loss: 312.5108, Validation Accuracy: 0.6341\n",
            "Epoch 191/100, Loss: 270.6831, Validation Accuracy: 0.6441\n",
            "Epoch 192/100, Loss: 35.4214, Validation Accuracy: 0.6680\n",
            "Epoch 193/100, Loss: 63.6647, Validation Accuracy: 0.6381\n",
            "Epoch 194/100, Loss: 95.5123, Validation Accuracy: 0.5713\n",
            "Epoch 195/100, Loss: 194.5464, Validation Accuracy: 0.5543\n",
            "Epoch 196/100, Loss: 45.3702, Validation Accuracy: 0.6461\n",
            "Epoch 197/100, Loss: 230.8456, Validation Accuracy: 0.6750\n",
            "Epoch 198/100, Loss: 124.7574, Validation Accuracy: 0.6201\n",
            "Epoch 199/100, Loss: 48.6624, Validation Accuracy: 0.6032\n",
            "Epoch 200/100, Loss: 125.3424, Validation Accuracy: 0.5304\n",
            "Reward for Child Model: 0.3075128065920478\n",
            "Child_6:  {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, [1, 3, 3, 0, 3, 0, 1, 2, 3, 0, 2, 1, 0, 3, 0], 0.3075128065920478\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 36, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(60, 64, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(124, 64, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(188, 64, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=54208, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 28, 22]             528\n",
            "       BatchNorm2d-2           [-1, 24, 28, 22]              48\n",
            "            Conv2d-3           [-1, 36, 26, 18]          12,996\n",
            "       BatchNorm2d-4           [-1, 36, 26, 18]              72\n",
            "              ReLU-5           [-1, 36, 26, 18]               0\n",
            "            Conv2d-6           [-1, 64, 26, 18]          57,664\n",
            "       BatchNorm2d-7           [-1, 64, 26, 18]             128\n",
            "              ReLU-8           [-1, 64, 26, 18]               0\n",
            "            Conv2d-9           [-1, 64, 28, 20]          23,872\n",
            "      BatchNorm2d-10           [-1, 64, 28, 20]             128\n",
            "             ReLU-11           [-1, 64, 28, 20]               0\n",
            "           Conv2d-12           [-1, 64, 28, 16]          84,288\n",
            "      BatchNorm2d-13           [-1, 64, 28, 16]             128\n",
            "             ReLU-14           [-1, 64, 28, 16]               0\n",
            "           Linear-15                    [-1, 7]         379,463\n",
            "================================================================\n",
            "Total params: 559,315\n",
            "Trainable params: 559,315\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.77\n",
            "Params size (MB): 2.13\n",
            "Estimated Total Size (MB): 4.92\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 7.5983, Validation Accuracy: 0.5673\n",
            "Epoch 2/100, Loss: 3.6503, Validation Accuracy: 0.5663\n",
            "Epoch 3/100, Loss: 1.2515, Validation Accuracy: 0.6630\n",
            "Epoch 4/100, Loss: 0.7846, Validation Accuracy: 0.6710\n",
            "Epoch 5/100, Loss: 55.4719, Validation Accuracy: 0.6730\n",
            "Epoch 6/100, Loss: 20.7929, Validation Accuracy: 0.5184\n",
            "Epoch 7/100, Loss: 5.1456, Validation Accuracy: 0.5902\n",
            "Epoch 8/100, Loss: 3.1323, Validation Accuracy: 0.6570\n",
            "Epoch 9/100, Loss: 2.1929, Validation Accuracy: 0.6451\n",
            "Epoch 10/100, Loss: 4.0974, Validation Accuracy: 0.5803\n",
            "Epoch 11/100, Loss: 3.4583, Validation Accuracy: 0.5733\n",
            "Epoch 12/100, Loss: 109.2591, Validation Accuracy: 0.6261\n",
            "Epoch 13/100, Loss: 42.6529, Validation Accuracy: 0.6510\n",
            "Epoch 14/100, Loss: 8.5170, Validation Accuracy: 0.5414\n",
            "Epoch 15/100, Loss: 15.0555, Validation Accuracy: 0.6670\n",
            "Epoch 16/100, Loss: 2.7598, Validation Accuracy: 0.5484\n",
            "Epoch 17/100, Loss: 2.6611, Validation Accuracy: 0.5703\n",
            "Epoch 18/100, Loss: 2.5065, Validation Accuracy: 0.5842\n",
            "Epoch 19/100, Loss: 31.7017, Validation Accuracy: 0.5165\n",
            "Epoch 20/100, Loss: 21.5104, Validation Accuracy: 0.3151\n",
            "Epoch 21/100, Loss: 4.4071, Validation Accuracy: 0.6062\n",
            "Epoch 22/100, Loss: 3.8052, Validation Accuracy: 0.6550\n",
            "Epoch 23/100, Loss: 4.8828, Validation Accuracy: 0.5065\n",
            "Epoch 24/100, Loss: 3.5808, Validation Accuracy: 0.6391\n",
            "Epoch 25/100, Loss: 7.3685, Validation Accuracy: 0.5364\n",
            "Epoch 26/100, Loss: 4.8901, Validation Accuracy: 0.6122\n",
            "Epoch 27/100, Loss: 6.3459, Validation Accuracy: 0.6510\n",
            "Epoch 28/100, Loss: 9.0300, Validation Accuracy: 0.6510\n",
            "Epoch 29/100, Loss: 33.0516, Validation Accuracy: 0.5683\n",
            "Epoch 30/100, Loss: 22.3248, Validation Accuracy: 0.6780\n",
            "Epoch 31/100, Loss: 3.6172, Validation Accuracy: 0.5773\n",
            "Epoch 32/100, Loss: 6.0551, Validation Accuracy: 0.6820\n",
            "Epoch 33/100, Loss: 7.2650, Validation Accuracy: 0.4626\n",
            "Epoch 34/100, Loss: 30.2400, Validation Accuracy: 0.3639\n",
            "Epoch 35/100, Loss: 45.3166, Validation Accuracy: 0.6431\n",
            "Epoch 36/100, Loss: 4.5350, Validation Accuracy: 0.6142\n",
            "Epoch 37/100, Loss: 6.6551, Validation Accuracy: 0.6540\n",
            "Epoch 38/100, Loss: 5.4042, Validation Accuracy: 0.6740\n",
            "Epoch 39/100, Loss: 8.6327, Validation Accuracy: 0.5583\n",
            "Epoch 40/100, Loss: 43.7906, Validation Accuracy: 0.5942\n",
            "Epoch 41/100, Loss: 26.9714, Validation Accuracy: 0.6700\n",
            "Epoch 42/100, Loss: 18.5783, Validation Accuracy: 0.6002\n",
            "Epoch 43/100, Loss: 6.6814, Validation Accuracy: 0.4915\n",
            "Epoch 44/100, Loss: 12.5406, Validation Accuracy: 0.6162\n",
            "Epoch 45/100, Loss: 15.7799, Validation Accuracy: 0.6381\n",
            "Epoch 46/100, Loss: 7.5442, Validation Accuracy: 0.4835\n",
            "Epoch 47/100, Loss: 31.0513, Validation Accuracy: 0.5145\n",
            "Epoch 48/100, Loss: 19.5261, Validation Accuracy: 0.1645\n",
            "Epoch 49/100, Loss: 31.5955, Validation Accuracy: 0.6132\n",
            "Epoch 50/100, Loss: 8.7354, Validation Accuracy: 0.5972\n",
            "Epoch 51/100, Loss: 4.7571, Validation Accuracy: 0.4845\n",
            "Epoch 52/100, Loss: 13.6404, Validation Accuracy: 0.6122\n",
            "Epoch 53/100, Loss: 20.3903, Validation Accuracy: 0.5912\n",
            "Epoch 54/100, Loss: 26.5548, Validation Accuracy: 0.5773\n",
            "Epoch 55/100, Loss: 12.8212, Validation Accuracy: 0.6132\n",
            "Epoch 56/100, Loss: 29.1538, Validation Accuracy: 0.5444\n",
            "Epoch 57/100, Loss: 4.6060, Validation Accuracy: 0.4806\n",
            "Epoch 58/100, Loss: 6.0105, Validation Accuracy: 0.6291\n",
            "Epoch 59/100, Loss: 9.9012, Validation Accuracy: 0.4955\n",
            "Epoch 60/100, Loss: 9.0483, Validation Accuracy: 0.6740\n",
            "Epoch 61/100, Loss: 8.0918, Validation Accuracy: 0.5842\n",
            "Epoch 62/100, Loss: 16.0394, Validation Accuracy: 0.6600\n",
            "Epoch 63/100, Loss: 7.0400, Validation Accuracy: 0.4696\n",
            "Epoch 64/100, Loss: 11.3689, Validation Accuracy: 0.5713\n",
            "Epoch 65/100, Loss: 33.2795, Validation Accuracy: 0.5484\n",
            "Epoch 66/100, Loss: 22.2949, Validation Accuracy: 0.5842\n",
            "Epoch 67/100, Loss: 8.5886, Validation Accuracy: 0.5952\n",
            "Epoch 68/100, Loss: 15.9808, Validation Accuracy: 0.3470\n",
            "Epoch 69/100, Loss: 4.6785, Validation Accuracy: 0.6411\n",
            "Epoch 70/100, Loss: 12.0688, Validation Accuracy: 0.5454\n",
            "Epoch 71/100, Loss: 26.5054, Validation Accuracy: 0.6461\n",
            "Epoch 72/100, Loss: 7.8639, Validation Accuracy: 0.6361\n",
            "Epoch 73/100, Loss: 26.1084, Validation Accuracy: 0.6550\n",
            "Epoch 74/100, Loss: 39.4781, Validation Accuracy: 0.5494\n",
            "Epoch 75/100, Loss: 10.8413, Validation Accuracy: 0.6650\n",
            "Epoch 76/100, Loss: 21.4429, Validation Accuracy: 0.5474\n",
            "Epoch 77/100, Loss: 7.4701, Validation Accuracy: 0.6331\n",
            "Epoch 78/100, Loss: 11.0973, Validation Accuracy: 0.6421\n",
            "Epoch 79/100, Loss: 15.9639, Validation Accuracy: 0.6580\n",
            "Epoch 80/100, Loss: 38.7703, Validation Accuracy: 0.5713\n",
            "Epoch 81/100, Loss: 6.1967, Validation Accuracy: 0.6201\n",
            "Epoch 82/100, Loss: 22.2902, Validation Accuracy: 0.6800\n",
            "Epoch 83/100, Loss: 34.9044, Validation Accuracy: 0.6421\n",
            "Epoch 84/100, Loss: 14.6487, Validation Accuracy: 0.4796\n",
            "Epoch 85/100, Loss: 38.9086, Validation Accuracy: 0.6142\n",
            "Epoch 86/100, Loss: 19.6335, Validation Accuracy: 0.4656\n",
            "Epoch 87/100, Loss: 4.9891, Validation Accuracy: 0.5663\n",
            "Epoch 88/100, Loss: 20.1913, Validation Accuracy: 0.6211\n",
            "Epoch 89/100, Loss: 28.2800, Validation Accuracy: 0.6530\n",
            "Epoch 90/100, Loss: 15.3546, Validation Accuracy: 0.6780\n",
            "Epoch 91/100, Loss: 8.6733, Validation Accuracy: 0.5862\n",
            "Epoch 92/100, Loss: 49.5617, Validation Accuracy: 0.5663\n",
            "Epoch 93/100, Loss: 9.4006, Validation Accuracy: 0.5444\n",
            "Epoch 94/100, Loss: 8.2768, Validation Accuracy: 0.6670\n",
            "Epoch 95/100, Loss: 9.9962, Validation Accuracy: 0.6281\n",
            "Epoch 96/100, Loss: 9.9718, Validation Accuracy: 0.6371\n",
            "Epoch 97/100, Loss: 5.0926, Validation Accuracy: 0.6112\n",
            "Epoch 98/100, Loss: 15.3442, Validation Accuracy: 0.5304\n",
            "Epoch 99/100, Loss: 86.7146, Validation Accuracy: 0.5264\n",
            "Epoch 100/100, Loss: 33.0738, Validation Accuracy: 0.6670\n",
            "Epoch 101/100, Loss: 22.8252, Validation Accuracy: 0.6351\n",
            "Epoch 102/100, Loss: 18.8726, Validation Accuracy: 0.5444\n",
            "Epoch 103/100, Loss: 17.8156, Validation Accuracy: 0.6540\n",
            "Epoch 104/100, Loss: 9.5591, Validation Accuracy: 0.6451\n",
            "Epoch 105/100, Loss: 7.6277, Validation Accuracy: 0.6052\n",
            "Epoch 106/100, Loss: 22.9756, Validation Accuracy: 0.3908\n",
            "Epoch 107/100, Loss: 11.5193, Validation Accuracy: 0.6341\n",
            "Epoch 108/100, Loss: 8.0446, Validation Accuracy: 0.5364\n",
            "Epoch 109/100, Loss: 24.5736, Validation Accuracy: 0.6052\n",
            "Epoch 110/100, Loss: 14.6028, Validation Accuracy: 0.5474\n",
            "Epoch 111/100, Loss: 13.3849, Validation Accuracy: 0.6062\n",
            "Epoch 112/100, Loss: 12.6297, Validation Accuracy: 0.5563\n",
            "Epoch 113/100, Loss: 6.6345, Validation Accuracy: 0.6520\n",
            "Epoch 114/100, Loss: 22.8523, Validation Accuracy: 0.4646\n",
            "Epoch 115/100, Loss: 6.6401, Validation Accuracy: 0.5494\n",
            "Epoch 116/100, Loss: 52.5447, Validation Accuracy: 0.4357\n",
            "Epoch 117/100, Loss: 28.0314, Validation Accuracy: 0.4287\n",
            "Epoch 118/100, Loss: 7.2055, Validation Accuracy: 0.5773\n",
            "Epoch 119/100, Loss: 4.6781, Validation Accuracy: 0.5613\n",
            "Epoch 120/100, Loss: 28.0117, Validation Accuracy: 0.4427\n",
            "Epoch 121/100, Loss: 33.1347, Validation Accuracy: 0.4855\n",
            "Epoch 122/100, Loss: 24.7786, Validation Accuracy: 0.6231\n",
            "Epoch 123/100, Loss: 16.7294, Validation Accuracy: 0.6261\n",
            "Epoch 124/100, Loss: 26.6783, Validation Accuracy: 0.6221\n",
            "Epoch 125/100, Loss: 6.7233, Validation Accuracy: 0.6550\n",
            "Epoch 126/100, Loss: 4.3333, Validation Accuracy: 0.5882\n",
            "Epoch 127/100, Loss: 11.0387, Validation Accuracy: 0.5683\n",
            "Epoch 128/100, Loss: 24.6458, Validation Accuracy: 0.6431\n",
            "Epoch 129/100, Loss: 33.3804, Validation Accuracy: 0.6082\n",
            "Epoch 130/100, Loss: 39.9260, Validation Accuracy: 0.6181\n",
            "Epoch 131/100, Loss: 11.5091, Validation Accuracy: 0.6162\n",
            "Epoch 132/100, Loss: 19.9755, Validation Accuracy: 0.3041\n",
            "Epoch 133/100, Loss: 6.7479, Validation Accuracy: 0.6510\n",
            "Epoch 134/100, Loss: 27.8076, Validation Accuracy: 0.6670\n",
            "Epoch 135/100, Loss: 26.6015, Validation Accuracy: 0.5484\n",
            "Epoch 136/100, Loss: 17.1162, Validation Accuracy: 0.6181\n",
            "Epoch 137/100, Loss: 21.3480, Validation Accuracy: 0.5284\n",
            "Epoch 138/100, Loss: 15.0281, Validation Accuracy: 0.6381\n",
            "Epoch 139/100, Loss: 13.6655, Validation Accuracy: 0.6062\n",
            "Epoch 140/100, Loss: 24.9974, Validation Accuracy: 0.5115\n",
            "Epoch 141/100, Loss: 28.4779, Validation Accuracy: 0.4885\n",
            "Epoch 142/100, Loss: 16.8226, Validation Accuracy: 0.6590\n",
            "Epoch 143/100, Loss: 8.4933, Validation Accuracy: 0.6132\n",
            "Epoch 144/100, Loss: 15.6355, Validation Accuracy: 0.5464\n",
            "Epoch 145/100, Loss: 13.7596, Validation Accuracy: 0.5813\n",
            "Epoch 146/100, Loss: 17.1425, Validation Accuracy: 0.6510\n",
            "Epoch 147/100, Loss: 11.2161, Validation Accuracy: 0.4915\n",
            "Epoch 148/100, Loss: 10.1149, Validation Accuracy: 0.6560\n",
            "Epoch 149/100, Loss: 39.0597, Validation Accuracy: 0.6241\n",
            "Epoch 150/100, Loss: 10.8341, Validation Accuracy: 0.6032\n",
            "Epoch 151/100, Loss: 15.7293, Validation Accuracy: 0.6301\n",
            "Epoch 152/100, Loss: 60.7909, Validation Accuracy: 0.6580\n",
            "Epoch 153/100, Loss: 10.2856, Validation Accuracy: 0.4317\n",
            "Epoch 154/100, Loss: 15.1704, Validation Accuracy: 0.6102\n",
            "Epoch 155/100, Loss: 13.1709, Validation Accuracy: 0.5972\n",
            "Epoch 156/100, Loss: 4.3236, Validation Accuracy: 0.6032\n",
            "Epoch 157/100, Loss: 15.2012, Validation Accuracy: 0.6780\n",
            "Epoch 158/100, Loss: 13.9047, Validation Accuracy: 0.4267\n",
            "Epoch 159/100, Loss: 6.0431, Validation Accuracy: 0.6889\n",
            "Epoch 160/100, Loss: 52.8969, Validation Accuracy: 0.6152\n",
            "Epoch 161/100, Loss: 6.8227, Validation Accuracy: 0.6241\n",
            "Epoch 162/100, Loss: 12.5178, Validation Accuracy: 0.5055\n",
            "Epoch 163/100, Loss: 5.3627, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 9.3827, Validation Accuracy: 0.5942\n",
            "Epoch 165/100, Loss: 10.1572, Validation Accuracy: 0.6201\n",
            "Epoch 166/100, Loss: 13.7315, Validation Accuracy: 0.4945\n",
            "Epoch 167/100, Loss: 11.8163, Validation Accuracy: 0.6700\n",
            "Epoch 168/100, Loss: 15.8052, Validation Accuracy: 0.4766\n",
            "Epoch 169/100, Loss: 6.8966, Validation Accuracy: 0.5065\n",
            "Epoch 170/100, Loss: 8.0761, Validation Accuracy: 0.4158\n",
            "Epoch 171/100, Loss: 111.6095, Validation Accuracy: 0.5793\n",
            "Epoch 172/100, Loss: 25.7165, Validation Accuracy: 0.6132\n",
            "Epoch 173/100, Loss: 11.6348, Validation Accuracy: 0.6321\n",
            "Epoch 174/100, Loss: 7.4931, Validation Accuracy: 0.6560\n",
            "Epoch 175/100, Loss: 10.8185, Validation Accuracy: 0.5334\n",
            "Epoch 176/100, Loss: 6.6240, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 5.0829, Validation Accuracy: 0.6401\n",
            "Epoch 178/100, Loss: 12.3934, Validation Accuracy: 0.5533\n",
            "Epoch 179/100, Loss: 29.8671, Validation Accuracy: 0.5613\n",
            "Epoch 180/100, Loss: 68.0651, Validation Accuracy: 0.6550\n",
            "Epoch 181/100, Loss: 15.8578, Validation Accuracy: 0.6421\n",
            "Epoch 182/100, Loss: 8.9546, Validation Accuracy: 0.6022\n",
            "Epoch 183/100, Loss: 14.7965, Validation Accuracy: 0.4516\n",
            "Epoch 184/100, Loss: 3.6163, Validation Accuracy: 0.6730\n",
            "Epoch 185/100, Loss: 5.7899, Validation Accuracy: 0.5773\n",
            "Epoch 186/100, Loss: 15.2346, Validation Accuracy: 0.5922\n",
            "Epoch 187/100, Loss: 8.3703, Validation Accuracy: 0.4816\n",
            "Epoch 188/100, Loss: 3.0660, Validation Accuracy: 0.5852\n",
            "Epoch 189/100, Loss: 21.5363, Validation Accuracy: 0.3549\n",
            "Epoch 190/100, Loss: 4.2792, Validation Accuracy: 0.6800\n",
            "Epoch 191/100, Loss: 16.5527, Validation Accuracy: 0.5912\n",
            "Epoch 192/100, Loss: 14.2584, Validation Accuracy: 0.6321\n",
            "Epoch 193/100, Loss: 14.5247, Validation Accuracy: 0.5783\n",
            "Epoch 194/100, Loss: 5.8740, Validation Accuracy: 0.6162\n",
            "Epoch 195/100, Loss: 24.8838, Validation Accuracy: 0.6241\n",
            "Epoch 196/100, Loss: 20.6717, Validation Accuracy: 0.6142\n",
            "Epoch 197/100, Loss: 18.6552, Validation Accuracy: 0.5922\n",
            "Epoch 198/100, Loss: 37.2708, Validation Accuracy: 0.6610\n",
            "Epoch 199/100, Loss: 12.1153, Validation Accuracy: 0.5912\n",
            "Epoch 200/100, Loss: 68.2410, Validation Accuracy: 0.6271\n",
            "Reward for Child Model: 0.2888269978917027\n",
            "Child_7:  {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, [0, 3, 0, 1, 2, 1, 1, 2, 3, 0, 1, 3, 0, 3, 3], 0.2888269978917027\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 48, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(72, 64, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(64, 48, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(136, 36, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=65472, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 22, 24]           2,544\n",
            "       BatchNorm2d-2           [-1, 24, 22, 24]              48\n",
            "            Conv2d-3           [-1, 48, 18, 22]          17,328\n",
            "       BatchNorm2d-4           [-1, 48, 18, 22]              96\n",
            "              ReLU-5           [-1, 48, 18, 22]               0\n",
            "            Conv2d-6           [-1, 64, 22, 22]          13,888\n",
            "       BatchNorm2d-7           [-1, 64, 22, 22]             128\n",
            "              ReLU-8           [-1, 64, 22, 22]               0\n",
            "            Conv2d-9           [-1, 48, 22, 16]          21,552\n",
            "      BatchNorm2d-10           [-1, 48, 22, 16]              96\n",
            "             ReLU-11           [-1, 48, 22, 16]               0\n",
            "           Conv2d-12           [-1, 36, 20, 18]         102,852\n",
            "      BatchNorm2d-13           [-1, 36, 20, 18]              72\n",
            "             ReLU-14           [-1, 36, 20, 18]               0\n",
            "           Linear-15                    [-1, 7]         458,311\n",
            "================================================================\n",
            "Total params: 616,915\n",
            "Trainable params: 616,915\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.02\n",
            "Params size (MB): 2.35\n",
            "Estimated Total Size (MB): 4.38\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 7.8111, Validation Accuracy: 0.5224\n",
            "Epoch 2/100, Loss: 1.5323, Validation Accuracy: 0.0518\n",
            "Epoch 3/100, Loss: 224.9717, Validation Accuracy: 0.3470\n",
            "Epoch 4/100, Loss: 11.7592, Validation Accuracy: 0.2353\n",
            "Epoch 5/100, Loss: 2.5177, Validation Accuracy: 0.6600\n",
            "Epoch 6/100, Loss: 1.5037, Validation Accuracy: 0.6221\n",
            "Epoch 7/100, Loss: 1.6179, Validation Accuracy: 0.5364\n",
            "Epoch 8/100, Loss: 0.4528, Validation Accuracy: 0.6241\n",
            "Epoch 9/100, Loss: 1.0298, Validation Accuracy: 0.6261\n",
            "Epoch 10/100, Loss: 1.3359, Validation Accuracy: 0.5922\n",
            "Epoch 11/100, Loss: 117.9023, Validation Accuracy: 0.6102\n",
            "Epoch 12/100, Loss: 4.5179, Validation Accuracy: 0.6919\n",
            "Epoch 13/100, Loss: 3.5613, Validation Accuracy: 0.3330\n",
            "Epoch 14/100, Loss: 5.8714, Validation Accuracy: 0.5344\n",
            "Epoch 15/100, Loss: 1.1667, Validation Accuracy: 0.6142\n",
            "Epoch 16/100, Loss: 2.7437, Validation Accuracy: 0.6201\n",
            "Epoch 17/100, Loss: 1.7029, Validation Accuracy: 0.6421\n",
            "Epoch 18/100, Loss: 3.4367, Validation Accuracy: 0.4925\n",
            "Epoch 19/100, Loss: 1.8070, Validation Accuracy: 0.6780\n",
            "Epoch 20/100, Loss: 2.8100, Validation Accuracy: 0.5354\n",
            "Epoch 21/100, Loss: 43.5907, Validation Accuracy: 0.6191\n",
            "Epoch 22/100, Loss: 6.0271, Validation Accuracy: 0.4925\n",
            "Epoch 23/100, Loss: 2.4023, Validation Accuracy: 0.5115\n",
            "Epoch 24/100, Loss: 6.7357, Validation Accuracy: 0.6281\n",
            "Epoch 25/100, Loss: 3.0225, Validation Accuracy: 0.6142\n",
            "Epoch 26/100, Loss: 1.5728, Validation Accuracy: 0.6002\n",
            "Epoch 27/100, Loss: 6.3006, Validation Accuracy: 0.5573\n",
            "Epoch 28/100, Loss: 18.8702, Validation Accuracy: 0.5424\n",
            "Epoch 29/100, Loss: 44.1053, Validation Accuracy: 0.6022\n",
            "Epoch 30/100, Loss: 6.2744, Validation Accuracy: 0.5264\n",
            "Epoch 31/100, Loss: 2.5242, Validation Accuracy: 0.5882\n",
            "Epoch 32/100, Loss: 7.8671, Validation Accuracy: 0.6441\n",
            "Epoch 33/100, Loss: 3.5699, Validation Accuracy: 0.6500\n",
            "Epoch 34/100, Loss: 38.7182, Validation Accuracy: 0.6491\n",
            "Epoch 35/100, Loss: 18.1273, Validation Accuracy: 0.5633\n",
            "Epoch 36/100, Loss: 16.3496, Validation Accuracy: 0.6321\n",
            "Epoch 37/100, Loss: 29.5427, Validation Accuracy: 0.5593\n",
            "Epoch 38/100, Loss: 6.6020, Validation Accuracy: 0.6371\n",
            "Epoch 39/100, Loss: 2.2450, Validation Accuracy: 0.5573\n",
            "Epoch 40/100, Loss: 10.0973, Validation Accuracy: 0.3719\n",
            "Epoch 41/100, Loss: 7.0630, Validation Accuracy: 0.5593\n",
            "Epoch 42/100, Loss: 1.8938, Validation Accuracy: 0.6530\n",
            "Epoch 43/100, Loss: 25.6064, Validation Accuracy: 0.6580\n",
            "Epoch 44/100, Loss: 16.1557, Validation Accuracy: 0.2722\n",
            "Epoch 45/100, Loss: 8.3335, Validation Accuracy: 0.5653\n",
            "Epoch 46/100, Loss: 9.8288, Validation Accuracy: 0.5703\n",
            "Epoch 47/100, Loss: 42.7527, Validation Accuracy: 0.6181\n",
            "Epoch 48/100, Loss: 19.0030, Validation Accuracy: 0.6251\n",
            "Epoch 49/100, Loss: 3.0252, Validation Accuracy: 0.6441\n",
            "Epoch 50/100, Loss: 6.4988, Validation Accuracy: 0.6630\n",
            "Epoch 51/100, Loss: 4.1153, Validation Accuracy: 0.6321\n",
            "Epoch 52/100, Loss: 4.8888, Validation Accuracy: 0.6670\n",
            "Epoch 53/100, Loss: 127.7721, Validation Accuracy: 0.6002\n",
            "Epoch 54/100, Loss: 33.4902, Validation Accuracy: 0.0140\n",
            "Epoch 55/100, Loss: 16.5733, Validation Accuracy: 0.6102\n",
            "Epoch 56/100, Loss: 11.0522, Validation Accuracy: 0.1107\n",
            "Epoch 57/100, Loss: 2.3177, Validation Accuracy: 0.5025\n",
            "Epoch 58/100, Loss: 13.1236, Validation Accuracy: 0.6630\n",
            "Epoch 59/100, Loss: 33.2873, Validation Accuracy: 0.6560\n",
            "Epoch 60/100, Loss: 13.3745, Validation Accuracy: 0.6122\n",
            "Epoch 61/100, Loss: 7.0400, Validation Accuracy: 0.5693\n",
            "Epoch 62/100, Loss: 7.0026, Validation Accuracy: 0.6032\n",
            "Epoch 63/100, Loss: 374.4706, Validation Accuracy: 0.5823\n",
            "Epoch 64/100, Loss: 17.1699, Validation Accuracy: 0.5693\n",
            "Epoch 65/100, Loss: 10.0688, Validation Accuracy: 0.6341\n",
            "Epoch 66/100, Loss: 5.5525, Validation Accuracy: 0.4646\n",
            "Epoch 67/100, Loss: 3.3257, Validation Accuracy: 0.6122\n",
            "Epoch 68/100, Loss: 1.7485, Validation Accuracy: 0.4177\n",
            "Epoch 69/100, Loss: 4.2657, Validation Accuracy: 0.6122\n",
            "Epoch 70/100, Loss: 2.8717, Validation Accuracy: 0.5673\n",
            "Epoch 71/100, Loss: 5.6085, Validation Accuracy: 0.5573\n",
            "Epoch 72/100, Loss: 4.6827, Validation Accuracy: 0.5763\n",
            "Epoch 73/100, Loss: 3.6713, Validation Accuracy: 0.6132\n",
            "Epoch 74/100, Loss: 4.6671, Validation Accuracy: 0.5673\n",
            "Epoch 75/100, Loss: 30.5263, Validation Accuracy: 0.1864\n",
            "Epoch 76/100, Loss: 15.0667, Validation Accuracy: 0.6162\n",
            "Epoch 77/100, Loss: 10.3090, Validation Accuracy: 0.3978\n",
            "Epoch 78/100, Loss: 7.6169, Validation Accuracy: 0.6351\n",
            "Epoch 79/100, Loss: 9.9627, Validation Accuracy: 0.6610\n",
            "Epoch 80/100, Loss: 4.4813, Validation Accuracy: 0.6520\n",
            "Epoch 81/100, Loss: 4.9302, Validation Accuracy: 0.6790\n",
            "Epoch 82/100, Loss: 37.9905, Validation Accuracy: 0.5852\n",
            "Epoch 83/100, Loss: 41.6078, Validation Accuracy: 0.3470\n",
            "Epoch 84/100, Loss: 6.9571, Validation Accuracy: 0.6122\n",
            "Epoch 85/100, Loss: 4.5175, Validation Accuracy: 0.6281\n",
            "Epoch 86/100, Loss: 7.7612, Validation Accuracy: 0.5703\n",
            "Epoch 87/100, Loss: 8.8839, Validation Accuracy: 0.6839\n",
            "Epoch 88/100, Loss: 27.8109, Validation Accuracy: 0.3988\n",
            "Epoch 89/100, Loss: 3.4496, Validation Accuracy: 0.5404\n",
            "Epoch 90/100, Loss: 12.0097, Validation Accuracy: 0.6441\n",
            "Epoch 91/100, Loss: 4.4882, Validation Accuracy: 0.6790\n",
            "Epoch 92/100, Loss: 11.5295, Validation Accuracy: 0.6770\n",
            "Epoch 93/100, Loss: 33.7340, Validation Accuracy: 0.5563\n",
            "Epoch 94/100, Loss: 10.0404, Validation Accuracy: 0.5384\n",
            "Epoch 95/100, Loss: 6.8010, Validation Accuracy: 0.4796\n",
            "Epoch 96/100, Loss: 33.7052, Validation Accuracy: 0.5095\n",
            "Epoch 97/100, Loss: 63.6995, Validation Accuracy: 0.5703\n",
            "Epoch 98/100, Loss: 5.2012, Validation Accuracy: 0.6510\n",
            "Epoch 99/100, Loss: 7.4465, Validation Accuracy: 0.5942\n",
            "Epoch 100/100, Loss: 16.0833, Validation Accuracy: 0.6540\n",
            "Epoch 101/100, Loss: 8.3101, Validation Accuracy: 0.5563\n",
            "Epoch 102/100, Loss: 16.4121, Validation Accuracy: 0.2074\n",
            "Epoch 103/100, Loss: 81.8035, Validation Accuracy: 0.5862\n",
            "Epoch 104/100, Loss: 14.0567, Validation Accuracy: 0.5663\n",
            "Epoch 105/100, Loss: 10.8942, Validation Accuracy: 0.6042\n",
            "Epoch 106/100, Loss: 3.7769, Validation Accuracy: 0.5005\n",
            "Epoch 107/100, Loss: 21.7314, Validation Accuracy: 0.6530\n",
            "Epoch 108/100, Loss: 7.7134, Validation Accuracy: 0.5165\n",
            "Epoch 109/100, Loss: 12.4081, Validation Accuracy: 0.5693\n",
            "Epoch 110/100, Loss: 10.0499, Validation Accuracy: 0.6680\n",
            "Epoch 111/100, Loss: 11.9515, Validation Accuracy: 0.5454\n",
            "Epoch 112/100, Loss: 11.1697, Validation Accuracy: 0.6680\n",
            "Epoch 113/100, Loss: 24.6616, Validation Accuracy: 0.5683\n",
            "Epoch 114/100, Loss: 10.8441, Validation Accuracy: 0.6520\n",
            "Epoch 115/100, Loss: 4.0709, Validation Accuracy: 0.6421\n",
            "Epoch 116/100, Loss: 63.9352, Validation Accuracy: 0.6271\n",
            "Epoch 117/100, Loss: 5.3156, Validation Accuracy: 0.6560\n",
            "Epoch 118/100, Loss: 20.8654, Validation Accuracy: 0.6780\n",
            "Epoch 119/100, Loss: 7.2880, Validation Accuracy: 0.4128\n",
            "Epoch 120/100, Loss: 4.7729, Validation Accuracy: 0.5673\n",
            "Epoch 121/100, Loss: 11.8165, Validation Accuracy: 0.5962\n",
            "Epoch 122/100, Loss: 26.6529, Validation Accuracy: 0.6710\n",
            "Epoch 123/100, Loss: 8.4150, Validation Accuracy: 0.6181\n",
            "Epoch 124/100, Loss: 13.8593, Validation Accuracy: 0.6700\n",
            "Epoch 125/100, Loss: 46.1424, Validation Accuracy: 0.6720\n",
            "Epoch 126/100, Loss: 18.6895, Validation Accuracy: 0.6221\n",
            "Epoch 127/100, Loss: 12.4980, Validation Accuracy: 0.6560\n",
            "Epoch 128/100, Loss: 7.0422, Validation Accuracy: 0.6281\n",
            "Epoch 129/100, Loss: 14.3520, Validation Accuracy: 0.6311\n",
            "Epoch 130/100, Loss: 10.7474, Validation Accuracy: 0.5793\n",
            "Epoch 131/100, Loss: 4.2837, Validation Accuracy: 0.4576\n",
            "Epoch 132/100, Loss: 24.2234, Validation Accuracy: 0.5922\n",
            "Epoch 133/100, Loss: 30.7897, Validation Accuracy: 0.5633\n",
            "Epoch 134/100, Loss: 9.7857, Validation Accuracy: 0.4457\n",
            "Epoch 135/100, Loss: 3.5726, Validation Accuracy: 0.6162\n",
            "Epoch 136/100, Loss: 27.2471, Validation Accuracy: 0.5394\n",
            "Epoch 137/100, Loss: 36.4640, Validation Accuracy: 0.4646\n",
            "Epoch 138/100, Loss: 32.9197, Validation Accuracy: 0.6520\n",
            "Epoch 139/100, Loss: 7.5993, Validation Accuracy: 0.6102\n",
            "Epoch 140/100, Loss: 12.4025, Validation Accuracy: 0.4985\n",
            "Epoch 141/100, Loss: 13.7825, Validation Accuracy: 0.3878\n",
            "Epoch 142/100, Loss: 11.7723, Validation Accuracy: 0.6271\n",
            "Epoch 143/100, Loss: 19.7756, Validation Accuracy: 0.6481\n",
            "Epoch 144/100, Loss: 8.6943, Validation Accuracy: 0.5992\n",
            "Epoch 145/100, Loss: 17.2884, Validation Accuracy: 0.6381\n",
            "Epoch 146/100, Loss: 28.6508, Validation Accuracy: 0.5713\n",
            "Epoch 147/100, Loss: 11.5477, Validation Accuracy: 0.5464\n",
            "Epoch 148/100, Loss: 13.1509, Validation Accuracy: 0.5813\n",
            "Epoch 149/100, Loss: 9.7761, Validation Accuracy: 0.1476\n",
            "Epoch 150/100, Loss: 33.6304, Validation Accuracy: 0.6530\n",
            "Epoch 151/100, Loss: 19.0943, Validation Accuracy: 0.5982\n",
            "Epoch 152/100, Loss: 11.3035, Validation Accuracy: 0.5653\n",
            "Epoch 153/100, Loss: 7.5014, Validation Accuracy: 0.5613\n",
            "Epoch 154/100, Loss: 12.2078, Validation Accuracy: 0.6291\n",
            "Epoch 155/100, Loss: 14.4098, Validation Accuracy: 0.5713\n",
            "Epoch 156/100, Loss: 20.5838, Validation Accuracy: 0.5623\n",
            "Epoch 157/100, Loss: 91.7684, Validation Accuracy: 0.6311\n",
            "Epoch 158/100, Loss: 11.4019, Validation Accuracy: 0.6540\n",
            "Epoch 159/100, Loss: 9.0542, Validation Accuracy: 0.6770\n",
            "Epoch 160/100, Loss: 8.7316, Validation Accuracy: 0.5194\n",
            "Epoch 161/100, Loss: 10.5135, Validation Accuracy: 0.5763\n",
            "Epoch 162/100, Loss: 15.5571, Validation Accuracy: 0.5424\n",
            "Epoch 163/100, Loss: 22.0224, Validation Accuracy: 0.5842\n",
            "Epoch 164/100, Loss: 22.9418, Validation Accuracy: 0.5763\n",
            "Epoch 165/100, Loss: 4.9571, Validation Accuracy: 0.6261\n",
            "Epoch 166/100, Loss: 13.1997, Validation Accuracy: 0.6042\n",
            "Epoch 167/100, Loss: 11.2515, Validation Accuracy: 0.6630\n",
            "Epoch 168/100, Loss: 35.1169, Validation Accuracy: 0.6720\n",
            "Epoch 169/100, Loss: 36.4181, Validation Accuracy: 0.5474\n",
            "Epoch 170/100, Loss: 13.1078, Validation Accuracy: 0.6042\n",
            "Epoch 171/100, Loss: 10.1667, Validation Accuracy: 0.5962\n",
            "Epoch 172/100, Loss: 10.9285, Validation Accuracy: 0.5045\n",
            "Epoch 173/100, Loss: 11.4121, Validation Accuracy: 0.5803\n",
            "Epoch 174/100, Loss: 12.2571, Validation Accuracy: 0.4616\n",
            "Epoch 175/100, Loss: 24.7654, Validation Accuracy: 0.6301\n",
            "Epoch 176/100, Loss: 12.3831, Validation Accuracy: 0.5922\n",
            "Epoch 177/100, Loss: 10.9417, Validation Accuracy: 0.6431\n",
            "Epoch 178/100, Loss: 9.1817, Validation Accuracy: 0.5125\n",
            "Epoch 179/100, Loss: 14.5639, Validation Accuracy: 0.6281\n",
            "Epoch 180/100, Loss: 21.0558, Validation Accuracy: 0.5533\n",
            "Epoch 181/100, Loss: 20.7468, Validation Accuracy: 0.5135\n",
            "Epoch 182/100, Loss: 19.2852, Validation Accuracy: 0.5513\n",
            "Epoch 183/100, Loss: 15.2861, Validation Accuracy: 0.5304\n",
            "Epoch 184/100, Loss: 401.1331, Validation Accuracy: 0.5932\n",
            "Epoch 185/100, Loss: 15.4302, Validation Accuracy: 0.5733\n",
            "Epoch 186/100, Loss: 7.5729, Validation Accuracy: 0.5683\n",
            "Epoch 187/100, Loss: 7.7360, Validation Accuracy: 0.6152\n",
            "Epoch 188/100, Loss: 3.7691, Validation Accuracy: 0.6421\n",
            "Epoch 189/100, Loss: 5.5620, Validation Accuracy: 0.6361\n",
            "Epoch 190/100, Loss: 10.7056, Validation Accuracy: 0.6102\n",
            "Epoch 191/100, Loss: 9.2572, Validation Accuracy: 0.6630\n",
            "Epoch 192/100, Loss: 12.4798, Validation Accuracy: 0.5264\n",
            "Epoch 193/100, Loss: 3.4877, Validation Accuracy: 0.6800\n",
            "Epoch 194/100, Loss: 10.8026, Validation Accuracy: 0.5892\n",
            "Epoch 195/100, Loss: 10.5610, Validation Accuracy: 0.6102\n",
            "Epoch 196/100, Loss: 16.5033, Validation Accuracy: 0.6162\n",
            "Epoch 197/100, Loss: 14.4744, Validation Accuracy: 0.6152\n",
            "Epoch 198/100, Loss: 13.5380, Validation Accuracy: 0.3639\n",
            "Epoch 199/100, Loss: 19.5473, Validation Accuracy: 0.6152\n",
            "Epoch 200/100, Loss: 38.1443, Validation Accuracy: 0.5204\n",
            "Reward for Child Model: 0.23391745283746496\n",
            "Child_8:  {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, [3, 2, 0, 2, 1, 2, 0, 1, 3, 0, 3, 2, 1, 3, 1], 0.23391745283746496\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 48, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(60, 64, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=126720, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 24, 24]           1,824\n",
            "       BatchNorm2d-2           [-1, 24, 24, 24]              48\n",
            "            Conv2d-3           [-1, 36, 24, 18]           6,084\n",
            "       BatchNorm2d-4           [-1, 36, 24, 18]              72\n",
            "              ReLU-5           [-1, 36, 24, 18]               0\n",
            "            Conv2d-6           [-1, 48, 20, 16]          25,968\n",
            "       BatchNorm2d-7           [-1, 48, 20, 16]              96\n",
            "              ReLU-8           [-1, 48, 20, 16]               0\n",
            "            Conv2d-9           [-1, 24, 24, 24]           1,752\n",
            "      BatchNorm2d-10           [-1, 24, 24, 24]              48\n",
            "             ReLU-11           [-1, 24, 24, 24]               0\n",
            "           Conv2d-12           [-1, 64, 22, 18]          80,704\n",
            "      BatchNorm2d-13           [-1, 64, 22, 18]             128\n",
            "             ReLU-14           [-1, 64, 22, 18]               0\n",
            "           Linear-15                    [-1, 7]         887,047\n",
            "================================================================\n",
            "Total params: 1,003,771\n",
            "Trainable params: 1,003,771\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.81\n",
            "Params size (MB): 3.83\n",
            "Estimated Total Size (MB): 5.65\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 28.1539, Validation Accuracy: 0.5663\n",
            "Epoch 2/100, Loss: 22.3817, Validation Accuracy: 0.3619\n",
            "Epoch 3/100, Loss: 21.7791, Validation Accuracy: 0.4596\n",
            "Epoch 4/100, Loss: 13.3351, Validation Accuracy: 0.5862\n",
            "Epoch 5/100, Loss: 46.1152, Validation Accuracy: 0.4885\n",
            "Epoch 6/100, Loss: 117.8849, Validation Accuracy: 0.5902\n",
            "Epoch 7/100, Loss: 18.7432, Validation Accuracy: 0.5992\n",
            "Epoch 8/100, Loss: 15.1525, Validation Accuracy: 0.6481\n",
            "Epoch 9/100, Loss: 89.0266, Validation Accuracy: 0.6461\n",
            "Epoch 10/100, Loss: 49.7775, Validation Accuracy: 0.6271\n",
            "Epoch 11/100, Loss: 1125.0251, Validation Accuracy: 0.1107\n",
            "Epoch 12/100, Loss: 24.8367, Validation Accuracy: 0.6491\n",
            "Epoch 13/100, Loss: 9.1649, Validation Accuracy: 0.6331\n",
            "Epoch 14/100, Loss: 7.1144, Validation Accuracy: 0.6191\n",
            "Epoch 15/100, Loss: 7.7803, Validation Accuracy: 0.6221\n",
            "Epoch 16/100, Loss: 4.2574, Validation Accuracy: 0.6381\n",
            "Epoch 17/100, Loss: 6.8887, Validation Accuracy: 0.6032\n",
            "Epoch 18/100, Loss: 5.7246, Validation Accuracy: 0.4616\n",
            "Epoch 19/100, Loss: 11.6096, Validation Accuracy: 0.3190\n",
            "Epoch 20/100, Loss: 6.5855, Validation Accuracy: 0.5194\n",
            "Epoch 21/100, Loss: 67.0057, Validation Accuracy: 0.5962\n",
            "Epoch 22/100, Loss: 34.5998, Validation Accuracy: 0.4138\n",
            "Epoch 23/100, Loss: 50.4664, Validation Accuracy: 0.2104\n",
            "Epoch 24/100, Loss: 44.4914, Validation Accuracy: 0.4606\n",
            "Epoch 25/100, Loss: 21.7536, Validation Accuracy: 0.5583\n",
            "Epoch 26/100, Loss: 21.3676, Validation Accuracy: 0.5334\n",
            "Epoch 27/100, Loss: 16.5924, Validation Accuracy: 0.4566\n",
            "Epoch 28/100, Loss: 7.4341, Validation Accuracy: 0.4207\n",
            "Epoch 29/100, Loss: 48.0771, Validation Accuracy: 0.6650\n",
            "Epoch 30/100, Loss: 11.8482, Validation Accuracy: 0.5374\n",
            "Epoch 31/100, Loss: 5.6399, Validation Accuracy: 0.5284\n",
            "Epoch 32/100, Loss: 9.4264, Validation Accuracy: 0.6351\n",
            "Epoch 33/100, Loss: 433.4037, Validation Accuracy: 0.6680\n",
            "Epoch 34/100, Loss: 24.4078, Validation Accuracy: 0.4427\n",
            "Epoch 35/100, Loss: 18.9437, Validation Accuracy: 0.6580\n",
            "Epoch 36/100, Loss: 12.4395, Validation Accuracy: 0.6321\n",
            "Epoch 37/100, Loss: 9.3255, Validation Accuracy: 0.6620\n",
            "Epoch 38/100, Loss: 15.2184, Validation Accuracy: 0.5274\n",
            "Epoch 39/100, Loss: 29.8292, Validation Accuracy: 0.6710\n",
            "Epoch 40/100, Loss: 623.9876, Validation Accuracy: 0.3858\n",
            "Epoch 41/100, Loss: 23.8091, Validation Accuracy: 0.6481\n",
            "Epoch 42/100, Loss: 24.3190, Validation Accuracy: 0.6162\n",
            "Epoch 43/100, Loss: 21.7535, Validation Accuracy: 0.5783\n",
            "Epoch 44/100, Loss: 45.4040, Validation Accuracy: 0.6191\n",
            "Epoch 45/100, Loss: 23.0473, Validation Accuracy: 0.6321\n",
            "Epoch 46/100, Loss: 13.9767, Validation Accuracy: 0.5613\n",
            "Epoch 47/100, Loss: 10.4022, Validation Accuracy: 0.5902\n",
            "Epoch 48/100, Loss: 10.0659, Validation Accuracy: 0.6171\n",
            "Epoch 49/100, Loss: 11.7271, Validation Accuracy: 0.5234\n",
            "Epoch 50/100, Loss: 9.1240, Validation Accuracy: 0.5145\n",
            "Epoch 51/100, Loss: 10.2069, Validation Accuracy: 0.6231\n",
            "Epoch 52/100, Loss: 28.1896, Validation Accuracy: 0.6530\n",
            "Epoch 53/100, Loss: 15.7495, Validation Accuracy: 0.5444\n",
            "Epoch 54/100, Loss: 14.4595, Validation Accuracy: 0.4826\n",
            "Epoch 55/100, Loss: 17.2022, Validation Accuracy: 0.5763\n",
            "Epoch 56/100, Loss: 18.7132, Validation Accuracy: 0.4875\n",
            "Epoch 57/100, Loss: 21.5984, Validation Accuracy: 0.6780\n",
            "Epoch 58/100, Loss: 37.9183, Validation Accuracy: 0.3838\n",
            "Epoch 59/100, Loss: 18.2673, Validation Accuracy: 0.5773\n",
            "Epoch 60/100, Loss: 19.1853, Validation Accuracy: 0.6909\n",
            "Epoch 61/100, Loss: 25.4352, Validation Accuracy: 0.6730\n",
            "Epoch 62/100, Loss: 25.2155, Validation Accuracy: 0.6859\n",
            "Epoch 63/100, Loss: 18.2116, Validation Accuracy: 0.6560\n",
            "Epoch 64/100, Loss: 107.5100, Validation Accuracy: 0.5314\n",
            "Epoch 65/100, Loss: 18.0231, Validation Accuracy: 0.6411\n",
            "Epoch 66/100, Loss: 409.0882, Validation Accuracy: 0.3270\n",
            "Epoch 67/100, Loss: 34.9456, Validation Accuracy: 0.6261\n",
            "Epoch 68/100, Loss: 4.3677, Validation Accuracy: 0.6132\n",
            "Epoch 69/100, Loss: 14.7098, Validation Accuracy: 0.6311\n",
            "Epoch 70/100, Loss: 82.0541, Validation Accuracy: 0.6052\n",
            "Epoch 71/100, Loss: 48.4229, Validation Accuracy: 0.6371\n",
            "Epoch 72/100, Loss: 18.6814, Validation Accuracy: 0.5972\n",
            "Epoch 73/100, Loss: 20.5821, Validation Accuracy: 0.5902\n",
            "Epoch 74/100, Loss: 6.1919, Validation Accuracy: 0.6481\n",
            "Epoch 75/100, Loss: 10.0297, Validation Accuracy: 0.6500\n",
            "Epoch 76/100, Loss: 3.3726, Validation Accuracy: 0.5015\n",
            "Epoch 77/100, Loss: 39.4173, Validation Accuracy: 0.5892\n",
            "Epoch 78/100, Loss: 52.2118, Validation Accuracy: 0.6062\n",
            "Epoch 79/100, Loss: 20.7703, Validation Accuracy: 0.3500\n",
            "Epoch 80/100, Loss: 25.0150, Validation Accuracy: 0.6461\n",
            "Epoch 81/100, Loss: 9.8862, Validation Accuracy: 0.6271\n",
            "Epoch 82/100, Loss: 33.3324, Validation Accuracy: 0.6052\n",
            "Epoch 83/100, Loss: 25.6484, Validation Accuracy: 0.2802\n",
            "Epoch 84/100, Loss: 16.4937, Validation Accuracy: 0.6620\n",
            "Epoch 85/100, Loss: 24.5093, Validation Accuracy: 0.6191\n",
            "Epoch 86/100, Loss: 7.3881, Validation Accuracy: 0.5992\n",
            "Epoch 87/100, Loss: 21.7458, Validation Accuracy: 0.6102\n",
            "Epoch 88/100, Loss: 34.1215, Validation Accuracy: 0.5474\n",
            "Epoch 89/100, Loss: 99.2262, Validation Accuracy: 0.6560\n",
            "Epoch 90/100, Loss: 67.5106, Validation Accuracy: 0.4347\n",
            "Epoch 91/100, Loss: 26.0723, Validation Accuracy: 0.6700\n",
            "Epoch 92/100, Loss: 27.8024, Validation Accuracy: 0.6291\n",
            "Epoch 93/100, Loss: 74.2915, Validation Accuracy: 0.6401\n",
            "Epoch 94/100, Loss: 68.6624, Validation Accuracy: 0.6580\n",
            "Epoch 95/100, Loss: 34.2671, Validation Accuracy: 0.6391\n",
            "Epoch 96/100, Loss: 97.6210, Validation Accuracy: 0.4158\n",
            "Epoch 97/100, Loss: 13.0150, Validation Accuracy: 0.5962\n",
            "Epoch 98/100, Loss: 20.2361, Validation Accuracy: 0.6162\n",
            "Epoch 99/100, Loss: 12.0261, Validation Accuracy: 0.6421\n",
            "Epoch 100/100, Loss: 37.3304, Validation Accuracy: 0.5833\n",
            "Epoch 101/100, Loss: 32.2725, Validation Accuracy: 0.3749\n",
            "Epoch 102/100, Loss: 25.5808, Validation Accuracy: 0.6491\n",
            "Epoch 103/100, Loss: 70.0956, Validation Accuracy: 0.5314\n",
            "Epoch 104/100, Loss: 141.3761, Validation Accuracy: 0.5563\n",
            "Epoch 105/100, Loss: 39.1705, Validation Accuracy: 0.5663\n",
            "Epoch 106/100, Loss: 51.8959, Validation Accuracy: 0.5693\n",
            "Epoch 107/100, Loss: 25.8335, Validation Accuracy: 0.6152\n",
            "Epoch 108/100, Loss: 43.4297, Validation Accuracy: 0.6431\n",
            "Epoch 109/100, Loss: 18.7671, Validation Accuracy: 0.5165\n",
            "Epoch 110/100, Loss: 25.9418, Validation Accuracy: 0.2792\n",
            "Epoch 111/100, Loss: 17.9918, Validation Accuracy: 0.6500\n",
            "Epoch 112/100, Loss: 44.1585, Validation Accuracy: 0.3330\n",
            "Epoch 113/100, Loss: 53.3907, Validation Accuracy: 0.5583\n",
            "Epoch 114/100, Loss: 47.5611, Validation Accuracy: 0.5165\n",
            "Epoch 115/100, Loss: 18.7721, Validation Accuracy: 0.6361\n",
            "Epoch 116/100, Loss: 20.4218, Validation Accuracy: 0.3539\n",
            "Epoch 117/100, Loss: 19.7727, Validation Accuracy: 0.6351\n",
            "Epoch 118/100, Loss: 36.9082, Validation Accuracy: 0.6441\n",
            "Epoch 119/100, Loss: 41.7127, Validation Accuracy: 0.6092\n",
            "Epoch 120/100, Loss: 131.4102, Validation Accuracy: 0.6301\n",
            "Epoch 121/100, Loss: 735.1193, Validation Accuracy: 0.5563\n",
            "Epoch 122/100, Loss: 37.0902, Validation Accuracy: 0.6510\n",
            "Epoch 123/100, Loss: 21.4705, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 11.5212, Validation Accuracy: 0.6231\n",
            "Epoch 125/100, Loss: 13.3691, Validation Accuracy: 0.5274\n",
            "Epoch 126/100, Loss: 5.7350, Validation Accuracy: 0.6770\n",
            "Epoch 127/100, Loss: 19.8025, Validation Accuracy: 0.5813\n",
            "Epoch 128/100, Loss: 34.3197, Validation Accuracy: 0.5833\n",
            "Epoch 129/100, Loss: 595.0688, Validation Accuracy: 0.4756\n",
            "Epoch 130/100, Loss: 7.3101, Validation Accuracy: 0.5394\n",
            "Epoch 131/100, Loss: 96.9528, Validation Accuracy: 0.5942\n",
            "Epoch 132/100, Loss: 100.0241, Validation Accuracy: 0.6411\n",
            "Epoch 133/100, Loss: 19.2348, Validation Accuracy: 0.6371\n",
            "Epoch 134/100, Loss: 49.5288, Validation Accuracy: 0.6171\n",
            "Epoch 135/100, Loss: 61.8116, Validation Accuracy: 0.5942\n",
            "Epoch 136/100, Loss: 3.7883, Validation Accuracy: 0.5184\n",
            "Epoch 137/100, Loss: 9.7162, Validation Accuracy: 0.4756\n",
            "Epoch 138/100, Loss: 3.8859, Validation Accuracy: 0.6550\n",
            "Epoch 139/100, Loss: 20.8603, Validation Accuracy: 0.6500\n",
            "Epoch 140/100, Loss: 3.8731, Validation Accuracy: 0.6560\n",
            "Epoch 141/100, Loss: 24.6641, Validation Accuracy: 0.5763\n",
            "Epoch 142/100, Loss: 17.0470, Validation Accuracy: 0.6271\n",
            "Epoch 143/100, Loss: 18.5224, Validation Accuracy: 0.5872\n",
            "Epoch 144/100, Loss: 25.9309, Validation Accuracy: 0.5474\n",
            "Epoch 145/100, Loss: 41.6437, Validation Accuracy: 0.5075\n",
            "Epoch 146/100, Loss: 22.5542, Validation Accuracy: 0.6291\n",
            "Epoch 147/100, Loss: 2412.8765, Validation Accuracy: 0.6530\n",
            "Epoch 148/100, Loss: 38.3223, Validation Accuracy: 0.6650\n",
            "Epoch 149/100, Loss: 35.2414, Validation Accuracy: 0.6570\n",
            "Epoch 150/100, Loss: 14.7744, Validation Accuracy: 0.6062\n",
            "Epoch 151/100, Loss: 12.1061, Validation Accuracy: 0.5922\n",
            "Epoch 152/100, Loss: 10.2188, Validation Accuracy: 0.5274\n",
            "Epoch 153/100, Loss: 50.6235, Validation Accuracy: 0.5823\n",
            "Epoch 154/100, Loss: 29.1962, Validation Accuracy: 0.5533\n",
            "Epoch 155/100, Loss: 1402.5319, Validation Accuracy: 0.6361\n",
            "Epoch 156/100, Loss: 91.5356, Validation Accuracy: 0.5414\n",
            "Epoch 157/100, Loss: 25.9049, Validation Accuracy: 0.5922\n",
            "Epoch 158/100, Loss: 21.7808, Validation Accuracy: 0.5852\n",
            "Epoch 159/100, Loss: 15.8631, Validation Accuracy: 0.5833\n",
            "Epoch 160/100, Loss: 23.8068, Validation Accuracy: 0.6381\n",
            "Epoch 161/100, Loss: 8.4659, Validation Accuracy: 0.5902\n",
            "Epoch 162/100, Loss: 13.4591, Validation Accuracy: 0.6560\n",
            "Epoch 163/100, Loss: 21.9044, Validation Accuracy: 0.5184\n",
            "Epoch 164/100, Loss: 31.3628, Validation Accuracy: 0.5992\n",
            "Epoch 165/100, Loss: 21.8558, Validation Accuracy: 0.3958\n",
            "Epoch 166/100, Loss: 59.0506, Validation Accuracy: 0.3200\n",
            "Epoch 167/100, Loss: 13.1829, Validation Accuracy: 0.6451\n",
            "Epoch 168/100, Loss: 10.6334, Validation Accuracy: 0.6391\n",
            "Epoch 169/100, Loss: 20.3032, Validation Accuracy: 0.5703\n",
            "Epoch 170/100, Loss: 43.0686, Validation Accuracy: 0.5892\n",
            "Epoch 171/100, Loss: 107.4201, Validation Accuracy: 0.6570\n",
            "Epoch 172/100, Loss: 18.0390, Validation Accuracy: 0.5593\n",
            "Epoch 173/100, Loss: 38.8245, Validation Accuracy: 0.5513\n",
            "Epoch 174/100, Loss: 25.7184, Validation Accuracy: 0.4726\n",
            "Epoch 175/100, Loss: 30.6291, Validation Accuracy: 0.6261\n",
            "Epoch 176/100, Loss: 24.5350, Validation Accuracy: 0.5783\n",
            "Epoch 177/100, Loss: 39.8490, Validation Accuracy: 0.6740\n",
            "Epoch 178/100, Loss: 64.5483, Validation Accuracy: 0.6301\n",
            "Epoch 179/100, Loss: 4.9242, Validation Accuracy: 0.5852\n",
            "Epoch 180/100, Loss: 11.1376, Validation Accuracy: 0.6630\n",
            "Epoch 181/100, Loss: 29.7410, Validation Accuracy: 0.6321\n",
            "Epoch 182/100, Loss: 17.6865, Validation Accuracy: 0.6251\n",
            "Epoch 183/100, Loss: 26.6816, Validation Accuracy: 0.6341\n",
            "Epoch 184/100, Loss: 52.5660, Validation Accuracy: 0.5464\n",
            "Epoch 185/100, Loss: 63.7405, Validation Accuracy: 0.6251\n",
            "Epoch 186/100, Loss: 41.5042, Validation Accuracy: 0.5813\n",
            "Epoch 187/100, Loss: 30.8444, Validation Accuracy: 0.6520\n",
            "Epoch 188/100, Loss: 44.2099, Validation Accuracy: 0.6600\n",
            "Epoch 189/100, Loss: 31.8484, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 10.5865, Validation Accuracy: 0.5503\n",
            "Epoch 191/100, Loss: 15.7531, Validation Accuracy: 0.6859\n",
            "Epoch 192/100, Loss: 15.7931, Validation Accuracy: 0.6311\n",
            "Epoch 193/100, Loss: 215.8356, Validation Accuracy: 0.6181\n",
            "Epoch 194/100, Loss: 80.5369, Validation Accuracy: 0.5414\n",
            "Epoch 195/100, Loss: 462.5055, Validation Accuracy: 0.6022\n",
            "Epoch 196/100, Loss: 108.9175, Validation Accuracy: 0.6700\n",
            "Epoch 197/100, Loss: 39.6642, Validation Accuracy: 0.6142\n",
            "Epoch 198/100, Loss: 12.2444, Validation Accuracy: 0.5852\n",
            "Epoch 199/100, Loss: 10.9149, Validation Accuracy: 0.6301\n",
            "Epoch 200/100, Loss: 8.6801, Validation Accuracy: 0.5882\n",
            "Reward for Child Model: 0.300749573479958\n",
            "Child_9:  {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, [2, 2, 0, 0, 3, 1, 2, 1, 2, 0, 0, 0, 1, 3, 3], 0.300749573479958\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 24, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(96, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(144, 36, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=157248, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 26, 24]           1,104\n",
            "       BatchNorm2d-2           [-1, 24, 26, 24]              48\n",
            "            Conv2d-3           [-1, 24, 24, 24]           1,752\n",
            "       BatchNorm2d-4           [-1, 24, 24, 24]              48\n",
            "              ReLU-5           [-1, 24, 24, 24]               0\n",
            "            Conv2d-6           [-1, 48, 20, 22]          48,432\n",
            "       BatchNorm2d-7           [-1, 48, 20, 22]              96\n",
            "              ReLU-8           [-1, 48, 20, 22]               0\n",
            "            Conv2d-9           [-1, 48, 24, 24]          13,872\n",
            "      BatchNorm2d-10           [-1, 48, 24, 24]              96\n",
            "             ReLU-11           [-1, 48, 24, 24]               0\n",
            "           Conv2d-12           [-1, 36, 24, 20]          77,796\n",
            "      BatchNorm2d-13           [-1, 36, 24, 20]              72\n",
            "             ReLU-14           [-1, 36, 24, 20]               0\n",
            "           Linear-15                    [-1, 7]       1,100,743\n",
            "================================================================\n",
            "Total params: 1,244,059\n",
            "Trainable params: 1,244,059\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.06\n",
            "Params size (MB): 4.75\n",
            "Estimated Total Size (MB): 6.81\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 14.3023, Validation Accuracy: 0.5384\n",
            "Epoch 2/100, Loss: 318.9988, Validation Accuracy: 0.5743\n",
            "Epoch 3/100, Loss: 15.7702, Validation Accuracy: 0.5733\n",
            "Epoch 4/100, Loss: 2.5847, Validation Accuracy: 0.5005\n",
            "Epoch 5/100, Loss: 124.0048, Validation Accuracy: 0.5972\n",
            "Epoch 6/100, Loss: 12.8019, Validation Accuracy: 0.5882\n",
            "Epoch 7/100, Loss: 5.4668, Validation Accuracy: 0.6341\n",
            "Epoch 8/100, Loss: 55.1631, Validation Accuracy: 0.6112\n",
            "Epoch 9/100, Loss: 60.2202, Validation Accuracy: 0.4467\n",
            "Epoch 10/100, Loss: 13.2566, Validation Accuracy: 0.6002\n",
            "Epoch 11/100, Loss: 15.0143, Validation Accuracy: 0.6770\n",
            "Epoch 12/100, Loss: 122.8627, Validation Accuracy: 0.6520\n",
            "Epoch 13/100, Loss: 146.7630, Validation Accuracy: 0.4915\n",
            "Epoch 14/100, Loss: 34.5368, Validation Accuracy: 0.6540\n",
            "Epoch 15/100, Loss: 12.7621, Validation Accuracy: 0.5414\n",
            "Epoch 16/100, Loss: 43.5239, Validation Accuracy: 0.6122\n",
            "Epoch 17/100, Loss: 25.4902, Validation Accuracy: 0.6481\n",
            "Epoch 18/100, Loss: 13.4429, Validation Accuracy: 0.4506\n",
            "Epoch 19/100, Loss: 308.4830, Validation Accuracy: 0.5713\n",
            "Epoch 20/100, Loss: 45.2997, Validation Accuracy: 0.6361\n",
            "Epoch 21/100, Loss: 12.4526, Validation Accuracy: 0.5833\n",
            "Epoch 22/100, Loss: 18.9353, Validation Accuracy: 0.6471\n",
            "Epoch 23/100, Loss: 2.9307, Validation Accuracy: 0.6032\n",
            "Epoch 24/100, Loss: 69.2623, Validation Accuracy: 0.4337\n",
            "Epoch 25/100, Loss: 105.9342, Validation Accuracy: 0.5364\n",
            "Epoch 26/100, Loss: 97.6355, Validation Accuracy: 0.6002\n",
            "Epoch 27/100, Loss: 21.2876, Validation Accuracy: 0.6082\n",
            "Epoch 28/100, Loss: 18.7534, Validation Accuracy: 0.6560\n",
            "Epoch 29/100, Loss: 16.9758, Validation Accuracy: 0.6540\n",
            "Epoch 30/100, Loss: 80.3418, Validation Accuracy: 0.6530\n",
            "Epoch 31/100, Loss: 121.8151, Validation Accuracy: 0.6510\n",
            "Epoch 32/100, Loss: 28.0609, Validation Accuracy: 0.4556\n",
            "Epoch 33/100, Loss: 29.6178, Validation Accuracy: 0.2622\n",
            "Epoch 34/100, Loss: 20.1287, Validation Accuracy: 0.4985\n",
            "Epoch 35/100, Loss: 9.8734, Validation Accuracy: 0.6102\n",
            "Epoch 36/100, Loss: 74.9557, Validation Accuracy: 0.5743\n",
            "Epoch 37/100, Loss: 66.9925, Validation Accuracy: 0.6012\n",
            "Epoch 38/100, Loss: 176.8353, Validation Accuracy: 0.4816\n",
            "Epoch 39/100, Loss: 30.1718, Validation Accuracy: 0.5055\n",
            "Epoch 40/100, Loss: 53.8936, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 16.1832, Validation Accuracy: 0.5025\n",
            "Epoch 42/100, Loss: 39.4728, Validation Accuracy: 0.5543\n",
            "Epoch 43/100, Loss: 27.9199, Validation Accuracy: 0.6411\n",
            "Epoch 44/100, Loss: 34.0763, Validation Accuracy: 0.6530\n",
            "Epoch 45/100, Loss: 51.1068, Validation Accuracy: 0.6879\n",
            "Epoch 46/100, Loss: 65.4325, Validation Accuracy: 0.4666\n",
            "Epoch 47/100, Loss: 33.6570, Validation Accuracy: 0.6600\n",
            "Epoch 48/100, Loss: 18.2601, Validation Accuracy: 0.4197\n",
            "Epoch 49/100, Loss: 116.7981, Validation Accuracy: 0.6181\n",
            "Epoch 50/100, Loss: 21.7200, Validation Accuracy: 0.6421\n",
            "Epoch 51/100, Loss: 32.1738, Validation Accuracy: 0.4786\n",
            "Epoch 52/100, Loss: 59.5162, Validation Accuracy: 0.6082\n",
            "Epoch 53/100, Loss: 35.8997, Validation Accuracy: 0.5833\n",
            "Epoch 54/100, Loss: 63.2599, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 90.7887, Validation Accuracy: 0.6680\n",
            "Epoch 56/100, Loss: 69.8035, Validation Accuracy: 0.4327\n",
            "Epoch 57/100, Loss: 44.6257, Validation Accuracy: 0.6261\n",
            "Epoch 58/100, Loss: 128.3817, Validation Accuracy: 0.6620\n",
            "Epoch 59/100, Loss: 54.3710, Validation Accuracy: 0.5992\n",
            "Epoch 60/100, Loss: 50.7479, Validation Accuracy: 0.4766\n",
            "Epoch 61/100, Loss: 76.7725, Validation Accuracy: 0.5793\n",
            "Epoch 62/100, Loss: 55.3414, Validation Accuracy: 0.6022\n",
            "Epoch 63/100, Loss: 19.3464, Validation Accuracy: 0.6321\n",
            "Epoch 64/100, Loss: 27.9296, Validation Accuracy: 0.6012\n",
            "Epoch 65/100, Loss: 38.7856, Validation Accuracy: 0.6491\n",
            "Epoch 66/100, Loss: 49.3958, Validation Accuracy: 0.4845\n",
            "Epoch 67/100, Loss: 215.5933, Validation Accuracy: 0.5922\n",
            "Epoch 68/100, Loss: 69.6566, Validation Accuracy: 0.6181\n",
            "Epoch 69/100, Loss: 16.4421, Validation Accuracy: 0.5135\n",
            "Epoch 70/100, Loss: 24.8354, Validation Accuracy: 0.6032\n",
            "Epoch 71/100, Loss: 85.6331, Validation Accuracy: 0.3868\n",
            "Epoch 72/100, Loss: 113.9848, Validation Accuracy: 0.6640\n",
            "Epoch 73/100, Loss: 20.1552, Validation Accuracy: 0.4277\n",
            "Epoch 74/100, Loss: 40.2984, Validation Accuracy: 0.6411\n",
            "Epoch 75/100, Loss: 13.5583, Validation Accuracy: 0.5852\n",
            "Epoch 76/100, Loss: 15.1034, Validation Accuracy: 0.6231\n",
            "Epoch 77/100, Loss: 140.0691, Validation Accuracy: 0.5872\n",
            "Epoch 78/100, Loss: 73.6716, Validation Accuracy: 0.5833\n",
            "Epoch 79/100, Loss: 65.3956, Validation Accuracy: 0.4656\n",
            "Epoch 80/100, Loss: 53.7079, Validation Accuracy: 0.6092\n",
            "Epoch 81/100, Loss: 27.1712, Validation Accuracy: 0.4756\n",
            "Epoch 82/100, Loss: 213.6718, Validation Accuracy: 0.4955\n",
            "Epoch 83/100, Loss: 82.8416, Validation Accuracy: 0.6391\n",
            "Epoch 84/100, Loss: 58.0259, Validation Accuracy: 0.5753\n",
            "Epoch 85/100, Loss: 34.0807, Validation Accuracy: 0.5823\n",
            "Epoch 86/100, Loss: 58.4336, Validation Accuracy: 0.4477\n",
            "Epoch 87/100, Loss: 75.9864, Validation Accuracy: 0.6132\n",
            "Epoch 88/100, Loss: 87.5004, Validation Accuracy: 0.6002\n",
            "Epoch 89/100, Loss: 34.2859, Validation Accuracy: 0.6471\n",
            "Epoch 90/100, Loss: 24.1584, Validation Accuracy: 0.4287\n",
            "Epoch 91/100, Loss: 25.8500, Validation Accuracy: 0.6770\n",
            "Epoch 92/100, Loss: 5.8860, Validation Accuracy: 0.6351\n",
            "Epoch 93/100, Loss: 50.2151, Validation Accuracy: 0.4766\n",
            "Epoch 94/100, Loss: 50.4585, Validation Accuracy: 0.5035\n",
            "Epoch 95/100, Loss: 36.6119, Validation Accuracy: 0.5414\n",
            "Epoch 96/100, Loss: 134.0809, Validation Accuracy: 0.5663\n",
            "Epoch 97/100, Loss: 18.7952, Validation Accuracy: 0.5723\n",
            "Epoch 98/100, Loss: 69.1368, Validation Accuracy: 0.6740\n",
            "Epoch 99/100, Loss: 48.8202, Validation Accuracy: 0.5992\n",
            "Epoch 100/100, Loss: 41.8870, Validation Accuracy: 0.5763\n",
            "Epoch 101/100, Loss: 12.8779, Validation Accuracy: 0.6371\n",
            "Epoch 102/100, Loss: 31.1254, Validation Accuracy: 0.4546\n",
            "Epoch 103/100, Loss: 44.9503, Validation Accuracy: 0.5454\n",
            "Epoch 104/100, Loss: 102.3424, Validation Accuracy: 0.6401\n",
            "Epoch 105/100, Loss: 59.1433, Validation Accuracy: 0.5464\n",
            "Epoch 106/100, Loss: 97.6950, Validation Accuracy: 0.5503\n",
            "Epoch 107/100, Loss: 33.5316, Validation Accuracy: 0.6152\n",
            "Epoch 108/100, Loss: 34.5035, Validation Accuracy: 0.6600\n",
            "Epoch 109/100, Loss: 166.8075, Validation Accuracy: 0.6351\n",
            "Epoch 110/100, Loss: 40.5913, Validation Accuracy: 0.6201\n",
            "Epoch 111/100, Loss: 14.5047, Validation Accuracy: 0.4826\n",
            "Epoch 112/100, Loss: 14.6121, Validation Accuracy: 0.6700\n",
            "Epoch 113/100, Loss: 43.2191, Validation Accuracy: 0.6271\n",
            "Epoch 114/100, Loss: 111.0671, Validation Accuracy: 0.6760\n",
            "Epoch 115/100, Loss: 22.4109, Validation Accuracy: 0.6740\n",
            "Epoch 116/100, Loss: 186.0742, Validation Accuracy: 0.6630\n",
            "Epoch 117/100, Loss: 97.1976, Validation Accuracy: 0.6361\n",
            "Epoch 118/100, Loss: 35.1346, Validation Accuracy: 0.4487\n",
            "Epoch 119/100, Loss: 41.3621, Validation Accuracy: 0.6181\n",
            "Epoch 120/100, Loss: 16.9134, Validation Accuracy: 0.6580\n",
            "Epoch 121/100, Loss: 100.9367, Validation Accuracy: 0.6231\n",
            "Epoch 122/100, Loss: 47.9889, Validation Accuracy: 0.4686\n",
            "Epoch 123/100, Loss: 123.2167, Validation Accuracy: 0.5533\n",
            "Epoch 124/100, Loss: 86.8890, Validation Accuracy: 0.6191\n",
            "Epoch 125/100, Loss: 30.6781, Validation Accuracy: 0.6530\n",
            "Epoch 126/100, Loss: 44.3736, Validation Accuracy: 0.5583\n",
            "Epoch 127/100, Loss: 51.7294, Validation Accuracy: 0.5105\n",
            "Epoch 128/100, Loss: 17.7695, Validation Accuracy: 0.6271\n",
            "Epoch 129/100, Loss: 45.5504, Validation Accuracy: 0.4955\n",
            "Epoch 130/100, Loss: 99.2679, Validation Accuracy: 0.5214\n",
            "Epoch 131/100, Loss: 59.6686, Validation Accuracy: 0.6740\n",
            "Epoch 132/100, Loss: 36.2666, Validation Accuracy: 0.4526\n",
            "Epoch 133/100, Loss: 25.2696, Validation Accuracy: 0.6012\n",
            "Epoch 134/100, Loss: 11.1059, Validation Accuracy: 0.4736\n",
            "Epoch 135/100, Loss: 201.3146, Validation Accuracy: 0.6162\n",
            "Epoch 136/100, Loss: 65.8607, Validation Accuracy: 0.6670\n",
            "Epoch 137/100, Loss: 72.9414, Validation Accuracy: 0.5653\n",
            "Epoch 138/100, Loss: 46.7517, Validation Accuracy: 0.6122\n",
            "Epoch 139/100, Loss: 39.6389, Validation Accuracy: 0.6670\n",
            "Epoch 140/100, Loss: 59.7501, Validation Accuracy: 0.6441\n",
            "Epoch 141/100, Loss: 83.9114, Validation Accuracy: 0.6102\n",
            "Epoch 142/100, Loss: 34.2688, Validation Accuracy: 0.5344\n",
            "Epoch 143/100, Loss: 24.7572, Validation Accuracy: 0.6620\n",
            "Epoch 144/100, Loss: 33.5207, Validation Accuracy: 0.5284\n",
            "Epoch 145/100, Loss: 89.8182, Validation Accuracy: 0.6271\n",
            "Epoch 146/100, Loss: 137.7657, Validation Accuracy: 0.6411\n",
            "Epoch 147/100, Loss: 64.7300, Validation Accuracy: 0.6431\n",
            "Epoch 148/100, Loss: 41.0459, Validation Accuracy: 0.5294\n",
            "Epoch 149/100, Loss: 51.1582, Validation Accuracy: 0.5952\n",
            "Epoch 150/100, Loss: 31.6699, Validation Accuracy: 0.6500\n",
            "Epoch 151/100, Loss: 56.6547, Validation Accuracy: 0.5404\n",
            "Epoch 152/100, Loss: 54.1018, Validation Accuracy: 0.5713\n",
            "Epoch 153/100, Loss: 37.3047, Validation Accuracy: 0.5663\n",
            "Epoch 154/100, Loss: 122.6276, Validation Accuracy: 0.6112\n",
            "Epoch 155/100, Loss: 69.6745, Validation Accuracy: 0.5852\n",
            "Epoch 156/100, Loss: 19.8335, Validation Accuracy: 0.4377\n",
            "Epoch 157/100, Loss: 43.9104, Validation Accuracy: 0.5823\n",
            "Epoch 158/100, Loss: 55.9187, Validation Accuracy: 0.5962\n",
            "Epoch 159/100, Loss: 55.1559, Validation Accuracy: 0.6640\n",
            "Epoch 160/100, Loss: 67.2166, Validation Accuracy: 0.6221\n",
            "Epoch 161/100, Loss: 59.9620, Validation Accuracy: 0.6481\n",
            "Epoch 162/100, Loss: 48.4975, Validation Accuracy: 0.5284\n",
            "Epoch 163/100, Loss: 50.5834, Validation Accuracy: 0.5523\n",
            "Epoch 164/100, Loss: 21.4259, Validation Accuracy: 0.6102\n",
            "Epoch 165/100, Loss: 26.9498, Validation Accuracy: 0.6560\n",
            "Epoch 166/100, Loss: 51.5791, Validation Accuracy: 0.4646\n",
            "Epoch 167/100, Loss: 104.1861, Validation Accuracy: 0.5304\n",
            "Epoch 168/100, Loss: 49.8347, Validation Accuracy: 0.5264\n",
            "Epoch 169/100, Loss: 45.3236, Validation Accuracy: 0.4696\n",
            "Epoch 170/100, Loss: 78.5610, Validation Accuracy: 0.6351\n",
            "Epoch 171/100, Loss: 20.8789, Validation Accuracy: 0.6510\n",
            "Epoch 172/100, Loss: 49.3375, Validation Accuracy: 0.4636\n",
            "Epoch 173/100, Loss: 72.4368, Validation Accuracy: 0.5603\n",
            "Epoch 174/100, Loss: 58.4731, Validation Accuracy: 0.6211\n",
            "Epoch 175/100, Loss: 18.4392, Validation Accuracy: 0.6341\n",
            "Epoch 176/100, Loss: 51.7329, Validation Accuracy: 0.5583\n",
            "Epoch 177/100, Loss: 72.7321, Validation Accuracy: 0.6261\n",
            "Epoch 178/100, Loss: 29.4320, Validation Accuracy: 0.6251\n",
            "Epoch 179/100, Loss: 61.5607, Validation Accuracy: 0.6162\n",
            "Epoch 180/100, Loss: 15.4999, Validation Accuracy: 0.6241\n",
            "Epoch 181/100, Loss: 48.1553, Validation Accuracy: 0.5314\n",
            "Epoch 182/100, Loss: 20.8373, Validation Accuracy: 0.5872\n",
            "Epoch 183/100, Loss: 37.8334, Validation Accuracy: 0.5673\n",
            "Epoch 184/100, Loss: 96.3701, Validation Accuracy: 0.6072\n",
            "Epoch 185/100, Loss: 45.8639, Validation Accuracy: 0.6540\n",
            "Epoch 186/100, Loss: 39.2144, Validation Accuracy: 0.6311\n",
            "Epoch 187/100, Loss: 19.5749, Validation Accuracy: 0.6152\n",
            "Epoch 188/100, Loss: 85.5081, Validation Accuracy: 0.4417\n",
            "Epoch 189/100, Loss: 43.8348, Validation Accuracy: 0.6520\n",
            "Epoch 190/100, Loss: 21.0477, Validation Accuracy: 0.6411\n",
            "Epoch 191/100, Loss: 18.9221, Validation Accuracy: 0.6361\n",
            "Epoch 192/100, Loss: 183.0033, Validation Accuracy: 0.6181\n",
            "Epoch 193/100, Loss: 43.2306, Validation Accuracy: 0.5922\n",
            "Epoch 194/100, Loss: 41.1411, Validation Accuracy: 0.4776\n",
            "Epoch 195/100, Loss: 29.7983, Validation Accuracy: 0.5513\n",
            "Epoch 196/100, Loss: 15.1199, Validation Accuracy: 0.6211\n",
            "Epoch 197/100, Loss: 23.2193, Validation Accuracy: 0.6241\n",
            "Epoch 198/100, Loss: 95.0710, Validation Accuracy: 0.6441\n",
            "Epoch 199/100, Loss: 36.7849, Validation Accuracy: 0.3470\n",
            "Epoch 200/100, Loss: 21.5173, Validation Accuracy: 0.6381\n",
            "Reward for Child Model: 0.2671743459652642\n",
            "Child_10:  {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, [1, 2, 0, 1, 0, 0, 3, 1, 2, 1, 0, 2, 1, 2, 1], 0.2671743459652642\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(60, 36, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(96, 24, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(180, 48, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=19008, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 24, 26]           1,104\n",
            "       BatchNorm2d-2           [-1, 24, 24, 26]              48\n",
            "            Conv2d-3           [-1, 36, 20, 22]          21,636\n",
            "       BatchNorm2d-4           [-1, 36, 20, 22]              72\n",
            "              ReLU-5           [-1, 36, 20, 22]               0\n",
            "            Conv2d-6           [-1, 36, 18, 26]          15,156\n",
            "       BatchNorm2d-7           [-1, 36, 18, 26]              72\n",
            "              ReLU-8           [-1, 36, 18, 26]               0\n",
            "            Conv2d-9           [-1, 24, 18, 20]         112,920\n",
            "      BatchNorm2d-10           [-1, 24, 18, 20]              48\n",
            "             ReLU-11           [-1, 24, 18, 20]               0\n",
            "           Conv2d-12           [-1, 48, 18, 22]         302,448\n",
            "      BatchNorm2d-13           [-1, 48, 18, 22]              96\n",
            "             ReLU-14           [-1, 48, 18, 22]               0\n",
            "           Linear-15                    [-1, 7]         133,063\n",
            "================================================================\n",
            "Total params: 586,663\n",
            "Trainable params: 586,663\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.61\n",
            "Params size (MB): 2.24\n",
            "Estimated Total Size (MB): 3.86\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 0.9096, Validation Accuracy: 0.6690\n",
            "Epoch 2/100, Loss: 1.2103, Validation Accuracy: 0.6690\n",
            "Epoch 3/100, Loss: 1.1417, Validation Accuracy: 0.6690\n",
            "Epoch 4/100, Loss: 1.0009, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 1.3528, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 1.0653, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 1.3286, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 1.1557, Validation Accuracy: 0.6690\n",
            "Epoch 9/100, Loss: 1.2505, Validation Accuracy: 0.6690\n",
            "Epoch 10/100, Loss: 1.3752, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 1.0644, Validation Accuracy: 0.6690\n",
            "Epoch 12/100, Loss: 1.0357, Validation Accuracy: 0.6690\n",
            "Epoch 13/100, Loss: 1.1741, Validation Accuracy: 0.6690\n",
            "Epoch 14/100, Loss: 1.1562, Validation Accuracy: 0.6690\n",
            "Epoch 15/100, Loss: 1.0216, Validation Accuracy: 0.6690\n",
            "Epoch 16/100, Loss: 1.0536, Validation Accuracy: 0.6690\n",
            "Epoch 17/100, Loss: 1.2089, Validation Accuracy: 0.6690\n",
            "Epoch 18/100, Loss: 1.1323, Validation Accuracy: 0.6690\n",
            "Epoch 19/100, Loss: 1.1942, Validation Accuracy: 0.6690\n",
            "Epoch 20/100, Loss: 1.2414, Validation Accuracy: 0.6690\n",
            "Epoch 21/100, Loss: 0.8438, Validation Accuracy: 0.6690\n",
            "Epoch 22/100, Loss: 1.1546, Validation Accuracy: 0.6690\n",
            "Epoch 23/100, Loss: 1.1621, Validation Accuracy: 0.6690\n",
            "Epoch 24/100, Loss: 1.2183, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 1.2331, Validation Accuracy: 0.6690\n",
            "Epoch 26/100, Loss: 1.0345, Validation Accuracy: 0.6690\n",
            "Epoch 27/100, Loss: 0.9970, Validation Accuracy: 0.6690\n",
            "Epoch 28/100, Loss: 1.1940, Validation Accuracy: 0.6690\n",
            "Epoch 29/100, Loss: 1.0381, Validation Accuracy: 0.6690\n",
            "Epoch 30/100, Loss: 1.0517, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 1.0903, Validation Accuracy: 0.6690\n",
            "Epoch 32/100, Loss: 0.8093, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 1.0837, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 0.8705, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 1.2815, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 1.1748, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 1.0186, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 0.8990, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 1.5491, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 1.1389, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 1.2529, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 1.2012, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 1.1077, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 1.1070, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 1.1902, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 0.9298, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 1.1302, Validation Accuracy: 0.6690\n",
            "Epoch 48/100, Loss: 1.3312, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 1.4447, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 1.3039, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 1.1901, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 1.3147, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 1.5970, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 1.2210, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 0.8469, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 1.4643, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 1.0329, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 1.3134, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 1.0333, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 1.2022, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 1.0096, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 1.1568, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 1.3526, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 0.8680, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 1.2078, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 1.4510, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 1.2648, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 1.3400, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 1.3611, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 1.2394, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 1.4959, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 0.8007, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 1.3371, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 1.0887, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 1.2241, Validation Accuracy: 0.6690\n",
            "Epoch 76/100, Loss: 1.1881, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 1.1024, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 1.1929, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 1.2301, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 0.9104, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 1.2556, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 0.8938, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 1.0659, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 1.1992, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 1.1370, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 1.1326, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 1.4110, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 0.9917, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 1.3566, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 1.2092, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 1.0169, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 1.1965, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 0.9869, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 1.0643, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 1.1764, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 0.8446, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 1.1934, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 0.7096, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 1.0415, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 1.2641, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 1.1263, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 1.4758, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 1.2430, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 1.2579, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 1.0789, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 1.0879, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 1.2618, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 1.0027, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 0.8682, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 1.5602, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.3341, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 0.9317, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 1.0436, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 1.1189, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 1.2107, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 1.2326, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 1.0775, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 1.1516, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 1.0960, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 0.8420, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 1.1109, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.1650, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 1.1133, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 1.0295, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 1.3839, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 0.9107, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 1.2042, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 1.2933, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 1.1075, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 0.9615, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 0.8801, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 1.2296, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 1.1169, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 1.2465, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 1.2033, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 1.4069, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 1.0528, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 0.7834, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 1.2619, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 1.2616, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 1.2002, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 1.5265, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 0.8583, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 1.2137, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 1.4796, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 1.0821, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 0.9542, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 0.6859, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 0.9496, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 0.8758, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 1.3281, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 0.9528, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 1.2374, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 1.1181, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 1.1214, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 1.1306, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 1.0381, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 1.3765, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 1.6040, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 1.5448, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 1.5275, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 1.0840, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 1.2429, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 1.1715, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 1.0666, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 1.3715, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 1.2243, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 0.9612, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 1.2828, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 1.2643, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 0.9909, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 0.9146, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 1.2893, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 1.1774, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 0.9863, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 1.2721, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 1.0655, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 0.9079, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 1.2252, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 1.0736, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 1.0130, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 1.4035, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 1.3840, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 1.2964, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 1.2485, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 1.2125, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 1.2457, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 1.2762, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 1.2822, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 1.5364, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 1.0114, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 1.3395, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 1.1334, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 1.3362, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 0.9668, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 1.1972, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 1.4468, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 0.9352, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 0.9478, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 1.4236, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_11:  {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, [2, 1, 0, 2, 2, 1, 3, 0, 1, 3, 3, 0, 3, 2, 2], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 64, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(64, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(136, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(176, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=173888, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 22, 26]           3,072\n",
            "       BatchNorm2d-2           [-1, 48, 22, 26]              96\n",
            "            Conv2d-3           [-1, 64, 18, 24]          46,144\n",
            "       BatchNorm2d-4           [-1, 64, 18, 24]             128\n",
            "              ReLU-5           [-1, 64, 18, 24]               0\n",
            "            Conv2d-6           [-1, 24, 18, 18]          10,776\n",
            "       BatchNorm2d-7           [-1, 24, 18, 18]              48\n",
            "              ReLU-8           [-1, 24, 18, 18]               0\n",
            "            Conv2d-9           [-1, 64, 20, 24]          78,400\n",
            "      BatchNorm2d-10           [-1, 64, 20, 24]             128\n",
            "             ReLU-11           [-1, 64, 20, 24]               0\n",
            "           Conv2d-12           [-1, 64, 18, 22]         281,664\n",
            "      BatchNorm2d-13           [-1, 64, 18, 22]             128\n",
            "             ReLU-14           [-1, 64, 18, 22]               0\n",
            "           Linear-15                    [-1, 7]       1,217,223\n",
            "================================================================\n",
            "Total params: 1,637,807\n",
            "Trainable params: 1,637,807\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.51\n",
            "Params size (MB): 6.25\n",
            "Estimated Total Size (MB): 8.77\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 24.3131, Validation Accuracy: 0.5912\n",
            "Epoch 2/100, Loss: 85.5604, Validation Accuracy: 0.6361\n",
            "Epoch 3/100, Loss: 17.6076, Validation Accuracy: 0.6441\n",
            "Epoch 4/100, Loss: 9.2277, Validation Accuracy: 0.4995\n",
            "Epoch 5/100, Loss: 70.3270, Validation Accuracy: 0.5065\n",
            "Epoch 6/100, Loss: 27.6820, Validation Accuracy: 0.4995\n",
            "Epoch 7/100, Loss: 18.3921, Validation Accuracy: 0.4397\n",
            "Epoch 8/100, Loss: 22.4456, Validation Accuracy: 0.2961\n",
            "Epoch 9/100, Loss: 13.9599, Validation Accuracy: 0.5643\n",
            "Epoch 10/100, Loss: 31.0761, Validation Accuracy: 0.3848\n",
            "Epoch 11/100, Loss: 37.4516, Validation Accuracy: 0.5384\n",
            "Epoch 12/100, Loss: 13.7626, Validation Accuracy: 0.6889\n",
            "Epoch 13/100, Loss: 114.8823, Validation Accuracy: 0.6241\n",
            "Epoch 14/100, Loss: 33.1978, Validation Accuracy: 0.4965\n",
            "Epoch 15/100, Loss: 38.3519, Validation Accuracy: 0.6351\n",
            "Epoch 16/100, Loss: 16.6066, Validation Accuracy: 0.5663\n",
            "Epoch 17/100, Loss: 13.8391, Validation Accuracy: 0.6461\n",
            "Epoch 18/100, Loss: 48.3358, Validation Accuracy: 0.6341\n",
            "Epoch 19/100, Loss: 16.8555, Validation Accuracy: 0.5793\n",
            "Epoch 20/100, Loss: 43.1625, Validation Accuracy: 0.4806\n",
            "Epoch 21/100, Loss: 33.2030, Validation Accuracy: 0.5773\n",
            "Epoch 22/100, Loss: 15.9747, Validation Accuracy: 0.6530\n",
            "Epoch 23/100, Loss: 33.5639, Validation Accuracy: 0.1984\n",
            "Epoch 24/100, Loss: 18.5015, Validation Accuracy: 0.5922\n",
            "Epoch 25/100, Loss: 143.2506, Validation Accuracy: 0.6690\n",
            "Epoch 26/100, Loss: 34.9828, Validation Accuracy: 0.6012\n",
            "Epoch 27/100, Loss: 14.4974, Validation Accuracy: 0.6122\n",
            "Epoch 28/100, Loss: 94.2096, Validation Accuracy: 0.6660\n",
            "Epoch 29/100, Loss: 65.8568, Validation Accuracy: 0.6181\n",
            "Epoch 30/100, Loss: 10.5719, Validation Accuracy: 0.6810\n",
            "Epoch 31/100, Loss: 522.9872, Validation Accuracy: 0.6540\n",
            "Epoch 32/100, Loss: 347.2487, Validation Accuracy: 0.6730\n",
            "Epoch 33/100, Loss: 289.7586, Validation Accuracy: 0.6670\n",
            "Epoch 34/100, Loss: 199.9372, Validation Accuracy: 0.6351\n",
            "Epoch 35/100, Loss: 169.0960, Validation Accuracy: 0.6620\n",
            "Epoch 36/100, Loss: 62.1235, Validation Accuracy: 0.5833\n",
            "Epoch 37/100, Loss: 48.0974, Validation Accuracy: 0.6989\n",
            "Epoch 38/100, Loss: 27.8841, Validation Accuracy: 0.6640\n",
            "Epoch 39/100, Loss: 32.6309, Validation Accuracy: 0.4696\n",
            "Epoch 40/100, Loss: 21.3023, Validation Accuracy: 0.4367\n",
            "Epoch 41/100, Loss: 23.9346, Validation Accuracy: 0.5842\n",
            "Epoch 42/100, Loss: 7.9862, Validation Accuracy: 0.5803\n",
            "Epoch 43/100, Loss: 5.8588, Validation Accuracy: 0.5374\n",
            "Epoch 44/100, Loss: 13.6483, Validation Accuracy: 0.5583\n",
            "Epoch 45/100, Loss: 8.4451, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 13.7687, Validation Accuracy: 0.6540\n",
            "Epoch 47/100, Loss: 20.2785, Validation Accuracy: 0.3739\n",
            "Epoch 48/100, Loss: 2.6017, Validation Accuracy: 0.6132\n",
            "Epoch 49/100, Loss: 34.5584, Validation Accuracy: 0.6830\n",
            "Epoch 50/100, Loss: 15.0053, Validation Accuracy: 0.5244\n",
            "Epoch 51/100, Loss: 131.2829, Validation Accuracy: 0.5942\n",
            "Epoch 52/100, Loss: 33.2992, Validation Accuracy: 0.5763\n",
            "Epoch 53/100, Loss: 15.7757, Validation Accuracy: 0.6181\n",
            "Epoch 54/100, Loss: 32.6266, Validation Accuracy: 0.6271\n",
            "Epoch 55/100, Loss: 48.1462, Validation Accuracy: 0.6790\n",
            "Epoch 56/100, Loss: 13.0476, Validation Accuracy: 0.5214\n",
            "Epoch 57/100, Loss: 25.4348, Validation Accuracy: 0.6341\n",
            "Epoch 58/100, Loss: 14.0056, Validation Accuracy: 0.5962\n",
            "Epoch 59/100, Loss: 5.8463, Validation Accuracy: 0.5454\n",
            "Epoch 60/100, Loss: 9.1295, Validation Accuracy: 0.6710\n",
            "Epoch 61/100, Loss: 41.9932, Validation Accuracy: 0.5563\n",
            "Epoch 62/100, Loss: 59.4320, Validation Accuracy: 0.6481\n",
            "Epoch 63/100, Loss: 12.2508, Validation Accuracy: 0.6620\n",
            "Epoch 64/100, Loss: 28.3924, Validation Accuracy: 0.6102\n",
            "Epoch 65/100, Loss: 54.3540, Validation Accuracy: 0.5543\n",
            "Epoch 66/100, Loss: 23.4308, Validation Accuracy: 0.6271\n",
            "Epoch 67/100, Loss: 64.5209, Validation Accuracy: 0.6889\n",
            "Epoch 68/100, Loss: 49.0019, Validation Accuracy: 0.6092\n",
            "Epoch 69/100, Loss: 14.8455, Validation Accuracy: 0.5474\n",
            "Epoch 70/100, Loss: 18.4272, Validation Accuracy: 0.6421\n",
            "Epoch 71/100, Loss: 103.1927, Validation Accuracy: 0.3928\n",
            "Epoch 72/100, Loss: 10.8959, Validation Accuracy: 0.6102\n",
            "Epoch 73/100, Loss: 24.5046, Validation Accuracy: 0.6680\n",
            "Epoch 74/100, Loss: 21.1789, Validation Accuracy: 0.6919\n",
            "Epoch 75/100, Loss: 20.3216, Validation Accuracy: 0.6441\n",
            "Epoch 76/100, Loss: 34.4674, Validation Accuracy: 0.4457\n",
            "Epoch 77/100, Loss: 30.1900, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 30.2679, Validation Accuracy: 0.5184\n",
            "Epoch 79/100, Loss: 29.4595, Validation Accuracy: 0.6680\n",
            "Epoch 80/100, Loss: 27.2080, Validation Accuracy: 0.6052\n",
            "Epoch 81/100, Loss: 11.5840, Validation Accuracy: 0.6680\n",
            "Epoch 82/100, Loss: 29.5088, Validation Accuracy: 0.6710\n",
            "Epoch 83/100, Loss: 497.1411, Validation Accuracy: 0.6750\n",
            "Epoch 84/100, Loss: 23.6566, Validation Accuracy: 0.3470\n",
            "Epoch 85/100, Loss: 21.6870, Validation Accuracy: 0.5424\n",
            "Epoch 86/100, Loss: 17.1417, Validation Accuracy: 0.6500\n",
            "Epoch 87/100, Loss: 18.0907, Validation Accuracy: 0.5872\n",
            "Epoch 88/100, Loss: 46.9700, Validation Accuracy: 0.5444\n",
            "Epoch 89/100, Loss: 91.5164, Validation Accuracy: 0.6162\n",
            "Epoch 90/100, Loss: 35.2867, Validation Accuracy: 0.6191\n",
            "Epoch 91/100, Loss: 10.2288, Validation Accuracy: 0.5184\n",
            "Epoch 92/100, Loss: 18.0927, Validation Accuracy: 0.6271\n",
            "Epoch 93/100, Loss: 35.7228, Validation Accuracy: 0.6351\n",
            "Epoch 94/100, Loss: 29.1256, Validation Accuracy: 0.6052\n",
            "Epoch 95/100, Loss: 20.2547, Validation Accuracy: 0.6281\n",
            "Epoch 96/100, Loss: 48.0807, Validation Accuracy: 0.5813\n",
            "Epoch 97/100, Loss: 45.9097, Validation Accuracy: 0.6311\n",
            "Epoch 98/100, Loss: 23.2967, Validation Accuracy: 0.5962\n",
            "Epoch 99/100, Loss: 21.8848, Validation Accuracy: 0.5902\n",
            "Epoch 100/100, Loss: 25.5722, Validation Accuracy: 0.6650\n",
            "Epoch 101/100, Loss: 30.6617, Validation Accuracy: 0.4477\n",
            "Epoch 102/100, Loss: 70.5098, Validation Accuracy: 0.6201\n",
            "Epoch 103/100, Loss: 25.4036, Validation Accuracy: 0.6162\n",
            "Epoch 104/100, Loss: 29.8609, Validation Accuracy: 0.5693\n",
            "Epoch 105/100, Loss: 27.0151, Validation Accuracy: 0.5922\n",
            "Epoch 106/100, Loss: 50.3067, Validation Accuracy: 0.6640\n",
            "Epoch 107/100, Loss: 45.8677, Validation Accuracy: 0.6580\n",
            "Epoch 108/100, Loss: 25.0768, Validation Accuracy: 0.5304\n",
            "Epoch 109/100, Loss: 34.3097, Validation Accuracy: 0.5733\n",
            "Epoch 110/100, Loss: 21.4761, Validation Accuracy: 0.5005\n",
            "Epoch 111/100, Loss: 39.3311, Validation Accuracy: 0.5364\n",
            "Epoch 112/100, Loss: 11.4754, Validation Accuracy: 0.6122\n",
            "Epoch 113/100, Loss: 22.6397, Validation Accuracy: 0.6839\n",
            "Epoch 114/100, Loss: 69.8271, Validation Accuracy: 0.6899\n",
            "Epoch 115/100, Loss: 5.8106, Validation Accuracy: 0.6720\n",
            "Epoch 116/100, Loss: 54.9330, Validation Accuracy: 0.6401\n",
            "Epoch 117/100, Loss: 53.6076, Validation Accuracy: 0.5264\n",
            "Epoch 118/100, Loss: 37.5682, Validation Accuracy: 0.5833\n",
            "Epoch 119/100, Loss: 36.0920, Validation Accuracy: 0.6550\n",
            "Epoch 120/100, Loss: 61.2203, Validation Accuracy: 0.6351\n",
            "Epoch 121/100, Loss: 359.0256, Validation Accuracy: 0.6401\n",
            "Epoch 122/100, Loss: 87.2218, Validation Accuracy: 0.6869\n",
            "Epoch 123/100, Loss: 30.4118, Validation Accuracy: 0.6281\n",
            "Epoch 124/100, Loss: 29.4048, Validation Accuracy: 0.3719\n",
            "Epoch 125/100, Loss: 18.9181, Validation Accuracy: 0.6291\n",
            "Epoch 126/100, Loss: 26.5301, Validation Accuracy: 0.6939\n",
            "Epoch 127/100, Loss: 33.3658, Validation Accuracy: 0.6481\n",
            "Epoch 128/100, Loss: 66.8315, Validation Accuracy: 0.5763\n",
            "Epoch 129/100, Loss: 51.2592, Validation Accuracy: 0.5234\n",
            "Epoch 130/100, Loss: 44.4966, Validation Accuracy: 0.4267\n",
            "Epoch 131/100, Loss: 33.1763, Validation Accuracy: 0.6770\n",
            "Epoch 132/100, Loss: 28.0256, Validation Accuracy: 0.6082\n",
            "Epoch 133/100, Loss: 13.1577, Validation Accuracy: 0.6381\n",
            "Epoch 134/100, Loss: 165.2006, Validation Accuracy: 0.5234\n",
            "Epoch 135/100, Loss: 37.6746, Validation Accuracy: 0.6341\n",
            "Epoch 136/100, Loss: 36.7758, Validation Accuracy: 0.6261\n",
            "Epoch 137/100, Loss: 37.0876, Validation Accuracy: 0.6550\n",
            "Epoch 138/100, Loss: 29.4558, Validation Accuracy: 0.6700\n",
            "Epoch 139/100, Loss: 29.0272, Validation Accuracy: 0.6351\n",
            "Epoch 140/100, Loss: 27.7254, Validation Accuracy: 0.6650\n",
            "Epoch 141/100, Loss: 19.3874, Validation Accuracy: 0.6471\n",
            "Epoch 142/100, Loss: 58.2165, Validation Accuracy: 0.5872\n",
            "Epoch 143/100, Loss: 86.5780, Validation Accuracy: 0.6770\n",
            "Epoch 144/100, Loss: 42.5548, Validation Accuracy: 0.6012\n",
            "Epoch 145/100, Loss: 9.2266, Validation Accuracy: 0.6530\n",
            "Epoch 146/100, Loss: 14.7790, Validation Accuracy: 0.5105\n",
            "Epoch 147/100, Loss: 32.8501, Validation Accuracy: 0.6042\n",
            "Epoch 148/100, Loss: 45.1574, Validation Accuracy: 0.6919\n",
            "Epoch 149/100, Loss: 21.3380, Validation Accuracy: 0.5733\n",
            "Epoch 150/100, Loss: 85.5877, Validation Accuracy: 0.6670\n",
            "Epoch 151/100, Loss: 71.7068, Validation Accuracy: 0.6451\n",
            "Epoch 152/100, Loss: 46.1090, Validation Accuracy: 0.6291\n",
            "Epoch 153/100, Loss: 23.2165, Validation Accuracy: 0.6132\n",
            "Epoch 154/100, Loss: 16.6445, Validation Accuracy: 0.6072\n",
            "Epoch 155/100, Loss: 9.9663, Validation Accuracy: 0.6022\n",
            "Epoch 156/100, Loss: 11.8480, Validation Accuracy: 0.6849\n",
            "Epoch 157/100, Loss: 60.9008, Validation Accuracy: 0.6640\n",
            "Epoch 158/100, Loss: 36.2353, Validation Accuracy: 0.6112\n",
            "Epoch 159/100, Loss: 39.1153, Validation Accuracy: 0.6919\n",
            "Epoch 160/100, Loss: 20.1433, Validation Accuracy: 0.6152\n",
            "Epoch 161/100, Loss: 61.7068, Validation Accuracy: 0.6580\n",
            "Epoch 162/100, Loss: 66.4154, Validation Accuracy: 0.5015\n",
            "Epoch 163/100, Loss: 24.5935, Validation Accuracy: 0.4646\n",
            "Epoch 164/100, Loss: 40.5414, Validation Accuracy: 0.5693\n",
            "Epoch 165/100, Loss: 33.0646, Validation Accuracy: 0.6112\n",
            "Epoch 166/100, Loss: 41.3150, Validation Accuracy: 0.5553\n",
            "Epoch 167/100, Loss: 17.4395, Validation Accuracy: 0.6959\n",
            "Epoch 168/100, Loss: 18.7417, Validation Accuracy: 0.5942\n",
            "Epoch 169/100, Loss: 87.9292, Validation Accuracy: 0.5454\n",
            "Epoch 170/100, Loss: 28.9161, Validation Accuracy: 0.6221\n",
            "Epoch 171/100, Loss: 9.0926, Validation Accuracy: 0.6441\n",
            "Epoch 172/100, Loss: 68.4289, Validation Accuracy: 0.6102\n",
            "Epoch 173/100, Loss: 32.5216, Validation Accuracy: 0.6710\n",
            "Epoch 174/100, Loss: 8.5696, Validation Accuracy: 0.6331\n",
            "Epoch 175/100, Loss: 33.8333, Validation Accuracy: 0.6760\n",
            "Epoch 176/100, Loss: 38.7227, Validation Accuracy: 0.6481\n",
            "Epoch 177/100, Loss: 30.4798, Validation Accuracy: 0.6640\n",
            "Epoch 178/100, Loss: 97.0574, Validation Accuracy: 0.6849\n",
            "Epoch 179/100, Loss: 18.0129, Validation Accuracy: 0.4217\n",
            "Epoch 180/100, Loss: 85.6226, Validation Accuracy: 0.5952\n",
            "Epoch 181/100, Loss: 23.8079, Validation Accuracy: 0.5543\n",
            "Epoch 182/100, Loss: 12.0324, Validation Accuracy: 0.6281\n",
            "Epoch 183/100, Loss: 43.5052, Validation Accuracy: 0.5952\n",
            "Epoch 184/100, Loss: 13.9314, Validation Accuracy: 0.5324\n",
            "Epoch 185/100, Loss: 10.1053, Validation Accuracy: 0.6311\n",
            "Epoch 186/100, Loss: 59.2363, Validation Accuracy: 0.6451\n",
            "Epoch 187/100, Loss: 49.6867, Validation Accuracy: 0.6750\n",
            "Epoch 188/100, Loss: 9.7487, Validation Accuracy: 0.6082\n",
            "Epoch 189/100, Loss: 41.7317, Validation Accuracy: 0.3131\n",
            "Epoch 190/100, Loss: 83.0495, Validation Accuracy: 0.6590\n",
            "Epoch 191/100, Loss: 31.7407, Validation Accuracy: 0.6301\n",
            "Epoch 192/100, Loss: 6.2906, Validation Accuracy: 0.6859\n",
            "Epoch 193/100, Loss: 32.5614, Validation Accuracy: 0.6680\n",
            "Epoch 194/100, Loss: 51.1356, Validation Accuracy: 0.3908\n",
            "Epoch 195/100, Loss: 21.9307, Validation Accuracy: 0.6052\n",
            "Epoch 196/100, Loss: 28.8822, Validation Accuracy: 0.5633\n",
            "Epoch 197/100, Loss: 33.2838, Validation Accuracy: 0.5623\n",
            "Epoch 198/100, Loss: 36.0754, Validation Accuracy: 0.5374\n",
            "Epoch 199/100, Loss: 21.7033, Validation Accuracy: 0.6082\n",
            "Epoch 200/100, Loss: 10.2436, Validation Accuracy: 0.5922\n",
            "Reward for Child Model: 0.2249503669637582\n",
            "Child_12:  {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, [3, 1, 2, 2, 1, 3, 0, 3, 0, 1, 1, 3, 2, 2, 3], 0.2249503669637582\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 64, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(112, 36, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(84, 36, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=112896, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 28, 24]             768\n",
            "       BatchNorm2d-2           [-1, 48, 28, 24]              96\n",
            "            Conv2d-3           [-1, 48, 26, 22]          20,784\n",
            "       BatchNorm2d-4           [-1, 48, 26, 22]              96\n",
            "              ReLU-5           [-1, 48, 26, 22]               0\n",
            "            Conv2d-6           [-1, 64, 24, 22]           9,280\n",
            "       BatchNorm2d-7           [-1, 64, 24, 22]             128\n",
            "              ReLU-8           [-1, 64, 24, 22]               0\n",
            "            Conv2d-9           [-1, 36, 22, 22]          20,196\n",
            "      BatchNorm2d-10           [-1, 36, 22, 22]              72\n",
            "             ReLU-11           [-1, 36, 22, 22]               0\n",
            "           Conv2d-12           [-1, 36, 22, 20]         105,876\n",
            "      BatchNorm2d-13           [-1, 36, 22, 20]              72\n",
            "             ReLU-14           [-1, 36, 22, 20]               0\n",
            "           Linear-15                    [-1, 7]         790,279\n",
            "================================================================\n",
            "Total params: 947,647\n",
            "Trainable params: 947,647\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.66\n",
            "Params size (MB): 3.61\n",
            "Estimated Total Size (MB): 6.28\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 16.0466, Validation Accuracy: 0.6052\n",
            "Epoch 2/100, Loss: 13.9930, Validation Accuracy: 0.6481\n",
            "Epoch 3/100, Loss: 46.3163, Validation Accuracy: 0.3131\n",
            "Epoch 4/100, Loss: 50.3055, Validation Accuracy: 0.6122\n",
            "Epoch 5/100, Loss: 27.3342, Validation Accuracy: 0.4367\n",
            "Epoch 6/100, Loss: 425.2423, Validation Accuracy: 0.4925\n",
            "Epoch 7/100, Loss: 52.7688, Validation Accuracy: 0.4287\n",
            "Epoch 8/100, Loss: 17.6816, Validation Accuracy: 0.5823\n",
            "Epoch 9/100, Loss: 26.4352, Validation Accuracy: 0.5005\n",
            "Epoch 10/100, Loss: 25.2657, Validation Accuracy: 0.6301\n",
            "Epoch 11/100, Loss: 9.8299, Validation Accuracy: 0.6441\n",
            "Epoch 12/100, Loss: 19.4626, Validation Accuracy: 0.6152\n",
            "Epoch 13/100, Loss: 5.7684, Validation Accuracy: 0.5663\n",
            "Epoch 14/100, Loss: 10.9968, Validation Accuracy: 0.6171\n",
            "Epoch 15/100, Loss: 13.7570, Validation Accuracy: 0.6281\n",
            "Epoch 16/100, Loss: 17.1339, Validation Accuracy: 0.4088\n",
            "Epoch 17/100, Loss: 56.0696, Validation Accuracy: 0.6730\n",
            "Epoch 18/100, Loss: 5.4165, Validation Accuracy: 0.6201\n",
            "Epoch 19/100, Loss: 315.7226, Validation Accuracy: 0.6471\n",
            "Epoch 20/100, Loss: 11.8433, Validation Accuracy: 0.6022\n",
            "Epoch 21/100, Loss: 12.8454, Validation Accuracy: 0.6231\n",
            "Epoch 22/100, Loss: 9.8628, Validation Accuracy: 0.5932\n",
            "Epoch 23/100, Loss: 6.4627, Validation Accuracy: 0.3131\n",
            "Epoch 24/100, Loss: 6110.5444, Validation Accuracy: 0.5673\n",
            "Epoch 25/100, Loss: 72.6612, Validation Accuracy: 0.4736\n",
            "Epoch 26/100, Loss: 19.2524, Validation Accuracy: 0.6052\n",
            "Epoch 27/100, Loss: 11.4500, Validation Accuracy: 0.2223\n",
            "Epoch 28/100, Loss: 28.7900, Validation Accuracy: 0.6271\n",
            "Epoch 29/100, Loss: 10.5288, Validation Accuracy: 0.5613\n",
            "Epoch 30/100, Loss: 12.4924, Validation Accuracy: 0.5573\n",
            "Epoch 31/100, Loss: 169.5122, Validation Accuracy: 0.6720\n",
            "Epoch 32/100, Loss: 134.3145, Validation Accuracy: 0.5733\n",
            "Epoch 33/100, Loss: 13.4522, Validation Accuracy: 0.4975\n",
            "Epoch 34/100, Loss: 18.2858, Validation Accuracy: 0.6391\n",
            "Epoch 35/100, Loss: 14.8623, Validation Accuracy: 0.5563\n",
            "Epoch 36/100, Loss: 9.6292, Validation Accuracy: 0.6072\n",
            "Epoch 37/100, Loss: 142.1267, Validation Accuracy: 0.5912\n",
            "Epoch 38/100, Loss: 52.7984, Validation Accuracy: 0.6610\n",
            "Epoch 39/100, Loss: 15.1485, Validation Accuracy: 0.6112\n",
            "Epoch 40/100, Loss: 7.4513, Validation Accuracy: 0.6510\n",
            "Epoch 41/100, Loss: 134.2901, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 31.0766, Validation Accuracy: 0.4098\n",
            "Epoch 43/100, Loss: 30.7944, Validation Accuracy: 0.5703\n",
            "Epoch 44/100, Loss: 26.1113, Validation Accuracy: 0.6022\n",
            "Epoch 45/100, Loss: 11.1284, Validation Accuracy: 0.5942\n",
            "Epoch 46/100, Loss: 10.9375, Validation Accuracy: 0.6171\n",
            "Epoch 47/100, Loss: 7.9331, Validation Accuracy: 0.6580\n",
            "Epoch 48/100, Loss: 13.9269, Validation Accuracy: 0.5304\n",
            "Epoch 49/100, Loss: 57.3377, Validation Accuracy: 0.6411\n",
            "Epoch 50/100, Loss: 21.5026, Validation Accuracy: 0.5932\n",
            "Epoch 51/100, Loss: 22.1075, Validation Accuracy: 0.5872\n",
            "Epoch 52/100, Loss: 18.0067, Validation Accuracy: 0.6311\n",
            "Epoch 53/100, Loss: 43.7678, Validation Accuracy: 0.6660\n",
            "Epoch 54/100, Loss: 25.8142, Validation Accuracy: 0.6311\n",
            "Epoch 55/100, Loss: 142.0502, Validation Accuracy: 0.6321\n",
            "Epoch 56/100, Loss: 61.1145, Validation Accuracy: 0.4905\n",
            "Epoch 57/100, Loss: 49.2298, Validation Accuracy: 0.2164\n",
            "Epoch 58/100, Loss: 25.9578, Validation Accuracy: 0.6162\n",
            "Epoch 59/100, Loss: 17.0427, Validation Accuracy: 0.6550\n",
            "Epoch 60/100, Loss: 28.5143, Validation Accuracy: 0.5234\n",
            "Epoch 61/100, Loss: 182.7192, Validation Accuracy: 0.6620\n",
            "Epoch 62/100, Loss: 89.7608, Validation Accuracy: 0.5922\n",
            "Epoch 63/100, Loss: 15.0967, Validation Accuracy: 0.6451\n",
            "Epoch 64/100, Loss: 17.0846, Validation Accuracy: 0.6650\n",
            "Epoch 65/100, Loss: 14.1655, Validation Accuracy: 0.5603\n",
            "Epoch 66/100, Loss: 42.3564, Validation Accuracy: 0.4257\n",
            "Epoch 67/100, Loss: 11.4689, Validation Accuracy: 0.6351\n",
            "Epoch 68/100, Loss: 791.0484, Validation Accuracy: 0.6740\n",
            "Epoch 69/100, Loss: 35.2228, Validation Accuracy: 0.6461\n",
            "Epoch 70/100, Loss: 21.5873, Validation Accuracy: 0.6630\n",
            "Epoch 71/100, Loss: 23.7341, Validation Accuracy: 0.6411\n",
            "Epoch 72/100, Loss: 14.3001, Validation Accuracy: 0.5234\n",
            "Epoch 73/100, Loss: 12.3558, Validation Accuracy: 0.5773\n",
            "Epoch 74/100, Loss: 7.6133, Validation Accuracy: 0.6241\n",
            "Epoch 75/100, Loss: 18.7047, Validation Accuracy: 0.5414\n",
            "Epoch 76/100, Loss: 25.4990, Validation Accuracy: 0.5643\n",
            "Epoch 77/100, Loss: 36.2405, Validation Accuracy: 0.5663\n",
            "Epoch 78/100, Loss: 11.5351, Validation Accuracy: 0.3948\n",
            "Epoch 79/100, Loss: 33.0827, Validation Accuracy: 0.6710\n",
            "Epoch 80/100, Loss: 20.0144, Validation Accuracy: 0.5982\n",
            "Epoch 81/100, Loss: 43.9682, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 54.7058, Validation Accuracy: 0.6122\n",
            "Epoch 83/100, Loss: 22.9034, Validation Accuracy: 0.6201\n",
            "Epoch 84/100, Loss: 8.5318, Validation Accuracy: 0.4696\n",
            "Epoch 85/100, Loss: 15.5736, Validation Accuracy: 0.5793\n",
            "Epoch 86/100, Loss: 32.8073, Validation Accuracy: 0.5912\n",
            "Epoch 87/100, Loss: 44.4365, Validation Accuracy: 0.6171\n",
            "Epoch 88/100, Loss: 19.7511, Validation Accuracy: 0.4826\n",
            "Epoch 89/100, Loss: 31.1925, Validation Accuracy: 0.5982\n",
            "Epoch 90/100, Loss: 29.4279, Validation Accuracy: 0.6670\n",
            "Epoch 91/100, Loss: 41.0558, Validation Accuracy: 0.5344\n",
            "Epoch 92/100, Loss: 25.8734, Validation Accuracy: 0.5394\n",
            "Epoch 93/100, Loss: 29.9387, Validation Accuracy: 0.5593\n",
            "Epoch 94/100, Loss: 49.2047, Validation Accuracy: 0.4995\n",
            "Epoch 95/100, Loss: 14.7443, Validation Accuracy: 0.6241\n",
            "Epoch 96/100, Loss: 97.1496, Validation Accuracy: 0.5972\n",
            "Epoch 97/100, Loss: 49.7190, Validation Accuracy: 0.4666\n",
            "Epoch 98/100, Loss: 63.1123, Validation Accuracy: 0.4666\n",
            "Epoch 99/100, Loss: 17.2095, Validation Accuracy: 0.4417\n",
            "Epoch 100/100, Loss: 47.7808, Validation Accuracy: 0.5404\n",
            "Epoch 101/100, Loss: 41.0066, Validation Accuracy: 0.5972\n",
            "Epoch 102/100, Loss: 91.3325, Validation Accuracy: 0.5932\n",
            "Epoch 103/100, Loss: 33.9694, Validation Accuracy: 0.6022\n",
            "Epoch 104/100, Loss: 18.2490, Validation Accuracy: 0.5464\n",
            "Epoch 105/100, Loss: 25.7695, Validation Accuracy: 0.6550\n",
            "Epoch 106/100, Loss: 40.1945, Validation Accuracy: 0.5872\n",
            "Epoch 107/100, Loss: 225.1656, Validation Accuracy: 0.4128\n",
            "Epoch 108/100, Loss: 46.0306, Validation Accuracy: 0.4736\n",
            "Epoch 109/100, Loss: 55.5557, Validation Accuracy: 0.5743\n",
            "Epoch 110/100, Loss: 21.1524, Validation Accuracy: 0.4746\n",
            "Epoch 111/100, Loss: 61.8065, Validation Accuracy: 0.5454\n",
            "Epoch 112/100, Loss: 26.6658, Validation Accuracy: 0.5523\n",
            "Epoch 113/100, Loss: 30.3240, Validation Accuracy: 0.5354\n",
            "Epoch 114/100, Loss: 28.6153, Validation Accuracy: 0.6162\n",
            "Epoch 115/100, Loss: 35.4252, Validation Accuracy: 0.5075\n",
            "Epoch 116/100, Loss: 19.9101, Validation Accuracy: 0.5075\n",
            "Epoch 117/100, Loss: 67.6996, Validation Accuracy: 0.5753\n",
            "Epoch 118/100, Loss: 55.0774, Validation Accuracy: 0.6401\n",
            "Epoch 119/100, Loss: 132.3191, Validation Accuracy: 0.5922\n",
            "Epoch 120/100, Loss: 51.0267, Validation Accuracy: 0.4327\n",
            "Epoch 121/100, Loss: 25.8827, Validation Accuracy: 0.6481\n",
            "Epoch 122/100, Loss: 18.9000, Validation Accuracy: 0.5135\n",
            "Epoch 123/100, Loss: 33.7760, Validation Accuracy: 0.4646\n",
            "Epoch 124/100, Loss: 33.1752, Validation Accuracy: 0.6142\n",
            "Epoch 125/100, Loss: 25.5963, Validation Accuracy: 0.6321\n",
            "Epoch 126/100, Loss: 54.4684, Validation Accuracy: 0.5723\n",
            "Epoch 127/100, Loss: 57.9917, Validation Accuracy: 0.6221\n",
            "Epoch 128/100, Loss: 35.3193, Validation Accuracy: 0.5952\n",
            "Epoch 129/100, Loss: 36.0076, Validation Accuracy: 0.6142\n",
            "Epoch 130/100, Loss: 22.1464, Validation Accuracy: 0.6171\n",
            "Epoch 131/100, Loss: 48.7502, Validation Accuracy: 0.5872\n",
            "Epoch 132/100, Loss: 126.1055, Validation Accuracy: 0.5404\n",
            "Epoch 133/100, Loss: 33.6216, Validation Accuracy: 0.2951\n",
            "Epoch 134/100, Loss: 19.0479, Validation Accuracy: 0.5823\n",
            "Epoch 135/100, Loss: 22.2460, Validation Accuracy: 0.6650\n",
            "Epoch 136/100, Loss: 22.0880, Validation Accuracy: 0.4626\n",
            "Epoch 137/100, Loss: 55.4703, Validation Accuracy: 0.6201\n",
            "Epoch 138/100, Loss: 25.2692, Validation Accuracy: 0.5573\n",
            "Epoch 139/100, Loss: 44.0540, Validation Accuracy: 0.6600\n",
            "Epoch 140/100, Loss: 70.0300, Validation Accuracy: 0.5384\n",
            "Epoch 141/100, Loss: 48.3993, Validation Accuracy: 0.5474\n",
            "Epoch 142/100, Loss: 8.7807, Validation Accuracy: 0.6072\n",
            "Epoch 143/100, Loss: 52.3927, Validation Accuracy: 0.4217\n",
            "Epoch 144/100, Loss: 77.7503, Validation Accuracy: 0.6191\n",
            "Epoch 145/100, Loss: 25.9847, Validation Accuracy: 0.5135\n",
            "Epoch 146/100, Loss: 63.9055, Validation Accuracy: 0.6590\n",
            "Epoch 147/100, Loss: 39.0337, Validation Accuracy: 0.5912\n",
            "Epoch 148/100, Loss: 34.8555, Validation Accuracy: 0.5783\n",
            "Epoch 149/100, Loss: 59.6042, Validation Accuracy: 0.6351\n",
            "Epoch 150/100, Loss: 30.0769, Validation Accuracy: 0.5872\n",
            "Epoch 151/100, Loss: 61.5336, Validation Accuracy: 0.6730\n",
            "Epoch 152/100, Loss: 20.8814, Validation Accuracy: 0.5743\n",
            "Epoch 153/100, Loss: 28.1408, Validation Accuracy: 0.6441\n",
            "Epoch 154/100, Loss: 96.5132, Validation Accuracy: 0.5484\n",
            "Epoch 155/100, Loss: 31.1630, Validation Accuracy: 0.4128\n",
            "Epoch 156/100, Loss: 71.4856, Validation Accuracy: 0.6560\n",
            "Epoch 157/100, Loss: 42.0257, Validation Accuracy: 0.5613\n",
            "Epoch 158/100, Loss: 44.9810, Validation Accuracy: 0.6770\n",
            "Epoch 159/100, Loss: 71.8220, Validation Accuracy: 0.6251\n",
            "Epoch 160/100, Loss: 44.8838, Validation Accuracy: 0.6750\n",
            "Epoch 161/100, Loss: 129.8258, Validation Accuracy: 0.6451\n",
            "Epoch 162/100, Loss: 17.9301, Validation Accuracy: 0.5753\n",
            "Epoch 163/100, Loss: 46.3966, Validation Accuracy: 0.5105\n",
            "Epoch 164/100, Loss: 45.6020, Validation Accuracy: 0.4686\n",
            "Epoch 165/100, Loss: 49.1270, Validation Accuracy: 0.5733\n",
            "Epoch 166/100, Loss: 26.6748, Validation Accuracy: 0.6830\n",
            "Epoch 167/100, Loss: 84.3678, Validation Accuracy: 0.6710\n",
            "Epoch 168/100, Loss: 22.0435, Validation Accuracy: 0.6331\n",
            "Epoch 169/100, Loss: 38.2706, Validation Accuracy: 0.6660\n",
            "Epoch 170/100, Loss: 44.2020, Validation Accuracy: 0.6381\n",
            "Epoch 171/100, Loss: 43.0500, Validation Accuracy: 0.6570\n",
            "Epoch 172/100, Loss: 41.8192, Validation Accuracy: 0.6560\n",
            "Epoch 173/100, Loss: 35.6101, Validation Accuracy: 0.6331\n",
            "Epoch 174/100, Loss: 37.7022, Validation Accuracy: 0.6570\n",
            "Epoch 175/100, Loss: 99.7478, Validation Accuracy: 0.6560\n",
            "Epoch 176/100, Loss: 48.9681, Validation Accuracy: 0.6750\n",
            "Epoch 177/100, Loss: 12.3754, Validation Accuracy: 0.6740\n",
            "Epoch 178/100, Loss: 49.8816, Validation Accuracy: 0.5932\n",
            "Epoch 179/100, Loss: 28.2158, Validation Accuracy: 0.5354\n",
            "Epoch 180/100, Loss: 24.9942, Validation Accuracy: 0.5394\n",
            "Epoch 181/100, Loss: 24.8362, Validation Accuracy: 0.6112\n",
            "Epoch 182/100, Loss: 30.8543, Validation Accuracy: 0.5513\n",
            "Epoch 183/100, Loss: 94.9544, Validation Accuracy: 0.5075\n",
            "Epoch 184/100, Loss: 32.3704, Validation Accuracy: 0.5673\n",
            "Epoch 185/100, Loss: 23.4993, Validation Accuracy: 0.4965\n",
            "Epoch 186/100, Loss: 35.9891, Validation Accuracy: 0.5474\n",
            "Epoch 187/100, Loss: 76.5625, Validation Accuracy: 0.5663\n",
            "Epoch 188/100, Loss: 30.4492, Validation Accuracy: 0.6391\n",
            "Epoch 189/100, Loss: 20.2951, Validation Accuracy: 0.6122\n",
            "Epoch 190/100, Loss: 47.7391, Validation Accuracy: 0.6082\n",
            "Epoch 191/100, Loss: 35.9353, Validation Accuracy: 0.5623\n",
            "Epoch 192/100, Loss: 44.7006, Validation Accuracy: 0.5743\n",
            "Epoch 193/100, Loss: 98.3842, Validation Accuracy: 0.6331\n",
            "Epoch 194/100, Loss: 37.1295, Validation Accuracy: 0.6381\n",
            "Epoch 195/100, Loss: 28.4416, Validation Accuracy: 0.6132\n",
            "Epoch 196/100, Loss: 25.9454, Validation Accuracy: 0.6401\n",
            "Epoch 197/100, Loss: 13.4214, Validation Accuracy: 0.5364\n",
            "Epoch 198/100, Loss: 22.3071, Validation Accuracy: 0.6082\n",
            "Epoch 199/100, Loss: 61.9383, Validation Accuracy: 0.5354\n",
            "Epoch 200/100, Loss: 48.1576, Validation Accuracy: 0.3470\n",
            "Reward for Child Model: 0.2622420221851996\n",
            "Child_13:  {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, [0, 2, 2, 1, 1, 2, 1, 0, 3, 2, 0, 1, 3, 2, 1], 0.2622420221851996\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(96, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(48, 64, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(112, 36, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=48048, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 26, 26]           1,344\n",
            "       BatchNorm2d-2           [-1, 48, 26, 26]              96\n",
            "            Conv2d-3           [-1, 48, 24, 26]           6,960\n",
            "       BatchNorm2d-4           [-1, 48, 24, 26]              96\n",
            "              ReLU-5           [-1, 48, 24, 26]               0\n",
            "            Conv2d-6           [-1, 48, 26, 22]          23,088\n",
            "       BatchNorm2d-7           [-1, 48, 26, 22]              96\n",
            "              ReLU-8           [-1, 48, 26, 22]               0\n",
            "            Conv2d-9           [-1, 64, 24, 22]           9,280\n",
            "      BatchNorm2d-10           [-1, 64, 24, 22]             128\n",
            "             ReLU-11           [-1, 64, 24, 22]               0\n",
            "           Conv2d-12           [-1, 36, 20, 22]          28,260\n",
            "      BatchNorm2d-13           [-1, 36, 20, 22]              72\n",
            "             ReLU-14           [-1, 36, 20, 22]               0\n",
            "           Linear-15                    [-1, 7]         336,343\n",
            "================================================================\n",
            "Total params: 405,763\n",
            "Trainable params: 405,763\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.95\n",
            "Params size (MB): 1.55\n",
            "Estimated Total Size (MB): 4.50\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 3.3429, Validation Accuracy: 0.6700\n",
            "Epoch 2/100, Loss: 1.3669, Validation Accuracy: 0.6690\n",
            "Epoch 3/100, Loss: 1.3538, Validation Accuracy: 0.6690\n",
            "Epoch 4/100, Loss: 0.7519, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 1.3056, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 1.3842, Validation Accuracy: 0.6650\n",
            "Epoch 7/100, Loss: 1.0515, Validation Accuracy: 0.6411\n",
            "Epoch 8/100, Loss: 1.1753, Validation Accuracy: 0.6610\n",
            "Epoch 9/100, Loss: 1.1132, Validation Accuracy: 0.6680\n",
            "Epoch 10/100, Loss: 1.1787, Validation Accuracy: 0.6630\n",
            "Epoch 11/100, Loss: 1.3101, Validation Accuracy: 0.6640\n",
            "Epoch 12/100, Loss: 0.8429, Validation Accuracy: 0.6630\n",
            "Epoch 13/100, Loss: 1.2260, Validation Accuracy: 0.6660\n",
            "Epoch 14/100, Loss: 1.0128, Validation Accuracy: 0.6640\n",
            "Epoch 15/100, Loss: 1.1797, Validation Accuracy: 0.6680\n",
            "Epoch 16/100, Loss: 1.3958, Validation Accuracy: 0.6660\n",
            "Epoch 17/100, Loss: 1.3919, Validation Accuracy: 0.6630\n",
            "Epoch 18/100, Loss: 0.9253, Validation Accuracy: 0.6660\n",
            "Epoch 19/100, Loss: 0.9071, Validation Accuracy: 0.6640\n",
            "Epoch 20/100, Loss: 0.9768, Validation Accuracy: 0.6650\n",
            "Epoch 21/100, Loss: 1.4192, Validation Accuracy: 0.6630\n",
            "Epoch 22/100, Loss: 0.6910, Validation Accuracy: 0.6640\n",
            "Epoch 23/100, Loss: 1.6446, Validation Accuracy: 0.6630\n",
            "Epoch 24/100, Loss: 0.9588, Validation Accuracy: 0.6650\n",
            "Epoch 25/100, Loss: 1.2527, Validation Accuracy: 0.6650\n",
            "Epoch 26/100, Loss: 1.3633, Validation Accuracy: 0.6630\n",
            "Epoch 27/100, Loss: 1.0126, Validation Accuracy: 0.6650\n",
            "Epoch 28/100, Loss: 0.9015, Validation Accuracy: 0.6650\n",
            "Epoch 29/100, Loss: 1.2949, Validation Accuracy: 0.6660\n",
            "Epoch 30/100, Loss: 1.1478, Validation Accuracy: 0.6670\n",
            "Epoch 31/100, Loss: 1.0506, Validation Accuracy: 0.6650\n",
            "Epoch 32/100, Loss: 1.1905, Validation Accuracy: 0.6680\n",
            "Epoch 33/100, Loss: 1.1724, Validation Accuracy: 0.6660\n",
            "Epoch 34/100, Loss: 1.0167, Validation Accuracy: 0.6670\n",
            "Epoch 35/100, Loss: 0.9633, Validation Accuracy: 0.6680\n",
            "Epoch 36/100, Loss: 0.8080, Validation Accuracy: 0.6670\n",
            "Epoch 37/100, Loss: 1.2370, Validation Accuracy: 0.6670\n",
            "Epoch 38/100, Loss: 1.0817, Validation Accuracy: 0.6680\n",
            "Epoch 39/100, Loss: 1.1883, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 1.3097, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 0.9166, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 0.9304, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 1.1329, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 1.0720, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 0.7494, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 1.0400, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 1.0191, Validation Accuracy: 0.6670\n",
            "Epoch 48/100, Loss: 0.9757, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 1.1981, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 0.8484, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 1.3205, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 0.9583, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 1.1048, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 0.8974, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 0.6855, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 1.2835, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 1.2383, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 1.1995, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 0.9076, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 1.0184, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 1.1836, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 1.2438, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 1.3991, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 0.9676, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 1.1475, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 1.3935, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 1.0381, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 0.8854, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 1.3357, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 0.9398, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 0.9882, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 0.9883, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 0.9386, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 1.1846, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 1.1593, Validation Accuracy: 0.6690\n",
            "Epoch 76/100, Loss: 1.0762, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 1.0628, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 1.4399, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 1.2184, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 1.0544, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 1.1084, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 1.0453, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 1.1715, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 1.0802, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 1.6365, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 1.4435, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 0.9677, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 1.1764, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 0.9415, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 1.2238, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 1.2064, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 0.9589, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 1.2531, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 1.0742, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 0.9977, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 1.0252, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 0.7271, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 1.3032, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 1.3288, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 0.9441, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 0.9967, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 1.2471, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 1.3106, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 1.1139, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 1.1729, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 1.3703, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 0.8359, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 0.9710, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 0.8745, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 1.0453, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.0204, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 0.9198, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 1.2277, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 0.9701, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 0.9857, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 0.9889, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 1.3487, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 1.1476, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 1.1207, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 1.2942, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 1.1117, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.3056, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 0.8885, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 1.4186, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 0.9454, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 1.4323, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 0.9977, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 1.5812, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 0.8622, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 1.1779, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 1.0913, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 1.1638, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 0.9963, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 1.4071, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 1.1182, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 0.9736, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 1.2054, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 1.0737, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 1.1047, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 0.9159, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 1.1346, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 0.9841, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 1.4706, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 1.1306, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 0.8893, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 1.2495, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 0.8915, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 0.9019, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 1.2172, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 1.1540, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 0.8867, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 0.9325, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 1.0339, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 0.8820, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 1.1097, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 1.0874, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 1.1877, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 1.1825, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 1.0413, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 1.0521, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 1.3955, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 0.9064, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 1.0322, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 1.3598, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 0.7771, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 0.9778, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 0.9333, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 1.5365, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 0.9195, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 1.6381, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 0.8755, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 0.9278, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 1.1267, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 1.1167, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 1.3190, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 0.9960, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 1.4239, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 1.2414, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 1.1199, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 1.1687, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 0.7060, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 1.2936, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 0.7539, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 1.4984, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 1.3046, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 1.2670, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 1.1766, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 0.8517, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 1.1222, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 1.1859, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 1.2048, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 0.7544, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 1.1474, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 1.6440, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 1.4714, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 1.0141, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 0.8630, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 1.1253, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 1.2028, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 0.9849, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_14:  {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, [1, 1, 2, 1, 0, 2, 0, 2, 2, 1, 0, 3, 3, 0, 1], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 24, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 48, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(48, 24, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=31680, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 24, 24]           1,824\n",
            "       BatchNorm2d-2           [-1, 24, 24, 24]              48\n",
            "            Conv2d-3           [-1, 24, 22, 20]           8,664\n",
            "       BatchNorm2d-4           [-1, 24, 22, 20]              48\n",
            "              ReLU-5           [-1, 24, 22, 20]               0\n",
            "            Conv2d-6           [-1, 48, 20, 16]          17,328\n",
            "       BatchNorm2d-7           [-1, 48, 20, 16]              96\n",
            "              ReLU-8           [-1, 48, 20, 16]               0\n",
            "            Conv2d-9           [-1, 24, 20, 12]           5,784\n",
            "      BatchNorm2d-10           [-1, 24, 20, 12]              48\n",
            "             ReLU-11           [-1, 24, 20, 12]               0\n",
            "           Conv2d-12           [-1, 48, 20, 18]          41,520\n",
            "      BatchNorm2d-13           [-1, 48, 20, 18]              96\n",
            "             ReLU-14           [-1, 48, 20, 18]               0\n",
            "           Linear-15                    [-1, 7]         221,767\n",
            "================================================================\n",
            "Total params: 297,223\n",
            "Trainable params: 297,223\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.33\n",
            "Params size (MB): 1.13\n",
            "Estimated Total Size (MB): 2.47\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 1.0007, Validation Accuracy: 0.6690\n",
            "Epoch 2/100, Loss: 0.6365, Validation Accuracy: 0.6690\n",
            "Epoch 3/100, Loss: 1.2715, Validation Accuracy: 0.6690\n",
            "Epoch 4/100, Loss: 1.0019, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 0.9449, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 1.1529, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 1.0338, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 1.1860, Validation Accuracy: 0.6690\n",
            "Epoch 9/100, Loss: 0.9204, Validation Accuracy: 0.6690\n",
            "Epoch 10/100, Loss: 1.0293, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 1.2178, Validation Accuracy: 0.6690\n",
            "Epoch 12/100, Loss: 1.1269, Validation Accuracy: 0.6690\n",
            "Epoch 13/100, Loss: 1.0927, Validation Accuracy: 0.6690\n",
            "Epoch 14/100, Loss: 1.1116, Validation Accuracy: 0.6690\n",
            "Epoch 15/100, Loss: 1.1107, Validation Accuracy: 0.6690\n",
            "Epoch 16/100, Loss: 1.2059, Validation Accuracy: 0.6690\n",
            "Epoch 17/100, Loss: 1.1768, Validation Accuracy: 0.6690\n",
            "Epoch 18/100, Loss: 1.4086, Validation Accuracy: 0.6690\n",
            "Epoch 19/100, Loss: 1.2521, Validation Accuracy: 0.6690\n",
            "Epoch 20/100, Loss: 0.9480, Validation Accuracy: 0.6690\n",
            "Epoch 21/100, Loss: 0.9802, Validation Accuracy: 0.6690\n",
            "Epoch 22/100, Loss: 1.1036, Validation Accuracy: 0.6690\n",
            "Epoch 23/100, Loss: 1.7330, Validation Accuracy: 0.6690\n",
            "Epoch 24/100, Loss: 1.1953, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 1.2336, Validation Accuracy: 0.6690\n",
            "Epoch 26/100, Loss: 0.8731, Validation Accuracy: 0.6690\n",
            "Epoch 27/100, Loss: 1.2592, Validation Accuracy: 0.6690\n",
            "Epoch 28/100, Loss: 1.4839, Validation Accuracy: 0.6690\n",
            "Epoch 29/100, Loss: 1.2130, Validation Accuracy: 0.6690\n",
            "Epoch 30/100, Loss: 1.1380, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 1.0994, Validation Accuracy: 0.6690\n",
            "Epoch 32/100, Loss: 1.1373, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 1.1700, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 1.1225, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 1.3659, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 0.9957, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 0.9310, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 0.9330, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 1.1163, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 1.3153, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 1.5461, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 0.7605, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 1.1811, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 1.5973, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 1.1897, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 1.0133, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 0.9341, Validation Accuracy: 0.6690\n",
            "Epoch 48/100, Loss: 1.0214, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 1.1988, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 1.0248, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 1.3748, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 1.2709, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 0.8505, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 0.9860, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 1.1895, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 0.7596, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 0.8698, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 1.4962, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 1.2167, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 0.6701, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 1.2017, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 0.9162, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 1.4095, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 1.1112, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 1.0133, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 0.9890, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 0.7952, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 1.2137, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 0.9412, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 0.8699, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 1.3076, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 1.3609, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 1.0950, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 1.0647, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 1.2264, Validation Accuracy: 0.6690\n",
            "Epoch 76/100, Loss: 1.2426, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 1.1973, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 1.1393, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 1.1811, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 1.0891, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 1.1118, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 1.1745, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 1.2810, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 1.1009, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 0.7801, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 0.9429, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 1.0483, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 1.5461, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 1.0327, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 1.0680, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 0.5843, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 0.7822, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 1.1070, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 0.9321, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 1.2151, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 1.1407, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 1.0003, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 0.9976, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 1.2238, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 1.1824, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 0.9785, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 1.4382, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 0.9260, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 1.2979, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 0.9257, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 1.1431, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 1.2181, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 0.6559, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 1.0909, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 1.4200, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.0259, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 1.1411, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 1.3865, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 1.3086, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 1.2476, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 0.9717, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 1.5854, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 1.4927, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 1.4624, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 1.0917, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 0.9173, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.4027, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 0.8652, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 1.1205, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 0.9185, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 1.2723, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 0.9404, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 0.9415, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 0.8566, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 1.0810, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 1.3115, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 0.9655, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 1.1688, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 0.9313, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 1.3884, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 0.7441, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 1.0139, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 0.9786, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 1.3570, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 1.0457, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 1.4001, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 1.3291, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 1.0940, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 0.9345, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 1.1965, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 1.2284, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 1.3319, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 1.1532, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 1.1726, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 1.4345, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 1.3747, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 1.2302, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 1.5089, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 1.3690, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 1.4050, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 1.3947, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 1.0345, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 0.9669, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 1.2217, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 1.3074, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 0.8710, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 1.2317, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 0.9420, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 1.2018, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 0.9115, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 0.9873, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 1.1244, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 1.1337, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 1.1709, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 1.1219, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 0.9522, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 1.0422, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 1.3770, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 0.9746, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 1.0545, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 1.2258, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 1.3847, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 1.1529, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 1.1058, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 0.6981, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 1.1407, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 1.6079, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 1.1619, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 1.1943, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 1.3438, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 1.3554, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 1.0182, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 1.4644, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 1.0997, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 0.8256, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 1.3909, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 1.0593, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 1.2711, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 1.0645, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 1.2354, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 1.2517, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 1.3200, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 1.1402, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 1.5387, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 0.8305, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_15:  {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, [2, 2, 0, 1, 2, 0, 1, 2, 2, 0, 2, 0, 1, 1, 2], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 24, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(72, 48, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(136, 24, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=150528, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 24, 28]           1,024\n",
            "       BatchNorm2d-2           [-1, 64, 24, 28]             128\n",
            "            Conv2d-3           [-1, 24, 22, 22]          32,280\n",
            "       BatchNorm2d-4           [-1, 24, 22, 22]              48\n",
            "              ReLU-5           [-1, 24, 22, 22]               0\n",
            "            Conv2d-6           [-1, 48, 16, 20]          24,240\n",
            "       BatchNorm2d-7           [-1, 48, 16, 20]              96\n",
            "              ReLU-8           [-1, 48, 16, 20]               0\n",
            "            Conv2d-9           [-1, 48, 22, 20]          10,416\n",
            "      BatchNorm2d-10           [-1, 48, 22, 20]              96\n",
            "             ReLU-11           [-1, 48, 22, 20]               0\n",
            "           Conv2d-12           [-1, 24, 20, 22]         114,264\n",
            "      BatchNorm2d-13           [-1, 24, 20, 22]              48\n",
            "             ReLU-14           [-1, 24, 20, 22]               0\n",
            "           Linear-15                    [-1, 7]       1,053,703\n",
            "================================================================\n",
            "Total params: 1,236,343\n",
            "Trainable params: 1,236,343\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.00\n",
            "Params size (MB): 4.72\n",
            "Estimated Total Size (MB): 6.72\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 48.2569, Validation Accuracy: 0.6381\n",
            "Epoch 2/100, Loss: 8.8235, Validation Accuracy: 0.5264\n",
            "Epoch 3/100, Loss: 898.0898, Validation Accuracy: 0.6550\n",
            "Epoch 4/100, Loss: 25.7758, Validation Accuracy: 0.6750\n",
            "Epoch 5/100, Loss: 56.6958, Validation Accuracy: 0.6700\n",
            "Epoch 6/100, Loss: 75.0178, Validation Accuracy: 0.6052\n",
            "Epoch 7/100, Loss: 52.4339, Validation Accuracy: 0.6560\n",
            "Epoch 8/100, Loss: 85.5782, Validation Accuracy: 0.6650\n",
            "Epoch 9/100, Loss: 91.3017, Validation Accuracy: 0.6680\n",
            "Epoch 10/100, Loss: 37.4682, Validation Accuracy: 0.6530\n",
            "Epoch 11/100, Loss: 141.3145, Validation Accuracy: 0.6401\n",
            "Epoch 12/100, Loss: 79.1000, Validation Accuracy: 0.5523\n",
            "Epoch 13/100, Loss: 48.8793, Validation Accuracy: 0.1934\n",
            "Epoch 14/100, Loss: 433.5905, Validation Accuracy: 0.4935\n",
            "Epoch 15/100, Loss: 175.9314, Validation Accuracy: 0.6231\n",
            "Epoch 16/100, Loss: 98.5900, Validation Accuracy: 0.5723\n",
            "Epoch 17/100, Loss: 60.5634, Validation Accuracy: 0.5803\n",
            "Epoch 18/100, Loss: 72.9692, Validation Accuracy: 0.6361\n",
            "Epoch 19/100, Loss: 46.8810, Validation Accuracy: 0.6720\n",
            "Epoch 20/100, Loss: 296.8050, Validation Accuracy: 0.4327\n",
            "Epoch 21/100, Loss: 90.9394, Validation Accuracy: 0.6261\n",
            "Epoch 22/100, Loss: 168.7178, Validation Accuracy: 0.4666\n",
            "Epoch 23/100, Loss: 117.4994, Validation Accuracy: 0.5454\n",
            "Epoch 24/100, Loss: 124.8397, Validation Accuracy: 0.6700\n",
            "Epoch 25/100, Loss: 210.3681, Validation Accuracy: 0.5833\n",
            "Epoch 26/100, Loss: 112.9558, Validation Accuracy: 0.5932\n",
            "Epoch 27/100, Loss: 125.9430, Validation Accuracy: 0.6251\n",
            "Epoch 28/100, Loss: 110.0941, Validation Accuracy: 0.5075\n",
            "Epoch 29/100, Loss: 179.8801, Validation Accuracy: 0.5892\n",
            "Epoch 30/100, Loss: 278.1592, Validation Accuracy: 0.5573\n",
            "Epoch 31/100, Loss: 75.0223, Validation Accuracy: 0.6411\n",
            "Epoch 32/100, Loss: 61.1829, Validation Accuracy: 0.6361\n",
            "Epoch 33/100, Loss: 40.4542, Validation Accuracy: 0.6221\n",
            "Epoch 34/100, Loss: 97.4339, Validation Accuracy: 0.6929\n",
            "Epoch 35/100, Loss: 48.3997, Validation Accuracy: 0.6132\n",
            "Epoch 36/100, Loss: 187.7000, Validation Accuracy: 0.5852\n",
            "Epoch 37/100, Loss: 153.1117, Validation Accuracy: 0.5643\n",
            "Epoch 38/100, Loss: 52.3572, Validation Accuracy: 0.6570\n",
            "Epoch 39/100, Loss: 60.6895, Validation Accuracy: 0.4826\n",
            "Epoch 40/100, Loss: 174.5679, Validation Accuracy: 0.6142\n",
            "Epoch 41/100, Loss: 185.7522, Validation Accuracy: 0.6431\n",
            "Epoch 42/100, Loss: 92.0061, Validation Accuracy: 0.4696\n",
            "Epoch 43/100, Loss: 74.2820, Validation Accuracy: 0.5364\n",
            "Epoch 44/100, Loss: 109.9030, Validation Accuracy: 0.5543\n",
            "Epoch 45/100, Loss: 104.2664, Validation Accuracy: 0.6550\n",
            "Epoch 46/100, Loss: 211.1065, Validation Accuracy: 0.5324\n",
            "Epoch 47/100, Loss: 117.6111, Validation Accuracy: 0.6281\n",
            "Epoch 48/100, Loss: 124.7225, Validation Accuracy: 0.6032\n",
            "Epoch 49/100, Loss: 40.9593, Validation Accuracy: 0.6361\n",
            "Epoch 50/100, Loss: 197.8750, Validation Accuracy: 0.6869\n",
            "Epoch 51/100, Loss: 59.7638, Validation Accuracy: 0.4796\n",
            "Epoch 52/100, Loss: 143.6675, Validation Accuracy: 0.6012\n",
            "Epoch 53/100, Loss: 189.6305, Validation Accuracy: 0.5494\n",
            "Epoch 54/100, Loss: 119.0743, Validation Accuracy: 0.6810\n",
            "Epoch 55/100, Loss: 203.7025, Validation Accuracy: 0.4855\n",
            "Epoch 56/100, Loss: 96.7973, Validation Accuracy: 0.6231\n",
            "Epoch 57/100, Loss: 82.7631, Validation Accuracy: 0.6371\n",
            "Epoch 58/100, Loss: 58.6474, Validation Accuracy: 0.6331\n",
            "Epoch 59/100, Loss: 162.1819, Validation Accuracy: 0.5613\n",
            "Epoch 60/100, Loss: 158.5762, Validation Accuracy: 0.6321\n",
            "Epoch 61/100, Loss: 77.5476, Validation Accuracy: 0.6181\n",
            "Epoch 62/100, Loss: 208.6819, Validation Accuracy: 0.6540\n",
            "Epoch 63/100, Loss: 162.4057, Validation Accuracy: 0.5324\n",
            "Epoch 64/100, Loss: 180.0344, Validation Accuracy: 0.6570\n",
            "Epoch 65/100, Loss: 135.7867, Validation Accuracy: 0.6431\n",
            "Epoch 66/100, Loss: 254.0361, Validation Accuracy: 0.6620\n",
            "Epoch 67/100, Loss: 72.2265, Validation Accuracy: 0.6082\n",
            "Epoch 68/100, Loss: 110.6807, Validation Accuracy: 0.6780\n",
            "Epoch 69/100, Loss: 139.3859, Validation Accuracy: 0.4566\n",
            "Epoch 70/100, Loss: 179.3644, Validation Accuracy: 0.6530\n",
            "Epoch 71/100, Loss: 125.4142, Validation Accuracy: 0.4536\n",
            "Epoch 72/100, Loss: 97.8011, Validation Accuracy: 0.6610\n",
            "Epoch 73/100, Loss: 247.7863, Validation Accuracy: 0.5015\n",
            "Epoch 74/100, Loss: 145.3706, Validation Accuracy: 0.5683\n",
            "Epoch 75/100, Loss: 118.7833, Validation Accuracy: 0.5005\n",
            "Epoch 76/100, Loss: 93.6816, Validation Accuracy: 0.6371\n",
            "Epoch 77/100, Loss: 153.2183, Validation Accuracy: 0.6062\n",
            "Epoch 78/100, Loss: 121.2349, Validation Accuracy: 0.5773\n",
            "Epoch 79/100, Loss: 35.4774, Validation Accuracy: 0.5982\n",
            "Epoch 80/100, Loss: 45.5538, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 58.2867, Validation Accuracy: 0.6800\n",
            "Epoch 82/100, Loss: 68.5941, Validation Accuracy: 0.6790\n",
            "Epoch 83/100, Loss: 83.2957, Validation Accuracy: 0.6680\n",
            "Epoch 84/100, Loss: 129.6648, Validation Accuracy: 0.5743\n",
            "Epoch 85/100, Loss: 50.5037, Validation Accuracy: 0.4158\n",
            "Epoch 86/100, Loss: 53.3629, Validation Accuracy: 0.6012\n",
            "Epoch 87/100, Loss: 103.9906, Validation Accuracy: 0.5902\n",
            "Epoch 88/100, Loss: 165.4057, Validation Accuracy: 0.6191\n",
            "Epoch 89/100, Loss: 105.8307, Validation Accuracy: 0.5454\n",
            "Epoch 90/100, Loss: 227.2886, Validation Accuracy: 0.5583\n",
            "Epoch 91/100, Loss: 130.3275, Validation Accuracy: 0.6321\n",
            "Epoch 92/100, Loss: 128.6817, Validation Accuracy: 0.6201\n",
            "Epoch 93/100, Loss: 210.2670, Validation Accuracy: 0.5374\n",
            "Epoch 94/100, Loss: 138.2852, Validation Accuracy: 0.6760\n",
            "Epoch 95/100, Loss: 158.8712, Validation Accuracy: 0.5803\n",
            "Epoch 96/100, Loss: 124.5218, Validation Accuracy: 0.5862\n",
            "Epoch 97/100, Loss: 211.2648, Validation Accuracy: 0.6281\n",
            "Epoch 98/100, Loss: 58.6929, Validation Accuracy: 0.6660\n",
            "Epoch 99/100, Loss: 145.4810, Validation Accuracy: 0.5743\n",
            "Epoch 100/100, Loss: 218.9476, Validation Accuracy: 0.6391\n",
            "Epoch 101/100, Loss: 119.9378, Validation Accuracy: 0.5803\n",
            "Epoch 102/100, Loss: 234.3941, Validation Accuracy: 0.5523\n",
            "Epoch 103/100, Loss: 51.7878, Validation Accuracy: 0.6859\n",
            "Epoch 104/100, Loss: 67.0530, Validation Accuracy: 0.4277\n",
            "Epoch 105/100, Loss: 111.8901, Validation Accuracy: 0.6191\n",
            "Epoch 106/100, Loss: 111.7297, Validation Accuracy: 0.6520\n",
            "Epoch 107/100, Loss: 123.8475, Validation Accuracy: 0.6500\n",
            "Epoch 108/100, Loss: 104.7949, Validation Accuracy: 0.6102\n",
            "Epoch 109/100, Loss: 60.2306, Validation Accuracy: 0.6710\n",
            "Epoch 110/100, Loss: 96.8375, Validation Accuracy: 0.5703\n",
            "Epoch 111/100, Loss: 239.9118, Validation Accuracy: 0.6670\n",
            "Epoch 112/100, Loss: 225.0254, Validation Accuracy: 0.5823\n",
            "Epoch 113/100, Loss: 94.0771, Validation Accuracy: 0.5015\n",
            "Epoch 114/100, Loss: 265.5372, Validation Accuracy: 0.5723\n",
            "Epoch 115/100, Loss: 78.2362, Validation Accuracy: 0.6361\n",
            "Epoch 116/100, Loss: 127.6087, Validation Accuracy: 0.5553\n",
            "Epoch 117/100, Loss: 115.5121, Validation Accuracy: 0.6949\n",
            "Epoch 118/100, Loss: 89.9124, Validation Accuracy: 0.5902\n",
            "Epoch 119/100, Loss: 188.3105, Validation Accuracy: 0.4148\n",
            "Epoch 120/100, Loss: 99.1127, Validation Accuracy: 0.6221\n",
            "Epoch 121/100, Loss: 189.8161, Validation Accuracy: 0.6660\n",
            "Epoch 122/100, Loss: 164.0170, Validation Accuracy: 0.6670\n",
            "Epoch 123/100, Loss: 276.8560, Validation Accuracy: 0.5862\n",
            "Epoch 124/100, Loss: 101.6872, Validation Accuracy: 0.6391\n",
            "Epoch 125/100, Loss: 110.3185, Validation Accuracy: 0.6949\n",
            "Epoch 126/100, Loss: 190.1329, Validation Accuracy: 0.6650\n",
            "Epoch 127/100, Loss: 76.9926, Validation Accuracy: 0.6491\n",
            "Epoch 128/100, Loss: 142.0704, Validation Accuracy: 0.6092\n",
            "Epoch 129/100, Loss: 80.5005, Validation Accuracy: 0.5783\n",
            "Epoch 130/100, Loss: 102.9318, Validation Accuracy: 0.5932\n",
            "Epoch 131/100, Loss: 45.8364, Validation Accuracy: 0.6680\n",
            "Epoch 132/100, Loss: 75.9115, Validation Accuracy: 0.6211\n",
            "Epoch 133/100, Loss: 139.2062, Validation Accuracy: 0.5852\n",
            "Epoch 134/100, Loss: 54.3168, Validation Accuracy: 0.6361\n",
            "Epoch 135/100, Loss: 103.5682, Validation Accuracy: 0.6810\n",
            "Epoch 136/100, Loss: 178.7675, Validation Accuracy: 0.5813\n",
            "Epoch 137/100, Loss: 92.2843, Validation Accuracy: 0.6800\n",
            "Epoch 138/100, Loss: 53.4032, Validation Accuracy: 0.6112\n",
            "Epoch 139/100, Loss: 136.0747, Validation Accuracy: 0.5404\n",
            "Epoch 140/100, Loss: 191.3536, Validation Accuracy: 0.5872\n",
            "Epoch 141/100, Loss: 81.1341, Validation Accuracy: 0.6610\n",
            "Epoch 142/100, Loss: 53.8755, Validation Accuracy: 0.6700\n",
            "Epoch 143/100, Loss: 266.4757, Validation Accuracy: 0.5404\n",
            "Epoch 144/100, Loss: 136.1645, Validation Accuracy: 0.5753\n",
            "Epoch 145/100, Loss: 56.2643, Validation Accuracy: 0.6401\n",
            "Epoch 146/100, Loss: 84.7690, Validation Accuracy: 0.6321\n",
            "Epoch 147/100, Loss: 99.9050, Validation Accuracy: 0.5384\n",
            "Epoch 148/100, Loss: 105.5449, Validation Accuracy: 0.6291\n",
            "Epoch 149/100, Loss: 242.1914, Validation Accuracy: 0.6620\n",
            "Epoch 150/100, Loss: 175.2164, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 61.3881, Validation Accuracy: 0.5693\n",
            "Epoch 152/100, Loss: 158.4933, Validation Accuracy: 0.5533\n",
            "Epoch 153/100, Loss: 162.1252, Validation Accuracy: 0.6640\n",
            "Epoch 154/100, Loss: 51.4004, Validation Accuracy: 0.6590\n",
            "Epoch 155/100, Loss: 176.9152, Validation Accuracy: 0.5922\n",
            "Epoch 156/100, Loss: 95.2948, Validation Accuracy: 0.6052\n",
            "Epoch 157/100, Loss: 39.8951, Validation Accuracy: 0.4487\n",
            "Epoch 158/100, Loss: 42.9244, Validation Accuracy: 0.6610\n",
            "Epoch 159/100, Loss: 184.5567, Validation Accuracy: 0.6251\n",
            "Epoch 160/100, Loss: 136.5434, Validation Accuracy: 0.4945\n",
            "Epoch 161/100, Loss: 137.8193, Validation Accuracy: 0.6291\n",
            "Epoch 162/100, Loss: 197.2851, Validation Accuracy: 0.5942\n",
            "Epoch 163/100, Loss: 154.6815, Validation Accuracy: 0.6191\n",
            "Epoch 164/100, Loss: 206.1231, Validation Accuracy: 0.5384\n",
            "Epoch 165/100, Loss: 206.9808, Validation Accuracy: 0.6760\n",
            "Epoch 166/100, Loss: 7.6889, Validation Accuracy: 0.5703\n",
            "Epoch 167/100, Loss: 177.2713, Validation Accuracy: 0.5434\n",
            "Epoch 168/100, Loss: 110.6567, Validation Accuracy: 0.6939\n",
            "Epoch 169/100, Loss: 163.0721, Validation Accuracy: 0.6700\n",
            "Epoch 170/100, Loss: 205.4367, Validation Accuracy: 0.6261\n",
            "Epoch 171/100, Loss: 177.3858, Validation Accuracy: 0.5424\n",
            "Epoch 172/100, Loss: 252.9364, Validation Accuracy: 0.6291\n",
            "Epoch 173/100, Loss: 146.3261, Validation Accuracy: 0.6530\n",
            "Epoch 174/100, Loss: 138.4991, Validation Accuracy: 0.5234\n",
            "Epoch 175/100, Loss: 65.6253, Validation Accuracy: 0.6181\n",
            "Epoch 176/100, Loss: 98.3952, Validation Accuracy: 0.6092\n",
            "Epoch 177/100, Loss: 59.2375, Validation Accuracy: 0.5623\n",
            "Epoch 178/100, Loss: 198.0642, Validation Accuracy: 0.6082\n",
            "Epoch 179/100, Loss: 56.6550, Validation Accuracy: 0.5902\n",
            "Epoch 180/100, Loss: 76.4689, Validation Accuracy: 0.6500\n",
            "Epoch 181/100, Loss: 135.3138, Validation Accuracy: 0.6171\n",
            "Epoch 182/100, Loss: 226.2459, Validation Accuracy: 0.5932\n",
            "Epoch 183/100, Loss: 72.6954, Validation Accuracy: 0.6421\n",
            "Epoch 184/100, Loss: 144.2214, Validation Accuracy: 0.6700\n",
            "Epoch 185/100, Loss: 42.2796, Validation Accuracy: 0.6760\n",
            "Epoch 186/100, Loss: 164.8288, Validation Accuracy: 0.6471\n",
            "Epoch 187/100, Loss: 159.1456, Validation Accuracy: 0.6530\n",
            "Epoch 188/100, Loss: 154.0194, Validation Accuracy: 0.6421\n",
            "Epoch 189/100, Loss: 172.2260, Validation Accuracy: 0.3948\n",
            "Epoch 190/100, Loss: 263.1059, Validation Accuracy: 0.6710\n",
            "Epoch 191/100, Loss: 251.4292, Validation Accuracy: 0.5912\n",
            "Epoch 192/100, Loss: 104.4633, Validation Accuracy: 0.6500\n",
            "Epoch 193/100, Loss: 245.1130, Validation Accuracy: 0.6520\n",
            "Epoch 194/100, Loss: 295.6639, Validation Accuracy: 0.6570\n",
            "Epoch 195/100, Loss: 253.0705, Validation Accuracy: 0.6640\n",
            "Epoch 196/100, Loss: 151.7404, Validation Accuracy: 0.6530\n",
            "Epoch 197/100, Loss: 64.3865, Validation Accuracy: 0.6820\n",
            "Epoch 198/100, Loss: 79.5886, Validation Accuracy: 0.5494\n",
            "Epoch 199/100, Loss: 243.6902, Validation Accuracy: 0.5962\n",
            "Epoch 200/100, Loss: 133.9527, Validation Accuracy: 0.5513\n",
            "Reward for Child Model: 0.3171505771767599\n",
            "Child_16:  {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, [2, 0, 3, 1, 3, 0, 3, 1, 2, 0, 1, 2, 2, 3, 0], 0.3171505771767599\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 36, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 24, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(60, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(72, 24, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=61776, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 26, 22]           3,072\n",
            "       BatchNorm2d-2           [-1, 48, 26, 22]              96\n",
            "            Conv2d-3           [-1, 36, 24, 16]          36,324\n",
            "       BatchNorm2d-4           [-1, 36, 24, 16]              72\n",
            "              ReLU-5           [-1, 36, 24, 16]               0\n",
            "            Conv2d-6           [-1, 24, 18, 10]          42,360\n",
            "       BatchNorm2d-7           [-1, 24, 18, 10]              48\n",
            "              ReLU-8           [-1, 24, 18, 10]               0\n",
            "            Conv2d-9           [-1, 36, 20, 12]          54,036\n",
            "      BatchNorm2d-10           [-1, 36, 20, 12]              72\n",
            "             ReLU-11           [-1, 36, 20, 12]               0\n",
            "           Conv2d-12           [-1, 24, 24, 12]           8,664\n",
            "      BatchNorm2d-13           [-1, 24, 24, 12]              48\n",
            "             ReLU-14           [-1, 24, 24, 12]               0\n",
            "           Linear-15                    [-1, 7]         432,439\n",
            "================================================================\n",
            "Total params: 577,231\n",
            "Trainable params: 577,231\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.19\n",
            "Params size (MB): 2.20\n",
            "Estimated Total Size (MB): 3.40\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 12.6534, Validation Accuracy: 0.6580\n",
            "Epoch 2/100, Loss: 20.0011, Validation Accuracy: 0.6381\n",
            "Epoch 3/100, Loss: 34.8364, Validation Accuracy: 0.3320\n",
            "Epoch 4/100, Loss: 3.9093, Validation Accuracy: 0.4417\n",
            "Epoch 5/100, Loss: 20.2487, Validation Accuracy: 0.6491\n",
            "Epoch 6/100, Loss: 6.4824, Validation Accuracy: 0.4536\n",
            "Epoch 7/100, Loss: 3.6336, Validation Accuracy: 0.6211\n",
            "Epoch 8/100, Loss: 318.4158, Validation Accuracy: 0.6491\n",
            "Epoch 9/100, Loss: 53.9649, Validation Accuracy: 0.5274\n",
            "Epoch 10/100, Loss: 34.8035, Validation Accuracy: 0.5324\n",
            "Epoch 11/100, Loss: 8.8093, Validation Accuracy: 0.5414\n",
            "Epoch 12/100, Loss: 15.5751, Validation Accuracy: 0.5753\n",
            "Epoch 13/100, Loss: 5.2123, Validation Accuracy: 0.5384\n",
            "Epoch 14/100, Loss: 37.4752, Validation Accuracy: 0.3998\n",
            "Epoch 15/100, Loss: 76.5595, Validation Accuracy: 0.6142\n",
            "Epoch 16/100, Loss: 25.8870, Validation Accuracy: 0.5972\n",
            "Epoch 17/100, Loss: 21.2213, Validation Accuracy: 0.6610\n",
            "Epoch 18/100, Loss: 12.6373, Validation Accuracy: 0.6560\n",
            "Epoch 19/100, Loss: 20.6519, Validation Accuracy: 0.6002\n",
            "Epoch 20/100, Loss: 44.2438, Validation Accuracy: 0.3190\n",
            "Epoch 21/100, Loss: 46.8693, Validation Accuracy: 0.6730\n",
            "Epoch 22/100, Loss: 13.5690, Validation Accuracy: 0.5075\n",
            "Epoch 23/100, Loss: 8.6539, Validation Accuracy: 0.4487\n",
            "Epoch 24/100, Loss: 11.5169, Validation Accuracy: 0.5653\n",
            "Epoch 25/100, Loss: 29.8255, Validation Accuracy: 0.6431\n",
            "Epoch 26/100, Loss: 72.9611, Validation Accuracy: 0.4756\n",
            "Epoch 27/100, Loss: 19.8834, Validation Accuracy: 0.6112\n",
            "Epoch 28/100, Loss: 14.7051, Validation Accuracy: 0.6510\n",
            "Epoch 29/100, Loss: 7.6429, Validation Accuracy: 0.5713\n",
            "Epoch 30/100, Loss: 8.4942, Validation Accuracy: 0.4477\n",
            "Epoch 31/100, Loss: 24.9143, Validation Accuracy: 0.5753\n",
            "Epoch 32/100, Loss: 8.0259, Validation Accuracy: 0.6401\n",
            "Epoch 33/100, Loss: 16.0951, Validation Accuracy: 0.5414\n",
            "Epoch 34/100, Loss: 85.9950, Validation Accuracy: 0.5324\n",
            "Epoch 35/100, Loss: 116.9860, Validation Accuracy: 0.5434\n",
            "Epoch 36/100, Loss: 20.5597, Validation Accuracy: 0.6839\n",
            "Epoch 37/100, Loss: 13.5685, Validation Accuracy: 0.6251\n",
            "Epoch 38/100, Loss: 27.2453, Validation Accuracy: 0.6570\n",
            "Epoch 39/100, Loss: 49.5970, Validation Accuracy: 0.3250\n",
            "Epoch 40/100, Loss: 71.0701, Validation Accuracy: 0.3330\n",
            "Epoch 41/100, Loss: 18.4165, Validation Accuracy: 0.6411\n",
            "Epoch 42/100, Loss: 29.6940, Validation Accuracy: 0.6012\n",
            "Epoch 43/100, Loss: 25.9791, Validation Accuracy: 0.6491\n",
            "Epoch 44/100, Loss: 20.2598, Validation Accuracy: 0.5992\n",
            "Epoch 45/100, Loss: 64.6009, Validation Accuracy: 0.5623\n",
            "Epoch 46/100, Loss: 9.0569, Validation Accuracy: 0.6530\n",
            "Epoch 47/100, Loss: 34.7330, Validation Accuracy: 0.4138\n",
            "Epoch 48/100, Loss: 24.3703, Validation Accuracy: 0.6082\n",
            "Epoch 49/100, Loss: 19.9718, Validation Accuracy: 0.5673\n",
            "Epoch 50/100, Loss: 45.5940, Validation Accuracy: 0.6022\n",
            "Epoch 51/100, Loss: 30.5483, Validation Accuracy: 0.5334\n",
            "Epoch 52/100, Loss: 6.8252, Validation Accuracy: 0.6451\n",
            "Epoch 53/100, Loss: 13.5234, Validation Accuracy: 0.4307\n",
            "Epoch 54/100, Loss: 23.5770, Validation Accuracy: 0.5344\n",
            "Epoch 55/100, Loss: 19.8535, Validation Accuracy: 0.6570\n",
            "Epoch 56/100, Loss: 11.2128, Validation Accuracy: 0.6590\n",
            "Epoch 57/100, Loss: 21.0658, Validation Accuracy: 0.5653\n",
            "Epoch 58/100, Loss: 17.5031, Validation Accuracy: 0.4347\n",
            "Epoch 59/100, Loss: 17.4039, Validation Accuracy: 0.6650\n",
            "Epoch 60/100, Loss: 48.4156, Validation Accuracy: 0.6311\n",
            "Epoch 61/100, Loss: 80.5266, Validation Accuracy: 0.5902\n",
            "Epoch 62/100, Loss: 34.1790, Validation Accuracy: 0.6710\n",
            "Epoch 63/100, Loss: 33.7272, Validation Accuracy: 0.6062\n",
            "Epoch 64/100, Loss: 12.8818, Validation Accuracy: 0.6600\n",
            "Epoch 65/100, Loss: 15.7013, Validation Accuracy: 0.6820\n",
            "Epoch 66/100, Loss: 45.6504, Validation Accuracy: 0.6710\n",
            "Epoch 67/100, Loss: 58.7463, Validation Accuracy: 0.6590\n",
            "Epoch 68/100, Loss: 32.7149, Validation Accuracy: 0.6700\n",
            "Epoch 69/100, Loss: 40.3371, Validation Accuracy: 0.4636\n",
            "Epoch 70/100, Loss: 16.9890, Validation Accuracy: 0.6341\n",
            "Epoch 71/100, Loss: 23.7289, Validation Accuracy: 0.5424\n",
            "Epoch 72/100, Loss: 21.9010, Validation Accuracy: 0.5165\n",
            "Epoch 73/100, Loss: 30.8248, Validation Accuracy: 0.6899\n",
            "Epoch 74/100, Loss: 29.0628, Validation Accuracy: 0.6281\n",
            "Epoch 75/100, Loss: 26.2839, Validation Accuracy: 0.6650\n",
            "Epoch 76/100, Loss: 27.8961, Validation Accuracy: 0.5503\n",
            "Epoch 77/100, Loss: 29.3908, Validation Accuracy: 0.4546\n",
            "Epoch 78/100, Loss: 22.4214, Validation Accuracy: 0.6451\n",
            "Epoch 79/100, Loss: 30.7412, Validation Accuracy: 0.6770\n",
            "Epoch 80/100, Loss: 17.9569, Validation Accuracy: 0.5464\n",
            "Epoch 81/100, Loss: 28.0186, Validation Accuracy: 0.6241\n",
            "Epoch 82/100, Loss: 27.6594, Validation Accuracy: 0.4816\n",
            "Epoch 83/100, Loss: 54.4246, Validation Accuracy: 0.3978\n",
            "Epoch 84/100, Loss: 59.3492, Validation Accuracy: 0.5743\n",
            "Epoch 85/100, Loss: 26.2079, Validation Accuracy: 0.6311\n",
            "Epoch 86/100, Loss: 49.9736, Validation Accuracy: 0.5922\n",
            "Epoch 87/100, Loss: 38.4392, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 53.4262, Validation Accuracy: 0.6221\n",
            "Epoch 89/100, Loss: 26.1124, Validation Accuracy: 0.6201\n",
            "Epoch 90/100, Loss: 24.8027, Validation Accuracy: 0.5404\n",
            "Epoch 91/100, Loss: 49.1752, Validation Accuracy: 0.6092\n",
            "Epoch 92/100, Loss: 56.0231, Validation Accuracy: 0.6371\n",
            "Epoch 93/100, Loss: 49.6666, Validation Accuracy: 0.5135\n",
            "Epoch 94/100, Loss: 9.4511, Validation Accuracy: 0.6381\n",
            "Epoch 95/100, Loss: 48.1493, Validation Accuracy: 0.5484\n",
            "Epoch 96/100, Loss: 41.9132, Validation Accuracy: 0.5823\n",
            "Epoch 97/100, Loss: 52.1738, Validation Accuracy: 0.3619\n",
            "Epoch 98/100, Loss: 30.9508, Validation Accuracy: 0.6211\n",
            "Epoch 99/100, Loss: 34.0576, Validation Accuracy: 0.6042\n",
            "Epoch 100/100, Loss: 40.6280, Validation Accuracy: 0.6401\n",
            "Epoch 101/100, Loss: 37.0137, Validation Accuracy: 0.4646\n",
            "Epoch 102/100, Loss: 110.6657, Validation Accuracy: 0.6261\n",
            "Epoch 103/100, Loss: 40.2501, Validation Accuracy: 0.4397\n",
            "Epoch 104/100, Loss: 32.5911, Validation Accuracy: 0.6491\n",
            "Epoch 105/100, Loss: 52.2299, Validation Accuracy: 0.5743\n",
            "Epoch 106/100, Loss: 20.0202, Validation Accuracy: 0.5194\n",
            "Epoch 107/100, Loss: 38.3114, Validation Accuracy: 0.5852\n",
            "Epoch 108/100, Loss: 52.8546, Validation Accuracy: 0.5494\n",
            "Epoch 109/100, Loss: 33.9794, Validation Accuracy: 0.5095\n",
            "Epoch 110/100, Loss: 39.6933, Validation Accuracy: 0.5693\n",
            "Epoch 111/100, Loss: 19.6334, Validation Accuracy: 0.6361\n",
            "Epoch 112/100, Loss: 31.0986, Validation Accuracy: 0.5852\n",
            "Epoch 113/100, Loss: 30.2728, Validation Accuracy: 0.5803\n",
            "Epoch 114/100, Loss: 32.2916, Validation Accuracy: 0.6520\n",
            "Epoch 115/100, Loss: 36.6261, Validation Accuracy: 0.6112\n",
            "Epoch 116/100, Loss: 79.8203, Validation Accuracy: 0.6750\n",
            "Epoch 117/100, Loss: 60.4109, Validation Accuracy: 0.3799\n",
            "Epoch 118/100, Loss: 19.7608, Validation Accuracy: 0.4835\n",
            "Epoch 119/100, Loss: 20.1446, Validation Accuracy: 0.6142\n",
            "Epoch 120/100, Loss: 101.5671, Validation Accuracy: 0.6191\n",
            "Epoch 121/100, Loss: 16.8713, Validation Accuracy: 0.5723\n",
            "Epoch 122/100, Loss: 7.0203, Validation Accuracy: 0.5174\n",
            "Epoch 123/100, Loss: 92.8568, Validation Accuracy: 0.6191\n",
            "Epoch 124/100, Loss: 14.2656, Validation Accuracy: 0.6520\n",
            "Epoch 125/100, Loss: 9.2016, Validation Accuracy: 0.5404\n",
            "Epoch 126/100, Loss: 19.0035, Validation Accuracy: 0.5862\n",
            "Epoch 127/100, Loss: 54.8060, Validation Accuracy: 0.5384\n",
            "Epoch 128/100, Loss: 65.9868, Validation Accuracy: 0.5155\n",
            "Epoch 129/100, Loss: 28.6156, Validation Accuracy: 0.6072\n",
            "Epoch 130/100, Loss: 29.1671, Validation Accuracy: 0.5763\n",
            "Epoch 131/100, Loss: 21.5881, Validation Accuracy: 0.6859\n",
            "Epoch 132/100, Loss: 27.8486, Validation Accuracy: 0.5603\n",
            "Epoch 133/100, Loss: 43.5273, Validation Accuracy: 0.5653\n",
            "Epoch 134/100, Loss: 32.6831, Validation Accuracy: 0.6600\n",
            "Epoch 135/100, Loss: 22.3867, Validation Accuracy: 0.6142\n",
            "Epoch 136/100, Loss: 11.4981, Validation Accuracy: 0.5892\n",
            "Epoch 137/100, Loss: 21.3250, Validation Accuracy: 0.4766\n",
            "Epoch 138/100, Loss: 20.9195, Validation Accuracy: 0.5035\n",
            "Epoch 139/100, Loss: 31.0118, Validation Accuracy: 0.6301\n",
            "Epoch 140/100, Loss: 128.4450, Validation Accuracy: 0.5803\n",
            "Epoch 141/100, Loss: 24.8893, Validation Accuracy: 0.6211\n",
            "Epoch 142/100, Loss: 6.1132, Validation Accuracy: 0.5613\n",
            "Epoch 143/100, Loss: 27.8375, Validation Accuracy: 0.5952\n",
            "Epoch 144/100, Loss: 24.9192, Validation Accuracy: 0.5165\n",
            "Epoch 145/100, Loss: 7.3884, Validation Accuracy: 0.6461\n",
            "Epoch 146/100, Loss: 23.6622, Validation Accuracy: 0.4287\n",
            "Epoch 147/100, Loss: 36.6316, Validation Accuracy: 0.4078\n",
            "Epoch 148/100, Loss: 28.6439, Validation Accuracy: 0.5354\n",
            "Epoch 149/100, Loss: 41.7564, Validation Accuracy: 0.5484\n",
            "Epoch 150/100, Loss: 23.2108, Validation Accuracy: 0.6171\n",
            "Epoch 151/100, Loss: 54.3944, Validation Accuracy: 0.6122\n",
            "Epoch 152/100, Loss: 34.7333, Validation Accuracy: 0.6251\n",
            "Epoch 153/100, Loss: 10.4577, Validation Accuracy: 0.6491\n",
            "Epoch 154/100, Loss: 45.4556, Validation Accuracy: 0.6580\n",
            "Epoch 155/100, Loss: 77.1048, Validation Accuracy: 0.5284\n",
            "Epoch 156/100, Loss: 28.3408, Validation Accuracy: 0.6730\n",
            "Epoch 157/100, Loss: 46.5418, Validation Accuracy: 0.5344\n",
            "Epoch 158/100, Loss: 51.8111, Validation Accuracy: 0.5324\n",
            "Epoch 159/100, Loss: 29.3265, Validation Accuracy: 0.5174\n",
            "Epoch 160/100, Loss: 42.0842, Validation Accuracy: 0.4756\n",
            "Epoch 161/100, Loss: 19.2338, Validation Accuracy: 0.5623\n",
            "Epoch 162/100, Loss: 34.6409, Validation Accuracy: 0.6261\n",
            "Epoch 163/100, Loss: 59.0432, Validation Accuracy: 0.6062\n",
            "Epoch 164/100, Loss: 62.3890, Validation Accuracy: 0.5942\n",
            "Epoch 165/100, Loss: 33.8455, Validation Accuracy: 0.5773\n",
            "Epoch 166/100, Loss: 94.6924, Validation Accuracy: 0.5713\n",
            "Epoch 167/100, Loss: 15.7229, Validation Accuracy: 0.4267\n",
            "Epoch 168/100, Loss: 45.2365, Validation Accuracy: 0.5503\n",
            "Epoch 169/100, Loss: 24.5352, Validation Accuracy: 0.5872\n",
            "Epoch 170/100, Loss: 53.3175, Validation Accuracy: 0.4875\n",
            "Epoch 171/100, Loss: 90.7391, Validation Accuracy: 0.5992\n",
            "Epoch 172/100, Loss: 16.0155, Validation Accuracy: 0.6191\n",
            "Epoch 173/100, Loss: 30.5457, Validation Accuracy: 0.6321\n",
            "Epoch 174/100, Loss: 42.1281, Validation Accuracy: 0.5912\n",
            "Epoch 175/100, Loss: 20.2047, Validation Accuracy: 0.5414\n",
            "Epoch 176/100, Loss: 14.2454, Validation Accuracy: 0.6241\n",
            "Epoch 177/100, Loss: 21.2717, Validation Accuracy: 0.5523\n",
            "Epoch 178/100, Loss: 103.9181, Validation Accuracy: 0.6530\n",
            "Epoch 179/100, Loss: 51.1325, Validation Accuracy: 0.6171\n",
            "Epoch 180/100, Loss: 53.3314, Validation Accuracy: 0.6311\n",
            "Epoch 181/100, Loss: 8.5824, Validation Accuracy: 0.4387\n",
            "Epoch 182/100, Loss: 21.9350, Validation Accuracy: 0.5793\n",
            "Epoch 183/100, Loss: 27.4576, Validation Accuracy: 0.6142\n",
            "Epoch 184/100, Loss: 85.7122, Validation Accuracy: 0.5633\n",
            "Epoch 185/100, Loss: 33.4774, Validation Accuracy: 0.5852\n",
            "Epoch 186/100, Loss: 29.7876, Validation Accuracy: 0.6520\n",
            "Epoch 187/100, Loss: 44.6763, Validation Accuracy: 0.5454\n",
            "Epoch 188/100, Loss: 43.4046, Validation Accuracy: 0.5803\n",
            "Epoch 189/100, Loss: 47.7475, Validation Accuracy: 0.5364\n",
            "Epoch 190/100, Loss: 105.8191, Validation Accuracy: 0.5962\n",
            "Epoch 191/100, Loss: 47.9720, Validation Accuracy: 0.6401\n",
            "Epoch 192/100, Loss: 40.7223, Validation Accuracy: 0.5962\n",
            "Epoch 193/100, Loss: 7.7966, Validation Accuracy: 0.6102\n",
            "Epoch 194/100, Loss: 68.8589, Validation Accuracy: 0.6431\n",
            "Epoch 195/100, Loss: 36.6845, Validation Accuracy: 0.6351\n",
            "Epoch 196/100, Loss: 101.6440, Validation Accuracy: 0.4786\n",
            "Epoch 197/100, Loss: 72.3882, Validation Accuracy: 0.5783\n",
            "Epoch 198/100, Loss: 21.8133, Validation Accuracy: 0.4766\n",
            "Epoch 199/100, Loss: 13.4273, Validation Accuracy: 0.5224\n",
            "Epoch 200/100, Loss: 17.3706, Validation Accuracy: 0.5374\n",
            "Reward for Child Model: 0.19336647560382939\n",
            "Child_17:  {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, [1, 3, 2, 1, 3, 1, 3, 3, 0, 2, 2, 1, 0, 2, 0], 0.19336647560382939\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 36, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 48, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(112, 36, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(184, 48, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=112288, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 22, 22]           9,472\n",
            "       BatchNorm2d-2           [-1, 64, 22, 22]             128\n",
            "            Conv2d-3           [-1, 36, 16, 18]          80,676\n",
            "       BatchNorm2d-4           [-1, 36, 16, 18]              72\n",
            "              ReLU-5           [-1, 36, 16, 18]               0\n",
            "            Conv2d-6           [-1, 48, 10, 14]          60,528\n",
            "       BatchNorm2d-7           [-1, 48, 10, 14]              96\n",
            "              ReLU-8           [-1, 48, 10, 14]               0\n",
            "            Conv2d-9           [-1, 36, 20, 18]          60,516\n",
            "      BatchNorm2d-10           [-1, 36, 20, 18]              72\n",
            "             ReLU-11           [-1, 36, 20, 18]               0\n",
            "           Conv2d-12           [-1, 48, 18, 22]          44,208\n",
            "      BatchNorm2d-13           [-1, 48, 18, 22]              96\n",
            "             ReLU-14           [-1, 48, 18, 22]               0\n",
            "           Linear-15                    [-1, 7]         786,023\n",
            "================================================================\n",
            "Total params: 1,041,887\n",
            "Trainable params: 1,041,887\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.60\n",
            "Params size (MB): 3.97\n",
            "Estimated Total Size (MB): 5.58\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 31.7296, Validation Accuracy: 0.4646\n",
            "Epoch 2/100, Loss: 17.6099, Validation Accuracy: 0.6540\n",
            "Epoch 3/100, Loss: 39.1497, Validation Accuracy: 0.5394\n",
            "Epoch 4/100, Loss: 29.3343, Validation Accuracy: 0.3769\n",
            "Epoch 5/100, Loss: 22.0811, Validation Accuracy: 0.2881\n",
            "Epoch 6/100, Loss: 113.9625, Validation Accuracy: 0.6411\n",
            "Epoch 7/100, Loss: 5.6488, Validation Accuracy: 0.5214\n",
            "Epoch 8/100, Loss: 8.0118, Validation Accuracy: 0.6211\n",
            "Epoch 9/100, Loss: 14.2565, Validation Accuracy: 0.2213\n",
            "Epoch 10/100, Loss: 57.5215, Validation Accuracy: 0.5354\n",
            "Epoch 11/100, Loss: 52.0686, Validation Accuracy: 0.6461\n",
            "Epoch 12/100, Loss: 138.4208, Validation Accuracy: 0.4477\n",
            "Epoch 13/100, Loss: 69.8305, Validation Accuracy: 0.6171\n",
            "Epoch 14/100, Loss: 16.2887, Validation Accuracy: 0.6112\n",
            "Epoch 15/100, Loss: 15.6683, Validation Accuracy: 0.5992\n",
            "Epoch 16/100, Loss: 18.8303, Validation Accuracy: 0.5713\n",
            "Epoch 17/100, Loss: 59.1825, Validation Accuracy: 0.5523\n",
            "Epoch 18/100, Loss: 16.9292, Validation Accuracy: 0.5015\n",
            "Epoch 19/100, Loss: 365.2183, Validation Accuracy: 0.5833\n",
            "Epoch 20/100, Loss: 52.3074, Validation Accuracy: 0.5892\n",
            "Epoch 21/100, Loss: 41.0490, Validation Accuracy: 0.6062\n",
            "Epoch 22/100, Loss: 10.4762, Validation Accuracy: 0.4975\n",
            "Epoch 23/100, Loss: 1.9136, Validation Accuracy: 0.5623\n",
            "Epoch 24/100, Loss: 10.8831, Validation Accuracy: 0.6630\n",
            "Epoch 25/100, Loss: 7.5700, Validation Accuracy: 0.5553\n",
            "Epoch 26/100, Loss: 5.1619, Validation Accuracy: 0.6680\n",
            "Epoch 27/100, Loss: 9.7249, Validation Accuracy: 0.5623\n",
            "Epoch 28/100, Loss: 49.8735, Validation Accuracy: 0.3838\n",
            "Epoch 29/100, Loss: 364.3705, Validation Accuracy: 0.5115\n",
            "Epoch 30/100, Loss: 18.8200, Validation Accuracy: 0.5304\n",
            "Epoch 31/100, Loss: 8.1303, Validation Accuracy: 0.6401\n",
            "Epoch 32/100, Loss: 12.4725, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 27.4979, Validation Accuracy: 0.6331\n",
            "Epoch 34/100, Loss: 9.5498, Validation Accuracy: 0.6401\n",
            "Epoch 35/100, Loss: 3.2535, Validation Accuracy: 0.6241\n",
            "Epoch 36/100, Loss: 8.6159, Validation Accuracy: 0.6570\n",
            "Epoch 37/100, Loss: 11.2184, Validation Accuracy: 0.6321\n",
            "Epoch 38/100, Loss: 2.3116, Validation Accuracy: 0.6849\n",
            "Epoch 39/100, Loss: 9.4384, Validation Accuracy: 0.6411\n",
            "Epoch 40/100, Loss: 9.0668, Validation Accuracy: 0.3629\n",
            "Epoch 41/100, Loss: 146.1548, Validation Accuracy: 0.5384\n",
            "Epoch 42/100, Loss: 64.0851, Validation Accuracy: 0.6500\n",
            "Epoch 43/100, Loss: 49.9772, Validation Accuracy: 0.6560\n",
            "Epoch 44/100, Loss: 50.1238, Validation Accuracy: 0.4915\n",
            "Epoch 45/100, Loss: 44.8125, Validation Accuracy: 0.4895\n",
            "Epoch 46/100, Loss: 36.5281, Validation Accuracy: 0.5165\n",
            "Epoch 47/100, Loss: 5.9587, Validation Accuracy: 0.5444\n",
            "Epoch 48/100, Loss: 5.0999, Validation Accuracy: 0.6461\n",
            "Epoch 49/100, Loss: 53.2421, Validation Accuracy: 0.4367\n",
            "Epoch 50/100, Loss: 62.6067, Validation Accuracy: 0.6730\n",
            "Epoch 51/100, Loss: 40.0831, Validation Accuracy: 0.6849\n",
            "Epoch 52/100, Loss: 32.5300, Validation Accuracy: 0.5823\n",
            "Epoch 53/100, Loss: 44.8084, Validation Accuracy: 0.5793\n",
            "Epoch 54/100, Loss: 75.9930, Validation Accuracy: 0.5095\n",
            "Epoch 55/100, Loss: 66.1948, Validation Accuracy: 0.6102\n",
            "Epoch 56/100, Loss: 20.4615, Validation Accuracy: 0.6720\n",
            "Epoch 57/100, Loss: 30.6544, Validation Accuracy: 0.4975\n",
            "Epoch 58/100, Loss: 9.3807, Validation Accuracy: 0.4337\n",
            "Epoch 59/100, Loss: 15.8019, Validation Accuracy: 0.6062\n",
            "Epoch 60/100, Loss: 10.7467, Validation Accuracy: 0.6610\n",
            "Epoch 61/100, Loss: 7.4305, Validation Accuracy: 0.3958\n",
            "Epoch 62/100, Loss: 61.0848, Validation Accuracy: 0.6201\n",
            "Epoch 63/100, Loss: 93.9759, Validation Accuracy: 0.5623\n",
            "Epoch 64/100, Loss: 53.0432, Validation Accuracy: 0.5414\n",
            "Epoch 65/100, Loss: 22.2953, Validation Accuracy: 0.5444\n",
            "Epoch 66/100, Loss: 82.4956, Validation Accuracy: 0.6042\n",
            "Epoch 67/100, Loss: 17.7254, Validation Accuracy: 0.6780\n",
            "Epoch 68/100, Loss: 17.5277, Validation Accuracy: 0.5673\n",
            "Epoch 69/100, Loss: 9.9152, Validation Accuracy: 0.6610\n",
            "Epoch 70/100, Loss: 45.7039, Validation Accuracy: 0.5842\n",
            "Epoch 71/100, Loss: 19.8953, Validation Accuracy: 0.6122\n",
            "Epoch 72/100, Loss: 15.6656, Validation Accuracy: 0.6580\n",
            "Epoch 73/100, Loss: 107.1015, Validation Accuracy: 0.6391\n",
            "Epoch 74/100, Loss: 30.3351, Validation Accuracy: 0.5543\n",
            "Epoch 75/100, Loss: 20.9016, Validation Accuracy: 0.6540\n",
            "Epoch 76/100, Loss: 8.9377, Validation Accuracy: 0.6770\n",
            "Epoch 77/100, Loss: 101.7460, Validation Accuracy: 0.5653\n",
            "Epoch 78/100, Loss: 41.8555, Validation Accuracy: 0.4826\n",
            "Epoch 79/100, Loss: 31.1064, Validation Accuracy: 0.5523\n",
            "Epoch 80/100, Loss: 16.1682, Validation Accuracy: 0.6491\n",
            "Epoch 81/100, Loss: 19.2847, Validation Accuracy: 0.5922\n",
            "Epoch 82/100, Loss: 18.2965, Validation Accuracy: 0.4337\n",
            "Epoch 83/100, Loss: 12.3382, Validation Accuracy: 0.6431\n",
            "Epoch 84/100, Loss: 10.8885, Validation Accuracy: 0.6231\n",
            "Epoch 85/100, Loss: 13.1785, Validation Accuracy: 0.4417\n",
            "Epoch 86/100, Loss: 8.9771, Validation Accuracy: 0.5842\n",
            "Epoch 87/100, Loss: 10.4864, Validation Accuracy: 0.6451\n",
            "Epoch 88/100, Loss: 7.4993, Validation Accuracy: 0.6092\n",
            "Epoch 89/100, Loss: 14.4355, Validation Accuracy: 0.5404\n",
            "Epoch 90/100, Loss: 15.2855, Validation Accuracy: 0.6261\n",
            "Epoch 91/100, Loss: 347.6446, Validation Accuracy: 0.4516\n",
            "Epoch 92/100, Loss: 34.0844, Validation Accuracy: 0.6481\n",
            "Epoch 93/100, Loss: 19.9592, Validation Accuracy: 0.6471\n",
            "Epoch 94/100, Loss: 17.8943, Validation Accuracy: 0.6022\n",
            "Epoch 95/100, Loss: 11.3041, Validation Accuracy: 0.6311\n",
            "Epoch 96/100, Loss: 30.4445, Validation Accuracy: 0.5783\n",
            "Epoch 97/100, Loss: 70.8160, Validation Accuracy: 0.3769\n",
            "Epoch 98/100, Loss: 15.7447, Validation Accuracy: 0.6301\n",
            "Epoch 99/100, Loss: 33.4586, Validation Accuracy: 0.5523\n",
            "Epoch 100/100, Loss: 51.3608, Validation Accuracy: 0.6122\n",
            "Epoch 101/100, Loss: 40.0479, Validation Accuracy: 0.3509\n",
            "Epoch 102/100, Loss: 14.3368, Validation Accuracy: 0.6590\n",
            "Epoch 103/100, Loss: 49.4438, Validation Accuracy: 0.5563\n",
            "Epoch 104/100, Loss: 34.2286, Validation Accuracy: 0.5972\n",
            "Epoch 105/100, Loss: 24.6457, Validation Accuracy: 0.5025\n",
            "Epoch 106/100, Loss: 30.1377, Validation Accuracy: 0.6381\n",
            "Epoch 107/100, Loss: 50.4840, Validation Accuracy: 0.4965\n",
            "Epoch 108/100, Loss: 20.8929, Validation Accuracy: 0.6301\n",
            "Epoch 109/100, Loss: 437.7305, Validation Accuracy: 0.6849\n",
            "Epoch 110/100, Loss: 34.0431, Validation Accuracy: 0.4915\n",
            "Epoch 111/100, Loss: 26.1380, Validation Accuracy: 0.6590\n",
            "Epoch 112/100, Loss: 15.9326, Validation Accuracy: 0.5454\n",
            "Epoch 113/100, Loss: 21.4140, Validation Accuracy: 0.6471\n",
            "Epoch 114/100, Loss: 33.1726, Validation Accuracy: 0.4307\n",
            "Epoch 115/100, Loss: 29.3468, Validation Accuracy: 0.5623\n",
            "Epoch 116/100, Loss: 53.4820, Validation Accuracy: 0.6500\n",
            "Epoch 117/100, Loss: 71.2727, Validation Accuracy: 0.6072\n",
            "Epoch 118/100, Loss: 12.5089, Validation Accuracy: 0.5952\n",
            "Epoch 119/100, Loss: 31.7336, Validation Accuracy: 0.5733\n",
            "Epoch 120/100, Loss: 32.4353, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 51.7314, Validation Accuracy: 0.5733\n",
            "Epoch 122/100, Loss: 53.1044, Validation Accuracy: 0.6381\n",
            "Epoch 123/100, Loss: 146.8875, Validation Accuracy: 0.5563\n",
            "Epoch 124/100, Loss: 56.2339, Validation Accuracy: 0.6530\n",
            "Epoch 125/100, Loss: 41.3867, Validation Accuracy: 0.6560\n",
            "Epoch 126/100, Loss: 47.8873, Validation Accuracy: 0.6331\n",
            "Epoch 127/100, Loss: 20.0525, Validation Accuracy: 0.6600\n",
            "Epoch 128/100, Loss: 39.0235, Validation Accuracy: 0.5234\n",
            "Epoch 129/100, Loss: 34.0798, Validation Accuracy: 0.6401\n",
            "Epoch 130/100, Loss: 21.9896, Validation Accuracy: 0.6461\n",
            "Epoch 131/100, Loss: 24.4666, Validation Accuracy: 0.6869\n",
            "Epoch 132/100, Loss: 46.7699, Validation Accuracy: 0.6530\n",
            "Epoch 133/100, Loss: 49.5010, Validation Accuracy: 0.5892\n",
            "Epoch 134/100, Loss: 33.0480, Validation Accuracy: 0.6002\n",
            "Epoch 135/100, Loss: 45.7427, Validation Accuracy: 0.5872\n",
            "Epoch 136/100, Loss: 21.3494, Validation Accuracy: 0.6441\n",
            "Epoch 137/100, Loss: 33.8055, Validation Accuracy: 0.6830\n",
            "Epoch 138/100, Loss: 8.1042, Validation Accuracy: 0.6241\n",
            "Epoch 139/100, Loss: 100.1064, Validation Accuracy: 0.4526\n",
            "Epoch 140/100, Loss: 44.2982, Validation Accuracy: 0.4646\n",
            "Epoch 141/100, Loss: 38.6803, Validation Accuracy: 0.3948\n",
            "Epoch 142/100, Loss: 27.7080, Validation Accuracy: 0.6520\n",
            "Epoch 143/100, Loss: 53.4136, Validation Accuracy: 0.6590\n",
            "Epoch 144/100, Loss: 53.3069, Validation Accuracy: 0.6670\n",
            "Epoch 145/100, Loss: 69.9614, Validation Accuracy: 0.6052\n",
            "Epoch 146/100, Loss: 63.1398, Validation Accuracy: 0.5932\n",
            "Epoch 147/100, Loss: 74.9147, Validation Accuracy: 0.6730\n",
            "Epoch 148/100, Loss: 35.9790, Validation Accuracy: 0.6211\n",
            "Epoch 149/100, Loss: 28.1210, Validation Accuracy: 0.6291\n",
            "Epoch 150/100, Loss: 50.0692, Validation Accuracy: 0.4516\n",
            "Epoch 151/100, Loss: 28.5941, Validation Accuracy: 0.4536\n",
            "Epoch 152/100, Loss: 45.4648, Validation Accuracy: 0.4806\n",
            "Epoch 153/100, Loss: 51.4722, Validation Accuracy: 0.6730\n",
            "Epoch 154/100, Loss: 37.4378, Validation Accuracy: 0.6879\n",
            "Epoch 155/100, Loss: 25.4773, Validation Accuracy: 0.5125\n",
            "Epoch 156/100, Loss: 83.8299, Validation Accuracy: 0.5673\n",
            "Epoch 157/100, Loss: 35.9336, Validation Accuracy: 0.6311\n",
            "Epoch 158/100, Loss: 184.0630, Validation Accuracy: 0.6331\n",
            "Epoch 159/100, Loss: 30.1176, Validation Accuracy: 0.6720\n",
            "Epoch 160/100, Loss: 16.7152, Validation Accuracy: 0.6510\n",
            "Epoch 161/100, Loss: 18.7857, Validation Accuracy: 0.6630\n",
            "Epoch 162/100, Loss: 20.4224, Validation Accuracy: 0.6241\n",
            "Epoch 163/100, Loss: 30.1735, Validation Accuracy: 0.6640\n",
            "Epoch 164/100, Loss: 19.1202, Validation Accuracy: 0.6311\n",
            "Epoch 165/100, Loss: 15.0325, Validation Accuracy: 0.6471\n",
            "Epoch 166/100, Loss: 65.2737, Validation Accuracy: 0.6311\n",
            "Epoch 167/100, Loss: 29.2555, Validation Accuracy: 0.6371\n",
            "Epoch 168/100, Loss: 45.0296, Validation Accuracy: 0.6251\n",
            "Epoch 169/100, Loss: 57.5204, Validation Accuracy: 0.5733\n",
            "Epoch 170/100, Loss: 11.1745, Validation Accuracy: 0.6461\n",
            "Epoch 171/100, Loss: 59.8541, Validation Accuracy: 0.6092\n",
            "Epoch 172/100, Loss: 24.6370, Validation Accuracy: 0.6022\n",
            "Epoch 173/100, Loss: 33.9404, Validation Accuracy: 0.4337\n",
            "Epoch 174/100, Loss: 22.2697, Validation Accuracy: 0.6560\n",
            "Epoch 175/100, Loss: 60.8981, Validation Accuracy: 0.5055\n",
            "Epoch 176/100, Loss: 55.0749, Validation Accuracy: 0.5932\n",
            "Epoch 177/100, Loss: 38.2163, Validation Accuracy: 0.6710\n",
            "Epoch 178/100, Loss: 43.2917, Validation Accuracy: 0.6391\n",
            "Epoch 179/100, Loss: 38.5127, Validation Accuracy: 0.6580\n",
            "Epoch 180/100, Loss: 48.2694, Validation Accuracy: 0.5055\n",
            "Epoch 181/100, Loss: 35.8327, Validation Accuracy: 0.6321\n",
            "Epoch 182/100, Loss: 8.5189, Validation Accuracy: 0.5533\n",
            "Epoch 183/100, Loss: 38.2826, Validation Accuracy: 0.6550\n",
            "Epoch 184/100, Loss: 210.9971, Validation Accuracy: 0.5693\n",
            "Epoch 185/100, Loss: 27.0000, Validation Accuracy: 0.5773\n",
            "Epoch 186/100, Loss: 14.8654, Validation Accuracy: 0.6132\n",
            "Epoch 187/100, Loss: 33.7706, Validation Accuracy: 0.6590\n",
            "Epoch 188/100, Loss: 20.1183, Validation Accuracy: 0.6291\n",
            "Epoch 189/100, Loss: 16.0466, Validation Accuracy: 0.5663\n",
            "Epoch 190/100, Loss: 96.8453, Validation Accuracy: 0.6500\n",
            "Epoch 191/100, Loss: 46.8219, Validation Accuracy: 0.6351\n",
            "Epoch 192/100, Loss: 52.6346, Validation Accuracy: 0.6171\n",
            "Epoch 193/100, Loss: 33.1694, Validation Accuracy: 0.5862\n",
            "Epoch 194/100, Loss: 38.0498, Validation Accuracy: 0.6341\n",
            "Epoch 195/100, Loss: 25.7243, Validation Accuracy: 0.6610\n",
            "Epoch 196/100, Loss: 25.9191, Validation Accuracy: 0.5892\n",
            "Epoch 197/100, Loss: 35.4142, Validation Accuracy: 0.5872\n",
            "Epoch 198/100, Loss: 39.5065, Validation Accuracy: 0.6491\n",
            "Epoch 199/100, Loss: 51.1314, Validation Accuracy: 0.5643\n",
            "Epoch 200/100, Loss: 23.3677, Validation Accuracy: 0.5503\n",
            "Reward for Child Model: 0.2734262250836617\n",
            "Child_18:  {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, [3, 3, 3, 3, 2, 1, 3, 2, 2, 1, 2, 1, 2, 0, 2], 0.2734262250836617\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(64, 36, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(72, 48, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(84, 64, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=86592, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 22, 24]           3,816\n",
            "       BatchNorm2d-2           [-1, 36, 22, 24]              72\n",
            "            Conv2d-3           [-1, 64, 18, 24]          11,584\n",
            "       BatchNorm2d-4           [-1, 64, 18, 24]             128\n",
            "              ReLU-5           [-1, 64, 18, 24]               0\n",
            "            Conv2d-6           [-1, 36, 12, 20]          80,676\n",
            "       BatchNorm2d-7           [-1, 36, 12, 20]              72\n",
            "              ReLU-8           [-1, 36, 12, 20]               0\n",
            "            Conv2d-9           [-1, 48, 16, 24]          24,240\n",
            "      BatchNorm2d-10           [-1, 48, 16, 24]              96\n",
            "             ReLU-11           [-1, 48, 16, 24]               0\n",
            "           Conv2d-12           [-1, 64, 18, 22]          80,704\n",
            "      BatchNorm2d-13           [-1, 64, 18, 22]             128\n",
            "             ReLU-14           [-1, 64, 18, 22]               0\n",
            "           Linear-15                    [-1, 7]         606,151\n",
            "================================================================\n",
            "Total params: 807,667\n",
            "Trainable params: 807,667\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.12\n",
            "Params size (MB): 3.08\n",
            "Estimated Total Size (MB): 5.21\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 12.8462, Validation Accuracy: 0.6471\n",
            "Epoch 2/100, Loss: 5.5148, Validation Accuracy: 0.6680\n",
            "Epoch 3/100, Loss: 230.4041, Validation Accuracy: 0.5633\n",
            "Epoch 4/100, Loss: 8.0894, Validation Accuracy: 0.5414\n",
            "Epoch 5/100, Loss: 6.2422, Validation Accuracy: 0.4826\n",
            "Epoch 6/100, Loss: 3.2109, Validation Accuracy: 0.5912\n",
            "Epoch 7/100, Loss: 4.4239, Validation Accuracy: 0.6530\n",
            "Epoch 8/100, Loss: 17.7377, Validation Accuracy: 0.5593\n",
            "Epoch 9/100, Loss: 19.0021, Validation Accuracy: 0.5972\n",
            "Epoch 10/100, Loss: 110.6627, Validation Accuracy: 0.6451\n",
            "Epoch 11/100, Loss: 5.8877, Validation Accuracy: 0.6351\n",
            "Epoch 12/100, Loss: 8.1806, Validation Accuracy: 0.6720\n",
            "Epoch 13/100, Loss: 4.0169, Validation Accuracy: 0.5533\n",
            "Epoch 14/100, Loss: 19.6193, Validation Accuracy: 0.6441\n",
            "Epoch 15/100, Loss: 11.3302, Validation Accuracy: 0.6102\n",
            "Epoch 16/100, Loss: 32.6368, Validation Accuracy: 0.5882\n",
            "Epoch 17/100, Loss: 23.7072, Validation Accuracy: 0.5424\n",
            "Epoch 18/100, Loss: 13.7554, Validation Accuracy: 0.6241\n",
            "Epoch 19/100, Loss: 8.5143, Validation Accuracy: 0.5404\n",
            "Epoch 20/100, Loss: 14.4660, Validation Accuracy: 0.5763\n",
            "Epoch 21/100, Loss: 2.2182, Validation Accuracy: 0.4975\n",
            "Epoch 22/100, Loss: 3.3021, Validation Accuracy: 0.5155\n",
            "Epoch 23/100, Loss: 21.8601, Validation Accuracy: 0.6710\n",
            "Epoch 24/100, Loss: 62.0898, Validation Accuracy: 0.6171\n",
            "Epoch 25/100, Loss: 4.4597, Validation Accuracy: 0.4158\n",
            "Epoch 26/100, Loss: 6.9422, Validation Accuracy: 0.6590\n",
            "Epoch 27/100, Loss: 9.3490, Validation Accuracy: 0.4536\n",
            "Epoch 28/100, Loss: 10.0953, Validation Accuracy: 0.5533\n",
            "Epoch 29/100, Loss: 50.5019, Validation Accuracy: 0.4835\n",
            "Epoch 30/100, Loss: 37.3955, Validation Accuracy: 0.5434\n",
            "Epoch 31/100, Loss: 9.2686, Validation Accuracy: 0.6042\n",
            "Epoch 32/100, Loss: 15.9738, Validation Accuracy: 0.4855\n",
            "Epoch 33/100, Loss: 7.9888, Validation Accuracy: 0.6640\n",
            "Epoch 34/100, Loss: 20.0519, Validation Accuracy: 0.5852\n",
            "Epoch 35/100, Loss: 26.0649, Validation Accuracy: 0.4606\n",
            "Epoch 36/100, Loss: 16.5146, Validation Accuracy: 0.4207\n",
            "Epoch 37/100, Loss: 7.2136, Validation Accuracy: 0.6461\n",
            "Epoch 38/100, Loss: 10.5431, Validation Accuracy: 0.4806\n",
            "Epoch 39/100, Loss: 8.3034, Validation Accuracy: 0.6162\n",
            "Epoch 40/100, Loss: 26.4217, Validation Accuracy: 0.6241\n",
            "Epoch 41/100, Loss: 13.6031, Validation Accuracy: 0.6391\n",
            "Epoch 42/100, Loss: 20.4886, Validation Accuracy: 0.6800\n",
            "Epoch 43/100, Loss: 10.7349, Validation Accuracy: 0.5872\n",
            "Epoch 44/100, Loss: 11.2951, Validation Accuracy: 0.5424\n",
            "Epoch 45/100, Loss: 55.5528, Validation Accuracy: 0.5513\n",
            "Epoch 46/100, Loss: 33.5622, Validation Accuracy: 0.6600\n",
            "Epoch 47/100, Loss: 57.4244, Validation Accuracy: 0.4875\n",
            "Epoch 48/100, Loss: 17.6062, Validation Accuracy: 0.5553\n",
            "Epoch 49/100, Loss: 9.8869, Validation Accuracy: 0.5314\n",
            "Epoch 50/100, Loss: 8.2096, Validation Accuracy: 0.5264\n",
            "Epoch 51/100, Loss: 13.2568, Validation Accuracy: 0.6859\n",
            "Epoch 52/100, Loss: 26.1226, Validation Accuracy: 0.5912\n",
            "Epoch 53/100, Loss: 41.7904, Validation Accuracy: 0.6580\n",
            "Epoch 54/100, Loss: 34.9290, Validation Accuracy: 0.3709\n",
            "Epoch 55/100, Loss: 17.2429, Validation Accuracy: 0.5204\n",
            "Epoch 56/100, Loss: 35.1272, Validation Accuracy: 0.5065\n",
            "Epoch 57/100, Loss: 22.5568, Validation Accuracy: 0.5015\n",
            "Epoch 58/100, Loss: 14.8931, Validation Accuracy: 0.3848\n",
            "Epoch 59/100, Loss: 39.0653, Validation Accuracy: 0.5045\n",
            "Epoch 60/100, Loss: 77.0075, Validation Accuracy: 0.6550\n",
            "Epoch 61/100, Loss: 13.7514, Validation Accuracy: 0.6810\n",
            "Epoch 62/100, Loss: 196.8840, Validation Accuracy: 0.6411\n",
            "Epoch 63/100, Loss: 7.8426, Validation Accuracy: 0.5962\n",
            "Epoch 64/100, Loss: 8.0308, Validation Accuracy: 0.5882\n",
            "Epoch 65/100, Loss: 8.9021, Validation Accuracy: 0.4786\n",
            "Epoch 66/100, Loss: 11.1277, Validation Accuracy: 0.4367\n",
            "Epoch 67/100, Loss: 12.7946, Validation Accuracy: 0.6620\n",
            "Epoch 68/100, Loss: 8.9158, Validation Accuracy: 0.5484\n",
            "Epoch 69/100, Loss: 5.6399, Validation Accuracy: 0.5872\n",
            "Epoch 70/100, Loss: 46.8094, Validation Accuracy: 0.5663\n",
            "Epoch 71/100, Loss: 32.1751, Validation Accuracy: 0.5753\n",
            "Epoch 72/100, Loss: 18.5276, Validation Accuracy: 0.6710\n",
            "Epoch 73/100, Loss: 13.8671, Validation Accuracy: 0.6122\n",
            "Epoch 74/100, Loss: 45.8360, Validation Accuracy: 0.5703\n",
            "Epoch 75/100, Loss: 13.5396, Validation Accuracy: 0.6550\n",
            "Epoch 76/100, Loss: 13.7486, Validation Accuracy: 0.6740\n",
            "Epoch 77/100, Loss: 52.5898, Validation Accuracy: 0.6570\n",
            "Epoch 78/100, Loss: 20.6491, Validation Accuracy: 0.6311\n",
            "Epoch 79/100, Loss: 27.4354, Validation Accuracy: 0.6650\n",
            "Epoch 80/100, Loss: 41.4000, Validation Accuracy: 0.5394\n",
            "Epoch 81/100, Loss: 30.8559, Validation Accuracy: 0.5613\n",
            "Epoch 82/100, Loss: 17.5827, Validation Accuracy: 0.6620\n",
            "Epoch 83/100, Loss: 7.8138, Validation Accuracy: 0.6670\n",
            "Epoch 84/100, Loss: 43.0947, Validation Accuracy: 0.5125\n",
            "Epoch 85/100, Loss: 18.0160, Validation Accuracy: 0.5673\n",
            "Epoch 86/100, Loss: 7.6724, Validation Accuracy: 0.6241\n",
            "Epoch 87/100, Loss: 6.3302, Validation Accuracy: 0.6730\n",
            "Epoch 88/100, Loss: 23.7100, Validation Accuracy: 0.6770\n",
            "Epoch 89/100, Loss: 70.6885, Validation Accuracy: 0.5115\n",
            "Epoch 90/100, Loss: 30.7271, Validation Accuracy: 0.5194\n",
            "Epoch 91/100, Loss: 13.4467, Validation Accuracy: 0.5922\n",
            "Epoch 92/100, Loss: 9.1005, Validation Accuracy: 0.6391\n",
            "Epoch 93/100, Loss: 22.7350, Validation Accuracy: 0.5434\n",
            "Epoch 94/100, Loss: 20.1677, Validation Accuracy: 0.4726\n",
            "Epoch 95/100, Loss: 7.9277, Validation Accuracy: 0.5793\n",
            "Epoch 96/100, Loss: 80.7482, Validation Accuracy: 0.6062\n",
            "Epoch 97/100, Loss: 22.0893, Validation Accuracy: 0.5384\n",
            "Epoch 98/100, Loss: 29.0627, Validation Accuracy: 0.4506\n",
            "Epoch 99/100, Loss: 7.5193, Validation Accuracy: 0.5912\n",
            "Epoch 100/100, Loss: 12.7184, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 19.1151, Validation Accuracy: 0.5862\n",
            "Epoch 102/100, Loss: 36.7610, Validation Accuracy: 0.6181\n",
            "Epoch 103/100, Loss: 12.9508, Validation Accuracy: 0.5663\n",
            "Epoch 104/100, Loss: 7.7842, Validation Accuracy: 0.6241\n",
            "Epoch 105/100, Loss: 10.5143, Validation Accuracy: 0.6012\n",
            "Epoch 106/100, Loss: 15.9668, Validation Accuracy: 0.6112\n",
            "Epoch 107/100, Loss: 26.5583, Validation Accuracy: 0.5523\n",
            "Epoch 108/100, Loss: 17.9421, Validation Accuracy: 0.2911\n",
            "Epoch 109/100, Loss: 28.3402, Validation Accuracy: 0.6142\n",
            "Epoch 110/100, Loss: 37.4419, Validation Accuracy: 0.6171\n",
            "Epoch 111/100, Loss: 12.4173, Validation Accuracy: 0.6052\n",
            "Epoch 112/100, Loss: 20.3721, Validation Accuracy: 0.6052\n",
            "Epoch 113/100, Loss: 13.6023, Validation Accuracy: 0.6780\n",
            "Epoch 114/100, Loss: 112.6987, Validation Accuracy: 0.5852\n",
            "Epoch 115/100, Loss: 41.2252, Validation Accuracy: 0.6191\n",
            "Epoch 116/100, Loss: 19.3488, Validation Accuracy: 0.6311\n",
            "Epoch 117/100, Loss: 14.4304, Validation Accuracy: 0.6839\n",
            "Epoch 118/100, Loss: 22.6636, Validation Accuracy: 0.4835\n",
            "Epoch 119/100, Loss: 20.7800, Validation Accuracy: 0.6112\n",
            "Epoch 120/100, Loss: 36.3625, Validation Accuracy: 0.5773\n",
            "Epoch 121/100, Loss: 16.6580, Validation Accuracy: 0.6171\n",
            "Epoch 122/100, Loss: 18.7369, Validation Accuracy: 0.5523\n",
            "Epoch 123/100, Loss: 12.3459, Validation Accuracy: 0.5214\n",
            "Epoch 124/100, Loss: 25.8132, Validation Accuracy: 0.6371\n",
            "Epoch 125/100, Loss: 27.4933, Validation Accuracy: 0.4586\n",
            "Epoch 126/100, Loss: 29.5986, Validation Accuracy: 0.6261\n",
            "Epoch 127/100, Loss: 29.9550, Validation Accuracy: 0.3101\n",
            "Epoch 128/100, Loss: 19.8813, Validation Accuracy: 0.4786\n",
            "Epoch 129/100, Loss: 12.7256, Validation Accuracy: 0.5035\n",
            "Epoch 130/100, Loss: 24.5999, Validation Accuracy: 0.6381\n",
            "Epoch 131/100, Loss: 12.3012, Validation Accuracy: 0.5703\n",
            "Epoch 132/100, Loss: 24.5853, Validation Accuracy: 0.5733\n",
            "Epoch 133/100, Loss: 29.3484, Validation Accuracy: 0.5125\n",
            "Epoch 134/100, Loss: 17.7771, Validation Accuracy: 0.6201\n",
            "Epoch 135/100, Loss: 16.2594, Validation Accuracy: 0.5872\n",
            "Epoch 136/100, Loss: 20.4413, Validation Accuracy: 0.6610\n",
            "Epoch 137/100, Loss: 37.5726, Validation Accuracy: 0.5952\n",
            "Epoch 138/100, Loss: 26.6771, Validation Accuracy: 0.5543\n",
            "Epoch 139/100, Loss: 39.9112, Validation Accuracy: 0.6780\n",
            "Epoch 140/100, Loss: 15.5154, Validation Accuracy: 0.6241\n",
            "Epoch 141/100, Loss: 4.6726, Validation Accuracy: 0.5862\n",
            "Epoch 142/100, Loss: 13.2957, Validation Accuracy: 0.6181\n",
            "Epoch 143/100, Loss: 19.6045, Validation Accuracy: 0.6042\n",
            "Epoch 144/100, Loss: 14.4405, Validation Accuracy: 0.4915\n",
            "Epoch 145/100, Loss: 8.9900, Validation Accuracy: 0.5304\n",
            "Epoch 146/100, Loss: 53.2837, Validation Accuracy: 0.4108\n",
            "Epoch 147/100, Loss: 10.7202, Validation Accuracy: 0.5743\n",
            "Epoch 148/100, Loss: 32.8898, Validation Accuracy: 0.6171\n",
            "Epoch 149/100, Loss: 10.9569, Validation Accuracy: 0.5743\n",
            "Epoch 150/100, Loss: 29.0150, Validation Accuracy: 0.5992\n",
            "Epoch 151/100, Loss: 32.1551, Validation Accuracy: 0.5703\n",
            "Epoch 152/100, Loss: 48.4814, Validation Accuracy: 0.5713\n",
            "Epoch 153/100, Loss: 20.1918, Validation Accuracy: 0.6132\n",
            "Epoch 154/100, Loss: 4.6665, Validation Accuracy: 0.5952\n",
            "Epoch 155/100, Loss: 13.6889, Validation Accuracy: 0.6650\n",
            "Epoch 156/100, Loss: 20.1842, Validation Accuracy: 0.6550\n",
            "Epoch 157/100, Loss: 21.8537, Validation Accuracy: 0.5653\n",
            "Epoch 158/100, Loss: 22.2847, Validation Accuracy: 0.6770\n",
            "Epoch 159/100, Loss: 10.5773, Validation Accuracy: 0.5992\n",
            "Epoch 160/100, Loss: 19.3669, Validation Accuracy: 0.6391\n",
            "Epoch 161/100, Loss: 33.4541, Validation Accuracy: 0.5823\n",
            "Epoch 162/100, Loss: 22.5262, Validation Accuracy: 0.5872\n",
            "Epoch 163/100, Loss: 36.1445, Validation Accuracy: 0.5264\n",
            "Epoch 164/100, Loss: 7.1213, Validation Accuracy: 0.6052\n",
            "Epoch 165/100, Loss: 7.6695, Validation Accuracy: 0.4756\n",
            "Epoch 166/100, Loss: 26.6693, Validation Accuracy: 0.5324\n",
            "Epoch 167/100, Loss: 19.4468, Validation Accuracy: 0.5005\n",
            "Epoch 168/100, Loss: 28.5776, Validation Accuracy: 0.6500\n",
            "Epoch 169/100, Loss: 4.7263, Validation Accuracy: 0.6072\n",
            "Epoch 170/100, Loss: 45.0018, Validation Accuracy: 0.6052\n",
            "Epoch 171/100, Loss: 46.8146, Validation Accuracy: 0.6381\n",
            "Epoch 172/100, Loss: 11.1372, Validation Accuracy: 0.6321\n",
            "Epoch 173/100, Loss: 21.9771, Validation Accuracy: 0.5553\n",
            "Epoch 174/100, Loss: 47.2443, Validation Accuracy: 0.5783\n",
            "Epoch 175/100, Loss: 26.4505, Validation Accuracy: 0.5643\n",
            "Epoch 176/100, Loss: 15.6306, Validation Accuracy: 0.6231\n",
            "Epoch 177/100, Loss: 5.3156, Validation Accuracy: 0.6361\n",
            "Epoch 178/100, Loss: 27.7646, Validation Accuracy: 0.5254\n",
            "Epoch 179/100, Loss: 15.3925, Validation Accuracy: 0.5932\n",
            "Epoch 180/100, Loss: 14.5363, Validation Accuracy: 0.6640\n",
            "Epoch 181/100, Loss: 18.7943, Validation Accuracy: 0.5155\n",
            "Epoch 182/100, Loss: 106.0861, Validation Accuracy: 0.6540\n",
            "Epoch 183/100, Loss: 14.3716, Validation Accuracy: 0.6152\n",
            "Epoch 184/100, Loss: 8.4621, Validation Accuracy: 0.5723\n",
            "Epoch 185/100, Loss: 15.2239, Validation Accuracy: 0.4257\n",
            "Epoch 186/100, Loss: 29.0734, Validation Accuracy: 0.5733\n",
            "Epoch 187/100, Loss: 23.3350, Validation Accuracy: 0.6171\n",
            "Epoch 188/100, Loss: 29.3258, Validation Accuracy: 0.6341\n",
            "Epoch 189/100, Loss: 25.6904, Validation Accuracy: 0.4995\n",
            "Epoch 190/100, Loss: 21.1948, Validation Accuracy: 0.5494\n",
            "Epoch 191/100, Loss: 20.5466, Validation Accuracy: 0.6620\n",
            "Epoch 192/100, Loss: 26.4892, Validation Accuracy: 0.6012\n",
            "Epoch 193/100, Loss: 26.3960, Validation Accuracy: 0.6291\n",
            "Epoch 194/100, Loss: 30.6004, Validation Accuracy: 0.4855\n",
            "Epoch 195/100, Loss: 14.8194, Validation Accuracy: 0.6411\n",
            "Epoch 196/100, Loss: 9.7552, Validation Accuracy: 0.6620\n",
            "Epoch 197/100, Loss: 68.6924, Validation Accuracy: 0.6361\n",
            "Epoch 198/100, Loss: 9.5324, Validation Accuracy: 0.3619\n",
            "Epoch 199/100, Loss: 4.9175, Validation Accuracy: 0.6630\n",
            "Epoch 200/100, Loss: 45.2806, Validation Accuracy: 0.4516\n",
            "Reward for Child Model: 0.2914487096290633\n",
            "Child_19:  {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, [3, 2, 1, 2, 0, 3, 3, 2, 1, 3, 0, 2, 2, 1, 3], 0.2914487096290633\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 24, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 24, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(48, 24, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(96, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=108416, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 22, 22]           9,472\n",
            "       BatchNorm2d-2           [-1, 64, 22, 22]             128\n",
            "            Conv2d-3           [-1, 24, 18, 16]          53,784\n",
            "       BatchNorm2d-4           [-1, 24, 18, 16]              48\n",
            "              ReLU-5           [-1, 24, 18, 16]               0\n",
            "            Conv2d-6           [-1, 24, 12, 16]           4,056\n",
            "       BatchNorm2d-7           [-1, 24, 12, 16]              48\n",
            "              ReLU-8           [-1, 24, 12, 16]               0\n",
            "            Conv2d-9           [-1, 24, 12, 12]          40,344\n",
            "      BatchNorm2d-10           [-1, 24, 12, 12]              48\n",
            "             ReLU-11           [-1, 24, 12, 12]               0\n",
            "           Conv2d-12           [-1, 64, 12, 10]         301,120\n",
            "      BatchNorm2d-13           [-1, 64, 12, 10]             128\n",
            "             ReLU-14           [-1, 64, 12, 10]               0\n",
            "           Linear-15                    [-1, 7]         758,919\n",
            "================================================================\n",
            "Total params: 1,168,095\n",
            "Trainable params: 1,168,095\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.99\n",
            "Params size (MB): 4.46\n",
            "Estimated Total Size (MB): 5.46\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 15.4631, Validation Accuracy: 0.6251\n",
            "Epoch 2/100, Loss: 29.6584, Validation Accuracy: 0.6201\n",
            "Epoch 3/100, Loss: 28.7049, Validation Accuracy: 0.6261\n",
            "Epoch 4/100, Loss: 91.5576, Validation Accuracy: 0.5484\n",
            "Epoch 5/100, Loss: 96.7364, Validation Accuracy: 0.4756\n",
            "Epoch 6/100, Loss: 9.2807, Validation Accuracy: 0.6231\n",
            "Epoch 7/100, Loss: 6.8573, Validation Accuracy: 0.5992\n",
            "Epoch 8/100, Loss: 10.4112, Validation Accuracy: 0.4656\n",
            "Epoch 9/100, Loss: 8.1025, Validation Accuracy: 0.5563\n",
            "Epoch 10/100, Loss: 12.3765, Validation Accuracy: 0.6391\n",
            "Epoch 11/100, Loss: 42.8719, Validation Accuracy: 0.6181\n",
            "Epoch 12/100, Loss: 42.1456, Validation Accuracy: 0.6082\n",
            "Epoch 13/100, Loss: 26.5924, Validation Accuracy: 0.6271\n",
            "Epoch 14/100, Loss: 30.0359, Validation Accuracy: 0.5593\n",
            "Epoch 15/100, Loss: 22.3506, Validation Accuracy: 0.6261\n",
            "Epoch 16/100, Loss: 12.1868, Validation Accuracy: 0.6610\n",
            "Epoch 17/100, Loss: 34.7924, Validation Accuracy: 0.6291\n",
            "Epoch 18/100, Loss: 32.7014, Validation Accuracy: 0.5823\n",
            "Epoch 19/100, Loss: 30.5074, Validation Accuracy: 0.6909\n",
            "Epoch 20/100, Loss: 28.3681, Validation Accuracy: 0.6221\n",
            "Epoch 21/100, Loss: 51.1107, Validation Accuracy: 0.2483\n",
            "Epoch 22/100, Loss: 61.6710, Validation Accuracy: 0.3868\n",
            "Epoch 23/100, Loss: 38.6455, Validation Accuracy: 0.4865\n",
            "Epoch 24/100, Loss: 40.3176, Validation Accuracy: 0.6371\n",
            "Epoch 25/100, Loss: 111.1539, Validation Accuracy: 0.6550\n",
            "Epoch 26/100, Loss: 50.8919, Validation Accuracy: 0.6201\n",
            "Epoch 27/100, Loss: 36.1181, Validation Accuracy: 0.6241\n",
            "Epoch 28/100, Loss: 143.3205, Validation Accuracy: 0.5354\n",
            "Epoch 29/100, Loss: 101.7689, Validation Accuracy: 0.6650\n",
            "Epoch 30/100, Loss: 36.4577, Validation Accuracy: 0.4526\n",
            "Epoch 31/100, Loss: 30.2051, Validation Accuracy: 0.6471\n",
            "Epoch 32/100, Loss: 29.9163, Validation Accuracy: 0.4826\n",
            "Epoch 33/100, Loss: 20.9249, Validation Accuracy: 0.5563\n",
            "Epoch 34/100, Loss: 16.9522, Validation Accuracy: 0.5444\n",
            "Epoch 35/100, Loss: 70.3725, Validation Accuracy: 0.6491\n",
            "Epoch 36/100, Loss: 121.1455, Validation Accuracy: 0.6112\n",
            "Epoch 37/100, Loss: 38.7018, Validation Accuracy: 0.6630\n",
            "Epoch 38/100, Loss: 53.4253, Validation Accuracy: 0.6700\n",
            "Epoch 39/100, Loss: 21.7201, Validation Accuracy: 0.5573\n",
            "Epoch 40/100, Loss: 35.1367, Validation Accuracy: 0.5982\n",
            "Epoch 41/100, Loss: 43.3743, Validation Accuracy: 0.5813\n",
            "Epoch 42/100, Loss: 24.4456, Validation Accuracy: 0.6431\n",
            "Epoch 43/100, Loss: 27.3945, Validation Accuracy: 0.6620\n",
            "Epoch 44/100, Loss: 51.2202, Validation Accuracy: 0.5753\n",
            "Epoch 45/100, Loss: 104.2727, Validation Accuracy: 0.5284\n",
            "Epoch 46/100, Loss: 111.8847, Validation Accuracy: 0.5583\n",
            "Epoch 47/100, Loss: 45.1030, Validation Accuracy: 0.4636\n",
            "Epoch 48/100, Loss: 12.3531, Validation Accuracy: 0.3988\n",
            "Epoch 49/100, Loss: 21.3571, Validation Accuracy: 0.5414\n",
            "Epoch 50/100, Loss: 50.5639, Validation Accuracy: 0.6570\n",
            "Epoch 51/100, Loss: 32.9454, Validation Accuracy: 0.5344\n",
            "Epoch 52/100, Loss: 19.1574, Validation Accuracy: 0.6411\n",
            "Epoch 53/100, Loss: 33.7415, Validation Accuracy: 0.6451\n",
            "Epoch 54/100, Loss: 132.0496, Validation Accuracy: 0.6869\n",
            "Epoch 55/100, Loss: 53.5221, Validation Accuracy: 0.5374\n",
            "Epoch 56/100, Loss: 38.7682, Validation Accuracy: 0.6341\n",
            "Epoch 57/100, Loss: 43.1020, Validation Accuracy: 0.4965\n",
            "Epoch 58/100, Loss: 21.8033, Validation Accuracy: 0.5653\n",
            "Epoch 59/100, Loss: 62.0738, Validation Accuracy: 0.6042\n",
            "Epoch 60/100, Loss: 5.6331, Validation Accuracy: 0.6162\n",
            "Epoch 61/100, Loss: 66.5162, Validation Accuracy: 0.5902\n",
            "Epoch 62/100, Loss: 18.3995, Validation Accuracy: 0.6152\n",
            "Epoch 63/100, Loss: 15.5449, Validation Accuracy: 0.6361\n",
            "Epoch 64/100, Loss: 34.8594, Validation Accuracy: 0.4317\n",
            "Epoch 65/100, Loss: 32.9222, Validation Accuracy: 0.5783\n",
            "Epoch 66/100, Loss: 44.1989, Validation Accuracy: 0.5494\n",
            "Epoch 67/100, Loss: 67.2958, Validation Accuracy: 0.5474\n",
            "Epoch 68/100, Loss: 52.4523, Validation Accuracy: 0.3380\n",
            "Epoch 69/100, Loss: 12.6232, Validation Accuracy: 0.5932\n",
            "Epoch 70/100, Loss: 72.4500, Validation Accuracy: 0.5862\n",
            "Epoch 71/100, Loss: 114.7593, Validation Accuracy: 0.5593\n",
            "Epoch 72/100, Loss: 35.0222, Validation Accuracy: 0.5823\n",
            "Epoch 73/100, Loss: 103.7887, Validation Accuracy: 0.6361\n",
            "Epoch 74/100, Loss: 31.4031, Validation Accuracy: 0.6291\n",
            "Epoch 75/100, Loss: 36.2201, Validation Accuracy: 0.5523\n",
            "Epoch 76/100, Loss: 20.6822, Validation Accuracy: 0.6351\n",
            "Epoch 77/100, Loss: 14.6158, Validation Accuracy: 0.6132\n",
            "Epoch 78/100, Loss: 86.0767, Validation Accuracy: 0.1097\n",
            "Epoch 79/100, Loss: 21.6197, Validation Accuracy: 0.5583\n",
            "Epoch 80/100, Loss: 7.2543, Validation Accuracy: 0.5633\n",
            "Epoch 81/100, Loss: 14.0143, Validation Accuracy: 0.5304\n",
            "Epoch 82/100, Loss: 28.8154, Validation Accuracy: 0.4227\n",
            "Epoch 83/100, Loss: 27.2957, Validation Accuracy: 0.6122\n",
            "Epoch 84/100, Loss: 10.1868, Validation Accuracy: 0.6191\n",
            "Epoch 85/100, Loss: 18.2488, Validation Accuracy: 0.6042\n",
            "Epoch 86/100, Loss: 19.0486, Validation Accuracy: 0.5603\n",
            "Epoch 87/100, Loss: 50.3852, Validation Accuracy: 0.6401\n",
            "Epoch 88/100, Loss: 10.0097, Validation Accuracy: 0.6062\n",
            "Epoch 89/100, Loss: 11.1144, Validation Accuracy: 0.5663\n",
            "Epoch 90/100, Loss: 34.3013, Validation Accuracy: 0.6062\n",
            "Epoch 91/100, Loss: 82.9239, Validation Accuracy: 0.5713\n",
            "Epoch 92/100, Loss: 14.2042, Validation Accuracy: 0.6331\n",
            "Epoch 93/100, Loss: 46.1857, Validation Accuracy: 0.6171\n",
            "Epoch 94/100, Loss: 21.2990, Validation Accuracy: 0.5065\n",
            "Epoch 95/100, Loss: 58.3940, Validation Accuracy: 0.6530\n",
            "Epoch 96/100, Loss: 123.5168, Validation Accuracy: 0.5892\n",
            "Epoch 97/100, Loss: 502.0899, Validation Accuracy: 0.5234\n",
            "Epoch 98/100, Loss: 86.5669, Validation Accuracy: 0.5992\n",
            "Epoch 99/100, Loss: 40.6151, Validation Accuracy: 0.5474\n",
            "Epoch 100/100, Loss: 36.2168, Validation Accuracy: 0.6431\n",
            "Epoch 101/100, Loss: 19.8138, Validation Accuracy: 0.5653\n",
            "Epoch 102/100, Loss: 14.4547, Validation Accuracy: 0.6281\n",
            "Epoch 103/100, Loss: 10.4380, Validation Accuracy: 0.6152\n",
            "Epoch 104/100, Loss: 19.3450, Validation Accuracy: 0.6730\n",
            "Epoch 105/100, Loss: 20.3347, Validation Accuracy: 0.5334\n",
            "Epoch 106/100, Loss: 62.6758, Validation Accuracy: 0.6670\n",
            "Epoch 107/100, Loss: 12.1211, Validation Accuracy: 0.6660\n",
            "Epoch 108/100, Loss: 30.8540, Validation Accuracy: 0.5194\n",
            "Epoch 109/100, Loss: 28.8866, Validation Accuracy: 0.5892\n",
            "Epoch 110/100, Loss: 12.7633, Validation Accuracy: 0.6580\n",
            "Epoch 111/100, Loss: 47.3578, Validation Accuracy: 0.4138\n",
            "Epoch 112/100, Loss: 82.5179, Validation Accuracy: 0.6271\n",
            "Epoch 113/100, Loss: 12.3214, Validation Accuracy: 0.5623\n",
            "Epoch 114/100, Loss: 13.6556, Validation Accuracy: 0.5942\n",
            "Epoch 115/100, Loss: 29.8145, Validation Accuracy: 0.6181\n",
            "Epoch 116/100, Loss: 72.0683, Validation Accuracy: 0.5743\n",
            "Epoch 117/100, Loss: 39.3417, Validation Accuracy: 0.5593\n",
            "Epoch 118/100, Loss: 47.6229, Validation Accuracy: 0.6311\n",
            "Epoch 119/100, Loss: 193.9627, Validation Accuracy: 0.4487\n",
            "Epoch 120/100, Loss: 65.0445, Validation Accuracy: 0.6770\n",
            "Epoch 121/100, Loss: 63.2187, Validation Accuracy: 0.2682\n",
            "Epoch 122/100, Loss: 34.2287, Validation Accuracy: 0.6291\n",
            "Epoch 123/100, Loss: 20.6188, Validation Accuracy: 0.5354\n",
            "Epoch 124/100, Loss: 19.4236, Validation Accuracy: 0.5992\n",
            "Epoch 125/100, Loss: 57.9292, Validation Accuracy: 0.6461\n",
            "Epoch 126/100, Loss: 59.5573, Validation Accuracy: 0.5025\n",
            "Epoch 127/100, Loss: 35.4801, Validation Accuracy: 0.5603\n",
            "Epoch 128/100, Loss: 112.4144, Validation Accuracy: 0.5125\n",
            "Epoch 129/100, Loss: 41.9113, Validation Accuracy: 0.6401\n",
            "Epoch 130/100, Loss: 13.4107, Validation Accuracy: 0.6700\n",
            "Epoch 131/100, Loss: 20.6241, Validation Accuracy: 0.5513\n",
            "Epoch 132/100, Loss: 22.6347, Validation Accuracy: 0.5324\n",
            "Epoch 133/100, Loss: 23.3533, Validation Accuracy: 0.6540\n",
            "Epoch 134/100, Loss: 150.5384, Validation Accuracy: 0.6451\n",
            "Epoch 135/100, Loss: 75.5616, Validation Accuracy: 0.6441\n",
            "Epoch 136/100, Loss: 38.8492, Validation Accuracy: 0.6201\n",
            "Epoch 137/100, Loss: 19.2266, Validation Accuracy: 0.6321\n",
            "Epoch 138/100, Loss: 31.8687, Validation Accuracy: 0.3868\n",
            "Epoch 139/100, Loss: 33.5843, Validation Accuracy: 0.5374\n",
            "Epoch 140/100, Loss: 10.1389, Validation Accuracy: 0.6381\n",
            "Epoch 141/100, Loss: 91.9630, Validation Accuracy: 0.0140\n",
            "Epoch 142/100, Loss: 7.7710, Validation Accuracy: 0.5803\n",
            "Epoch 143/100, Loss: 50.9109, Validation Accuracy: 0.4776\n",
            "Epoch 144/100, Loss: 9.4883, Validation Accuracy: 0.5773\n",
            "Epoch 145/100, Loss: 17.3318, Validation Accuracy: 0.5663\n",
            "Epoch 146/100, Loss: 3.7973, Validation Accuracy: 0.5842\n",
            "Epoch 147/100, Loss: 13.3849, Validation Accuracy: 0.6431\n",
            "Epoch 148/100, Loss: 29.1766, Validation Accuracy: 0.5045\n",
            "Epoch 149/100, Loss: 195.3000, Validation Accuracy: 0.4995\n",
            "Epoch 150/100, Loss: 65.8596, Validation Accuracy: 0.5274\n",
            "Epoch 151/100, Loss: 29.3660, Validation Accuracy: 0.6311\n",
            "Epoch 152/100, Loss: 62.3832, Validation Accuracy: 0.6351\n",
            "Epoch 153/100, Loss: 15.0445, Validation Accuracy: 0.6082\n",
            "Epoch 154/100, Loss: 21.2713, Validation Accuracy: 0.6231\n",
            "Epoch 155/100, Loss: 15.8338, Validation Accuracy: 0.6221\n",
            "Epoch 156/100, Loss: 7.9345, Validation Accuracy: 0.6002\n",
            "Epoch 157/100, Loss: 17.7792, Validation Accuracy: 0.5434\n",
            "Epoch 158/100, Loss: 12.9958, Validation Accuracy: 0.6162\n",
            "Epoch 159/100, Loss: 15.6623, Validation Accuracy: 0.5424\n",
            "Epoch 160/100, Loss: 7.2904, Validation Accuracy: 0.6620\n",
            "Epoch 161/100, Loss: 21.9235, Validation Accuracy: 0.5942\n",
            "Epoch 162/100, Loss: 23.3225, Validation Accuracy: 0.6351\n",
            "Epoch 163/100, Loss: 52.1632, Validation Accuracy: 0.4177\n",
            "Epoch 164/100, Loss: 520.3992, Validation Accuracy: 0.5354\n",
            "Epoch 165/100, Loss: 26.0777, Validation Accuracy: 0.4656\n",
            "Epoch 166/100, Loss: 8.8895, Validation Accuracy: 0.5763\n",
            "Epoch 167/100, Loss: 32.7823, Validation Accuracy: 0.5932\n",
            "Epoch 168/100, Loss: 11.9748, Validation Accuracy: 0.5583\n",
            "Epoch 169/100, Loss: 17.2719, Validation Accuracy: 0.6152\n",
            "Epoch 170/100, Loss: 73.3743, Validation Accuracy: 0.6211\n",
            "Epoch 171/100, Loss: 17.0697, Validation Accuracy: 0.6421\n",
            "Epoch 172/100, Loss: 40.0605, Validation Accuracy: 0.5374\n",
            "Epoch 173/100, Loss: 36.5358, Validation Accuracy: 0.5384\n",
            "Epoch 174/100, Loss: 89.5889, Validation Accuracy: 0.6411\n",
            "Epoch 175/100, Loss: 41.9912, Validation Accuracy: 0.5952\n",
            "Epoch 176/100, Loss: 11.9085, Validation Accuracy: 0.5763\n",
            "Epoch 177/100, Loss: 45.7112, Validation Accuracy: 0.5474\n",
            "Epoch 178/100, Loss: 22.9744, Validation Accuracy: 0.5135\n",
            "Epoch 179/100, Loss: 105.5202, Validation Accuracy: 0.3519\n",
            "Epoch 180/100, Loss: 34.3554, Validation Accuracy: 0.5683\n",
            "Epoch 181/100, Loss: 144.4876, Validation Accuracy: 0.6391\n",
            "Epoch 182/100, Loss: 32.3286, Validation Accuracy: 0.5055\n",
            "Epoch 183/100, Loss: 52.4881, Validation Accuracy: 0.5005\n",
            "Epoch 184/100, Loss: 31.0665, Validation Accuracy: 0.6321\n",
            "Epoch 185/100, Loss: 14.9084, Validation Accuracy: 0.5902\n",
            "Epoch 186/100, Loss: 42.0477, Validation Accuracy: 0.5643\n",
            "Epoch 187/100, Loss: 22.2269, Validation Accuracy: 0.6590\n",
            "Epoch 188/100, Loss: 16.3945, Validation Accuracy: 0.6351\n",
            "Epoch 189/100, Loss: 38.9626, Validation Accuracy: 0.6790\n",
            "Epoch 190/100, Loss: 2025.9745, Validation Accuracy: 0.6331\n",
            "Epoch 191/100, Loss: 18.6216, Validation Accuracy: 0.4915\n",
            "Epoch 192/100, Loss: 920.9544, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 23.9256, Validation Accuracy: 0.5972\n",
            "Epoch 194/100, Loss: 8.3700, Validation Accuracy: 0.5862\n",
            "Epoch 195/100, Loss: 7.4812, Validation Accuracy: 0.5872\n",
            "Epoch 196/100, Loss: 25.6901, Validation Accuracy: 0.5713\n",
            "Epoch 197/100, Loss: 10.7194, Validation Accuracy: 0.6152\n",
            "Epoch 198/100, Loss: 12.2619, Validation Accuracy: 0.4885\n",
            "Epoch 199/100, Loss: 12.9161, Validation Accuracy: 0.6580\n",
            "Epoch 200/100, Loss: 7.5963, Validation Accuracy: 0.4686\n",
            "Reward for Child Model: 0.28492398350792647\n",
            "Child_20:  {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, [3, 3, 3, 2, 3, 0, 3, 0, 0, 3, 2, 0, 3, 3, 3], 0.28492398350792647\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 48, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(84, 64, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(184, 48, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(352, 48, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=379456, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 28, 28]             144\n",
            "       BatchNorm2d-2           [-1, 36, 28, 28]              72\n",
            "            Conv2d-3           [-1, 48, 24, 24]          43,248\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "              ReLU-5           [-1, 48, 24, 24]               0\n",
            "            Conv2d-6           [-1, 64, 26, 22]         112,960\n",
            "       BatchNorm2d-7           [-1, 64, 26, 22]             128\n",
            "              ReLU-8           [-1, 64, 26, 22]               0\n",
            "            Conv2d-9           [-1, 48, 22, 28]          61,872\n",
            "      BatchNorm2d-10           [-1, 48, 22, 28]              96\n",
            "             ReLU-11           [-1, 48, 22, 28]               0\n",
            "           Conv2d-12           [-1, 48, 26, 24]         253,488\n",
            "      BatchNorm2d-13           [-1, 48, 26, 24]              96\n",
            "             ReLU-14           [-1, 48, 26, 24]               0\n",
            "           Linear-15                    [-1, 7]       2,656,199\n",
            "================================================================\n",
            "Total params: 3,128,399\n",
            "Trainable params: 3,128,399\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.26\n",
            "Params size (MB): 11.93\n",
            "Estimated Total Size (MB): 15.21\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 22.1107, Validation Accuracy: 0.1944\n",
            "Epoch 2/100, Loss: 118.9707, Validation Accuracy: 0.6022\n",
            "Epoch 3/100, Loss: 72.0008, Validation Accuracy: 0.6251\n",
            "Epoch 4/100, Loss: 1699.1604, Validation Accuracy: 0.3430\n",
            "Epoch 5/100, Loss: 209.7933, Validation Accuracy: 0.6371\n",
            "Epoch 6/100, Loss: 89.8666, Validation Accuracy: 0.4596\n",
            "Epoch 7/100, Loss: 59.3878, Validation Accuracy: 0.7039\n",
            "Epoch 8/100, Loss: 133.3204, Validation Accuracy: 0.5344\n",
            "Epoch 9/100, Loss: 22.6063, Validation Accuracy: 0.4526\n",
            "Epoch 10/100, Loss: 276.3286, Validation Accuracy: 0.6790\n",
            "Epoch 11/100, Loss: 449.4041, Validation Accuracy: 0.3689\n",
            "Epoch 12/100, Loss: 131.3808, Validation Accuracy: 0.3529\n",
            "Epoch 13/100, Loss: 69.4674, Validation Accuracy: 0.5653\n",
            "Epoch 14/100, Loss: 23.0216, Validation Accuracy: 0.6750\n",
            "Epoch 15/100, Loss: 129.4890, Validation Accuracy: 0.5075\n",
            "Epoch 16/100, Loss: 57.7065, Validation Accuracy: 0.6849\n",
            "Epoch 17/100, Loss: 132.9649, Validation Accuracy: 0.3819\n",
            "Epoch 18/100, Loss: 353.2548, Validation Accuracy: 0.6550\n",
            "Epoch 19/100, Loss: 130.9654, Validation Accuracy: 0.6391\n",
            "Epoch 20/100, Loss: 181.6829, Validation Accuracy: 0.2921\n",
            "Epoch 21/100, Loss: 528.4777, Validation Accuracy: 0.6491\n",
            "Epoch 22/100, Loss: 225.0853, Validation Accuracy: 0.5882\n",
            "Epoch 23/100, Loss: 43.3958, Validation Accuracy: 0.6331\n",
            "Epoch 24/100, Loss: 108.2396, Validation Accuracy: 0.5563\n",
            "Epoch 25/100, Loss: 84.1524, Validation Accuracy: 0.6640\n",
            "Epoch 26/100, Loss: 201.0847, Validation Accuracy: 0.5394\n",
            "Epoch 27/100, Loss: 238.5438, Validation Accuracy: 0.6142\n",
            "Epoch 28/100, Loss: 188.4017, Validation Accuracy: 0.6211\n",
            "Epoch 29/100, Loss: 123.5373, Validation Accuracy: 0.4666\n",
            "Epoch 30/100, Loss: 330.5682, Validation Accuracy: 0.4158\n",
            "Epoch 31/100, Loss: 329.2191, Validation Accuracy: 0.5573\n",
            "Epoch 32/100, Loss: 88.7219, Validation Accuracy: 0.4387\n",
            "Epoch 33/100, Loss: 41.0299, Validation Accuracy: 0.6291\n",
            "Epoch 34/100, Loss: 283.8145, Validation Accuracy: 0.6271\n",
            "Epoch 35/100, Loss: 231.4142, Validation Accuracy: 0.4965\n",
            "Epoch 36/100, Loss: 202.2005, Validation Accuracy: 0.5204\n",
            "Epoch 37/100, Loss: 154.6768, Validation Accuracy: 0.5723\n",
            "Epoch 38/100, Loss: 298.0128, Validation Accuracy: 0.6740\n",
            "Epoch 39/100, Loss: 298.4785, Validation Accuracy: 0.5045\n",
            "Epoch 40/100, Loss: 110.7883, Validation Accuracy: 0.6491\n",
            "Epoch 41/100, Loss: 192.2434, Validation Accuracy: 0.5852\n",
            "Epoch 42/100, Loss: 344.9555, Validation Accuracy: 0.6780\n",
            "Epoch 43/100, Loss: 197.4482, Validation Accuracy: 0.6132\n",
            "Epoch 44/100, Loss: 199.5674, Validation Accuracy: 0.6112\n",
            "Epoch 45/100, Loss: 103.5701, Validation Accuracy: 0.6281\n",
            "Epoch 46/100, Loss: 221.6135, Validation Accuracy: 0.5653\n",
            "Epoch 47/100, Loss: 173.9475, Validation Accuracy: 0.5852\n",
            "Epoch 48/100, Loss: 244.7676, Validation Accuracy: 0.6720\n",
            "Epoch 49/100, Loss: 407.0236, Validation Accuracy: 0.5224\n",
            "Epoch 50/100, Loss: 177.5309, Validation Accuracy: 0.5344\n",
            "Epoch 51/100, Loss: 155.9086, Validation Accuracy: 0.6570\n",
            "Epoch 52/100, Loss: 52.5845, Validation Accuracy: 0.4317\n",
            "Epoch 53/100, Loss: 588.4767, Validation Accuracy: 0.4955\n",
            "Epoch 54/100, Loss: 392.1499, Validation Accuracy: 0.6530\n",
            "Epoch 55/100, Loss: 93.4732, Validation Accuracy: 0.5543\n",
            "Epoch 56/100, Loss: 48.4002, Validation Accuracy: 0.6670\n",
            "Epoch 57/100, Loss: 151.2833, Validation Accuracy: 0.6421\n",
            "Epoch 58/100, Loss: 454.3384, Validation Accuracy: 0.6879\n",
            "Epoch 59/100, Loss: 88.7729, Validation Accuracy: 0.2243\n",
            "Epoch 60/100, Loss: 352.8449, Validation Accuracy: 0.6500\n",
            "Epoch 61/100, Loss: 131.2583, Validation Accuracy: 0.4556\n",
            "Epoch 62/100, Loss: 181.7784, Validation Accuracy: 0.4895\n",
            "Epoch 63/100, Loss: 126.8425, Validation Accuracy: 0.5204\n",
            "Epoch 64/100, Loss: 289.8185, Validation Accuracy: 0.5165\n",
            "Epoch 65/100, Loss: 49.2979, Validation Accuracy: 0.6929\n",
            "Epoch 66/100, Loss: 224.7201, Validation Accuracy: 0.6401\n",
            "Epoch 67/100, Loss: 181.8477, Validation Accuracy: 0.6291\n",
            "Epoch 68/100, Loss: 240.9584, Validation Accuracy: 0.5912\n",
            "Epoch 69/100, Loss: 239.1751, Validation Accuracy: 0.6830\n",
            "Epoch 70/100, Loss: 187.1345, Validation Accuracy: 0.5793\n",
            "Epoch 71/100, Loss: 363.1022, Validation Accuracy: 0.6351\n",
            "Epoch 72/100, Loss: 134.0378, Validation Accuracy: 0.6800\n",
            "Epoch 73/100, Loss: 94.0232, Validation Accuracy: 0.5474\n",
            "Epoch 74/100, Loss: 194.7000, Validation Accuracy: 0.5872\n",
            "Epoch 75/100, Loss: 155.8126, Validation Accuracy: 0.5952\n",
            "Epoch 76/100, Loss: 220.5888, Validation Accuracy: 0.6520\n",
            "Epoch 77/100, Loss: 224.7120, Validation Accuracy: 0.5324\n",
            "Epoch 78/100, Loss: 134.7724, Validation Accuracy: 0.6191\n",
            "Epoch 79/100, Loss: 142.3351, Validation Accuracy: 0.5444\n",
            "Epoch 80/100, Loss: 104.7597, Validation Accuracy: 0.6760\n",
            "Epoch 81/100, Loss: 293.0307, Validation Accuracy: 0.6520\n",
            "Epoch 82/100, Loss: 149.5816, Validation Accuracy: 0.3021\n",
            "Epoch 83/100, Loss: 284.6108, Validation Accuracy: 0.6810\n",
            "Epoch 84/100, Loss: 181.9670, Validation Accuracy: 0.6301\n",
            "Epoch 85/100, Loss: 137.8556, Validation Accuracy: 0.4207\n",
            "Epoch 86/100, Loss: 202.8232, Validation Accuracy: 0.6431\n",
            "Epoch 87/100, Loss: 66.3890, Validation Accuracy: 0.5992\n",
            "Epoch 88/100, Loss: 298.5075, Validation Accuracy: 0.6122\n",
            "Epoch 89/100, Loss: 61.5072, Validation Accuracy: 0.5593\n",
            "Epoch 90/100, Loss: 82.3793, Validation Accuracy: 0.6171\n",
            "Epoch 91/100, Loss: 94.6609, Validation Accuracy: 0.4377\n",
            "Epoch 92/100, Loss: 157.5255, Validation Accuracy: 0.6122\n",
            "Epoch 93/100, Loss: 203.2565, Validation Accuracy: 0.4506\n",
            "Epoch 94/100, Loss: 157.0481, Validation Accuracy: 0.5653\n",
            "Epoch 95/100, Loss: 280.0085, Validation Accuracy: 0.3061\n",
            "Epoch 96/100, Loss: 157.1319, Validation Accuracy: 0.6700\n",
            "Epoch 97/100, Loss: 97.4852, Validation Accuracy: 0.6062\n",
            "Epoch 98/100, Loss: 93.2335, Validation Accuracy: 0.5833\n",
            "Epoch 99/100, Loss: 54.0125, Validation Accuracy: 0.5593\n",
            "Epoch 100/100, Loss: 187.7924, Validation Accuracy: 0.6650\n",
            "Epoch 101/100, Loss: 125.2395, Validation Accuracy: 0.5434\n",
            "Epoch 102/100, Loss: 149.8554, Validation Accuracy: 0.6869\n",
            "Epoch 103/100, Loss: 39.4806, Validation Accuracy: 0.6660\n",
            "Epoch 104/100, Loss: 223.5731, Validation Accuracy: 0.6820\n",
            "Epoch 105/100, Loss: 75.3345, Validation Accuracy: 0.5653\n",
            "Epoch 106/100, Loss: 338.8426, Validation Accuracy: 0.5783\n",
            "Epoch 107/100, Loss: 277.6449, Validation Accuracy: 0.6650\n",
            "Epoch 108/100, Loss: 292.1851, Validation Accuracy: 0.4128\n",
            "Epoch 109/100, Loss: 258.7174, Validation Accuracy: 0.6092\n",
            "Epoch 110/100, Loss: 42.2162, Validation Accuracy: 0.6331\n",
            "Epoch 111/100, Loss: 207.4561, Validation Accuracy: 0.6301\n",
            "Epoch 112/100, Loss: 163.5818, Validation Accuracy: 0.6640\n",
            "Epoch 113/100, Loss: 264.4027, Validation Accuracy: 0.6720\n",
            "Epoch 114/100, Loss: 314.8027, Validation Accuracy: 0.6311\n",
            "Epoch 115/100, Loss: 255.8172, Validation Accuracy: 0.6291\n",
            "Epoch 116/100, Loss: 498.2511, Validation Accuracy: 0.6311\n",
            "Epoch 117/100, Loss: 388.0741, Validation Accuracy: 0.6162\n",
            "Epoch 118/100, Loss: 250.4858, Validation Accuracy: 0.6839\n",
            "Epoch 119/100, Loss: 244.3251, Validation Accuracy: 0.5942\n",
            "Epoch 120/100, Loss: 135.0292, Validation Accuracy: 0.5613\n",
            "Epoch 121/100, Loss: 128.4273, Validation Accuracy: 0.6620\n",
            "Epoch 122/100, Loss: 134.9566, Validation Accuracy: 0.6281\n",
            "Epoch 123/100, Loss: 86.3806, Validation Accuracy: 0.5912\n",
            "Epoch 124/100, Loss: 147.7406, Validation Accuracy: 0.5503\n",
            "Epoch 125/100, Loss: 155.2922, Validation Accuracy: 0.6012\n",
            "Epoch 126/100, Loss: 372.4310, Validation Accuracy: 0.4806\n",
            "Epoch 127/100, Loss: 107.1451, Validation Accuracy: 0.6660\n",
            "Epoch 128/100, Loss: 419.0992, Validation Accuracy: 0.4327\n",
            "Epoch 129/100, Loss: 208.4852, Validation Accuracy: 0.5753\n",
            "Epoch 130/100, Loss: 125.8183, Validation Accuracy: 0.5174\n",
            "Epoch 131/100, Loss: 397.0724, Validation Accuracy: 0.6730\n",
            "Epoch 132/100, Loss: 98.5064, Validation Accuracy: 0.6082\n",
            "Epoch 133/100, Loss: 185.5692, Validation Accuracy: 0.6441\n",
            "Epoch 134/100, Loss: 119.5642, Validation Accuracy: 0.4566\n",
            "Epoch 135/100, Loss: 380.4497, Validation Accuracy: 0.4257\n",
            "Epoch 136/100, Loss: 80.9038, Validation Accuracy: 0.6361\n",
            "Epoch 137/100, Loss: 418.2935, Validation Accuracy: 0.5633\n",
            "Epoch 138/100, Loss: 166.6397, Validation Accuracy: 0.6550\n",
            "Epoch 139/100, Loss: 62.2672, Validation Accuracy: 0.6959\n",
            "Epoch 140/100, Loss: 468.4417, Validation Accuracy: 0.5892\n",
            "Epoch 141/100, Loss: 275.6472, Validation Accuracy: 0.6032\n",
            "Epoch 142/100, Loss: 393.4134, Validation Accuracy: 0.6800\n",
            "Epoch 143/100, Loss: 246.3440, Validation Accuracy: 0.5892\n",
            "Epoch 144/100, Loss: 165.3547, Validation Accuracy: 0.5563\n",
            "Epoch 145/100, Loss: 339.4884, Validation Accuracy: 0.5454\n",
            "Epoch 146/100, Loss: 290.0277, Validation Accuracy: 0.6560\n",
            "Epoch 147/100, Loss: 184.9271, Validation Accuracy: 0.6461\n",
            "Epoch 148/100, Loss: 107.3229, Validation Accuracy: 0.4975\n",
            "Epoch 149/100, Loss: 161.1401, Validation Accuracy: 0.6590\n",
            "Epoch 150/100, Loss: 97.8457, Validation Accuracy: 0.4138\n",
            "Epoch 151/100, Loss: 263.0470, Validation Accuracy: 0.6211\n",
            "Epoch 152/100, Loss: 469.8815, Validation Accuracy: 0.6680\n",
            "Epoch 153/100, Loss: 259.2425, Validation Accuracy: 0.6241\n",
            "Epoch 154/100, Loss: 220.4848, Validation Accuracy: 0.6650\n",
            "Epoch 155/100, Loss: 223.9693, Validation Accuracy: 0.5763\n",
            "Epoch 156/100, Loss: 86.9140, Validation Accuracy: 0.6211\n",
            "Epoch 157/100, Loss: 100.9057, Validation Accuracy: 0.6680\n",
            "Epoch 158/100, Loss: 121.3660, Validation Accuracy: 0.6730\n",
            "Epoch 159/100, Loss: 575.2736, Validation Accuracy: 0.3779\n",
            "Epoch 160/100, Loss: 123.7684, Validation Accuracy: 0.6770\n",
            "Epoch 161/100, Loss: 235.9154, Validation Accuracy: 0.6660\n",
            "Epoch 162/100, Loss: 281.3897, Validation Accuracy: 0.6251\n",
            "Epoch 163/100, Loss: 333.9667, Validation Accuracy: 0.6371\n",
            "Epoch 164/100, Loss: 94.4324, Validation Accuracy: 0.6002\n",
            "Epoch 165/100, Loss: 133.1136, Validation Accuracy: 0.6909\n",
            "Epoch 166/100, Loss: 182.3240, Validation Accuracy: 0.6610\n",
            "Epoch 167/100, Loss: 333.2334, Validation Accuracy: 0.6181\n",
            "Epoch 168/100, Loss: 195.6518, Validation Accuracy: 0.6570\n",
            "Epoch 169/100, Loss: 76.5996, Validation Accuracy: 0.6341\n",
            "Epoch 170/100, Loss: 101.2798, Validation Accuracy: 0.5553\n",
            "Epoch 171/100, Loss: 138.9762, Validation Accuracy: 0.5882\n",
            "Epoch 172/100, Loss: 322.5813, Validation Accuracy: 0.6570\n",
            "Epoch 173/100, Loss: 338.0584, Validation Accuracy: 0.6371\n",
            "Epoch 174/100, Loss: 145.8442, Validation Accuracy: 0.6381\n",
            "Epoch 175/100, Loss: 396.6360, Validation Accuracy: 0.2323\n",
            "Epoch 176/100, Loss: 234.6680, Validation Accuracy: 0.6630\n",
            "Epoch 177/100, Loss: 298.0224, Validation Accuracy: 0.4716\n",
            "Epoch 178/100, Loss: 300.7959, Validation Accuracy: 0.5194\n",
            "Epoch 179/100, Loss: 142.0327, Validation Accuracy: 0.6032\n",
            "Epoch 180/100, Loss: 203.5900, Validation Accuracy: 0.6321\n",
            "Epoch 181/100, Loss: 176.9747, Validation Accuracy: 0.5723\n",
            "Epoch 182/100, Loss: 116.3025, Validation Accuracy: 0.6381\n",
            "Epoch 183/100, Loss: 154.4563, Validation Accuracy: 0.6810\n",
            "Epoch 184/100, Loss: 249.4722, Validation Accuracy: 0.5174\n",
            "Epoch 185/100, Loss: 117.8857, Validation Accuracy: 0.5902\n",
            "Epoch 186/100, Loss: 121.5523, Validation Accuracy: 0.6391\n",
            "Epoch 187/100, Loss: 287.6289, Validation Accuracy: 0.5065\n",
            "Epoch 188/100, Loss: 301.2754, Validation Accuracy: 0.6411\n",
            "Epoch 189/100, Loss: 90.2775, Validation Accuracy: 0.5424\n",
            "Epoch 190/100, Loss: 304.7893, Validation Accuracy: 0.5743\n",
            "Epoch 191/100, Loss: 185.1176, Validation Accuracy: 0.6750\n",
            "Epoch 192/100, Loss: 177.1021, Validation Accuracy: 0.6500\n",
            "Epoch 193/100, Loss: 361.4384, Validation Accuracy: 0.6570\n",
            "Epoch 194/100, Loss: 295.5636, Validation Accuracy: 0.6849\n",
            "Epoch 195/100, Loss: 424.2952, Validation Accuracy: 0.6680\n",
            "Epoch 196/100, Loss: 259.8806, Validation Accuracy: 0.5264\n",
            "Epoch 197/100, Loss: 279.4555, Validation Accuracy: 0.5494\n",
            "Epoch 198/100, Loss: 176.0297, Validation Accuracy: 0.6660\n",
            "Epoch 199/100, Loss: 149.8808, Validation Accuracy: 0.6152\n",
            "Epoch 200/100, Loss: 56.3143, Validation Accuracy: 0.5912\n",
            "Reward for Child Model: 0.2954109493838166\n",
            "Child_21:  {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, [0, 0, 1, 2, 2, 2, 1, 3, 3, 3, 0, 2, 1, 2, 2], 0.2954109493838166\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 36, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 24, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(60, 64, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(124, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=174944, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 28, 22]             792\n",
            "       BatchNorm2d-2           [-1, 36, 28, 22]              72\n",
            "            Conv2d-3           [-1, 36, 26, 16]          27,252\n",
            "       BatchNorm2d-4           [-1, 36, 26, 16]              72\n",
            "              ReLU-5           [-1, 36, 26, 16]               0\n",
            "            Conv2d-6           [-1, 24, 20, 12]          30,264\n",
            "       BatchNorm2d-7           [-1, 24, 20, 12]              48\n",
            "              ReLU-8           [-1, 24, 20, 12]               0\n",
            "            Conv2d-9           [-1, 64, 20, 14]          80,704\n",
            "      BatchNorm2d-10           [-1, 64, 20, 14]             128\n",
            "             ReLU-11           [-1, 64, 20, 14]               0\n",
            "           Conv2d-12           [-1, 64, 22, 16]          39,744\n",
            "      BatchNorm2d-13           [-1, 64, 22, 16]             128\n",
            "             ReLU-14           [-1, 64, 22, 16]               0\n",
            "           Linear-15                    [-1, 7]       1,224,615\n",
            "================================================================\n",
            "Total params: 1,403,819\n",
            "Trainable params: 1,403,819\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.74\n",
            "Params size (MB): 5.36\n",
            "Estimated Total Size (MB): 7.10\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 15.3564, Validation Accuracy: 0.4875\n",
            "Epoch 2/100, Loss: 34.0926, Validation Accuracy: 0.5633\n",
            "Epoch 3/100, Loss: 13.5283, Validation Accuracy: 0.5155\n",
            "Epoch 4/100, Loss: 15.1330, Validation Accuracy: 0.6820\n",
            "Epoch 5/100, Loss: 507.4701, Validation Accuracy: 0.5623\n",
            "Epoch 6/100, Loss: 44.3499, Validation Accuracy: 0.4895\n",
            "Epoch 7/100, Loss: 56.2346, Validation Accuracy: 0.2343\n",
            "Epoch 8/100, Loss: 6.3210, Validation Accuracy: 0.5783\n",
            "Epoch 9/100, Loss: 19.4917, Validation Accuracy: 0.5543\n",
            "Epoch 10/100, Loss: 334.0490, Validation Accuracy: 0.5932\n",
            "Epoch 11/100, Loss: 44.1854, Validation Accuracy: 0.6301\n",
            "Epoch 12/100, Loss: 22.6450, Validation Accuracy: 0.6052\n",
            "Epoch 13/100, Loss: 3.3494, Validation Accuracy: 0.6102\n",
            "Epoch 14/100, Loss: 6.2109, Validation Accuracy: 0.5274\n",
            "Epoch 15/100, Loss: 7.5811, Validation Accuracy: 0.5733\n",
            "Epoch 16/100, Loss: 3.6195, Validation Accuracy: 0.6171\n",
            "Epoch 17/100, Loss: 203.3941, Validation Accuracy: 0.5922\n",
            "Epoch 18/100, Loss: 33.9913, Validation Accuracy: 0.6072\n",
            "Epoch 19/100, Loss: 6.3645, Validation Accuracy: 0.6102\n",
            "Epoch 20/100, Loss: 28.6859, Validation Accuracy: 0.6510\n",
            "Epoch 21/100, Loss: 8.0013, Validation Accuracy: 0.5174\n",
            "Epoch 22/100, Loss: 10.2309, Validation Accuracy: 0.5234\n",
            "Epoch 23/100, Loss: 5.1192, Validation Accuracy: 0.6670\n",
            "Epoch 24/100, Loss: 7.8224, Validation Accuracy: 0.5523\n",
            "Epoch 25/100, Loss: 3.2686, Validation Accuracy: 0.6660\n",
            "Epoch 26/100, Loss: 4.3266, Validation Accuracy: 0.4317\n",
            "Epoch 27/100, Loss: 9.7459, Validation Accuracy: 0.6411\n",
            "Epoch 28/100, Loss: 54.5442, Validation Accuracy: 0.6062\n",
            "Epoch 29/100, Loss: 11.7658, Validation Accuracy: 0.6092\n",
            "Epoch 30/100, Loss: 229.8947, Validation Accuracy: 0.5713\n",
            "Epoch 31/100, Loss: 12.0998, Validation Accuracy: 0.4985\n",
            "Epoch 32/100, Loss: 33.5338, Validation Accuracy: 0.5803\n",
            "Epoch 33/100, Loss: 1756.6887, Validation Accuracy: 0.5783\n",
            "Epoch 34/100, Loss: 54.6385, Validation Accuracy: 0.6281\n",
            "Epoch 35/100, Loss: 101.4454, Validation Accuracy: 0.5065\n",
            "Epoch 36/100, Loss: 30.2498, Validation Accuracy: 0.6191\n",
            "Epoch 37/100, Loss: 29.1947, Validation Accuracy: 0.6540\n",
            "Epoch 38/100, Loss: 11.9234, Validation Accuracy: 0.5693\n",
            "Epoch 39/100, Loss: 5.0508, Validation Accuracy: 0.6670\n",
            "Epoch 40/100, Loss: 4.6938, Validation Accuracy: 0.6461\n",
            "Epoch 41/100, Loss: 7.1358, Validation Accuracy: 0.6092\n",
            "Epoch 42/100, Loss: 8.1228, Validation Accuracy: 0.6500\n",
            "Epoch 43/100, Loss: 13.7391, Validation Accuracy: 0.6620\n",
            "Epoch 44/100, Loss: 9.1224, Validation Accuracy: 0.6630\n",
            "Epoch 45/100, Loss: 3.7371, Validation Accuracy: 0.4606\n",
            "Epoch 46/100, Loss: 132.5148, Validation Accuracy: 0.5912\n",
            "Epoch 47/100, Loss: 15.7675, Validation Accuracy: 0.4556\n",
            "Epoch 48/100, Loss: 7.5451, Validation Accuracy: 0.6211\n",
            "Epoch 49/100, Loss: 3.9359, Validation Accuracy: 0.6610\n",
            "Epoch 50/100, Loss: 304.9007, Validation Accuracy: 0.1615\n",
            "Epoch 51/100, Loss: 9.8762, Validation Accuracy: 0.6620\n",
            "Epoch 52/100, Loss: 9.2053, Validation Accuracy: 0.5852\n",
            "Epoch 53/100, Loss: 21.9741, Validation Accuracy: 0.6311\n",
            "Epoch 54/100, Loss: 9.9918, Validation Accuracy: 0.5912\n",
            "Epoch 55/100, Loss: 12.0848, Validation Accuracy: 0.5055\n",
            "Epoch 56/100, Loss: 7.9859, Validation Accuracy: 0.6032\n",
            "Epoch 57/100, Loss: 348.8158, Validation Accuracy: 0.5872\n",
            "Epoch 58/100, Loss: 52.3105, Validation Accuracy: 0.6520\n",
            "Epoch 59/100, Loss: 65.8267, Validation Accuracy: 0.6191\n",
            "Epoch 60/100, Loss: 18.8934, Validation Accuracy: 0.6361\n",
            "Epoch 61/100, Loss: 9.9568, Validation Accuracy: 0.6052\n",
            "Epoch 62/100, Loss: 2.7966, Validation Accuracy: 0.6780\n",
            "Epoch 63/100, Loss: 13.5984, Validation Accuracy: 0.5723\n",
            "Epoch 64/100, Loss: 5.4550, Validation Accuracy: 0.6042\n",
            "Epoch 65/100, Loss: 2.8126, Validation Accuracy: 0.6361\n",
            "Epoch 66/100, Loss: 6.4052, Validation Accuracy: 0.5872\n",
            "Epoch 67/100, Loss: 31.0019, Validation Accuracy: 0.6461\n",
            "Epoch 68/100, Loss: 8.5261, Validation Accuracy: 0.6301\n",
            "Epoch 69/100, Loss: 2.5862, Validation Accuracy: 0.5444\n",
            "Epoch 70/100, Loss: 1400.2142, Validation Accuracy: 0.6032\n",
            "Epoch 71/100, Loss: 897.8765, Validation Accuracy: 0.5852\n",
            "Epoch 72/100, Loss: 565.3129, Validation Accuracy: 0.5633\n",
            "Epoch 73/100, Loss: 202.6612, Validation Accuracy: 0.5533\n",
            "Epoch 74/100, Loss: 180.4325, Validation Accuracy: 0.5513\n",
            "Epoch 75/100, Loss: 70.8693, Validation Accuracy: 0.3549\n",
            "Epoch 76/100, Loss: 34.9294, Validation Accuracy: 0.5484\n",
            "Epoch 77/100, Loss: 79.9651, Validation Accuracy: 0.6341\n",
            "Epoch 78/100, Loss: 12.8143, Validation Accuracy: 0.6361\n",
            "Epoch 79/100, Loss: 8.1787, Validation Accuracy: 0.6002\n",
            "Epoch 80/100, Loss: 18.9277, Validation Accuracy: 0.5553\n",
            "Epoch 81/100, Loss: 10.8250, Validation Accuracy: 0.6221\n",
            "Epoch 82/100, Loss: 19.0395, Validation Accuracy: 0.6620\n",
            "Epoch 83/100, Loss: 7.9123, Validation Accuracy: 0.5733\n",
            "Epoch 84/100, Loss: 8.6559, Validation Accuracy: 0.6092\n",
            "Epoch 85/100, Loss: 6.2581, Validation Accuracy: 0.6301\n",
            "Epoch 86/100, Loss: 7.7884, Validation Accuracy: 0.5454\n",
            "Epoch 87/100, Loss: 16.2134, Validation Accuracy: 0.6700\n",
            "Epoch 88/100, Loss: 5.2424, Validation Accuracy: 0.5733\n",
            "Epoch 89/100, Loss: 14.6847, Validation Accuracy: 0.5942\n",
            "Epoch 90/100, Loss: 60.9856, Validation Accuracy: 0.5753\n",
            "Epoch 91/100, Loss: 54.2064, Validation Accuracy: 0.5593\n",
            "Epoch 92/100, Loss: 6.4791, Validation Accuracy: 0.6301\n",
            "Epoch 93/100, Loss: 3.4220, Validation Accuracy: 0.6231\n",
            "Epoch 94/100, Loss: 6.9157, Validation Accuracy: 0.6012\n",
            "Epoch 95/100, Loss: 9.0706, Validation Accuracy: 0.6321\n",
            "Epoch 96/100, Loss: 1362.6494, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 47.1520, Validation Accuracy: 0.5882\n",
            "Epoch 98/100, Loss: 18.2151, Validation Accuracy: 0.6790\n",
            "Epoch 99/100, Loss: 19.8282, Validation Accuracy: 0.6032\n",
            "Epoch 100/100, Loss: 7.7204, Validation Accuracy: 0.6530\n",
            "Epoch 101/100, Loss: 6.7913, Validation Accuracy: 0.6281\n",
            "Epoch 102/100, Loss: 11.8700, Validation Accuracy: 0.6839\n",
            "Epoch 103/100, Loss: 9.6212, Validation Accuracy: 0.6540\n",
            "Epoch 104/100, Loss: 11.0293, Validation Accuracy: 0.6471\n",
            "Epoch 105/100, Loss: 11.2852, Validation Accuracy: 0.6600\n",
            "Epoch 106/100, Loss: 10.4728, Validation Accuracy: 0.6331\n",
            "Epoch 107/100, Loss: 16.5238, Validation Accuracy: 0.5972\n",
            "Epoch 108/100, Loss: 46.2013, Validation Accuracy: 0.5743\n",
            "Epoch 109/100, Loss: 46.8906, Validation Accuracy: 0.4995\n",
            "Epoch 110/100, Loss: 31.6881, Validation Accuracy: 0.6241\n",
            "Epoch 111/100, Loss: 9.0995, Validation Accuracy: 0.6650\n",
            "Epoch 112/100, Loss: 2094.7954, Validation Accuracy: 0.6411\n",
            "Epoch 113/100, Loss: 88.7668, Validation Accuracy: 0.5952\n",
            "Epoch 114/100, Loss: 16.4378, Validation Accuracy: 0.5035\n",
            "Epoch 115/100, Loss: 4.1862, Validation Accuracy: 0.6411\n",
            "Epoch 116/100, Loss: 9.4717, Validation Accuracy: 0.3878\n",
            "Epoch 117/100, Loss: 11.9076, Validation Accuracy: 0.6351\n",
            "Epoch 118/100, Loss: 9.0422, Validation Accuracy: 0.5902\n",
            "Epoch 119/100, Loss: 2.8343, Validation Accuracy: 0.6231\n",
            "Epoch 120/100, Loss: 17.4386, Validation Accuracy: 0.4706\n",
            "Epoch 121/100, Loss: 17.0770, Validation Accuracy: 0.5603\n",
            "Epoch 122/100, Loss: 6.6132, Validation Accuracy: 0.6271\n",
            "Epoch 123/100, Loss: 11.5396, Validation Accuracy: 0.6770\n",
            "Epoch 124/100, Loss: 58.6065, Validation Accuracy: 0.6700\n",
            "Epoch 125/100, Loss: 10.2251, Validation Accuracy: 0.6231\n",
            "Epoch 126/100, Loss: 14.4776, Validation Accuracy: 0.5603\n",
            "Epoch 127/100, Loss: 12.0257, Validation Accuracy: 0.6849\n",
            "Epoch 128/100, Loss: 139.8062, Validation Accuracy: 0.5892\n",
            "Epoch 129/100, Loss: 8.2227, Validation Accuracy: 0.4417\n",
            "Epoch 130/100, Loss: 19.3898, Validation Accuracy: 0.6431\n",
            "Epoch 131/100, Loss: 8.0495, Validation Accuracy: 0.6152\n",
            "Epoch 132/100, Loss: 17.6663, Validation Accuracy: 0.6670\n",
            "Epoch 133/100, Loss: 42.1549, Validation Accuracy: 0.4736\n",
            "Epoch 134/100, Loss: 15.6178, Validation Accuracy: 0.5753\n",
            "Epoch 135/100, Loss: 23.1159, Validation Accuracy: 0.5344\n",
            "Epoch 136/100, Loss: 20.4917, Validation Accuracy: 0.4855\n",
            "Epoch 137/100, Loss: 13.3835, Validation Accuracy: 0.5663\n",
            "Epoch 138/100, Loss: 24.0280, Validation Accuracy: 0.6610\n",
            "Epoch 139/100, Loss: 33.1155, Validation Accuracy: 0.5494\n",
            "Epoch 140/100, Loss: 21.9056, Validation Accuracy: 0.6710\n",
            "Epoch 141/100, Loss: 18.8142, Validation Accuracy: 0.6431\n",
            "Epoch 142/100, Loss: 24.7697, Validation Accuracy: 0.5125\n",
            "Epoch 143/100, Loss: 7.3792, Validation Accuracy: 0.6191\n",
            "Epoch 144/100, Loss: 22.6129, Validation Accuracy: 0.5733\n",
            "Epoch 145/100, Loss: 58.1911, Validation Accuracy: 0.5344\n",
            "Epoch 146/100, Loss: 19.2071, Validation Accuracy: 0.5763\n",
            "Epoch 147/100, Loss: 64.9196, Validation Accuracy: 0.6431\n",
            "Epoch 148/100, Loss: 830.8160, Validation Accuracy: 0.5623\n",
            "Epoch 149/100, Loss: 51.5847, Validation Accuracy: 0.6032\n",
            "Epoch 150/100, Loss: 13.0487, Validation Accuracy: 0.5693\n",
            "Epoch 151/100, Loss: 24.9860, Validation Accuracy: 0.6471\n",
            "Epoch 152/100, Loss: 7.1341, Validation Accuracy: 0.5374\n",
            "Epoch 153/100, Loss: 111.5151, Validation Accuracy: 0.5693\n",
            "Epoch 154/100, Loss: 4.1754, Validation Accuracy: 0.5623\n",
            "Epoch 155/100, Loss: 5.8869, Validation Accuracy: 0.6491\n",
            "Epoch 156/100, Loss: 10.1684, Validation Accuracy: 0.5922\n",
            "Epoch 157/100, Loss: 5.2748, Validation Accuracy: 0.6590\n",
            "Epoch 158/100, Loss: 1494.4320, Validation Accuracy: 0.5962\n",
            "Epoch 159/100, Loss: 805.6240, Validation Accuracy: 0.5254\n",
            "Epoch 160/100, Loss: 512.4396, Validation Accuracy: 0.6780\n",
            "Epoch 161/100, Loss: 594.5951, Validation Accuracy: 0.5803\n",
            "Epoch 162/100, Loss: 471.1782, Validation Accuracy: 0.6610\n",
            "Epoch 163/100, Loss: 428.7710, Validation Accuracy: 0.6441\n",
            "Epoch 164/100, Loss: 100.0796, Validation Accuracy: 0.6461\n",
            "Epoch 165/100, Loss: 155.6989, Validation Accuracy: 0.5593\n",
            "Epoch 166/100, Loss: 106.6066, Validation Accuracy: 0.6351\n",
            "Epoch 167/100, Loss: 118.3618, Validation Accuracy: 0.6820\n",
            "Epoch 168/100, Loss: 83.8206, Validation Accuracy: 0.6381\n",
            "Epoch 169/100, Loss: 37.8235, Validation Accuracy: 0.5563\n",
            "Epoch 170/100, Loss: 64.9062, Validation Accuracy: 0.5703\n",
            "Epoch 171/100, Loss: 26.6785, Validation Accuracy: 0.6012\n",
            "Epoch 172/100, Loss: 182.5743, Validation Accuracy: 0.5783\n",
            "Epoch 173/100, Loss: 8.4311, Validation Accuracy: 0.6750\n",
            "Epoch 174/100, Loss: 11.6558, Validation Accuracy: 0.6879\n",
            "Epoch 175/100, Loss: 11.1909, Validation Accuracy: 0.6810\n",
            "Epoch 176/100, Loss: 15.1775, Validation Accuracy: 0.5743\n",
            "Epoch 177/100, Loss: 6.6807, Validation Accuracy: 0.4925\n",
            "Epoch 178/100, Loss: 8.4620, Validation Accuracy: 0.6859\n",
            "Epoch 179/100, Loss: 17.9963, Validation Accuracy: 0.5942\n",
            "Epoch 180/100, Loss: 7.4059, Validation Accuracy: 0.4806\n",
            "Epoch 181/100, Loss: 655.7029, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 39.8884, Validation Accuracy: 0.6102\n",
            "Epoch 183/100, Loss: 4.7945, Validation Accuracy: 0.6790\n",
            "Epoch 184/100, Loss: 120.5140, Validation Accuracy: 0.6421\n",
            "Epoch 185/100, Loss: 24.6943, Validation Accuracy: 0.6281\n",
            "Epoch 186/100, Loss: 11.0774, Validation Accuracy: 0.6500\n",
            "Epoch 187/100, Loss: 7.3927, Validation Accuracy: 0.6391\n",
            "Epoch 188/100, Loss: 39.1362, Validation Accuracy: 0.6700\n",
            "Epoch 189/100, Loss: 3.9063, Validation Accuracy: 0.5603\n",
            "Epoch 190/100, Loss: 9.7854, Validation Accuracy: 0.6112\n",
            "Epoch 191/100, Loss: 4.8926, Validation Accuracy: 0.6301\n",
            "Epoch 192/100, Loss: 9.2526, Validation Accuracy: 0.5404\n",
            "Epoch 193/100, Loss: 1051.5981, Validation Accuracy: 0.4875\n",
            "Epoch 194/100, Loss: 14.1958, Validation Accuracy: 0.6560\n",
            "Epoch 195/100, Loss: 288.6382, Validation Accuracy: 0.6660\n",
            "Epoch 196/100, Loss: 19.3115, Validation Accuracy: 0.6540\n",
            "Epoch 197/100, Loss: 12.0006, Validation Accuracy: 0.6540\n",
            "Epoch 198/100, Loss: 166.5935, Validation Accuracy: 0.5274\n",
            "Epoch 199/100, Loss: 14.2308, Validation Accuracy: 0.6181\n",
            "Epoch 200/100, Loss: 8.9397, Validation Accuracy: 0.5852\n",
            "Reward for Child Model: 0.2797748805989118\n",
            "Child_22:  {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, [0, 3, 1, 1, 3, 1, 3, 2, 0, 3, 1, 3, 2, 0, 3], 0.2797748805989118\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 48, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(84, 48, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(48, 48, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(48, 36, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=58080, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 24, 24]           2,736\n",
            "       BatchNorm2d-2           [-1, 36, 24, 24]              72\n",
            "            Conv2d-3           [-1, 48, 22, 18]          36,336\n",
            "       BatchNorm2d-4           [-1, 48, 22, 18]              96\n",
            "              ReLU-5           [-1, 48, 22, 18]               0\n",
            "            Conv2d-6           [-1, 48, 20, 22]          60,528\n",
            "       BatchNorm2d-7           [-1, 48, 20, 22]              96\n",
            "              ReLU-8           [-1, 48, 20, 22]               0\n",
            "            Conv2d-9           [-1, 48, 16, 18]          57,648\n",
            "      BatchNorm2d-10           [-1, 48, 16, 18]              96\n",
            "             ReLU-11           [-1, 48, 16, 18]               0\n",
            "           Conv2d-12           [-1, 36, 12, 12]          60,516\n",
            "      BatchNorm2d-13           [-1, 36, 12, 12]              72\n",
            "             ReLU-14           [-1, 36, 12, 12]               0\n",
            "           Linear-15                    [-1, 7]         406,567\n",
            "================================================================\n",
            "Total params: 624,763\n",
            "Trainable params: 624,763\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.67\n",
            "Params size (MB): 2.38\n",
            "Estimated Total Size (MB): 4.06\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 1.0506, Validation Accuracy: 0.6690\n",
            "Epoch 2/100, Loss: 0.8200, Validation Accuracy: 0.6650\n",
            "Epoch 3/100, Loss: 1.1624, Validation Accuracy: 0.6670\n",
            "Epoch 4/100, Loss: 1.3420, Validation Accuracy: 0.6670\n",
            "Epoch 5/100, Loss: 0.7674, Validation Accuracy: 0.6640\n",
            "Epoch 6/100, Loss: 0.8215, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 0.9403, Validation Accuracy: 0.6680\n",
            "Epoch 8/100, Loss: 1.2813, Validation Accuracy: 0.6670\n",
            "Epoch 9/100, Loss: 1.0417, Validation Accuracy: 0.6680\n",
            "Epoch 10/100, Loss: 1.7806, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 0.8530, Validation Accuracy: 0.6600\n",
            "Epoch 12/100, Loss: 0.9207, Validation Accuracy: 0.6640\n",
            "Epoch 13/100, Loss: 1.4202, Validation Accuracy: 0.6660\n",
            "Epoch 14/100, Loss: 1.2285, Validation Accuracy: 0.6640\n",
            "Epoch 15/100, Loss: 0.8391, Validation Accuracy: 0.6670\n",
            "Epoch 16/100, Loss: 0.7749, Validation Accuracy: 0.6650\n",
            "Epoch 17/100, Loss: 10.1081, Validation Accuracy: 0.6690\n",
            "Epoch 18/100, Loss: 1.0795, Validation Accuracy: 0.6680\n",
            "Epoch 19/100, Loss: 1.0658, Validation Accuracy: 0.6680\n",
            "Epoch 20/100, Loss: 1.1758, Validation Accuracy: 0.6690\n",
            "Epoch 21/100, Loss: 1.3070, Validation Accuracy: 0.6690\n",
            "Epoch 22/100, Loss: 0.8408, Validation Accuracy: 0.6690\n",
            "Epoch 23/100, Loss: 1.3867, Validation Accuracy: 0.6690\n",
            "Epoch 24/100, Loss: 1.2539, Validation Accuracy: 0.6670\n",
            "Epoch 25/100, Loss: 1.1088, Validation Accuracy: 0.0140\n",
            "Epoch 26/100, Loss: 41.3441, Validation Accuracy: 0.5543\n",
            "Epoch 27/100, Loss: 1.1471, Validation Accuracy: 0.5842\n",
            "Epoch 28/100, Loss: 0.8741, Validation Accuracy: 0.6590\n",
            "Epoch 29/100, Loss: 0.8463, Validation Accuracy: 0.6650\n",
            "Epoch 30/100, Loss: 2.1310, Validation Accuracy: 0.6650\n",
            "Epoch 31/100, Loss: 1.1718, Validation Accuracy: 0.6640\n",
            "Epoch 32/100, Loss: 1.4089, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 1.1115, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 1.1394, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 0.8268, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 0.8460, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 1.4379, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 1.2724, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 1.2022, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 1.0693, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 1.4513, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 1.0666, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 0.9682, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 1.2751, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 0.9983, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 1.1252, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 0.9075, Validation Accuracy: 0.6690\n",
            "Epoch 48/100, Loss: 1.6137, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 1.0842, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 0.8604, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 0.9281, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 1.0163, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 1.0712, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 1.2217, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 1.4674, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 1.6959, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 1.3977, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 1.2337, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 0.8822, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 0.8777, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 1.5853, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 1.5859, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 1.0344, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 1.1928, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 0.9294, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 1.0022, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 1.0468, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 1.1942, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 0.9692, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 1.3129, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 0.9763, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 0.9494, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 1.3613, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 1.1516, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 1.2389, Validation Accuracy: 0.6690\n",
            "Epoch 76/100, Loss: 0.8591, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 1.1612, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 1.0505, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 1.0555, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 1.2038, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 1.0272, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 1.1042, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 0.9056, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 0.9380, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 0.9181, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 1.1073, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 1.1743, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 1.4030, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 1.5781, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 0.9934, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 1.1413, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 1.4210, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 0.9048, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 1.1310, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 0.9489, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 0.9608, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 0.8240, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 1.2538, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 1.1263, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 1.5177, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 1.3711, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 0.9509, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 0.8786, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 0.9296, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 1.4748, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 0.8356, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 1.1137, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 1.0988, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 1.4989, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 1.3005, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.2350, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 1.0831, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 1.5756, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 0.9154, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 0.9749, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 0.9461, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 1.2556, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 1.7018, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 0.9835, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 0.9581, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 1.1598, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.1260, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 1.2517, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 1.2999, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 1.1100, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 0.9251, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 1.0496, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 1.1340, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 1.1917, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 1.3026, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 1.0814, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 1.0959, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 1.1760, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 1.0575, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 1.1638, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 1.2110, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 0.9065, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 1.3067, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 1.4407, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 1.0811, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 0.9447, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 1.0017, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 1.1072, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 1.0037, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 0.9504, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 1.1095, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 1.2908, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 1.0536, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 1.1135, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 1.1974, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 0.7987, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 1.0337, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 1.0971, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 1.1544, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 0.8043, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 1.0667, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 1.0226, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 1.0387, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 1.2853, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 1.0441, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 1.1727, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 0.8614, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 1.3199, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 1.1943, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 1.2969, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 1.1703, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 0.8813, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 0.9410, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 0.9888, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 0.9855, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 1.1892, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 1.1212, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 1.0431, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 1.0601, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 0.8723, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 1.1376, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 1.4642, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 1.4001, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 1.0712, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 1.4328, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 1.3018, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 0.9736, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 1.1961, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 1.0056, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 1.1324, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 0.7871, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 0.9917, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 0.8054, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 1.5189, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 0.8539, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 1.1374, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 1.2795, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 1.0774, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 0.7980, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 1.1077, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 1.0014, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 1.2635, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 0.8633, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 1.1938, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 1.1202, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_23:  {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, [2, 2, 1, 1, 3, 2, 2, 1, 2, 2, 2, 2, 2, 3, 1], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 48, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(84, 48, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(48, 64, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(232, 24, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=196224, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 24, 28]             576\n",
            "       BatchNorm2d-2           [-1, 36, 24, 28]              72\n",
            "            Conv2d-3           [-1, 48, 20, 28]           8,688\n",
            "       BatchNorm2d-4           [-1, 48, 20, 28]              96\n",
            "              ReLU-5           [-1, 48, 20, 28]               0\n",
            "            Conv2d-6           [-1, 48, 22, 24]          60,528\n",
            "       BatchNorm2d-7           [-1, 48, 22, 24]              96\n",
            "              ReLU-8           [-1, 48, 22, 24]               0\n",
            "            Conv2d-9           [-1, 64, 22, 22]           9,280\n",
            "      BatchNorm2d-10           [-1, 64, 22, 22]             128\n",
            "             ReLU-11           [-1, 64, 22, 22]               0\n",
            "           Conv2d-12           [-1, 24, 22, 28]          16,728\n",
            "      BatchNorm2d-13           [-1, 24, 22, 28]              48\n",
            "             ReLU-14           [-1, 24, 22, 28]               0\n",
            "           Linear-15                    [-1, 7]       1,373,575\n",
            "================================================================\n",
            "Total params: 1,469,815\n",
            "Trainable params: 1,469,815\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.61\n",
            "Params size (MB): 5.61\n",
            "Estimated Total Size (MB): 8.23\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 29.3187, Validation Accuracy: 0.6500\n",
            "Epoch 2/100, Loss: 116.9194, Validation Accuracy: 0.6221\n",
            "Epoch 3/100, Loss: 51.6809, Validation Accuracy: 0.6560\n",
            "Epoch 4/100, Loss: 251.0287, Validation Accuracy: 0.3958\n",
            "Epoch 5/100, Loss: 160.4831, Validation Accuracy: 0.3410\n",
            "Epoch 6/100, Loss: 71.3195, Validation Accuracy: 0.6361\n",
            "Epoch 7/100, Loss: 107.2573, Validation Accuracy: 0.4905\n",
            "Epoch 8/100, Loss: 27.7373, Validation Accuracy: 0.6371\n",
            "Epoch 9/100, Loss: 54.1432, Validation Accuracy: 0.2861\n",
            "Epoch 10/100, Loss: 41.1149, Validation Accuracy: 0.5673\n",
            "Epoch 11/100, Loss: 112.0806, Validation Accuracy: 0.4477\n",
            "Epoch 12/100, Loss: 319.2952, Validation Accuracy: 0.1107\n",
            "Epoch 13/100, Loss: 89.6112, Validation Accuracy: 0.4108\n",
            "Epoch 14/100, Loss: 514.2645, Validation Accuracy: 0.6640\n",
            "Epoch 15/100, Loss: 124.1077, Validation Accuracy: 0.5454\n",
            "Epoch 16/100, Loss: 57.5943, Validation Accuracy: 0.5583\n",
            "Epoch 17/100, Loss: 51.1140, Validation Accuracy: 0.3998\n",
            "Epoch 18/100, Loss: 48.4121, Validation Accuracy: 0.6879\n",
            "Epoch 19/100, Loss: 39.7238, Validation Accuracy: 0.5344\n",
            "Epoch 20/100, Loss: 39.5957, Validation Accuracy: 0.6251\n",
            "Epoch 21/100, Loss: 82.1893, Validation Accuracy: 0.6680\n",
            "Epoch 22/100, Loss: 136.9669, Validation Accuracy: 0.4596\n",
            "Epoch 23/100, Loss: 257.1604, Validation Accuracy: 0.5145\n",
            "Epoch 24/100, Loss: 55.4188, Validation Accuracy: 0.4865\n",
            "Epoch 25/100, Loss: 172.7355, Validation Accuracy: 0.5115\n",
            "Epoch 26/100, Loss: 54.6849, Validation Accuracy: 0.6610\n",
            "Epoch 27/100, Loss: 58.9701, Validation Accuracy: 0.6680\n",
            "Epoch 28/100, Loss: 99.2867, Validation Accuracy: 0.6690\n",
            "Epoch 29/100, Loss: 143.2343, Validation Accuracy: 0.6281\n",
            "Epoch 30/100, Loss: 253.1712, Validation Accuracy: 0.6730\n",
            "Epoch 31/100, Loss: 104.4670, Validation Accuracy: 0.6411\n",
            "Epoch 32/100, Loss: 46.0443, Validation Accuracy: 0.6321\n",
            "Epoch 33/100, Loss: 76.9716, Validation Accuracy: 0.1097\n",
            "Epoch 34/100, Loss: 43.5014, Validation Accuracy: 0.5823\n",
            "Epoch 35/100, Loss: 96.4443, Validation Accuracy: 0.6431\n",
            "Epoch 36/100, Loss: 113.4267, Validation Accuracy: 0.6401\n",
            "Epoch 37/100, Loss: 110.8207, Validation Accuracy: 0.5862\n",
            "Epoch 38/100, Loss: 436.9543, Validation Accuracy: 0.5224\n",
            "Epoch 39/100, Loss: 117.5846, Validation Accuracy: 0.6171\n",
            "Epoch 40/100, Loss: 462.1324, Validation Accuracy: 0.0828\n",
            "Epoch 41/100, Loss: 44.2293, Validation Accuracy: 0.5254\n",
            "Epoch 42/100, Loss: 32.0145, Validation Accuracy: 0.5494\n",
            "Epoch 43/100, Loss: 422.9084, Validation Accuracy: 0.4835\n",
            "Epoch 44/100, Loss: 67.1746, Validation Accuracy: 0.5862\n",
            "Epoch 45/100, Loss: 29.2745, Validation Accuracy: 0.5912\n",
            "Epoch 46/100, Loss: 90.5223, Validation Accuracy: 0.6700\n",
            "Epoch 47/100, Loss: 34.1173, Validation Accuracy: 0.5643\n",
            "Epoch 48/100, Loss: 49.1087, Validation Accuracy: 0.5065\n",
            "Epoch 49/100, Loss: 28.2083, Validation Accuracy: 0.6560\n",
            "Epoch 50/100, Loss: 37.2273, Validation Accuracy: 0.5364\n",
            "Epoch 51/100, Loss: 33.7861, Validation Accuracy: 0.6052\n",
            "Epoch 52/100, Loss: 70.0557, Validation Accuracy: 0.4835\n",
            "Epoch 53/100, Loss: 69.9685, Validation Accuracy: 0.6251\n",
            "Epoch 54/100, Loss: 34.4785, Validation Accuracy: 0.6401\n",
            "Epoch 55/100, Loss: 24.9547, Validation Accuracy: 0.6520\n",
            "Epoch 56/100, Loss: 51.6981, Validation Accuracy: 0.4457\n",
            "Epoch 57/100, Loss: 64.4670, Validation Accuracy: 0.6271\n",
            "Epoch 58/100, Loss: 176.1163, Validation Accuracy: 0.6989\n",
            "Epoch 59/100, Loss: 112.1983, Validation Accuracy: 0.6730\n",
            "Epoch 60/100, Loss: 100.1576, Validation Accuracy: 0.6291\n",
            "Epoch 61/100, Loss: 76.0846, Validation Accuracy: 0.6361\n",
            "Epoch 62/100, Loss: 83.1416, Validation Accuracy: 0.6301\n",
            "Epoch 63/100, Loss: 103.2148, Validation Accuracy: 0.5115\n",
            "Epoch 64/100, Loss: 83.6996, Validation Accuracy: 0.6431\n",
            "Epoch 65/100, Loss: 76.7998, Validation Accuracy: 0.4885\n",
            "Epoch 66/100, Loss: 244.9910, Validation Accuracy: 0.6112\n",
            "Epoch 67/100, Loss: 79.4359, Validation Accuracy: 0.6730\n",
            "Epoch 68/100, Loss: 88.4401, Validation Accuracy: 0.6002\n",
            "Epoch 69/100, Loss: 1002.4074, Validation Accuracy: 0.4417\n",
            "Epoch 70/100, Loss: 94.3383, Validation Accuracy: 0.6830\n",
            "Epoch 71/100, Loss: 41.3084, Validation Accuracy: 0.6361\n",
            "Epoch 72/100, Loss: 50.0124, Validation Accuracy: 0.6520\n",
            "Epoch 73/100, Loss: 29.6511, Validation Accuracy: 0.6092\n",
            "Epoch 74/100, Loss: 77.1390, Validation Accuracy: 0.6351\n",
            "Epoch 75/100, Loss: 33.4720, Validation Accuracy: 0.6261\n",
            "Epoch 76/100, Loss: 80.2707, Validation Accuracy: 0.6610\n",
            "Epoch 77/100, Loss: 100.3400, Validation Accuracy: 0.5304\n",
            "Epoch 78/100, Loss: 76.4274, Validation Accuracy: 0.6211\n",
            "Epoch 79/100, Loss: 59.9255, Validation Accuracy: 0.5294\n",
            "Epoch 80/100, Loss: 77.0200, Validation Accuracy: 0.5623\n",
            "Epoch 81/100, Loss: 161.1314, Validation Accuracy: 0.5673\n",
            "Epoch 82/100, Loss: 84.0251, Validation Accuracy: 0.6381\n",
            "Epoch 83/100, Loss: 34.9741, Validation Accuracy: 0.6790\n",
            "Epoch 84/100, Loss: 99.0477, Validation Accuracy: 0.5783\n",
            "Epoch 85/100, Loss: 54.8389, Validation Accuracy: 0.6171\n",
            "Epoch 86/100, Loss: 33.5813, Validation Accuracy: 0.5882\n",
            "Epoch 87/100, Loss: 49.8489, Validation Accuracy: 0.6640\n",
            "Epoch 88/100, Loss: 91.4395, Validation Accuracy: 0.6102\n",
            "Epoch 89/100, Loss: 179.3069, Validation Accuracy: 0.6301\n",
            "Epoch 90/100, Loss: 138.9052, Validation Accuracy: 0.6700\n",
            "Epoch 91/100, Loss: 63.9577, Validation Accuracy: 0.6082\n",
            "Epoch 92/100, Loss: 89.4461, Validation Accuracy: 0.6311\n",
            "Epoch 93/100, Loss: 124.3921, Validation Accuracy: 0.4816\n",
            "Epoch 94/100, Loss: 119.0948, Validation Accuracy: 0.6261\n",
            "Epoch 95/100, Loss: 238.6362, Validation Accuracy: 0.6640\n",
            "Epoch 96/100, Loss: 60.0022, Validation Accuracy: 0.5803\n",
            "Epoch 97/100, Loss: 334.1785, Validation Accuracy: 0.6630\n",
            "Epoch 98/100, Loss: 57.2923, Validation Accuracy: 0.6630\n",
            "Epoch 99/100, Loss: 294.1713, Validation Accuracy: 0.6012\n",
            "Epoch 100/100, Loss: 242.4049, Validation Accuracy: 0.5902\n",
            "Epoch 101/100, Loss: 140.4731, Validation Accuracy: 0.6451\n",
            "Epoch 102/100, Loss: 77.4199, Validation Accuracy: 0.5942\n",
            "Epoch 103/100, Loss: 67.0632, Validation Accuracy: 0.5723\n",
            "Epoch 104/100, Loss: 67.8773, Validation Accuracy: 0.5314\n",
            "Epoch 105/100, Loss: 34.0809, Validation Accuracy: 0.6112\n",
            "Epoch 106/100, Loss: 41.5643, Validation Accuracy: 0.6889\n",
            "Epoch 107/100, Loss: 40.2177, Validation Accuracy: 0.6859\n",
            "Epoch 108/100, Loss: 33.0419, Validation Accuracy: 0.5095\n",
            "Epoch 109/100, Loss: 107.2942, Validation Accuracy: 0.6411\n",
            "Epoch 110/100, Loss: 58.7934, Validation Accuracy: 0.5454\n",
            "Epoch 111/100, Loss: 91.4270, Validation Accuracy: 0.5862\n",
            "Epoch 112/100, Loss: 161.1043, Validation Accuracy: 0.6002\n",
            "Epoch 113/100, Loss: 11.6291, Validation Accuracy: 0.6710\n",
            "Epoch 114/100, Loss: 111.1054, Validation Accuracy: 0.4307\n",
            "Epoch 115/100, Loss: 49.8318, Validation Accuracy: 0.5892\n",
            "Epoch 116/100, Loss: 33.8370, Validation Accuracy: 0.6371\n",
            "Epoch 117/100, Loss: 106.0726, Validation Accuracy: 0.4646\n",
            "Epoch 118/100, Loss: 310.9334, Validation Accuracy: 0.6720\n",
            "Epoch 119/100, Loss: 87.9354, Validation Accuracy: 0.5444\n",
            "Epoch 120/100, Loss: 82.2311, Validation Accuracy: 0.6171\n",
            "Epoch 121/100, Loss: 31.2705, Validation Accuracy: 0.4985\n",
            "Epoch 122/100, Loss: 71.9370, Validation Accuracy: 0.6431\n",
            "Epoch 123/100, Loss: 47.1797, Validation Accuracy: 0.5494\n",
            "Epoch 124/100, Loss: 119.8444, Validation Accuracy: 0.6710\n",
            "Epoch 125/100, Loss: 96.8650, Validation Accuracy: 0.6142\n",
            "Epoch 126/100, Loss: 133.5693, Validation Accuracy: 0.6361\n",
            "Epoch 127/100, Loss: 86.8197, Validation Accuracy: 0.6132\n",
            "Epoch 128/100, Loss: 80.3865, Validation Accuracy: 0.4327\n",
            "Epoch 129/100, Loss: 118.9010, Validation Accuracy: 0.4686\n",
            "Epoch 130/100, Loss: 43.4697, Validation Accuracy: 0.6471\n",
            "Epoch 131/100, Loss: 227.0992, Validation Accuracy: 0.6640\n",
            "Epoch 132/100, Loss: 82.0891, Validation Accuracy: 0.5234\n",
            "Epoch 133/100, Loss: 63.7802, Validation Accuracy: 0.6092\n",
            "Epoch 134/100, Loss: 66.7533, Validation Accuracy: 0.5992\n",
            "Epoch 135/100, Loss: 56.6666, Validation Accuracy: 0.6052\n",
            "Epoch 136/100, Loss: 54.9535, Validation Accuracy: 0.6142\n",
            "Epoch 137/100, Loss: 129.5295, Validation Accuracy: 0.5703\n",
            "Epoch 138/100, Loss: 67.6639, Validation Accuracy: 0.6391\n",
            "Epoch 139/100, Loss: 141.8180, Validation Accuracy: 0.5922\n",
            "Epoch 140/100, Loss: 53.4919, Validation Accuracy: 0.5085\n",
            "Epoch 141/100, Loss: 188.9749, Validation Accuracy: 0.5683\n",
            "Epoch 142/100, Loss: 246.8223, Validation Accuracy: 0.5753\n",
            "Epoch 143/100, Loss: 60.6734, Validation Accuracy: 0.5733\n",
            "Epoch 144/100, Loss: 111.5580, Validation Accuracy: 0.6590\n",
            "Epoch 145/100, Loss: 158.2091, Validation Accuracy: 0.6520\n",
            "Epoch 146/100, Loss: 32.4498, Validation Accuracy: 0.6560\n",
            "Epoch 147/100, Loss: 244.8065, Validation Accuracy: 0.6221\n",
            "Epoch 148/100, Loss: 87.0277, Validation Accuracy: 0.6500\n",
            "Epoch 149/100, Loss: 158.3342, Validation Accuracy: 0.6072\n",
            "Epoch 150/100, Loss: 121.1784, Validation Accuracy: 0.6102\n",
            "Epoch 151/100, Loss: 249.0185, Validation Accuracy: 0.5962\n",
            "Epoch 152/100, Loss: 64.0506, Validation Accuracy: 0.6301\n",
            "Epoch 153/100, Loss: 159.8238, Validation Accuracy: 0.6401\n",
            "Epoch 154/100, Loss: 124.9176, Validation Accuracy: 0.6261\n",
            "Epoch 155/100, Loss: 87.6452, Validation Accuracy: 0.5663\n",
            "Epoch 156/100, Loss: 34.6868, Validation Accuracy: 0.6620\n",
            "Epoch 157/100, Loss: 47.5340, Validation Accuracy: 0.6132\n",
            "Epoch 158/100, Loss: 214.6232, Validation Accuracy: 0.6520\n",
            "Epoch 159/100, Loss: 116.3617, Validation Accuracy: 0.6451\n",
            "Epoch 160/100, Loss: 85.4549, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 78.6225, Validation Accuracy: 0.5374\n",
            "Epoch 162/100, Loss: 85.4438, Validation Accuracy: 0.5015\n",
            "Epoch 163/100, Loss: 137.8853, Validation Accuracy: 0.6072\n",
            "Epoch 164/100, Loss: 90.1292, Validation Accuracy: 0.5484\n",
            "Epoch 165/100, Loss: 113.3911, Validation Accuracy: 0.4975\n",
            "Epoch 166/100, Loss: 153.6957, Validation Accuracy: 0.6351\n",
            "Epoch 167/100, Loss: 105.8508, Validation Accuracy: 0.5394\n",
            "Epoch 168/100, Loss: 106.0230, Validation Accuracy: 0.6092\n",
            "Epoch 169/100, Loss: 39.5637, Validation Accuracy: 0.6181\n",
            "Epoch 170/100, Loss: 85.7992, Validation Accuracy: 0.6052\n",
            "Epoch 171/100, Loss: 121.4229, Validation Accuracy: 0.6700\n",
            "Epoch 172/100, Loss: 272.2966, Validation Accuracy: 0.5703\n",
            "Epoch 173/100, Loss: 52.9366, Validation Accuracy: 0.6530\n",
            "Epoch 174/100, Loss: 95.1829, Validation Accuracy: 0.6341\n",
            "Epoch 175/100, Loss: 115.0378, Validation Accuracy: 0.5823\n",
            "Epoch 176/100, Loss: 85.2431, Validation Accuracy: 0.5942\n",
            "Epoch 177/100, Loss: 100.4238, Validation Accuracy: 0.6451\n",
            "Epoch 178/100, Loss: 67.3766, Validation Accuracy: 0.6481\n",
            "Epoch 179/100, Loss: 165.0656, Validation Accuracy: 0.4506\n",
            "Epoch 180/100, Loss: 132.2585, Validation Accuracy: 0.5952\n",
            "Epoch 181/100, Loss: 52.1831, Validation Accuracy: 0.5972\n",
            "Epoch 182/100, Loss: 155.1729, Validation Accuracy: 0.5224\n",
            "Epoch 183/100, Loss: 76.0566, Validation Accuracy: 0.6122\n",
            "Epoch 184/100, Loss: 119.7929, Validation Accuracy: 0.6002\n",
            "Epoch 185/100, Loss: 164.3241, Validation Accuracy: 0.6849\n",
            "Epoch 186/100, Loss: 134.3029, Validation Accuracy: 0.4556\n",
            "Epoch 187/100, Loss: 12.8297, Validation Accuracy: 0.6550\n",
            "Epoch 188/100, Loss: 46.8997, Validation Accuracy: 0.5962\n",
            "Epoch 189/100, Loss: 67.0120, Validation Accuracy: 0.6740\n",
            "Epoch 190/100, Loss: 104.3487, Validation Accuracy: 0.5763\n",
            "Epoch 191/100, Loss: 115.8618, Validation Accuracy: 0.6740\n",
            "Epoch 192/100, Loss: 69.6789, Validation Accuracy: 0.5842\n",
            "Epoch 193/100, Loss: 99.4339, Validation Accuracy: 0.6171\n",
            "Epoch 194/100, Loss: 110.1480, Validation Accuracy: 0.6022\n",
            "Epoch 195/100, Loss: 98.5193, Validation Accuracy: 0.5823\n",
            "Epoch 196/100, Loss: 196.4767, Validation Accuracy: 0.6640\n",
            "Epoch 197/100, Loss: 124.8057, Validation Accuracy: 0.6221\n",
            "Epoch 198/100, Loss: 66.3962, Validation Accuracy: 0.6630\n",
            "Epoch 199/100, Loss: 55.6210, Validation Accuracy: 0.6221\n",
            "Epoch 200/100, Loss: 50.1954, Validation Accuracy: 0.6221\n",
            "Reward for Child Model: 0.2927654939811637\n",
            "Child_24:  {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, [2, 0, 1, 2, 0, 2, 1, 2, 2, 0, 1, 3, 1, 0, 0], 0.2927654939811637\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 48, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 64, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(200, 64, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=215072, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 22, 26]           1,536\n",
            "       BatchNorm2d-2           [-1, 24, 22, 26]              48\n",
            "            Conv2d-3           [-1, 48, 20, 22]          17,328\n",
            "       BatchNorm2d-4           [-1, 48, 20, 22]              96\n",
            "              ReLU-5           [-1, 48, 20, 22]               0\n",
            "            Conv2d-6           [-1, 64, 16, 16]         107,584\n",
            "       BatchNorm2d-7           [-1, 64, 16, 16]             128\n",
            "              ReLU-8           [-1, 64, 16, 16]               0\n",
            "            Conv2d-9           [-1, 64, 12, 16]          20,544\n",
            "      BatchNorm2d-10           [-1, 64, 12, 16]             128\n",
            "             ReLU-11           [-1, 64, 12, 16]               0\n",
            "           Conv2d-12           [-1, 64, 18, 20]         448,064\n",
            "      BatchNorm2d-13           [-1, 64, 18, 20]             128\n",
            "             ReLU-14           [-1, 64, 18, 20]               0\n",
            "           Linear-15                    [-1, 7]       1,505,511\n",
            "================================================================\n",
            "Total params: 2,101,095\n",
            "Trainable params: 2,101,095\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.88\n",
            "Params size (MB): 8.02\n",
            "Estimated Total Size (MB): 9.90\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 28.4169, Validation Accuracy: 0.1097\n",
            "Epoch 2/100, Loss: 23.1634, Validation Accuracy: 0.5254\n",
            "Epoch 3/100, Loss: 45.8904, Validation Accuracy: 0.5833\n",
            "Epoch 4/100, Loss: 17.5355, Validation Accuracy: 0.6680\n",
            "Epoch 5/100, Loss: 3.4127, Validation Accuracy: 0.6720\n",
            "Epoch 6/100, Loss: 45.3789, Validation Accuracy: 0.6022\n",
            "Epoch 7/100, Loss: 17.2310, Validation Accuracy: 0.6311\n",
            "Epoch 8/100, Loss: 8.8629, Validation Accuracy: 0.5234\n",
            "Epoch 9/100, Loss: 20.9726, Validation Accuracy: 0.4816\n",
            "Epoch 10/100, Loss: 5.6996, Validation Accuracy: 0.5254\n",
            "Epoch 11/100, Loss: 134.2972, Validation Accuracy: 0.5842\n",
            "Epoch 12/100, Loss: 97.7468, Validation Accuracy: 0.5553\n",
            "Epoch 13/100, Loss: 21.3684, Validation Accuracy: 0.5892\n",
            "Epoch 14/100, Loss: 5.1423, Validation Accuracy: 0.5783\n",
            "Epoch 15/100, Loss: 6.0460, Validation Accuracy: 0.6211\n",
            "Epoch 16/100, Loss: 24.3811, Validation Accuracy: 0.4776\n",
            "Epoch 17/100, Loss: 49.3999, Validation Accuracy: 0.5424\n",
            "Epoch 18/100, Loss: 22.3068, Validation Accuracy: 0.3928\n",
            "Epoch 19/100, Loss: 23.2150, Validation Accuracy: 0.6152\n",
            "Epoch 20/100, Loss: 2.5475, Validation Accuracy: 0.6481\n",
            "Epoch 21/100, Loss: 2.1802, Validation Accuracy: 0.6211\n",
            "Epoch 22/100, Loss: 2.2376, Validation Accuracy: 0.6261\n",
            "Epoch 23/100, Loss: 3.9291, Validation Accuracy: 0.5723\n",
            "Epoch 24/100, Loss: 2.8307, Validation Accuracy: 0.4676\n",
            "Epoch 25/100, Loss: 3.7284, Validation Accuracy: 0.6500\n",
            "Epoch 26/100, Loss: 2.4446, Validation Accuracy: 0.5902\n",
            "Epoch 27/100, Loss: 1.7354, Validation Accuracy: 0.5773\n",
            "Epoch 28/100, Loss: 1.3977, Validation Accuracy: 0.6311\n",
            "Epoch 29/100, Loss: 1.5639, Validation Accuracy: 0.6231\n",
            "Epoch 30/100, Loss: 8.3803, Validation Accuracy: 0.6311\n",
            "Epoch 31/100, Loss: 12.2009, Validation Accuracy: 0.6520\n",
            "Epoch 32/100, Loss: 6.5706, Validation Accuracy: 0.4855\n",
            "Epoch 33/100, Loss: 4.4573, Validation Accuracy: 0.5962\n",
            "Epoch 34/100, Loss: 1.4344, Validation Accuracy: 0.6211\n",
            "Epoch 35/100, Loss: 2.6842, Validation Accuracy: 0.6431\n",
            "Epoch 36/100, Loss: 3.3582, Validation Accuracy: 0.6122\n",
            "Epoch 37/100, Loss: 1.2120, Validation Accuracy: 0.6371\n",
            "Epoch 38/100, Loss: 239.5876, Validation Accuracy: 0.6301\n",
            "Epoch 39/100, Loss: 207.4029, Validation Accuracy: 0.3320\n",
            "Epoch 40/100, Loss: 212.0376, Validation Accuracy: 0.5743\n",
            "Epoch 41/100, Loss: 70.0632, Validation Accuracy: 0.5703\n",
            "Epoch 42/100, Loss: 41.0855, Validation Accuracy: 0.5523\n",
            "Epoch 43/100, Loss: 37.6475, Validation Accuracy: 0.6431\n",
            "Epoch 44/100, Loss: 11.4023, Validation Accuracy: 0.5882\n",
            "Epoch 45/100, Loss: 4.9685, Validation Accuracy: 0.5842\n",
            "Epoch 46/100, Loss: 10.5240, Validation Accuracy: 0.4187\n",
            "Epoch 47/100, Loss: 4.2890, Validation Accuracy: 0.4327\n",
            "Epoch 48/100, Loss: 278.9485, Validation Accuracy: 0.4427\n",
            "Epoch 49/100, Loss: 78.8255, Validation Accuracy: 0.5733\n",
            "Epoch 50/100, Loss: 31.9004, Validation Accuracy: 0.5892\n",
            "Epoch 51/100, Loss: 5.3743, Validation Accuracy: 0.6530\n",
            "Epoch 52/100, Loss: 4.2414, Validation Accuracy: 0.6042\n",
            "Epoch 53/100, Loss: 52.1199, Validation Accuracy: 0.6550\n",
            "Epoch 54/100, Loss: 9.0294, Validation Accuracy: 0.5733\n",
            "Epoch 55/100, Loss: 11.1707, Validation Accuracy: 0.6391\n",
            "Epoch 56/100, Loss: 1.8769, Validation Accuracy: 0.6361\n",
            "Epoch 57/100, Loss: 4.8545, Validation Accuracy: 0.6570\n",
            "Epoch 58/100, Loss: 2.5825, Validation Accuracy: 0.6849\n",
            "Epoch 59/100, Loss: 8.2848, Validation Accuracy: 0.1107\n",
            "Epoch 60/100, Loss: 5.0640, Validation Accuracy: 0.5523\n",
            "Epoch 61/100, Loss: 2.5513, Validation Accuracy: 0.6032\n",
            "Epoch 62/100, Loss: 51.9904, Validation Accuracy: 0.6540\n",
            "Epoch 63/100, Loss: 63.5920, Validation Accuracy: 0.6191\n",
            "Epoch 64/100, Loss: 40.2838, Validation Accuracy: 0.4746\n",
            "Epoch 65/100, Loss: 5.0089, Validation Accuracy: 0.5823\n",
            "Epoch 66/100, Loss: 35.1637, Validation Accuracy: 0.3151\n",
            "Epoch 67/100, Loss: 20.1973, Validation Accuracy: 0.5912\n",
            "Epoch 68/100, Loss: 8.7762, Validation Accuracy: 0.6271\n",
            "Epoch 69/100, Loss: 3.7232, Validation Accuracy: 0.6002\n",
            "Epoch 70/100, Loss: 3.7022, Validation Accuracy: 0.6241\n",
            "Epoch 71/100, Loss: 7.3022, Validation Accuracy: 0.4905\n",
            "Epoch 72/100, Loss: 2.9454, Validation Accuracy: 0.6760\n",
            "Epoch 73/100, Loss: 4.6740, Validation Accuracy: 0.5374\n",
            "Epoch 74/100, Loss: 6.2759, Validation Accuracy: 0.5852\n",
            "Epoch 75/100, Loss: 90.7929, Validation Accuracy: 0.4516\n",
            "Epoch 76/100, Loss: 9.6581, Validation Accuracy: 0.6072\n",
            "Epoch 77/100, Loss: 11.6999, Validation Accuracy: 0.6570\n",
            "Epoch 78/100, Loss: 3.0389, Validation Accuracy: 0.6630\n",
            "Epoch 79/100, Loss: 4.7701, Validation Accuracy: 0.6710\n",
            "Epoch 80/100, Loss: 17.6069, Validation Accuracy: 0.5364\n",
            "Epoch 81/100, Loss: 13.5860, Validation Accuracy: 0.5424\n",
            "Epoch 82/100, Loss: 8.4844, Validation Accuracy: 0.6271\n",
            "Epoch 83/100, Loss: 9.7319, Validation Accuracy: 0.5942\n",
            "Epoch 84/100, Loss: 6.5294, Validation Accuracy: 0.6650\n",
            "Epoch 85/100, Loss: 4.9727, Validation Accuracy: 0.6640\n",
            "Epoch 86/100, Loss: 2.4746, Validation Accuracy: 0.6560\n",
            "Epoch 87/100, Loss: 2323.8687, Validation Accuracy: 0.5773\n",
            "Epoch 88/100, Loss: 181.6586, Validation Accuracy: 0.5105\n",
            "Epoch 89/100, Loss: 39.5666, Validation Accuracy: 0.5813\n",
            "Epoch 90/100, Loss: 9.1661, Validation Accuracy: 0.6371\n",
            "Epoch 91/100, Loss: 9.3152, Validation Accuracy: 0.5942\n",
            "Epoch 92/100, Loss: 7.4913, Validation Accuracy: 0.5045\n",
            "Epoch 93/100, Loss: 13.7817, Validation Accuracy: 0.6680\n",
            "Epoch 94/100, Loss: 4.2696, Validation Accuracy: 0.6441\n",
            "Epoch 95/100, Loss: 19.2502, Validation Accuracy: 0.4736\n",
            "Epoch 96/100, Loss: 8.0930, Validation Accuracy: 0.6062\n",
            "Epoch 97/100, Loss: 4.7925, Validation Accuracy: 0.5713\n",
            "Epoch 98/100, Loss: 20.3043, Validation Accuracy: 0.5813\n",
            "Epoch 99/100, Loss: 0.9539, Validation Accuracy: 0.6231\n",
            "Epoch 100/100, Loss: 41.0245, Validation Accuracy: 0.6421\n",
            "Epoch 101/100, Loss: 60.5293, Validation Accuracy: 0.4536\n",
            "Epoch 102/100, Loss: 90.3592, Validation Accuracy: 0.5065\n",
            "Epoch 103/100, Loss: 3.5403, Validation Accuracy: 0.5613\n",
            "Epoch 104/100, Loss: 8.8941, Validation Accuracy: 0.6461\n",
            "Epoch 105/100, Loss: 90.1072, Validation Accuracy: 0.6491\n",
            "Epoch 106/100, Loss: 146.3629, Validation Accuracy: 0.6162\n",
            "Epoch 107/100, Loss: 17.9768, Validation Accuracy: 0.6341\n",
            "Epoch 108/100, Loss: 2.4513, Validation Accuracy: 0.5862\n",
            "Epoch 109/100, Loss: 1.7358, Validation Accuracy: 0.6092\n",
            "Epoch 110/100, Loss: 9.2938, Validation Accuracy: 0.4845\n",
            "Epoch 111/100, Loss: 8.4192, Validation Accuracy: 0.6451\n",
            "Epoch 112/100, Loss: 3.6421, Validation Accuracy: 0.5823\n",
            "Epoch 113/100, Loss: 12.8382, Validation Accuracy: 0.6640\n",
            "Epoch 114/100, Loss: 3.4646, Validation Accuracy: 0.6102\n",
            "Epoch 115/100, Loss: 178.6876, Validation Accuracy: 0.5803\n",
            "Epoch 116/100, Loss: 13.9271, Validation Accuracy: 0.5703\n",
            "Epoch 117/100, Loss: 340.4325, Validation Accuracy: 0.6471\n",
            "Epoch 118/100, Loss: 43.5870, Validation Accuracy: 0.5783\n",
            "Epoch 119/100, Loss: 14.0158, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 6.4464, Validation Accuracy: 0.5105\n",
            "Epoch 121/100, Loss: 1.5496, Validation Accuracy: 0.6371\n",
            "Epoch 122/100, Loss: 32.8778, Validation Accuracy: 0.6610\n",
            "Epoch 123/100, Loss: 4.4754, Validation Accuracy: 0.5793\n",
            "Epoch 124/100, Loss: 3.6166, Validation Accuracy: 0.5753\n",
            "Epoch 125/100, Loss: 19.8584, Validation Accuracy: 0.4985\n",
            "Epoch 126/100, Loss: 6.3945, Validation Accuracy: 0.5673\n",
            "Epoch 127/100, Loss: 1545.0338, Validation Accuracy: 0.6072\n",
            "Epoch 128/100, Loss: 235.2850, Validation Accuracy: 0.4536\n",
            "Epoch 129/100, Loss: 137.1238, Validation Accuracy: 0.6760\n",
            "Epoch 130/100, Loss: 55.4790, Validation Accuracy: 0.5872\n",
            "Epoch 131/100, Loss: 78.6609, Validation Accuracy: 0.6351\n",
            "Epoch 132/100, Loss: 80.5134, Validation Accuracy: 0.6341\n",
            "Epoch 133/100, Loss: 18.4201, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 32.3960, Validation Accuracy: 0.5892\n",
            "Epoch 135/100, Loss: 18.3639, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 4.5567, Validation Accuracy: 0.6830\n",
            "Epoch 137/100, Loss: 4.3358, Validation Accuracy: 0.5633\n",
            "Epoch 138/100, Loss: 10.4408, Validation Accuracy: 0.6560\n",
            "Epoch 139/100, Loss: 5.5417, Validation Accuracy: 0.5773\n",
            "Epoch 140/100, Loss: 1.6781, Validation Accuracy: 0.5683\n",
            "Epoch 141/100, Loss: 5.4458, Validation Accuracy: 0.6540\n",
            "Epoch 142/100, Loss: 22.7192, Validation Accuracy: 0.5314\n",
            "Epoch 143/100, Loss: 4.5165, Validation Accuracy: 0.6510\n",
            "Epoch 144/100, Loss: 11.7062, Validation Accuracy: 0.6072\n",
            "Epoch 145/100, Loss: 436.2112, Validation Accuracy: 0.1216\n",
            "Epoch 146/100, Loss: 5.2591, Validation Accuracy: 0.6251\n",
            "Epoch 147/100, Loss: 10.6802, Validation Accuracy: 0.6351\n",
            "Epoch 148/100, Loss: 1.9729, Validation Accuracy: 0.5932\n",
            "Epoch 149/100, Loss: 3.9457, Validation Accuracy: 0.6072\n",
            "Epoch 150/100, Loss: 2.9342, Validation Accuracy: 0.5583\n",
            "Epoch 151/100, Loss: 3.9264, Validation Accuracy: 0.6879\n",
            "Epoch 152/100, Loss: 3.0861, Validation Accuracy: 0.6660\n",
            "Epoch 153/100, Loss: 1071.4058, Validation Accuracy: 0.5823\n",
            "Epoch 154/100, Loss: 4.1431, Validation Accuracy: 0.5603\n",
            "Epoch 155/100, Loss: 10.4362, Validation Accuracy: 0.6770\n",
            "Epoch 156/100, Loss: 4.2153, Validation Accuracy: 0.5593\n",
            "Epoch 157/100, Loss: 6.2431, Validation Accuracy: 0.6341\n",
            "Epoch 158/100, Loss: 9.5773, Validation Accuracy: 0.6002\n",
            "Epoch 159/100, Loss: 6.7799, Validation Accuracy: 0.5304\n",
            "Epoch 160/100, Loss: 1.7010, Validation Accuracy: 0.6750\n",
            "Epoch 161/100, Loss: 1.6816, Validation Accuracy: 0.6251\n",
            "Epoch 162/100, Loss: 4.4605, Validation Accuracy: 0.4148\n",
            "Epoch 163/100, Loss: 6.6984, Validation Accuracy: 0.6341\n",
            "Epoch 164/100, Loss: 3.5525, Validation Accuracy: 0.5753\n",
            "Epoch 165/100, Loss: 7.5844, Validation Accuracy: 0.4905\n",
            "Epoch 166/100, Loss: 127.6836, Validation Accuracy: 0.4636\n",
            "Epoch 167/100, Loss: 16.7071, Validation Accuracy: 0.6251\n",
            "Epoch 168/100, Loss: 79.0044, Validation Accuracy: 0.5912\n",
            "Epoch 169/100, Loss: 7.5610, Validation Accuracy: 0.2981\n",
            "Epoch 170/100, Loss: 609.9760, Validation Accuracy: 0.6042\n",
            "Epoch 171/100, Loss: 105.7337, Validation Accuracy: 0.5543\n",
            "Epoch 172/100, Loss: 11.1343, Validation Accuracy: 0.6022\n",
            "Epoch 173/100, Loss: 6.5380, Validation Accuracy: 0.6540\n",
            "Epoch 174/100, Loss: 9.5102, Validation Accuracy: 0.6321\n",
            "Epoch 175/100, Loss: 5.3696, Validation Accuracy: 0.6211\n",
            "Epoch 176/100, Loss: 9.9924, Validation Accuracy: 0.6471\n",
            "Epoch 177/100, Loss: 838.1082, Validation Accuracy: 0.5693\n",
            "Epoch 178/100, Loss: 48.9928, Validation Accuracy: 0.5902\n",
            "Epoch 179/100, Loss: 3.4222, Validation Accuracy: 0.5842\n",
            "Epoch 180/100, Loss: 5.0825, Validation Accuracy: 0.6281\n",
            "Epoch 181/100, Loss: 10.0622, Validation Accuracy: 0.5932\n",
            "Epoch 182/100, Loss: 3.0512, Validation Accuracy: 0.5005\n",
            "Epoch 183/100, Loss: 4.2229, Validation Accuracy: 0.5892\n",
            "Epoch 184/100, Loss: 312.7693, Validation Accuracy: 0.4277\n",
            "Epoch 185/100, Loss: 4.8691, Validation Accuracy: 0.5494\n",
            "Epoch 186/100, Loss: 8.3499, Validation Accuracy: 0.5643\n",
            "Epoch 187/100, Loss: 4.7632, Validation Accuracy: 0.5912\n",
            "Epoch 188/100, Loss: 3.8222, Validation Accuracy: 0.6660\n",
            "Epoch 189/100, Loss: 1.9708, Validation Accuracy: 0.6142\n",
            "Epoch 190/100, Loss: 22.2741, Validation Accuracy: 0.6560\n",
            "Epoch 191/100, Loss: 6.5999, Validation Accuracy: 0.5474\n",
            "Epoch 192/100, Loss: 6.4044, Validation Accuracy: 0.6241\n",
            "Epoch 193/100, Loss: 4.1629, Validation Accuracy: 0.5204\n",
            "Epoch 194/100, Loss: 1.5011, Validation Accuracy: 0.6301\n",
            "Epoch 195/100, Loss: 10.2641, Validation Accuracy: 0.6062\n",
            "Epoch 196/100, Loss: 6.6338, Validation Accuracy: 0.4606\n",
            "Epoch 197/100, Loss: 57.8072, Validation Accuracy: 0.6720\n",
            "Epoch 198/100, Loss: 7.8779, Validation Accuracy: 0.6411\n",
            "Epoch 199/100, Loss: 5.1302, Validation Accuracy: 0.6550\n",
            "Epoch 200/100, Loss: 1.9103, Validation Accuracy: 0.5603\n",
            "Reward for Child Model: 0.3034428373146045\n",
            "Child_25:  {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, [3, 1, 0, 1, 2, 2, 2, 3, 3, 2, 0, 3, 2, 3, 3], 0.3034428373146045\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(84, 64, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(184, 24, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(144, 48, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=129024, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 28, 24]             576\n",
            "       BatchNorm2d-2           [-1, 36, 28, 24]              72\n",
            "            Conv2d-3           [-1, 48, 28, 20]           8,688\n",
            "       BatchNorm2d-4           [-1, 48, 28, 20]              96\n",
            "              ReLU-5           [-1, 48, 28, 20]               0\n",
            "            Conv2d-6           [-1, 64, 24, 18]         188,224\n",
            "       BatchNorm2d-7           [-1, 64, 24, 18]             128\n",
            "              ReLU-8           [-1, 64, 24, 18]               0\n",
            "            Conv2d-9           [-1, 24, 24, 18]         154,584\n",
            "      BatchNorm2d-10           [-1, 24, 24, 18]              48\n",
            "             ReLU-11           [-1, 24, 24, 18]               0\n",
            "           Conv2d-12           [-1, 48, 22, 24]          48,432\n",
            "      BatchNorm2d-13           [-1, 48, 22, 24]              96\n",
            "             ReLU-14           [-1, 48, 22, 24]               0\n",
            "           Linear-15                    [-1, 7]         903,175\n",
            "================================================================\n",
            "Total params: 1,304,119\n",
            "Trainable params: 1,304,119\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.43\n",
            "Params size (MB): 4.97\n",
            "Estimated Total Size (MB): 7.42\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 16.1415, Validation Accuracy: 0.6241\n",
            "Epoch 2/100, Loss: 13.8842, Validation Accuracy: 0.4018\n",
            "Epoch 3/100, Loss: 46.2661, Validation Accuracy: 0.4786\n",
            "Epoch 4/100, Loss: 32.1824, Validation Accuracy: 0.5434\n",
            "Epoch 5/100, Loss: 53.3186, Validation Accuracy: 0.5922\n",
            "Epoch 6/100, Loss: 48.8152, Validation Accuracy: 0.6072\n",
            "Epoch 7/100, Loss: 18.9899, Validation Accuracy: 0.2223\n",
            "Epoch 8/100, Loss: 46.7471, Validation Accuracy: 0.5254\n",
            "Epoch 9/100, Loss: 71.6649, Validation Accuracy: 0.4566\n",
            "Epoch 10/100, Loss: 49.6949, Validation Accuracy: 0.4905\n",
            "Epoch 11/100, Loss: 171.7033, Validation Accuracy: 0.6580\n",
            "Epoch 12/100, Loss: 23.0230, Validation Accuracy: 0.3699\n",
            "Epoch 13/100, Loss: 33.5832, Validation Accuracy: 0.3240\n",
            "Epoch 14/100, Loss: 33.3300, Validation Accuracy: 0.6122\n",
            "Epoch 15/100, Loss: 39.4408, Validation Accuracy: 0.6401\n",
            "Epoch 16/100, Loss: 76.4765, Validation Accuracy: 0.4875\n",
            "Epoch 17/100, Loss: 51.6145, Validation Accuracy: 0.6411\n",
            "Epoch 18/100, Loss: 54.5782, Validation Accuracy: 0.6171\n",
            "Epoch 19/100, Loss: 146.2531, Validation Accuracy: 0.6072\n",
            "Epoch 20/100, Loss: 43.9909, Validation Accuracy: 0.6640\n",
            "Epoch 21/100, Loss: 41.8681, Validation Accuracy: 0.6411\n",
            "Epoch 22/100, Loss: 18.8336, Validation Accuracy: 0.5264\n",
            "Epoch 23/100, Loss: 32.5940, Validation Accuracy: 0.4207\n",
            "Epoch 24/100, Loss: 15.4338, Validation Accuracy: 0.6371\n",
            "Epoch 25/100, Loss: 34.9586, Validation Accuracy: 0.6032\n",
            "Epoch 26/100, Loss: 216.9142, Validation Accuracy: 0.6112\n",
            "Epoch 27/100, Loss: 103.4881, Validation Accuracy: 0.5783\n",
            "Epoch 28/100, Loss: 55.0817, Validation Accuracy: 0.4467\n",
            "Epoch 29/100, Loss: 122.4241, Validation Accuracy: 0.5434\n",
            "Epoch 30/100, Loss: 68.9532, Validation Accuracy: 0.5364\n",
            "Epoch 31/100, Loss: 28.3599, Validation Accuracy: 0.4686\n",
            "Epoch 32/100, Loss: 44.2528, Validation Accuracy: 0.6590\n",
            "Epoch 33/100, Loss: 49.1764, Validation Accuracy: 0.4287\n",
            "Epoch 34/100, Loss: 196.5830, Validation Accuracy: 0.5155\n",
            "Epoch 35/100, Loss: 125.2747, Validation Accuracy: 0.6321\n",
            "Epoch 36/100, Loss: 21.6550, Validation Accuracy: 0.4865\n",
            "Epoch 37/100, Loss: 24.7007, Validation Accuracy: 0.6311\n",
            "Epoch 38/100, Loss: 25.6752, Validation Accuracy: 0.4277\n",
            "Epoch 39/100, Loss: 53.0799, Validation Accuracy: 0.5613\n",
            "Epoch 40/100, Loss: 20.4006, Validation Accuracy: 0.6710\n",
            "Epoch 41/100, Loss: 49.8235, Validation Accuracy: 0.5464\n",
            "Epoch 42/100, Loss: 75.3874, Validation Accuracy: 0.6650\n",
            "Epoch 43/100, Loss: 89.2454, Validation Accuracy: 0.6640\n",
            "Epoch 44/100, Loss: 83.4049, Validation Accuracy: 0.4925\n",
            "Epoch 45/100, Loss: 11.1936, Validation Accuracy: 0.4756\n",
            "Epoch 46/100, Loss: 53.6973, Validation Accuracy: 0.6122\n",
            "Epoch 47/100, Loss: 80.9440, Validation Accuracy: 0.6171\n",
            "Epoch 48/100, Loss: 31.2602, Validation Accuracy: 0.6371\n",
            "Epoch 49/100, Loss: 17.7978, Validation Accuracy: 0.6889\n",
            "Epoch 50/100, Loss: 63.9304, Validation Accuracy: 0.6421\n",
            "Epoch 51/100, Loss: 30.7710, Validation Accuracy: 0.6072\n",
            "Epoch 52/100, Loss: 43.6152, Validation Accuracy: 0.4287\n",
            "Epoch 53/100, Loss: 52.8971, Validation Accuracy: 0.5693\n",
            "Epoch 54/100, Loss: 40.6297, Validation Accuracy: 0.5713\n",
            "Epoch 55/100, Loss: 48.7708, Validation Accuracy: 0.5693\n",
            "Epoch 56/100, Loss: 73.6024, Validation Accuracy: 0.4417\n",
            "Epoch 57/100, Loss: 74.2191, Validation Accuracy: 0.5484\n",
            "Epoch 58/100, Loss: 102.0877, Validation Accuracy: 0.6800\n",
            "Epoch 59/100, Loss: 109.5116, Validation Accuracy: 0.6820\n",
            "Epoch 60/100, Loss: 123.3871, Validation Accuracy: 0.3679\n",
            "Epoch 61/100, Loss: 67.3810, Validation Accuracy: 0.5972\n",
            "Epoch 62/100, Loss: 65.5863, Validation Accuracy: 0.5184\n",
            "Epoch 63/100, Loss: 30.6235, Validation Accuracy: 0.5145\n",
            "Epoch 64/100, Loss: 48.7276, Validation Accuracy: 0.6780\n",
            "Epoch 65/100, Loss: 47.3493, Validation Accuracy: 0.4536\n",
            "Epoch 66/100, Loss: 43.1201, Validation Accuracy: 0.6520\n",
            "Epoch 67/100, Loss: 71.2503, Validation Accuracy: 0.6780\n",
            "Epoch 68/100, Loss: 40.0210, Validation Accuracy: 0.6092\n",
            "Epoch 69/100, Loss: 83.1123, Validation Accuracy: 0.6680\n",
            "Epoch 70/100, Loss: 168.6091, Validation Accuracy: 0.5733\n",
            "Epoch 71/100, Loss: 43.8096, Validation Accuracy: 0.5713\n",
            "Epoch 72/100, Loss: 91.6750, Validation Accuracy: 0.6520\n",
            "Epoch 73/100, Loss: 41.5687, Validation Accuracy: 0.5583\n",
            "Epoch 74/100, Loss: 48.5590, Validation Accuracy: 0.6650\n",
            "Epoch 75/100, Loss: 53.4396, Validation Accuracy: 0.4975\n",
            "Epoch 76/100, Loss: 171.6697, Validation Accuracy: 0.6142\n",
            "Epoch 77/100, Loss: 60.3815, Validation Accuracy: 0.6201\n",
            "Epoch 78/100, Loss: 17.1522, Validation Accuracy: 0.6321\n",
            "Epoch 79/100, Loss: 50.3420, Validation Accuracy: 0.6381\n",
            "Epoch 80/100, Loss: 57.0422, Validation Accuracy: 0.4945\n",
            "Epoch 81/100, Loss: 45.5293, Validation Accuracy: 0.6610\n",
            "Epoch 82/100, Loss: 73.9058, Validation Accuracy: 0.5912\n",
            "Epoch 83/100, Loss: 27.6746, Validation Accuracy: 0.3290\n",
            "Epoch 84/100, Loss: 79.2872, Validation Accuracy: 0.5912\n",
            "Epoch 85/100, Loss: 119.7194, Validation Accuracy: 0.5852\n",
            "Epoch 86/100, Loss: 141.0139, Validation Accuracy: 0.5773\n",
            "Epoch 87/100, Loss: 59.0135, Validation Accuracy: 0.6321\n",
            "Epoch 88/100, Loss: 105.0300, Validation Accuracy: 0.6142\n",
            "Epoch 89/100, Loss: 66.2349, Validation Accuracy: 0.6600\n",
            "Epoch 90/100, Loss: 100.6609, Validation Accuracy: 0.5703\n",
            "Epoch 91/100, Loss: 38.6206, Validation Accuracy: 0.5982\n",
            "Epoch 92/100, Loss: 39.6837, Validation Accuracy: 0.6560\n",
            "Epoch 93/100, Loss: 45.9308, Validation Accuracy: 0.6112\n",
            "Epoch 94/100, Loss: 34.0913, Validation Accuracy: 0.5673\n",
            "Epoch 95/100, Loss: 92.9613, Validation Accuracy: 0.5703\n",
            "Epoch 96/100, Loss: 113.4272, Validation Accuracy: 0.6102\n",
            "Epoch 97/100, Loss: 120.3165, Validation Accuracy: 0.6281\n",
            "Epoch 98/100, Loss: 56.5588, Validation Accuracy: 0.6710\n",
            "Epoch 99/100, Loss: 63.2894, Validation Accuracy: 0.6361\n",
            "Epoch 100/100, Loss: 43.7736, Validation Accuracy: 0.6271\n",
            "Epoch 101/100, Loss: 57.3389, Validation Accuracy: 0.6520\n",
            "Epoch 102/100, Loss: 68.3006, Validation Accuracy: 0.6381\n",
            "Epoch 103/100, Loss: 60.1011, Validation Accuracy: 0.6481\n",
            "Epoch 104/100, Loss: 54.6803, Validation Accuracy: 0.6401\n",
            "Epoch 105/100, Loss: 54.4668, Validation Accuracy: 0.6301\n",
            "Epoch 106/100, Loss: 142.3970, Validation Accuracy: 0.6550\n",
            "Epoch 107/100, Loss: 82.4229, Validation Accuracy: 0.5872\n",
            "Epoch 108/100, Loss: 52.8592, Validation Accuracy: 0.6112\n",
            "Epoch 109/100, Loss: 130.4183, Validation Accuracy: 0.5952\n",
            "Epoch 110/100, Loss: 113.8017, Validation Accuracy: 0.6311\n",
            "Epoch 111/100, Loss: 38.5016, Validation Accuracy: 0.6052\n",
            "Epoch 112/100, Loss: 40.3685, Validation Accuracy: 0.3091\n",
            "Epoch 113/100, Loss: 32.2473, Validation Accuracy: 0.6421\n",
            "Epoch 114/100, Loss: 43.4887, Validation Accuracy: 0.5733\n",
            "Epoch 115/100, Loss: 76.6702, Validation Accuracy: 0.6052\n",
            "Epoch 116/100, Loss: 158.2072, Validation Accuracy: 0.6879\n",
            "Epoch 117/100, Loss: 88.2017, Validation Accuracy: 0.5374\n",
            "Epoch 118/100, Loss: 20.8859, Validation Accuracy: 0.5932\n",
            "Epoch 119/100, Loss: 147.9679, Validation Accuracy: 0.5823\n",
            "Epoch 120/100, Loss: 85.8808, Validation Accuracy: 0.5852\n",
            "Epoch 121/100, Loss: 139.3896, Validation Accuracy: 0.5962\n",
            "Epoch 122/100, Loss: 50.3230, Validation Accuracy: 0.6112\n",
            "Epoch 123/100, Loss: 47.8359, Validation Accuracy: 0.5513\n",
            "Epoch 124/100, Loss: 40.5418, Validation Accuracy: 0.5952\n",
            "Epoch 125/100, Loss: 37.9203, Validation Accuracy: 0.5962\n",
            "Epoch 126/100, Loss: 20.7931, Validation Accuracy: 0.6082\n",
            "Epoch 127/100, Loss: 84.3789, Validation Accuracy: 0.6251\n",
            "Epoch 128/100, Loss: 117.9144, Validation Accuracy: 0.5284\n",
            "Epoch 129/100, Loss: 25.2785, Validation Accuracy: 0.5962\n",
            "Epoch 130/100, Loss: 50.0500, Validation Accuracy: 0.6122\n",
            "Epoch 131/100, Loss: 29.6857, Validation Accuracy: 0.5314\n",
            "Epoch 132/100, Loss: 20.9401, Validation Accuracy: 0.6092\n",
            "Epoch 133/100, Loss: 41.8375, Validation Accuracy: 0.5872\n",
            "Epoch 134/100, Loss: 52.5725, Validation Accuracy: 0.6122\n",
            "Epoch 135/100, Loss: 61.9715, Validation Accuracy: 0.6241\n",
            "Epoch 136/100, Loss: 73.6345, Validation Accuracy: 0.6770\n",
            "Epoch 137/100, Loss: 60.2626, Validation Accuracy: 0.5912\n",
            "Epoch 138/100, Loss: 66.1460, Validation Accuracy: 0.5095\n",
            "Epoch 139/100, Loss: 69.7335, Validation Accuracy: 0.6610\n",
            "Epoch 140/100, Loss: 113.2126, Validation Accuracy: 0.4636\n",
            "Epoch 141/100, Loss: 222.1243, Validation Accuracy: 0.3480\n",
            "Epoch 142/100, Loss: 49.9719, Validation Accuracy: 0.4696\n",
            "Epoch 143/100, Loss: 60.2546, Validation Accuracy: 0.6032\n",
            "Epoch 144/100, Loss: 44.7258, Validation Accuracy: 0.5763\n",
            "Epoch 145/100, Loss: 43.3451, Validation Accuracy: 0.5693\n",
            "Epoch 146/100, Loss: 260.9786, Validation Accuracy: 0.6152\n",
            "Epoch 147/100, Loss: 65.4066, Validation Accuracy: 0.4566\n",
            "Epoch 148/100, Loss: 63.2103, Validation Accuracy: 0.5852\n",
            "Epoch 149/100, Loss: 51.8804, Validation Accuracy: 0.5663\n",
            "Epoch 150/100, Loss: 65.1586, Validation Accuracy: 0.4895\n",
            "Epoch 151/100, Loss: 41.0189, Validation Accuracy: 0.6491\n",
            "Epoch 152/100, Loss: 46.7963, Validation Accuracy: 0.5294\n",
            "Epoch 153/100, Loss: 57.3880, Validation Accuracy: 0.3848\n",
            "Epoch 154/100, Loss: 17.8019, Validation Accuracy: 0.6610\n",
            "Epoch 155/100, Loss: 26.2964, Validation Accuracy: 0.5454\n",
            "Epoch 156/100, Loss: 65.2407, Validation Accuracy: 0.6102\n",
            "Epoch 157/100, Loss: 110.3445, Validation Accuracy: 0.6012\n",
            "Epoch 158/100, Loss: 47.5471, Validation Accuracy: 0.6281\n",
            "Epoch 159/100, Loss: 66.3317, Validation Accuracy: 0.5902\n",
            "Epoch 160/100, Loss: 294.7441, Validation Accuracy: 0.5673\n",
            "Epoch 161/100, Loss: 131.0744, Validation Accuracy: 0.6770\n",
            "Epoch 162/100, Loss: 91.3928, Validation Accuracy: 0.6411\n",
            "Epoch 163/100, Loss: 36.4225, Validation Accuracy: 0.6431\n",
            "Epoch 164/100, Loss: 106.5489, Validation Accuracy: 0.6550\n",
            "Epoch 165/100, Loss: 89.4208, Validation Accuracy: 0.6241\n",
            "Epoch 166/100, Loss: 103.4120, Validation Accuracy: 0.6231\n",
            "Epoch 167/100, Loss: 68.5559, Validation Accuracy: 0.5075\n",
            "Epoch 168/100, Loss: 76.3887, Validation Accuracy: 0.3410\n",
            "Epoch 169/100, Loss: 103.1946, Validation Accuracy: 0.5254\n",
            "Epoch 170/100, Loss: 34.3749, Validation Accuracy: 0.5813\n",
            "Epoch 171/100, Loss: 90.3399, Validation Accuracy: 0.6211\n",
            "Epoch 172/100, Loss: 27.7479, Validation Accuracy: 0.5484\n",
            "Epoch 173/100, Loss: 96.6791, Validation Accuracy: 0.6122\n",
            "Epoch 174/100, Loss: 56.7738, Validation Accuracy: 0.5643\n",
            "Epoch 175/100, Loss: 65.2127, Validation Accuracy: 0.5324\n",
            "Epoch 176/100, Loss: 66.2822, Validation Accuracy: 0.6540\n",
            "Epoch 177/100, Loss: 52.2358, Validation Accuracy: 0.6022\n",
            "Epoch 178/100, Loss: 98.5008, Validation Accuracy: 0.6211\n",
            "Epoch 179/100, Loss: 70.6602, Validation Accuracy: 0.6849\n",
            "Epoch 180/100, Loss: 39.0567, Validation Accuracy: 0.6042\n",
            "Epoch 181/100, Loss: 76.1150, Validation Accuracy: 0.4078\n",
            "Epoch 182/100, Loss: 103.2850, Validation Accuracy: 0.5055\n",
            "Epoch 183/100, Loss: 67.0918, Validation Accuracy: 0.6650\n",
            "Epoch 184/100, Loss: 58.8372, Validation Accuracy: 0.6142\n",
            "Epoch 185/100, Loss: 36.2246, Validation Accuracy: 0.6371\n",
            "Epoch 186/100, Loss: 13.0213, Validation Accuracy: 0.6500\n",
            "Epoch 187/100, Loss: 67.2121, Validation Accuracy: 0.6012\n",
            "Epoch 188/100, Loss: 53.5827, Validation Accuracy: 0.6650\n",
            "Epoch 189/100, Loss: 71.8774, Validation Accuracy: 0.5882\n",
            "Epoch 190/100, Loss: 85.7156, Validation Accuracy: 0.6281\n",
            "Epoch 191/100, Loss: 174.4160, Validation Accuracy: 0.6421\n",
            "Epoch 192/100, Loss: 60.7879, Validation Accuracy: 0.5573\n",
            "Epoch 193/100, Loss: 102.7443, Validation Accuracy: 0.6291\n",
            "Epoch 194/100, Loss: 60.3420, Validation Accuracy: 0.6421\n",
            "Epoch 195/100, Loss: 79.9160, Validation Accuracy: 0.6780\n",
            "Epoch 196/100, Loss: 38.9261, Validation Accuracy: 0.6630\n",
            "Epoch 197/100, Loss: 44.0448, Validation Accuracy: 0.3430\n",
            "Epoch 198/100, Loss: 86.2895, Validation Accuracy: 0.6471\n",
            "Epoch 199/100, Loss: 78.8410, Validation Accuracy: 0.6640\n",
            "Epoch 200/100, Loss: 65.1514, Validation Accuracy: 0.6062\n",
            "Reward for Child Model: 0.2927654939811637\n",
            "Child_26:  {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, [0, 2, 1, 0, 2, 2, 2, 3, 3, 2, 3, 0, 3, 0, 2], 0.2927654939811637\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 36, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(100, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(64, 36, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=29040, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 22, 22]           3,552\n",
            "       BatchNorm2d-2           [-1, 24, 22, 22]              48\n",
            "            Conv2d-3           [-1, 36, 18, 20]          12,996\n",
            "       BatchNorm2d-4           [-1, 36, 18, 20]              72\n",
            "              ReLU-5           [-1, 36, 18, 20]               0\n",
            "            Conv2d-6           [-1, 64, 18, 20]           2,368\n",
            "       BatchNorm2d-7           [-1, 64, 18, 20]             128\n",
            "              ReLU-8           [-1, 64, 18, 20]               0\n",
            "            Conv2d-9           [-1, 64, 16, 18]          57,664\n",
            "      BatchNorm2d-10           [-1, 64, 16, 18]             128\n",
            "             ReLU-11           [-1, 64, 16, 18]               0\n",
            "           Conv2d-12           [-1, 36, 12, 16]          34,596\n",
            "      BatchNorm2d-13           [-1, 36, 12, 16]              72\n",
            "             ReLU-14           [-1, 36, 12, 16]               0\n",
            "           Linear-15                    [-1, 7]         203,287\n",
            "================================================================\n",
            "Total params: 314,911\n",
            "Trainable params: 314,911\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.58\n",
            "Params size (MB): 1.20\n",
            "Estimated Total Size (MB): 2.79\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 15.9294, Validation Accuracy: 0.4915\n",
            "Epoch 2/100, Loss: 9.9068, Validation Accuracy: 0.4925\n",
            "Epoch 3/100, Loss: 28.4970, Validation Accuracy: 0.6760\n",
            "Epoch 4/100, Loss: 10.0931, Validation Accuracy: 0.5932\n",
            "Epoch 5/100, Loss: 3.1092, Validation Accuracy: 0.5982\n",
            "Epoch 6/100, Loss: 2.1119, Validation Accuracy: 0.6002\n",
            "Epoch 7/100, Loss: 0.9516, Validation Accuracy: 0.5454\n",
            "Epoch 8/100, Loss: 66.3502, Validation Accuracy: 0.6341\n",
            "Epoch 9/100, Loss: 9.3233, Validation Accuracy: 0.5882\n",
            "Epoch 10/100, Loss: 10.4627, Validation Accuracy: 0.4447\n",
            "Epoch 11/100, Loss: 4.3855, Validation Accuracy: 0.6321\n",
            "Epoch 12/100, Loss: 3.1133, Validation Accuracy: 0.4835\n",
            "Epoch 13/100, Loss: 2.7838, Validation Accuracy: 0.6381\n",
            "Epoch 14/100, Loss: 3.4388, Validation Accuracy: 0.4975\n",
            "Epoch 15/100, Loss: 4.3991, Validation Accuracy: 0.4786\n",
            "Epoch 16/100, Loss: 57.6525, Validation Accuracy: 0.4716\n",
            "Epoch 17/100, Loss: 28.1192, Validation Accuracy: 0.5454\n",
            "Epoch 18/100, Loss: 3.6397, Validation Accuracy: 0.6401\n",
            "Epoch 19/100, Loss: 22.7443, Validation Accuracy: 0.5105\n",
            "Epoch 20/100, Loss: 51.8227, Validation Accuracy: 0.5055\n",
            "Epoch 21/100, Loss: 3.2888, Validation Accuracy: 0.5035\n",
            "Epoch 22/100, Loss: 4.2793, Validation Accuracy: 0.6760\n",
            "Epoch 23/100, Loss: 6.2085, Validation Accuracy: 0.5783\n",
            "Epoch 24/100, Loss: 6.1507, Validation Accuracy: 0.5833\n",
            "Epoch 25/100, Loss: 25.7262, Validation Accuracy: 0.6510\n",
            "Epoch 26/100, Loss: 16.2955, Validation Accuracy: 0.5035\n",
            "Epoch 27/100, Loss: 12.3171, Validation Accuracy: 0.5852\n",
            "Epoch 28/100, Loss: 6.8425, Validation Accuracy: 0.6221\n",
            "Epoch 29/100, Loss: 3.7837, Validation Accuracy: 0.5633\n",
            "Epoch 30/100, Loss: 2.0858, Validation Accuracy: 0.5563\n",
            "Epoch 31/100, Loss: 3.3659, Validation Accuracy: 0.6351\n",
            "Epoch 32/100, Loss: 5.9866, Validation Accuracy: 0.5892\n",
            "Epoch 33/100, Loss: 38.6944, Validation Accuracy: 0.5803\n",
            "Epoch 34/100, Loss: 45.5520, Validation Accuracy: 0.6122\n",
            "Epoch 35/100, Loss: 11.2691, Validation Accuracy: 0.5384\n",
            "Epoch 36/100, Loss: 12.6836, Validation Accuracy: 0.6590\n",
            "Epoch 37/100, Loss: 5.0603, Validation Accuracy: 0.5424\n",
            "Epoch 38/100, Loss: 3.9272, Validation Accuracy: 0.5793\n",
            "Epoch 39/100, Loss: 5.0423, Validation Accuracy: 0.3659\n",
            "Epoch 40/100, Loss: 4.4399, Validation Accuracy: 0.6620\n",
            "Epoch 41/100, Loss: 4.9848, Validation Accuracy: 0.6580\n",
            "Epoch 42/100, Loss: 103.2026, Validation Accuracy: 0.6241\n",
            "Epoch 43/100, Loss: 9.8429, Validation Accuracy: 0.5573\n",
            "Epoch 44/100, Loss: 5.5222, Validation Accuracy: 0.6032\n",
            "Epoch 45/100, Loss: 6.0631, Validation Accuracy: 0.5902\n",
            "Epoch 46/100, Loss: 1.9975, Validation Accuracy: 0.5135\n",
            "Epoch 47/100, Loss: 4.9556, Validation Accuracy: 0.6421\n",
            "Epoch 48/100, Loss: 7.3182, Validation Accuracy: 0.6191\n",
            "Epoch 49/100, Loss: 13.1971, Validation Accuracy: 0.4885\n",
            "Epoch 50/100, Loss: 12.6250, Validation Accuracy: 0.6171\n",
            "Epoch 51/100, Loss: 145.4481, Validation Accuracy: 0.5274\n",
            "Epoch 52/100, Loss: 16.1378, Validation Accuracy: 0.3480\n",
            "Epoch 53/100, Loss: 2.4205, Validation Accuracy: 0.6331\n",
            "Epoch 54/100, Loss: 8.6181, Validation Accuracy: 0.5464\n",
            "Epoch 55/100, Loss: 5.5102, Validation Accuracy: 0.6710\n",
            "Epoch 56/100, Loss: 70.7123, Validation Accuracy: 0.5823\n",
            "Epoch 57/100, Loss: 16.8065, Validation Accuracy: 0.5085\n",
            "Epoch 58/100, Loss: 10.0604, Validation Accuracy: 0.5194\n",
            "Epoch 59/100, Loss: 4.3941, Validation Accuracy: 0.6381\n",
            "Epoch 60/100, Loss: 3.4499, Validation Accuracy: 0.3928\n",
            "Epoch 61/100, Loss: 3.5715, Validation Accuracy: 0.6790\n",
            "Epoch 62/100, Loss: 4.6430, Validation Accuracy: 0.6790\n",
            "Epoch 63/100, Loss: 230.7840, Validation Accuracy: 0.5613\n",
            "Epoch 64/100, Loss: 17.0678, Validation Accuracy: 0.5354\n",
            "Epoch 65/100, Loss: 2.4696, Validation Accuracy: 0.5932\n",
            "Epoch 66/100, Loss: 3.4452, Validation Accuracy: 0.5324\n",
            "Epoch 67/100, Loss: 3.5595, Validation Accuracy: 0.5942\n",
            "Epoch 68/100, Loss: 7.9271, Validation Accuracy: 0.6102\n",
            "Epoch 69/100, Loss: 7.5601, Validation Accuracy: 0.6640\n",
            "Epoch 70/100, Loss: 40.6716, Validation Accuracy: 0.3988\n",
            "Epoch 71/100, Loss: 5.8819, Validation Accuracy: 0.6720\n",
            "Epoch 72/100, Loss: 7.5629, Validation Accuracy: 0.6162\n",
            "Epoch 73/100, Loss: 12.7010, Validation Accuracy: 0.6291\n",
            "Epoch 74/100, Loss: 9.3485, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 21.1837, Validation Accuracy: 0.3689\n",
            "Epoch 76/100, Loss: 9.9596, Validation Accuracy: 0.5952\n",
            "Epoch 77/100, Loss: 5.9946, Validation Accuracy: 0.6062\n",
            "Epoch 78/100, Loss: 11.0032, Validation Accuracy: 0.6411\n",
            "Epoch 79/100, Loss: 4.5279, Validation Accuracy: 0.5673\n",
            "Epoch 80/100, Loss: 30.8227, Validation Accuracy: 0.4736\n",
            "Epoch 81/100, Loss: 20.2504, Validation Accuracy: 0.4955\n",
            "Epoch 82/100, Loss: 1.8468, Validation Accuracy: 0.6580\n",
            "Epoch 83/100, Loss: 3.0706, Validation Accuracy: 0.5922\n",
            "Epoch 84/100, Loss: 2.1161, Validation Accuracy: 0.6680\n",
            "Epoch 85/100, Loss: 5.4768, Validation Accuracy: 0.5823\n",
            "Epoch 86/100, Loss: 2.8260, Validation Accuracy: 0.4347\n",
            "Epoch 87/100, Loss: 8.8956, Validation Accuracy: 0.6590\n",
            "Epoch 88/100, Loss: 10.8814, Validation Accuracy: 0.4347\n",
            "Epoch 89/100, Loss: 6.5702, Validation Accuracy: 0.6271\n",
            "Epoch 90/100, Loss: 8.9177, Validation Accuracy: 0.5633\n",
            "Epoch 91/100, Loss: 12.1445, Validation Accuracy: 0.5902\n",
            "Epoch 92/100, Loss: 8.2489, Validation Accuracy: 0.6570\n",
            "Epoch 93/100, Loss: 4.6874, Validation Accuracy: 0.5862\n",
            "Epoch 94/100, Loss: 19.5903, Validation Accuracy: 0.4566\n",
            "Epoch 95/100, Loss: 25.1112, Validation Accuracy: 0.6660\n",
            "Epoch 96/100, Loss: 15.5089, Validation Accuracy: 0.5623\n",
            "Epoch 97/100, Loss: 19.5951, Validation Accuracy: 0.6331\n",
            "Epoch 98/100, Loss: 11.1714, Validation Accuracy: 0.5503\n",
            "Epoch 99/100, Loss: 5.4414, Validation Accuracy: 0.5793\n",
            "Epoch 100/100, Loss: 14.8415, Validation Accuracy: 0.4158\n",
            "Epoch 101/100, Loss: 4.5124, Validation Accuracy: 0.5324\n",
            "Epoch 102/100, Loss: 29.6828, Validation Accuracy: 0.5713\n",
            "Epoch 103/100, Loss: 11.7471, Validation Accuracy: 0.5683\n",
            "Epoch 104/100, Loss: 9.4267, Validation Accuracy: 0.5713\n",
            "Epoch 105/100, Loss: 3.7630, Validation Accuracy: 0.6162\n",
            "Epoch 106/100, Loss: 10.3464, Validation Accuracy: 0.5842\n",
            "Epoch 107/100, Loss: 8.4146, Validation Accuracy: 0.5025\n",
            "Epoch 108/100, Loss: 50.8097, Validation Accuracy: 0.6231\n",
            "Epoch 109/100, Loss: 24.1868, Validation Accuracy: 0.5274\n",
            "Epoch 110/100, Loss: 5.7731, Validation Accuracy: 0.6171\n",
            "Epoch 111/100, Loss: 14.6227, Validation Accuracy: 0.6261\n",
            "Epoch 112/100, Loss: 14.8198, Validation Accuracy: 0.6072\n",
            "Epoch 113/100, Loss: 4.4056, Validation Accuracy: 0.3759\n",
            "Epoch 114/100, Loss: 17.1891, Validation Accuracy: 0.6132\n",
            "Epoch 115/100, Loss: 15.8712, Validation Accuracy: 0.6520\n",
            "Epoch 116/100, Loss: 7.0236, Validation Accuracy: 0.5613\n",
            "Epoch 117/100, Loss: 5.1282, Validation Accuracy: 0.5813\n",
            "Epoch 118/100, Loss: 8.1867, Validation Accuracy: 0.5484\n",
            "Epoch 119/100, Loss: 21.2790, Validation Accuracy: 0.6351\n",
            "Epoch 120/100, Loss: 14.9934, Validation Accuracy: 0.5673\n",
            "Epoch 121/100, Loss: 6.3223, Validation Accuracy: 0.6560\n",
            "Epoch 122/100, Loss: 5.6793, Validation Accuracy: 0.5852\n",
            "Epoch 123/100, Loss: 8.2097, Validation Accuracy: 0.6580\n",
            "Epoch 124/100, Loss: 8.5757, Validation Accuracy: 0.6411\n",
            "Epoch 125/100, Loss: 14.6869, Validation Accuracy: 0.4806\n",
            "Epoch 126/100, Loss: 24.5915, Validation Accuracy: 0.5882\n",
            "Epoch 127/100, Loss: 13.4518, Validation Accuracy: 0.4566\n",
            "Epoch 128/100, Loss: 11.2336, Validation Accuracy: 0.5892\n",
            "Epoch 129/100, Loss: 27.3792, Validation Accuracy: 0.6670\n",
            "Epoch 130/100, Loss: 18.3702, Validation Accuracy: 0.2502\n",
            "Epoch 131/100, Loss: 6.0882, Validation Accuracy: 0.5902\n",
            "Epoch 132/100, Loss: 7.6362, Validation Accuracy: 0.6032\n",
            "Epoch 133/100, Loss: 8.9876, Validation Accuracy: 0.6790\n",
            "Epoch 134/100, Loss: 13.9278, Validation Accuracy: 0.6301\n",
            "Epoch 135/100, Loss: 37.6653, Validation Accuracy: 0.6441\n",
            "Epoch 136/100, Loss: 6.3152, Validation Accuracy: 0.5553\n",
            "Epoch 137/100, Loss: 3.4813, Validation Accuracy: 0.6600\n",
            "Epoch 138/100, Loss: 4.5606, Validation Accuracy: 0.6401\n",
            "Epoch 139/100, Loss: 16.7728, Validation Accuracy: 0.6271\n",
            "Epoch 140/100, Loss: 11.2235, Validation Accuracy: 0.4776\n",
            "Epoch 141/100, Loss: 8.2015, Validation Accuracy: 0.5145\n",
            "Epoch 142/100, Loss: 17.6415, Validation Accuracy: 0.5434\n",
            "Epoch 143/100, Loss: 24.0239, Validation Accuracy: 0.5982\n",
            "Epoch 144/100, Loss: 21.1423, Validation Accuracy: 0.6421\n",
            "Epoch 145/100, Loss: 11.2648, Validation Accuracy: 0.4925\n",
            "Epoch 146/100, Loss: 4.0371, Validation Accuracy: 0.5434\n",
            "Epoch 147/100, Loss: 5.8089, Validation Accuracy: 0.5723\n",
            "Epoch 148/100, Loss: 12.6775, Validation Accuracy: 0.6640\n",
            "Epoch 149/100, Loss: 41.6144, Validation Accuracy: 0.6720\n",
            "Epoch 150/100, Loss: 8.5253, Validation Accuracy: 0.5663\n",
            "Epoch 151/100, Loss: 16.3648, Validation Accuracy: 0.5892\n",
            "Epoch 152/100, Loss: 6.6011, Validation Accuracy: 0.5852\n",
            "Epoch 153/100, Loss: 9.4751, Validation Accuracy: 0.5444\n",
            "Epoch 154/100, Loss: 23.0726, Validation Accuracy: 0.6261\n",
            "Epoch 155/100, Loss: 24.3270, Validation Accuracy: 0.5563\n",
            "Epoch 156/100, Loss: 15.2203, Validation Accuracy: 0.5274\n",
            "Epoch 157/100, Loss: 9.8945, Validation Accuracy: 0.5105\n",
            "Epoch 158/100, Loss: 9.7695, Validation Accuracy: 0.5912\n",
            "Epoch 159/100, Loss: 14.7055, Validation Accuracy: 0.6201\n",
            "Epoch 160/100, Loss: 7.8599, Validation Accuracy: 0.6650\n",
            "Epoch 161/100, Loss: 24.5170, Validation Accuracy: 0.5872\n",
            "Epoch 162/100, Loss: 3.3215, Validation Accuracy: 0.6441\n",
            "Epoch 163/100, Loss: 3.8633, Validation Accuracy: 0.5892\n",
            "Epoch 164/100, Loss: 8.8597, Validation Accuracy: 0.4307\n",
            "Epoch 165/100, Loss: 9.8563, Validation Accuracy: 0.5823\n",
            "Epoch 166/100, Loss: 24.2833, Validation Accuracy: 0.5882\n",
            "Epoch 167/100, Loss: 4.2954, Validation Accuracy: 0.6471\n",
            "Epoch 168/100, Loss: 15.7500, Validation Accuracy: 0.6740\n",
            "Epoch 169/100, Loss: 9.6796, Validation Accuracy: 0.4576\n",
            "Epoch 170/100, Loss: 19.3914, Validation Accuracy: 0.6211\n",
            "Epoch 171/100, Loss: 14.5764, Validation Accuracy: 0.6461\n",
            "Epoch 172/100, Loss: 5.0960, Validation Accuracy: 0.5693\n",
            "Epoch 173/100, Loss: 19.5552, Validation Accuracy: 0.6281\n",
            "Epoch 174/100, Loss: 11.6610, Validation Accuracy: 0.5543\n",
            "Epoch 175/100, Loss: 13.7237, Validation Accuracy: 0.6102\n",
            "Epoch 176/100, Loss: 18.1567, Validation Accuracy: 0.5823\n",
            "Epoch 177/100, Loss: 30.7813, Validation Accuracy: 0.6560\n",
            "Epoch 178/100, Loss: 11.1288, Validation Accuracy: 0.6620\n",
            "Epoch 179/100, Loss: 10.1960, Validation Accuracy: 0.6441\n",
            "Epoch 180/100, Loss: 7.2155, Validation Accuracy: 0.6142\n",
            "Epoch 181/100, Loss: 25.2374, Validation Accuracy: 0.6072\n",
            "Epoch 182/100, Loss: 4.4451, Validation Accuracy: 0.6331\n",
            "Epoch 183/100, Loss: 6.9203, Validation Accuracy: 0.6301\n",
            "Epoch 184/100, Loss: 8.7932, Validation Accuracy: 0.6421\n",
            "Epoch 185/100, Loss: 6.9676, Validation Accuracy: 0.4796\n",
            "Epoch 186/100, Loss: 27.5215, Validation Accuracy: 0.4307\n",
            "Epoch 187/100, Loss: 25.2369, Validation Accuracy: 0.5065\n",
            "Epoch 188/100, Loss: 6.7130, Validation Accuracy: 0.6371\n",
            "Epoch 189/100, Loss: 22.1891, Validation Accuracy: 0.6162\n",
            "Epoch 190/100, Loss: 18.6933, Validation Accuracy: 0.6540\n",
            "Epoch 191/100, Loss: 2.5485, Validation Accuracy: 0.4826\n",
            "Epoch 192/100, Loss: 4.2383, Validation Accuracy: 0.4726\n",
            "Epoch 193/100, Loss: 57.1640, Validation Accuracy: 0.4068\n",
            "Epoch 194/100, Loss: 8.0921, Validation Accuracy: 0.4905\n",
            "Epoch 195/100, Loss: 10.1822, Validation Accuracy: 0.5872\n",
            "Epoch 196/100, Loss: 3.3930, Validation Accuracy: 0.6570\n",
            "Epoch 197/100, Loss: 6.6602, Validation Accuracy: 0.6012\n",
            "Epoch 198/100, Loss: 3.6469, Validation Accuracy: 0.6670\n",
            "Epoch 199/100, Loss: 25.6618, Validation Accuracy: 0.6540\n",
            "Epoch 200/100, Loss: 19.5681, Validation Accuracy: 0.4885\n",
            "Reward for Child Model: 0.2967396323270139\n",
            "Child_27:  {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, [3, 3, 0, 2, 1, 1, 0, 0, 3, 1, 1, 3, 2, 1, 1], 0.2967396323270139\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 64, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(64, 24, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(72, 48, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(96, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=118976, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 26, 22]           3,072\n",
            "       BatchNorm2d-2           [-1, 48, 26, 22]              96\n",
            "            Conv2d-3           [-1, 64, 26, 18]          15,424\n",
            "       BatchNorm2d-4           [-1, 64, 26, 18]             128\n",
            "              ReLU-5           [-1, 64, 26, 18]               0\n",
            "            Conv2d-6           [-1, 24, 20, 16]          32,280\n",
            "       BatchNorm2d-7           [-1, 24, 20, 16]              48\n",
            "              ReLU-8           [-1, 24, 20, 16]               0\n",
            "            Conv2d-9           [-1, 48, 20, 18]         121,008\n",
            "      BatchNorm2d-10           [-1, 48, 20, 18]              96\n",
            "             ReLU-11           [-1, 48, 20, 18]               0\n",
            "           Conv2d-12           [-1, 48, 26, 18]          23,088\n",
            "      BatchNorm2d-13           [-1, 48, 26, 18]              96\n",
            "             ReLU-14           [-1, 48, 26, 18]               0\n",
            "           Linear-15                    [-1, 7]         832,839\n",
            "================================================================\n",
            "Total params: 1,028,175\n",
            "Trainable params: 1,028,175\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.19\n",
            "Params size (MB): 3.92\n",
            "Estimated Total Size (MB): 6.12\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 11.3785, Validation Accuracy: 0.5922\n",
            "Epoch 2/100, Loss: 32.3691, Validation Accuracy: 0.5992\n",
            "Epoch 3/100, Loss: 10.6291, Validation Accuracy: 0.4437\n",
            "Epoch 4/100, Loss: 52.7500, Validation Accuracy: 0.6491\n",
            "Epoch 5/100, Loss: 20.7559, Validation Accuracy: 0.5204\n",
            "Epoch 6/100, Loss: 10.5402, Validation Accuracy: 0.3848\n",
            "Epoch 7/100, Loss: 152.7848, Validation Accuracy: 0.6251\n",
            "Epoch 8/100, Loss: 47.4725, Validation Accuracy: 0.4945\n",
            "Epoch 9/100, Loss: 29.0144, Validation Accuracy: 0.4875\n",
            "Epoch 10/100, Loss: 44.2897, Validation Accuracy: 0.6500\n",
            "Epoch 11/100, Loss: 63.0266, Validation Accuracy: 0.5145\n",
            "Epoch 12/100, Loss: 31.2832, Validation Accuracy: 0.5194\n",
            "Epoch 13/100, Loss: 50.8016, Validation Accuracy: 0.6710\n",
            "Epoch 14/100, Loss: 10.9769, Validation Accuracy: 0.5852\n",
            "Epoch 15/100, Loss: 8.4472, Validation Accuracy: 0.6720\n",
            "Epoch 16/100, Loss: 36.0567, Validation Accuracy: 0.5653\n",
            "Epoch 17/100, Loss: 42.5927, Validation Accuracy: 0.5683\n",
            "Epoch 18/100, Loss: 40.9709, Validation Accuracy: 0.6471\n",
            "Epoch 19/100, Loss: 88.0020, Validation Accuracy: 0.6112\n",
            "Epoch 20/100, Loss: 29.7208, Validation Accuracy: 0.5563\n",
            "Epoch 21/100, Loss: 24.2909, Validation Accuracy: 0.4337\n",
            "Epoch 22/100, Loss: 30.8653, Validation Accuracy: 0.4257\n",
            "Epoch 23/100, Loss: 23.7920, Validation Accuracy: 0.4766\n",
            "Epoch 24/100, Loss: 163.0553, Validation Accuracy: 0.4217\n",
            "Epoch 25/100, Loss: 41.3811, Validation Accuracy: 0.6401\n",
            "Epoch 26/100, Loss: 32.0447, Validation Accuracy: 0.5813\n",
            "Epoch 27/100, Loss: 19.6744, Validation Accuracy: 0.6062\n",
            "Epoch 28/100, Loss: 14.5848, Validation Accuracy: 0.6510\n",
            "Epoch 29/100, Loss: 15.7832, Validation Accuracy: 0.4985\n",
            "Epoch 30/100, Loss: 27.9063, Validation Accuracy: 0.5852\n",
            "Epoch 31/100, Loss: 18.3603, Validation Accuracy: 0.6162\n",
            "Epoch 32/100, Loss: 52.8881, Validation Accuracy: 0.5952\n",
            "Epoch 33/100, Loss: 27.2073, Validation Accuracy: 0.6620\n",
            "Epoch 34/100, Loss: 52.1727, Validation Accuracy: 0.6500\n",
            "Epoch 35/100, Loss: 15.2119, Validation Accuracy: 0.3829\n",
            "Epoch 36/100, Loss: 27.6491, Validation Accuracy: 0.6142\n",
            "Epoch 37/100, Loss: 123.1512, Validation Accuracy: 0.6401\n",
            "Epoch 38/100, Loss: 46.6418, Validation Accuracy: 0.5234\n",
            "Epoch 39/100, Loss: 52.3589, Validation Accuracy: 0.5254\n",
            "Epoch 40/100, Loss: 32.8623, Validation Accuracy: 0.4985\n",
            "Epoch 41/100, Loss: 13.9214, Validation Accuracy: 0.6331\n",
            "Epoch 42/100, Loss: 22.7687, Validation Accuracy: 0.5663\n",
            "Epoch 43/100, Loss: 29.3889, Validation Accuracy: 0.6181\n",
            "Epoch 44/100, Loss: 98.7073, Validation Accuracy: 0.5174\n",
            "Epoch 45/100, Loss: 38.1006, Validation Accuracy: 0.5623\n",
            "Epoch 46/100, Loss: 30.9351, Validation Accuracy: 0.4965\n",
            "Epoch 47/100, Loss: 77.8594, Validation Accuracy: 0.3549\n",
            "Epoch 48/100, Loss: 19.0564, Validation Accuracy: 0.5254\n",
            "Epoch 49/100, Loss: 38.5147, Validation Accuracy: 0.5952\n",
            "Epoch 50/100, Loss: 29.3192, Validation Accuracy: 0.3779\n",
            "Epoch 51/100, Loss: 16.3814, Validation Accuracy: 0.6191\n",
            "Epoch 52/100, Loss: 19.4244, Validation Accuracy: 0.6610\n",
            "Epoch 53/100, Loss: 427.5538, Validation Accuracy: 0.6162\n",
            "Epoch 54/100, Loss: 16.3997, Validation Accuracy: 0.5484\n",
            "Epoch 55/100, Loss: 23.0518, Validation Accuracy: 0.3569\n",
            "Epoch 56/100, Loss: 10.4413, Validation Accuracy: 0.5274\n",
            "Epoch 57/100, Loss: 14.3015, Validation Accuracy: 0.5783\n",
            "Epoch 58/100, Loss: 8.6488, Validation Accuracy: 0.5743\n",
            "Epoch 59/100, Loss: 47.5193, Validation Accuracy: 0.5085\n",
            "Epoch 60/100, Loss: 49.1535, Validation Accuracy: 0.6321\n",
            "Epoch 61/100, Loss: 12.2806, Validation Accuracy: 0.6261\n",
            "Epoch 62/100, Loss: 26.3686, Validation Accuracy: 0.5703\n",
            "Epoch 63/100, Loss: 48.7482, Validation Accuracy: 0.5085\n",
            "Epoch 64/100, Loss: 16.3267, Validation Accuracy: 0.6102\n",
            "Epoch 65/100, Loss: 31.2135, Validation Accuracy: 0.6122\n",
            "Epoch 66/100, Loss: 24.2760, Validation Accuracy: 0.5254\n",
            "Epoch 67/100, Loss: 21.5514, Validation Accuracy: 0.6381\n",
            "Epoch 68/100, Loss: 30.7217, Validation Accuracy: 0.6540\n",
            "Epoch 69/100, Loss: 54.1678, Validation Accuracy: 0.4297\n",
            "Epoch 70/100, Loss: 38.0844, Validation Accuracy: 0.4905\n",
            "Epoch 71/100, Loss: 42.2632, Validation Accuracy: 0.6481\n",
            "Epoch 72/100, Loss: 65.8227, Validation Accuracy: 0.6441\n",
            "Epoch 73/100, Loss: 13.2372, Validation Accuracy: 0.6510\n",
            "Epoch 74/100, Loss: 45.2136, Validation Accuracy: 0.6760\n",
            "Epoch 75/100, Loss: 41.7154, Validation Accuracy: 0.6520\n",
            "Epoch 76/100, Loss: 61.9333, Validation Accuracy: 0.5394\n",
            "Epoch 77/100, Loss: 8.6337, Validation Accuracy: 0.5703\n",
            "Epoch 78/100, Loss: 30.9724, Validation Accuracy: 0.6221\n",
            "Epoch 79/100, Loss: 30.3383, Validation Accuracy: 0.6540\n",
            "Epoch 80/100, Loss: 89.4901, Validation Accuracy: 0.6620\n",
            "Epoch 81/100, Loss: 17.6761, Validation Accuracy: 0.5523\n",
            "Epoch 82/100, Loss: 31.7844, Validation Accuracy: 0.3639\n",
            "Epoch 83/100, Loss: 22.1581, Validation Accuracy: 0.4626\n",
            "Epoch 84/100, Loss: 28.1136, Validation Accuracy: 0.5254\n",
            "Epoch 85/100, Loss: 43.9931, Validation Accuracy: 0.5284\n",
            "Epoch 86/100, Loss: 39.8195, Validation Accuracy: 0.6570\n",
            "Epoch 87/100, Loss: 46.8865, Validation Accuracy: 0.6082\n",
            "Epoch 88/100, Loss: 30.6571, Validation Accuracy: 0.6700\n",
            "Epoch 89/100, Loss: 50.1604, Validation Accuracy: 0.6660\n",
            "Epoch 90/100, Loss: 17.7902, Validation Accuracy: 0.6201\n",
            "Epoch 91/100, Loss: 20.5515, Validation Accuracy: 0.6491\n",
            "Epoch 92/100, Loss: 48.3502, Validation Accuracy: 0.6321\n",
            "Epoch 93/100, Loss: 30.5032, Validation Accuracy: 0.6311\n",
            "Epoch 94/100, Loss: 61.8305, Validation Accuracy: 0.6381\n",
            "Epoch 95/100, Loss: 58.1242, Validation Accuracy: 0.5015\n",
            "Epoch 96/100, Loss: 39.8267, Validation Accuracy: 0.5085\n",
            "Epoch 97/100, Loss: 38.6352, Validation Accuracy: 0.6650\n",
            "Epoch 98/100, Loss: 60.0414, Validation Accuracy: 0.5434\n",
            "Epoch 99/100, Loss: 18.0477, Validation Accuracy: 0.6211\n",
            "Epoch 100/100, Loss: 15.3661, Validation Accuracy: 0.6530\n",
            "Epoch 101/100, Loss: 46.4664, Validation Accuracy: 0.4397\n",
            "Epoch 102/100, Loss: 19.3113, Validation Accuracy: 0.6730\n",
            "Epoch 103/100, Loss: 55.1913, Validation Accuracy: 0.6002\n",
            "Epoch 104/100, Loss: 73.3795, Validation Accuracy: 0.4716\n",
            "Epoch 105/100, Loss: 27.1986, Validation Accuracy: 0.6171\n",
            "Epoch 106/100, Loss: 52.6684, Validation Accuracy: 0.6211\n",
            "Epoch 107/100, Loss: 55.5218, Validation Accuracy: 0.5374\n",
            "Epoch 108/100, Loss: 18.5019, Validation Accuracy: 0.4776\n",
            "Epoch 109/100, Loss: 56.3523, Validation Accuracy: 0.2961\n",
            "Epoch 110/100, Loss: 47.4905, Validation Accuracy: 0.6112\n",
            "Epoch 111/100, Loss: 82.6586, Validation Accuracy: 0.5753\n",
            "Epoch 112/100, Loss: 25.6881, Validation Accuracy: 0.6371\n",
            "Epoch 113/100, Loss: 114.5219, Validation Accuracy: 0.5982\n",
            "Epoch 114/100, Loss: 15.5431, Validation Accuracy: 0.6630\n",
            "Epoch 115/100, Loss: 19.3956, Validation Accuracy: 0.6142\n",
            "Epoch 116/100, Loss: 25.4303, Validation Accuracy: 0.5384\n",
            "Epoch 117/100, Loss: 16.2394, Validation Accuracy: 0.5304\n",
            "Epoch 118/100, Loss: 25.4782, Validation Accuracy: 0.6062\n",
            "Epoch 119/100, Loss: 42.0068, Validation Accuracy: 0.5503\n",
            "Epoch 120/100, Loss: 33.0582, Validation Accuracy: 0.5005\n",
            "Epoch 121/100, Loss: 23.0674, Validation Accuracy: 0.6152\n",
            "Epoch 122/100, Loss: 27.2229, Validation Accuracy: 0.5583\n",
            "Epoch 123/100, Loss: 46.3188, Validation Accuracy: 0.6171\n",
            "Epoch 124/100, Loss: 17.7083, Validation Accuracy: 0.6680\n",
            "Epoch 125/100, Loss: 20.6899, Validation Accuracy: 0.5693\n",
            "Epoch 126/100, Loss: 39.6720, Validation Accuracy: 0.6620\n",
            "Epoch 127/100, Loss: 32.5567, Validation Accuracy: 0.5912\n",
            "Epoch 128/100, Loss: 21.4120, Validation Accuracy: 0.5593\n",
            "Epoch 129/100, Loss: 19.4272, Validation Accuracy: 0.6740\n",
            "Epoch 130/100, Loss: 35.6827, Validation Accuracy: 0.5932\n",
            "Epoch 131/100, Loss: 21.0095, Validation Accuracy: 0.6700\n",
            "Epoch 132/100, Loss: 21.5471, Validation Accuracy: 0.5224\n",
            "Epoch 133/100, Loss: 51.1823, Validation Accuracy: 0.6680\n",
            "Epoch 134/100, Loss: 29.8012, Validation Accuracy: 0.6251\n",
            "Epoch 135/100, Loss: 42.9262, Validation Accuracy: 0.5922\n",
            "Epoch 136/100, Loss: 90.8173, Validation Accuracy: 0.5374\n",
            "Epoch 137/100, Loss: 89.1024, Validation Accuracy: 0.6411\n",
            "Epoch 138/100, Loss: 12.6949, Validation Accuracy: 0.6431\n",
            "Epoch 139/100, Loss: 8.7293, Validation Accuracy: 0.5513\n",
            "Epoch 140/100, Loss: 7.5187, Validation Accuracy: 0.5374\n",
            "Epoch 141/100, Loss: 36.5126, Validation Accuracy: 0.5842\n",
            "Epoch 142/100, Loss: 37.0001, Validation Accuracy: 0.5334\n",
            "Epoch 143/100, Loss: 13.4278, Validation Accuracy: 0.6421\n",
            "Epoch 144/100, Loss: 55.6851, Validation Accuracy: 0.6251\n",
            "Epoch 145/100, Loss: 16.4803, Validation Accuracy: 0.6221\n",
            "Epoch 146/100, Loss: 147.9429, Validation Accuracy: 0.4696\n",
            "Epoch 147/100, Loss: 11.7312, Validation Accuracy: 0.6560\n",
            "Epoch 148/100, Loss: 14.7137, Validation Accuracy: 0.5334\n",
            "Epoch 149/100, Loss: 34.1103, Validation Accuracy: 0.5753\n",
            "Epoch 150/100, Loss: 65.0490, Validation Accuracy: 0.5653\n",
            "Epoch 151/100, Loss: 56.2904, Validation Accuracy: 0.5972\n",
            "Epoch 152/100, Loss: 26.9346, Validation Accuracy: 0.6221\n",
            "Epoch 153/100, Loss: 171.1614, Validation Accuracy: 0.4736\n",
            "Epoch 154/100, Loss: 25.6919, Validation Accuracy: 0.5613\n",
            "Epoch 155/100, Loss: 40.5084, Validation Accuracy: 0.6251\n",
            "Epoch 156/100, Loss: 31.1228, Validation Accuracy: 0.6002\n",
            "Epoch 157/100, Loss: 24.1241, Validation Accuracy: 0.4925\n",
            "Epoch 158/100, Loss: 30.3618, Validation Accuracy: 0.3410\n",
            "Epoch 159/100, Loss: 21.5280, Validation Accuracy: 0.5902\n",
            "Epoch 160/100, Loss: 39.2176, Validation Accuracy: 0.5484\n",
            "Epoch 161/100, Loss: 17.0201, Validation Accuracy: 0.6241\n",
            "Epoch 162/100, Loss: 7.1926, Validation Accuracy: 0.6550\n",
            "Epoch 163/100, Loss: 69.8627, Validation Accuracy: 0.6580\n",
            "Epoch 164/100, Loss: 78.4599, Validation Accuracy: 0.5962\n",
            "Epoch 165/100, Loss: 11.4623, Validation Accuracy: 0.5334\n",
            "Epoch 166/100, Loss: 32.0784, Validation Accuracy: 0.4606\n",
            "Epoch 167/100, Loss: 40.5412, Validation Accuracy: 0.5763\n",
            "Epoch 168/100, Loss: 17.8233, Validation Accuracy: 0.6510\n",
            "Epoch 169/100, Loss: 53.9650, Validation Accuracy: 0.5703\n",
            "Epoch 170/100, Loss: 24.5697, Validation Accuracy: 0.5513\n",
            "Epoch 171/100, Loss: 67.4785, Validation Accuracy: 0.5763\n",
            "Epoch 172/100, Loss: 20.4757, Validation Accuracy: 0.5932\n",
            "Epoch 173/100, Loss: 47.1530, Validation Accuracy: 0.5274\n",
            "Epoch 174/100, Loss: 50.3184, Validation Accuracy: 0.4955\n",
            "Epoch 175/100, Loss: 39.3287, Validation Accuracy: 0.6002\n",
            "Epoch 176/100, Loss: 17.4280, Validation Accuracy: 0.6530\n",
            "Epoch 177/100, Loss: 31.8214, Validation Accuracy: 0.5952\n",
            "Epoch 178/100, Loss: 23.8184, Validation Accuracy: 0.5613\n",
            "Epoch 179/100, Loss: 27.1641, Validation Accuracy: 0.5842\n",
            "Epoch 180/100, Loss: 59.2721, Validation Accuracy: 0.4975\n",
            "Epoch 181/100, Loss: 58.1247, Validation Accuracy: 0.5573\n",
            "Epoch 182/100, Loss: 25.0320, Validation Accuracy: 0.6321\n",
            "Epoch 183/100, Loss: 15.2681, Validation Accuracy: 0.6221\n",
            "Epoch 184/100, Loss: 17.5156, Validation Accuracy: 0.5494\n",
            "Epoch 185/100, Loss: 36.2906, Validation Accuracy: 0.6321\n",
            "Epoch 186/100, Loss: 24.5423, Validation Accuracy: 0.6540\n",
            "Epoch 187/100, Loss: 26.5205, Validation Accuracy: 0.6092\n",
            "Epoch 188/100, Loss: 75.3707, Validation Accuracy: 0.6580\n",
            "Epoch 189/100, Loss: 65.2057, Validation Accuracy: 0.5494\n",
            "Epoch 190/100, Loss: 50.8160, Validation Accuracy: 0.6002\n",
            "Epoch 191/100, Loss: 25.3491, Validation Accuracy: 0.4995\n",
            "Epoch 192/100, Loss: 45.8981, Validation Accuracy: 0.5484\n",
            "Epoch 193/100, Loss: 101.7623, Validation Accuracy: 0.5593\n",
            "Epoch 194/100, Loss: 47.3271, Validation Accuracy: 0.5872\n",
            "Epoch 195/100, Loss: 23.5498, Validation Accuracy: 0.5902\n",
            "Epoch 196/100, Loss: 10.8207, Validation Accuracy: 0.6132\n",
            "Epoch 197/100, Loss: 18.2914, Validation Accuracy: 0.5992\n",
            "Epoch 198/100, Loss: 18.5518, Validation Accuracy: 0.5065\n",
            "Epoch 199/100, Loss: 40.8121, Validation Accuracy: 0.5135\n",
            "Epoch 200/100, Loss: 84.3764, Validation Accuracy: 0.5174\n",
            "Reward for Child Model: 0.23052739795442567\n",
            "Child_28:  {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, [1, 3, 2, 0, 2, 3, 3, 1, 0, 3, 2, 2, 0, 2, 2], 0.23052739795442567\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 64, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(64, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(160, 36, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(100, 64, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=249392, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 22, 26]           3,072\n",
            "       BatchNorm2d-2           [-1, 48, 22, 26]              96\n",
            "            Conv2d-3           [-1, 64, 18, 20]         107,584\n",
            "       BatchNorm2d-4           [-1, 64, 18, 20]             128\n",
            "              ReLU-5           [-1, 64, 18, 20]               0\n",
            "            Conv2d-6           [-1, 48, 16, 20]           9,264\n",
            "       BatchNorm2d-7           [-1, 48, 16, 20]              96\n",
            "              ReLU-8           [-1, 48, 16, 20]               0\n",
            "            Conv2d-9           [-1, 36, 20, 24]          51,876\n",
            "      BatchNorm2d-10           [-1, 36, 20, 24]              72\n",
            "             ReLU-11           [-1, 36, 20, 24]               0\n",
            "           Conv2d-12           [-1, 64, 16, 18]         224,064\n",
            "      BatchNorm2d-13           [-1, 64, 16, 18]             128\n",
            "             ReLU-14           [-1, 64, 16, 18]               0\n",
            "           Linear-15                    [-1, 7]       1,745,751\n",
            "================================================================\n",
            "Total params: 2,142,131\n",
            "Trainable params: 2,142,131\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.12\n",
            "Params size (MB): 8.17\n",
            "Estimated Total Size (MB): 10.30\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 36.0507, Validation Accuracy: 0.6271\n",
            "Epoch 2/100, Loss: 27.3322, Validation Accuracy: 0.6381\n",
            "Epoch 3/100, Loss: 25.3646, Validation Accuracy: 0.6082\n",
            "Epoch 4/100, Loss: 107.4669, Validation Accuracy: 0.5653\n",
            "Epoch 5/100, Loss: 982.4828, Validation Accuracy: 0.4407\n",
            "Epoch 6/100, Loss: 26.4089, Validation Accuracy: 0.4626\n",
            "Epoch 7/100, Loss: 21.9296, Validation Accuracy: 0.6680\n",
            "Epoch 8/100, Loss: 12.4811, Validation Accuracy: 0.6191\n",
            "Epoch 9/100, Loss: 389.3371, Validation Accuracy: 0.5414\n",
            "Epoch 10/100, Loss: 68.3614, Validation Accuracy: 0.4756\n",
            "Epoch 11/100, Loss: 20.9305, Validation Accuracy: 0.3420\n",
            "Epoch 12/100, Loss: 38.7473, Validation Accuracy: 0.6570\n",
            "Epoch 13/100, Loss: 30.4997, Validation Accuracy: 0.5484\n",
            "Epoch 14/100, Loss: 17.8127, Validation Accuracy: 0.6680\n",
            "Epoch 15/100, Loss: 23.1485, Validation Accuracy: 0.6062\n",
            "Epoch 16/100, Loss: 20.7163, Validation Accuracy: 0.4965\n",
            "Epoch 17/100, Loss: 17.4283, Validation Accuracy: 0.5653\n",
            "Epoch 18/100, Loss: 28.6041, Validation Accuracy: 0.4606\n",
            "Epoch 19/100, Loss: 17.7319, Validation Accuracy: 0.5025\n",
            "Epoch 20/100, Loss: 68.0776, Validation Accuracy: 0.6491\n",
            "Epoch 21/100, Loss: 26.8163, Validation Accuracy: 0.4048\n",
            "Epoch 22/100, Loss: 18.7046, Validation Accuracy: 0.6560\n",
            "Epoch 23/100, Loss: 27.9247, Validation Accuracy: 0.5374\n",
            "Epoch 24/100, Loss: 24.4273, Validation Accuracy: 0.6660\n",
            "Epoch 25/100, Loss: 30.1744, Validation Accuracy: 0.4945\n",
            "Epoch 26/100, Loss: 167.3389, Validation Accuracy: 0.5354\n",
            "Epoch 27/100, Loss: 37.3125, Validation Accuracy: 0.4337\n",
            "Epoch 28/100, Loss: 19.8375, Validation Accuracy: 0.3400\n",
            "Epoch 29/100, Loss: 21.5065, Validation Accuracy: 0.5743\n",
            "Epoch 30/100, Loss: 28.1684, Validation Accuracy: 0.5244\n",
            "Epoch 31/100, Loss: 39.9023, Validation Accuracy: 0.4885\n",
            "Epoch 32/100, Loss: 84.1650, Validation Accuracy: 0.6500\n",
            "Epoch 33/100, Loss: 60.7384, Validation Accuracy: 0.5334\n",
            "Epoch 34/100, Loss: 71.6541, Validation Accuracy: 0.4636\n",
            "Epoch 35/100, Loss: 135.6154, Validation Accuracy: 0.6730\n",
            "Epoch 36/100, Loss: 76.1476, Validation Accuracy: 0.6301\n",
            "Epoch 37/100, Loss: 130.6996, Validation Accuracy: 0.6251\n",
            "Epoch 38/100, Loss: 30.0714, Validation Accuracy: 0.6092\n",
            "Epoch 39/100, Loss: 21.3224, Validation Accuracy: 0.6411\n",
            "Epoch 40/100, Loss: 155.3548, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 15.6579, Validation Accuracy: 0.3709\n",
            "Epoch 42/100, Loss: 60.4093, Validation Accuracy: 0.6032\n",
            "Epoch 43/100, Loss: 22.3984, Validation Accuracy: 0.6311\n",
            "Epoch 44/100, Loss: 77.7351, Validation Accuracy: 0.5902\n",
            "Epoch 45/100, Loss: 155.7027, Validation Accuracy: 0.6421\n",
            "Epoch 46/100, Loss: 362.7279, Validation Accuracy: 0.6560\n",
            "Epoch 47/100, Loss: 147.0495, Validation Accuracy: 0.5145\n",
            "Epoch 48/100, Loss: 129.2616, Validation Accuracy: 0.3978\n",
            "Epoch 49/100, Loss: 86.7116, Validation Accuracy: 0.5852\n",
            "Epoch 50/100, Loss: 68.2662, Validation Accuracy: 0.6251\n",
            "Epoch 51/100, Loss: 39.0570, Validation Accuracy: 0.5703\n",
            "Epoch 52/100, Loss: 259.7850, Validation Accuracy: 0.6660\n",
            "Epoch 53/100, Loss: 86.9975, Validation Accuracy: 0.3978\n",
            "Epoch 54/100, Loss: 43.7588, Validation Accuracy: 0.6481\n",
            "Epoch 55/100, Loss: 66.9060, Validation Accuracy: 0.5344\n",
            "Epoch 56/100, Loss: 29.2312, Validation Accuracy: 0.6660\n",
            "Epoch 57/100, Loss: 29.4307, Validation Accuracy: 0.6510\n",
            "Epoch 58/100, Loss: 44.2218, Validation Accuracy: 0.5025\n",
            "Epoch 59/100, Loss: 18.5829, Validation Accuracy: 0.3709\n",
            "Epoch 60/100, Loss: 77.8307, Validation Accuracy: 0.6461\n",
            "Epoch 61/100, Loss: 33.4238, Validation Accuracy: 0.5952\n",
            "Epoch 62/100, Loss: 20.8192, Validation Accuracy: 0.6580\n",
            "Epoch 63/100, Loss: 48.5010, Validation Accuracy: 0.4865\n",
            "Epoch 64/100, Loss: 65.2597, Validation Accuracy: 0.6520\n",
            "Epoch 65/100, Loss: 44.2178, Validation Accuracy: 0.6520\n",
            "Epoch 66/100, Loss: 83.5996, Validation Accuracy: 0.6510\n",
            "Epoch 67/100, Loss: 46.6368, Validation Accuracy: 0.6650\n",
            "Epoch 68/100, Loss: 55.4664, Validation Accuracy: 0.6710\n",
            "Epoch 69/100, Loss: 52.3133, Validation Accuracy: 0.5962\n",
            "Epoch 70/100, Loss: 64.1472, Validation Accuracy: 0.6142\n",
            "Epoch 71/100, Loss: 91.0946, Validation Accuracy: 0.1137\n",
            "Epoch 72/100, Loss: 35.4895, Validation Accuracy: 0.5484\n",
            "Epoch 73/100, Loss: 176.0364, Validation Accuracy: 0.4177\n",
            "Epoch 74/100, Loss: 57.5319, Validation Accuracy: 0.5793\n",
            "Epoch 75/100, Loss: 34.1444, Validation Accuracy: 0.5912\n",
            "Epoch 76/100, Loss: 120.0609, Validation Accuracy: 0.6321\n",
            "Epoch 77/100, Loss: 79.4917, Validation Accuracy: 0.5842\n",
            "Epoch 78/100, Loss: 86.8870, Validation Accuracy: 0.6680\n",
            "Epoch 79/100, Loss: 72.7356, Validation Accuracy: 0.6710\n",
            "Epoch 80/100, Loss: 37.0623, Validation Accuracy: 0.5145\n",
            "Epoch 81/100, Loss: 215.4422, Validation Accuracy: 0.4895\n",
            "Epoch 82/100, Loss: 25.9451, Validation Accuracy: 0.5723\n",
            "Epoch 83/100, Loss: 13.4183, Validation Accuracy: 0.6132\n",
            "Epoch 84/100, Loss: 715.4519, Validation Accuracy: 0.1186\n",
            "Epoch 85/100, Loss: 96.3019, Validation Accuracy: 0.6730\n",
            "Epoch 86/100, Loss: 14.0786, Validation Accuracy: 0.5494\n",
            "Epoch 87/100, Loss: 35.2776, Validation Accuracy: 0.5394\n",
            "Epoch 88/100, Loss: 20.2910, Validation Accuracy: 0.5414\n",
            "Epoch 89/100, Loss: 47.9296, Validation Accuracy: 0.1137\n",
            "Epoch 90/100, Loss: 80.4472, Validation Accuracy: 0.6311\n",
            "Epoch 91/100, Loss: 46.2592, Validation Accuracy: 0.5862\n",
            "Epoch 92/100, Loss: 74.7601, Validation Accuracy: 0.6301\n",
            "Epoch 93/100, Loss: 41.6556, Validation Accuracy: 0.6391\n",
            "Epoch 94/100, Loss: 32.7223, Validation Accuracy: 0.4317\n",
            "Epoch 95/100, Loss: 74.9174, Validation Accuracy: 0.5434\n",
            "Epoch 96/100, Loss: 136.6333, Validation Accuracy: 0.6211\n",
            "Epoch 97/100, Loss: 29.3378, Validation Accuracy: 0.5703\n",
            "Epoch 98/100, Loss: 23.1284, Validation Accuracy: 0.5743\n",
            "Epoch 99/100, Loss: 86.4392, Validation Accuracy: 0.6291\n",
            "Epoch 100/100, Loss: 80.4152, Validation Accuracy: 0.6431\n",
            "Epoch 101/100, Loss: 48.9653, Validation Accuracy: 0.4447\n",
            "Epoch 102/100, Loss: 65.7548, Validation Accuracy: 0.6211\n",
            "Epoch 103/100, Loss: 112.6283, Validation Accuracy: 0.6072\n",
            "Epoch 104/100, Loss: 57.9024, Validation Accuracy: 0.5593\n",
            "Epoch 105/100, Loss: 58.7524, Validation Accuracy: 0.6281\n",
            "Epoch 106/100, Loss: 45.7718, Validation Accuracy: 0.6750\n",
            "Epoch 107/100, Loss: 204.0145, Validation Accuracy: 0.5713\n",
            "Epoch 108/100, Loss: 59.8381, Validation Accuracy: 0.5633\n",
            "Epoch 109/100, Loss: 36.4566, Validation Accuracy: 0.5793\n",
            "Epoch 110/100, Loss: 74.2227, Validation Accuracy: 0.5773\n",
            "Epoch 111/100, Loss: 226.7054, Validation Accuracy: 0.6560\n",
            "Epoch 112/100, Loss: 82.2959, Validation Accuracy: 0.5872\n",
            "Epoch 113/100, Loss: 115.5738, Validation Accuracy: 0.6271\n",
            "Epoch 114/100, Loss: 47.6387, Validation Accuracy: 0.6142\n",
            "Epoch 115/100, Loss: 82.5171, Validation Accuracy: 0.4656\n",
            "Epoch 116/100, Loss: 41.5205, Validation Accuracy: 0.5603\n",
            "Epoch 117/100, Loss: 78.9567, Validation Accuracy: 0.5892\n",
            "Epoch 118/100, Loss: 31.4198, Validation Accuracy: 0.5434\n",
            "Epoch 119/100, Loss: 31.2979, Validation Accuracy: 0.5494\n",
            "Epoch 120/100, Loss: 186.9701, Validation Accuracy: 0.6351\n",
            "Epoch 121/100, Loss: 78.6273, Validation Accuracy: 0.4706\n",
            "Epoch 122/100, Loss: 84.6158, Validation Accuracy: 0.6271\n",
            "Epoch 123/100, Loss: 112.8128, Validation Accuracy: 0.5234\n",
            "Epoch 124/100, Loss: 48.1536, Validation Accuracy: 0.6550\n",
            "Epoch 125/100, Loss: 39.8394, Validation Accuracy: 0.5823\n",
            "Epoch 126/100, Loss: 101.1766, Validation Accuracy: 0.6610\n",
            "Epoch 127/100, Loss: 46.0349, Validation Accuracy: 0.6740\n",
            "Epoch 128/100, Loss: 101.0344, Validation Accuracy: 0.5892\n",
            "Epoch 129/100, Loss: 64.8124, Validation Accuracy: 0.6092\n",
            "Epoch 130/100, Loss: 26.2481, Validation Accuracy: 0.5444\n",
            "Epoch 131/100, Loss: 199.7868, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 37.7536, Validation Accuracy: 0.4925\n",
            "Epoch 133/100, Loss: 30.5224, Validation Accuracy: 0.4875\n",
            "Epoch 134/100, Loss: 16.5182, Validation Accuracy: 0.6361\n",
            "Epoch 135/100, Loss: 15.5132, Validation Accuracy: 0.5533\n",
            "Epoch 136/100, Loss: 27.7264, Validation Accuracy: 0.6261\n",
            "Epoch 137/100, Loss: 61.6816, Validation Accuracy: 0.6500\n",
            "Epoch 138/100, Loss: 22.3833, Validation Accuracy: 0.5533\n",
            "Epoch 139/100, Loss: 28.1489, Validation Accuracy: 0.6500\n",
            "Epoch 140/100, Loss: 44.7339, Validation Accuracy: 0.5573\n",
            "Epoch 141/100, Loss: 91.5207, Validation Accuracy: 0.6261\n",
            "Epoch 142/100, Loss: 20.1666, Validation Accuracy: 0.6820\n",
            "Epoch 143/100, Loss: 51.0060, Validation Accuracy: 0.5613\n",
            "Epoch 144/100, Loss: 27.2772, Validation Accuracy: 0.5823\n",
            "Epoch 145/100, Loss: 10.6318, Validation Accuracy: 0.5663\n",
            "Epoch 146/100, Loss: 70.3834, Validation Accuracy: 0.5075\n",
            "Epoch 147/100, Loss: 28.7669, Validation Accuracy: 0.3769\n",
            "Epoch 148/100, Loss: 35.2311, Validation Accuracy: 0.5813\n",
            "Epoch 149/100, Loss: 103.9772, Validation Accuracy: 0.5474\n",
            "Epoch 150/100, Loss: 13.6447, Validation Accuracy: 0.6112\n",
            "Epoch 151/100, Loss: 53.9784, Validation Accuracy: 0.6002\n",
            "Epoch 152/100, Loss: 58.1692, Validation Accuracy: 0.6441\n",
            "Epoch 153/100, Loss: 28.4198, Validation Accuracy: 0.5573\n",
            "Epoch 154/100, Loss: 37.6544, Validation Accuracy: 0.2812\n",
            "Epoch 155/100, Loss: 83.1942, Validation Accuracy: 0.6361\n",
            "Epoch 156/100, Loss: 115.4901, Validation Accuracy: 0.5763\n",
            "Epoch 157/100, Loss: 41.6430, Validation Accuracy: 0.5743\n",
            "Epoch 158/100, Loss: 64.9586, Validation Accuracy: 0.5464\n",
            "Epoch 159/100, Loss: 74.7244, Validation Accuracy: 0.6221\n",
            "Epoch 160/100, Loss: 224.8518, Validation Accuracy: 0.6670\n",
            "Epoch 161/100, Loss: 40.0453, Validation Accuracy: 0.4955\n",
            "Epoch 162/100, Loss: 97.5414, Validation Accuracy: 0.6211\n",
            "Epoch 163/100, Loss: 18.8393, Validation Accuracy: 0.6351\n",
            "Epoch 164/100, Loss: 222.8389, Validation Accuracy: 0.5214\n",
            "Epoch 165/100, Loss: 56.6006, Validation Accuracy: 0.6132\n",
            "Epoch 166/100, Loss: 95.9803, Validation Accuracy: 0.6361\n",
            "Epoch 167/100, Loss: 113.9640, Validation Accuracy: 0.5214\n",
            "Epoch 168/100, Loss: 29.9838, Validation Accuracy: 0.6421\n",
            "Epoch 169/100, Loss: 140.9439, Validation Accuracy: 0.5184\n",
            "Epoch 170/100, Loss: 66.2814, Validation Accuracy: 0.6431\n",
            "Epoch 171/100, Loss: 24.2750, Validation Accuracy: 0.5613\n",
            "Epoch 172/100, Loss: 690.0856, Validation Accuracy: 0.5563\n",
            "Epoch 173/100, Loss: 69.4877, Validation Accuracy: 0.5713\n",
            "Epoch 174/100, Loss: 20.1193, Validation Accuracy: 0.6441\n",
            "Epoch 175/100, Loss: 30.7744, Validation Accuracy: 0.5613\n",
            "Epoch 176/100, Loss: 49.2891, Validation Accuracy: 0.5304\n",
            "Epoch 177/100, Loss: 18.1015, Validation Accuracy: 0.5573\n",
            "Epoch 178/100, Loss: 13.1290, Validation Accuracy: 0.5793\n",
            "Epoch 179/100, Loss: 17.0688, Validation Accuracy: 0.6321\n",
            "Epoch 180/100, Loss: 100.0308, Validation Accuracy: 0.6211\n",
            "Epoch 181/100, Loss: 47.4852, Validation Accuracy: 0.3769\n",
            "Epoch 182/100, Loss: 44.9249, Validation Accuracy: 0.6231\n",
            "Epoch 183/100, Loss: 27.0412, Validation Accuracy: 0.5912\n",
            "Epoch 184/100, Loss: 50.6439, Validation Accuracy: 0.5484\n",
            "Epoch 185/100, Loss: 101.2724, Validation Accuracy: 0.4227\n",
            "Epoch 186/100, Loss: 18.4996, Validation Accuracy: 0.6441\n",
            "Epoch 187/100, Loss: 102.6753, Validation Accuracy: 0.6550\n",
            "Epoch 188/100, Loss: 115.7184, Validation Accuracy: 0.6710\n",
            "Epoch 189/100, Loss: 85.8473, Validation Accuracy: 0.6431\n",
            "Epoch 190/100, Loss: 31.9200, Validation Accuracy: 0.5105\n",
            "Epoch 191/100, Loss: 234.4057, Validation Accuracy: 0.6680\n",
            "Epoch 192/100, Loss: 99.7627, Validation Accuracy: 0.6331\n",
            "Epoch 193/100, Loss: 66.3268, Validation Accuracy: 0.5912\n",
            "Epoch 194/100, Loss: 249.4560, Validation Accuracy: 0.4955\n",
            "Epoch 195/100, Loss: 71.6309, Validation Accuracy: 0.6102\n",
            "Epoch 196/100, Loss: 126.4568, Validation Accuracy: 0.5593\n",
            "Epoch 197/100, Loss: 300.6927, Validation Accuracy: 0.5803\n",
            "Epoch 198/100, Loss: 25.7042, Validation Accuracy: 0.5364\n",
            "Epoch 199/100, Loss: 79.4324, Validation Accuracy: 0.5045\n",
            "Epoch 200/100, Loss: 4244.4170, Validation Accuracy: 0.6500\n",
            "Reward for Child Model: 0.274688190289674\n",
            "Child_29:  {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, [3, 1, 2, 2, 3, 3, 1, 0, 2, 1, 1, 1, 2, 3, 3], 0.274688190289674\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 64, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=129024, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 24, 28]           1,024\n",
            "       BatchNorm2d-2           [-1, 64, 24, 28]             128\n",
            "            Conv2d-3           [-1, 48, 22, 28]           9,264\n",
            "       BatchNorm2d-4           [-1, 48, 22, 28]              96\n",
            "              ReLU-5           [-1, 48, 22, 28]               0\n",
            "            Conv2d-6           [-1, 64, 20, 28]           9,280\n",
            "       BatchNorm2d-7           [-1, 64, 20, 28]             128\n",
            "              ReLU-8           [-1, 64, 20, 28]               0\n",
            "            Conv2d-9           [-1, 64, 24, 28]           8,256\n",
            "      BatchNorm2d-10           [-1, 64, 24, 28]             128\n",
            "             ReLU-11           [-1, 64, 24, 28]               0\n",
            "           Conv2d-12           [-1, 64, 22, 26]          73,792\n",
            "      BatchNorm2d-13           [-1, 64, 22, 26]             128\n",
            "             ReLU-14           [-1, 64, 22, 26]               0\n",
            "           Linear-15                    [-1, 7]         903,175\n",
            "================================================================\n",
            "Total params: 1,005,399\n",
            "Trainable params: 1,005,399\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.98\n",
            "Params size (MB): 3.84\n",
            "Estimated Total Size (MB): 7.82\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 10.9600, Validation Accuracy: 0.6481\n",
            "Epoch 2/100, Loss: 22.1314, Validation Accuracy: 0.1675\n",
            "Epoch 3/100, Loss: 13.3392, Validation Accuracy: 0.3061\n",
            "Epoch 4/100, Loss: 138.6510, Validation Accuracy: 0.5603\n",
            "Epoch 5/100, Loss: 53.7713, Validation Accuracy: 0.4706\n",
            "Epoch 6/100, Loss: 15.4953, Validation Accuracy: 0.4985\n",
            "Epoch 7/100, Loss: 29.3327, Validation Accuracy: 0.6530\n",
            "Epoch 8/100, Loss: 15.6009, Validation Accuracy: 0.6690\n",
            "Epoch 9/100, Loss: 36.2876, Validation Accuracy: 0.6491\n",
            "Epoch 10/100, Loss: 118.3168, Validation Accuracy: 0.3390\n",
            "Epoch 11/100, Loss: 41.1082, Validation Accuracy: 0.6690\n",
            "Epoch 12/100, Loss: 57.3225, Validation Accuracy: 0.6431\n",
            "Epoch 13/100, Loss: 58.5561, Validation Accuracy: 0.5005\n",
            "Epoch 14/100, Loss: 46.2956, Validation Accuracy: 0.6181\n",
            "Epoch 15/100, Loss: 35.2098, Validation Accuracy: 0.4487\n",
            "Epoch 16/100, Loss: 99.0525, Validation Accuracy: 0.5753\n",
            "Epoch 17/100, Loss: 64.9428, Validation Accuracy: 0.5005\n",
            "Epoch 18/100, Loss: 32.6860, Validation Accuracy: 0.5603\n",
            "Epoch 19/100, Loss: 75.6035, Validation Accuracy: 0.6760\n",
            "Epoch 20/100, Loss: 47.4739, Validation Accuracy: 0.5484\n",
            "Epoch 21/100, Loss: 65.3508, Validation Accuracy: 0.4636\n",
            "Epoch 22/100, Loss: 98.9809, Validation Accuracy: 0.5194\n",
            "Epoch 23/100, Loss: 48.8339, Validation Accuracy: 0.5045\n",
            "Epoch 24/100, Loss: 6.7312, Validation Accuracy: 0.6241\n",
            "Epoch 25/100, Loss: 42.3358, Validation Accuracy: 0.5922\n",
            "Epoch 26/100, Loss: 101.1573, Validation Accuracy: 0.6112\n",
            "Epoch 27/100, Loss: 56.0066, Validation Accuracy: 0.6530\n",
            "Epoch 28/100, Loss: 88.5546, Validation Accuracy: 0.6321\n",
            "Epoch 29/100, Loss: 133.5114, Validation Accuracy: 0.6301\n",
            "Epoch 30/100, Loss: 118.3070, Validation Accuracy: 0.6171\n",
            "Epoch 31/100, Loss: 52.2634, Validation Accuracy: 0.5513\n",
            "Epoch 32/100, Loss: 88.7423, Validation Accuracy: 0.6341\n",
            "Epoch 33/100, Loss: 131.8161, Validation Accuracy: 0.6291\n",
            "Epoch 34/100, Loss: 22.2044, Validation Accuracy: 0.6062\n",
            "Epoch 35/100, Loss: 16.8486, Validation Accuracy: 0.5414\n",
            "Epoch 36/100, Loss: 113.7609, Validation Accuracy: 0.5474\n",
            "Epoch 37/100, Loss: 120.0063, Validation Accuracy: 0.6530\n",
            "Epoch 38/100, Loss: 60.3768, Validation Accuracy: 0.6391\n",
            "Epoch 39/100, Loss: 81.5847, Validation Accuracy: 0.6810\n",
            "Epoch 40/100, Loss: 75.8013, Validation Accuracy: 0.5503\n",
            "Epoch 41/100, Loss: 87.4990, Validation Accuracy: 0.3490\n",
            "Epoch 42/100, Loss: 65.1949, Validation Accuracy: 0.6311\n",
            "Epoch 43/100, Loss: 31.3003, Validation Accuracy: 0.6680\n",
            "Epoch 44/100, Loss: 145.0394, Validation Accuracy: 0.5613\n",
            "Epoch 45/100, Loss: 108.9608, Validation Accuracy: 0.6909\n",
            "Epoch 46/100, Loss: 25.4691, Validation Accuracy: 0.6142\n",
            "Epoch 47/100, Loss: 97.5114, Validation Accuracy: 0.6820\n",
            "Epoch 48/100, Loss: 33.8294, Validation Accuracy: 0.6132\n",
            "Epoch 49/100, Loss: 31.4017, Validation Accuracy: 0.6461\n",
            "Epoch 50/100, Loss: 38.6211, Validation Accuracy: 0.5932\n",
            "Epoch 51/100, Loss: 94.3145, Validation Accuracy: 0.6022\n",
            "Epoch 52/100, Loss: 119.7635, Validation Accuracy: 0.6421\n",
            "Epoch 53/100, Loss: 62.1422, Validation Accuracy: 0.6391\n",
            "Epoch 54/100, Loss: 11.7228, Validation Accuracy: 0.6122\n",
            "Epoch 55/100, Loss: 37.8727, Validation Accuracy: 0.6520\n",
            "Epoch 56/100, Loss: 127.5274, Validation Accuracy: 0.4975\n",
            "Epoch 57/100, Loss: 37.2314, Validation Accuracy: 0.6849\n",
            "Epoch 58/100, Loss: 68.1985, Validation Accuracy: 0.6171\n",
            "Epoch 59/100, Loss: 250.1488, Validation Accuracy: 0.6381\n",
            "Epoch 60/100, Loss: 92.7307, Validation Accuracy: 0.5623\n",
            "Epoch 61/100, Loss: 62.8425, Validation Accuracy: 0.6251\n",
            "Epoch 62/100, Loss: 42.4234, Validation Accuracy: 0.6221\n",
            "Epoch 63/100, Loss: 28.2006, Validation Accuracy: 0.5294\n",
            "Epoch 64/100, Loss: 87.3692, Validation Accuracy: 0.6331\n",
            "Epoch 65/100, Loss: 37.0680, Validation Accuracy: 0.6600\n",
            "Epoch 66/100, Loss: 86.5451, Validation Accuracy: 0.6191\n",
            "Epoch 67/100, Loss: 100.1064, Validation Accuracy: 0.5972\n",
            "Epoch 68/100, Loss: 71.2000, Validation Accuracy: 0.6580\n",
            "Epoch 69/100, Loss: 113.7187, Validation Accuracy: 0.6491\n",
            "Epoch 70/100, Loss: 162.0216, Validation Accuracy: 0.6351\n",
            "Epoch 71/100, Loss: 69.0984, Validation Accuracy: 0.6361\n",
            "Epoch 72/100, Loss: 79.9043, Validation Accuracy: 0.6082\n",
            "Epoch 73/100, Loss: 110.1052, Validation Accuracy: 0.4666\n",
            "Epoch 74/100, Loss: 68.1081, Validation Accuracy: 0.6520\n",
            "Epoch 75/100, Loss: 67.4792, Validation Accuracy: 0.6530\n",
            "Epoch 76/100, Loss: 41.1750, Validation Accuracy: 0.6082\n",
            "Epoch 77/100, Loss: 67.0511, Validation Accuracy: 0.6790\n",
            "Epoch 78/100, Loss: 104.3040, Validation Accuracy: 0.6830\n",
            "Epoch 79/100, Loss: 137.8054, Validation Accuracy: 0.5683\n",
            "Epoch 80/100, Loss: 111.1238, Validation Accuracy: 0.6640\n",
            "Epoch 81/100, Loss: 65.5067, Validation Accuracy: 0.6600\n",
            "Epoch 82/100, Loss: 38.6639, Validation Accuracy: 0.6670\n",
            "Epoch 83/100, Loss: 81.4450, Validation Accuracy: 0.6889\n",
            "Epoch 84/100, Loss: 89.8789, Validation Accuracy: 0.5643\n",
            "Epoch 85/100, Loss: 109.2375, Validation Accuracy: 0.5384\n",
            "Epoch 86/100, Loss: 56.4046, Validation Accuracy: 0.6301\n",
            "Epoch 87/100, Loss: 96.2104, Validation Accuracy: 0.5513\n",
            "Epoch 88/100, Loss: 30.1490, Validation Accuracy: 0.6231\n",
            "Epoch 89/100, Loss: 44.7815, Validation Accuracy: 0.4108\n",
            "Epoch 90/100, Loss: 121.1900, Validation Accuracy: 0.5563\n",
            "Epoch 91/100, Loss: 106.2346, Validation Accuracy: 0.6002\n",
            "Epoch 92/100, Loss: 41.9866, Validation Accuracy: 0.5753\n",
            "Epoch 93/100, Loss: 105.4535, Validation Accuracy: 0.6670\n",
            "Epoch 94/100, Loss: 130.0336, Validation Accuracy: 0.6281\n",
            "Epoch 95/100, Loss: 39.1514, Validation Accuracy: 0.6491\n",
            "Epoch 96/100, Loss: 60.9137, Validation Accuracy: 0.4875\n",
            "Epoch 97/100, Loss: 99.0863, Validation Accuracy: 0.6710\n",
            "Epoch 98/100, Loss: 42.9640, Validation Accuracy: 0.5942\n",
            "Epoch 99/100, Loss: 172.5934, Validation Accuracy: 0.5155\n",
            "Epoch 100/100, Loss: 79.0513, Validation Accuracy: 0.6899\n",
            "Epoch 101/100, Loss: 116.9276, Validation Accuracy: 0.6530\n",
            "Epoch 102/100, Loss: 61.3483, Validation Accuracy: 0.6680\n",
            "Epoch 103/100, Loss: 118.7649, Validation Accuracy: 0.6720\n",
            "Epoch 104/100, Loss: 22.7210, Validation Accuracy: 0.5653\n",
            "Epoch 105/100, Loss: 62.6786, Validation Accuracy: 0.5872\n",
            "Epoch 106/100, Loss: 41.4681, Validation Accuracy: 0.6600\n",
            "Epoch 107/100, Loss: 82.6334, Validation Accuracy: 0.6411\n",
            "Epoch 108/100, Loss: 23.4632, Validation Accuracy: 0.6889\n",
            "Epoch 109/100, Loss: 62.4561, Validation Accuracy: 0.5454\n",
            "Epoch 110/100, Loss: 42.7223, Validation Accuracy: 0.4905\n",
            "Epoch 111/100, Loss: 82.4549, Validation Accuracy: 0.6530\n",
            "Epoch 112/100, Loss: 100.2123, Validation Accuracy: 0.5743\n",
            "Epoch 113/100, Loss: 87.0285, Validation Accuracy: 0.5972\n",
            "Epoch 114/100, Loss: 75.6222, Validation Accuracy: 0.6162\n",
            "Epoch 115/100, Loss: 80.9038, Validation Accuracy: 0.6441\n",
            "Epoch 116/100, Loss: 24.3545, Validation Accuracy: 0.5992\n",
            "Epoch 117/100, Loss: 106.1405, Validation Accuracy: 0.6849\n",
            "Epoch 118/100, Loss: 157.1176, Validation Accuracy: 0.5852\n",
            "Epoch 119/100, Loss: 35.2811, Validation Accuracy: 0.3928\n",
            "Epoch 120/100, Loss: 106.6827, Validation Accuracy: 0.5194\n",
            "Epoch 121/100, Loss: 30.7103, Validation Accuracy: 0.5803\n",
            "Epoch 122/100, Loss: 98.9470, Validation Accuracy: 0.6411\n",
            "Epoch 123/100, Loss: 63.7158, Validation Accuracy: 0.6520\n",
            "Epoch 124/100, Loss: 59.7251, Validation Accuracy: 0.6600\n",
            "Epoch 125/100, Loss: 56.2301, Validation Accuracy: 0.6261\n",
            "Epoch 126/100, Loss: 89.5519, Validation Accuracy: 0.6381\n",
            "Epoch 127/100, Loss: 50.7528, Validation Accuracy: 0.6221\n",
            "Epoch 128/100, Loss: 37.9227, Validation Accuracy: 0.6411\n",
            "Epoch 129/100, Loss: 61.9179, Validation Accuracy: 0.5982\n",
            "Epoch 130/100, Loss: 46.2785, Validation Accuracy: 0.5852\n",
            "Epoch 131/100, Loss: 100.8515, Validation Accuracy: 0.5663\n",
            "Epoch 132/100, Loss: 93.7050, Validation Accuracy: 0.6211\n",
            "Epoch 133/100, Loss: 60.4832, Validation Accuracy: 0.6321\n",
            "Epoch 134/100, Loss: 153.0564, Validation Accuracy: 0.5902\n",
            "Epoch 135/100, Loss: 8.5432, Validation Accuracy: 0.6361\n",
            "Epoch 136/100, Loss: 62.9977, Validation Accuracy: 0.6371\n",
            "Epoch 137/100, Loss: 97.1254, Validation Accuracy: 0.6191\n",
            "Epoch 138/100, Loss: 145.7540, Validation Accuracy: 0.6291\n",
            "Epoch 139/100, Loss: 78.4371, Validation Accuracy: 0.6441\n",
            "Epoch 140/100, Loss: 222.3208, Validation Accuracy: 0.5015\n",
            "Epoch 141/100, Loss: 94.1020, Validation Accuracy: 0.6102\n",
            "Epoch 142/100, Loss: 78.3901, Validation Accuracy: 0.6391\n",
            "Epoch 143/100, Loss: 55.5876, Validation Accuracy: 0.5643\n",
            "Epoch 144/100, Loss: 96.7540, Validation Accuracy: 0.6660\n",
            "Epoch 145/100, Loss: 150.0853, Validation Accuracy: 0.6610\n",
            "Epoch 146/100, Loss: 31.7122, Validation Accuracy: 0.6331\n",
            "Epoch 147/100, Loss: 79.1692, Validation Accuracy: 0.6261\n",
            "Epoch 148/100, Loss: 80.0666, Validation Accuracy: 0.6201\n",
            "Epoch 149/100, Loss: 75.6667, Validation Accuracy: 0.5922\n",
            "Epoch 150/100, Loss: 81.9535, Validation Accuracy: 0.6431\n",
            "Epoch 151/100, Loss: 79.5078, Validation Accuracy: 0.4935\n",
            "Epoch 152/100, Loss: 38.9648, Validation Accuracy: 0.5075\n",
            "Epoch 153/100, Loss: 85.7419, Validation Accuracy: 0.6032\n",
            "Epoch 154/100, Loss: 94.8888, Validation Accuracy: 0.5833\n",
            "Epoch 155/100, Loss: 105.9622, Validation Accuracy: 0.6750\n",
            "Epoch 156/100, Loss: 75.8572, Validation Accuracy: 0.4407\n",
            "Epoch 157/100, Loss: 234.5319, Validation Accuracy: 0.5573\n",
            "Epoch 158/100, Loss: 127.6059, Validation Accuracy: 0.6152\n",
            "Epoch 159/100, Loss: 98.8941, Validation Accuracy: 0.6112\n",
            "Epoch 160/100, Loss: 111.8017, Validation Accuracy: 0.6451\n",
            "Epoch 161/100, Loss: 32.2738, Validation Accuracy: 0.5414\n",
            "Epoch 162/100, Loss: 70.5625, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 152.2024, Validation Accuracy: 0.6590\n",
            "Epoch 164/100, Loss: 129.7783, Validation Accuracy: 0.6251\n",
            "Epoch 165/100, Loss: 139.3397, Validation Accuracy: 0.5982\n",
            "Epoch 166/100, Loss: 72.6143, Validation Accuracy: 0.5793\n",
            "Epoch 167/100, Loss: 125.7226, Validation Accuracy: 0.6381\n",
            "Epoch 168/100, Loss: 43.8475, Validation Accuracy: 0.6680\n",
            "Epoch 169/100, Loss: 36.6367, Validation Accuracy: 0.6431\n",
            "Epoch 170/100, Loss: 85.5054, Validation Accuracy: 0.6162\n",
            "Epoch 171/100, Loss: 27.5317, Validation Accuracy: 0.5753\n",
            "Epoch 172/100, Loss: 46.9447, Validation Accuracy: 0.6530\n",
            "Epoch 173/100, Loss: 47.7595, Validation Accuracy: 0.6401\n",
            "Epoch 174/100, Loss: 119.1854, Validation Accuracy: 0.5484\n",
            "Epoch 175/100, Loss: 72.0134, Validation Accuracy: 0.6032\n",
            "Epoch 176/100, Loss: 106.0992, Validation Accuracy: 0.6670\n",
            "Epoch 177/100, Loss: 68.9153, Validation Accuracy: 0.6391\n",
            "Epoch 178/100, Loss: 78.2337, Validation Accuracy: 0.6849\n",
            "Epoch 179/100, Loss: 58.1733, Validation Accuracy: 0.6341\n",
            "Epoch 180/100, Loss: 116.7584, Validation Accuracy: 0.6600\n",
            "Epoch 181/100, Loss: 123.0570, Validation Accuracy: 0.5264\n",
            "Epoch 182/100, Loss: 66.2926, Validation Accuracy: 0.6271\n",
            "Epoch 183/100, Loss: 84.4330, Validation Accuracy: 0.6052\n",
            "Epoch 184/100, Loss: 24.3106, Validation Accuracy: 0.6201\n",
            "Epoch 185/100, Loss: 138.2717, Validation Accuracy: 0.6122\n",
            "Epoch 186/100, Loss: 129.4351, Validation Accuracy: 0.5912\n",
            "Epoch 187/100, Loss: 128.0717, Validation Accuracy: 0.5962\n",
            "Epoch 188/100, Loss: 81.8598, Validation Accuracy: 0.5643\n",
            "Epoch 189/100, Loss: 52.3428, Validation Accuracy: 0.5214\n",
            "Epoch 190/100, Loss: 66.5973, Validation Accuracy: 0.6251\n",
            "Epoch 191/100, Loss: 9.8238, Validation Accuracy: 0.6361\n",
            "Epoch 192/100, Loss: 24.3490, Validation Accuracy: 0.6500\n",
            "Epoch 193/100, Loss: 47.5028, Validation Accuracy: 0.5803\n",
            "Epoch 194/100, Loss: 119.0980, Validation Accuracy: 0.6700\n",
            "Epoch 195/100, Loss: 67.9961, Validation Accuracy: 0.6560\n",
            "Epoch 196/100, Loss: 145.8597, Validation Accuracy: 0.6491\n",
            "Epoch 197/100, Loss: 118.8157, Validation Accuracy: 0.6022\n",
            "Epoch 198/100, Loss: 130.2152, Validation Accuracy: 0.6142\n",
            "Epoch 199/100, Loss: 44.3259, Validation Accuracy: 0.5992\n",
            "Epoch 200/100, Loss: 63.7094, Validation Accuracy: 0.6610\n",
            "Reward for Child Model: 0.2888269978917027\n",
            "Child_30:  {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, [2, 0, 3, 1, 0, 2, 1, 0, 3, 0, 0, 3, 1, 1, 3], 0.2888269978917027\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 24, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(72, 36, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(108, 24, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(144, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=225792, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 24, 28]             768\n",
            "       BatchNorm2d-2           [-1, 48, 24, 28]              96\n",
            "            Conv2d-3           [-1, 24, 20, 26]          17,304\n",
            "       BatchNorm2d-4           [-1, 24, 20, 26]              48\n",
            "              ReLU-5           [-1, 24, 20, 26]               0\n",
            "            Conv2d-6           [-1, 36, 24, 26]           7,812\n",
            "       BatchNorm2d-7           [-1, 36, 24, 26]              72\n",
            "              ReLU-8           [-1, 36, 24, 26]               0\n",
            "            Conv2d-9           [-1, 24, 22, 26]          23,352\n",
            "      BatchNorm2d-10           [-1, 24, 22, 26]              48\n",
            "             ReLU-11           [-1, 24, 22, 26]               0\n",
            "           Conv2d-12           [-1, 36, 20, 24]         129,636\n",
            "      BatchNorm2d-13           [-1, 36, 20, 24]              72\n",
            "             ReLU-14           [-1, 36, 20, 24]               0\n",
            "           Linear-15                    [-1, 7]       1,580,551\n",
            "================================================================\n",
            "Total params: 1,759,759\n",
            "Trainable params: 1,759,759\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.00\n",
            "Params size (MB): 6.71\n",
            "Estimated Total Size (MB): 8.72\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 29.6391, Validation Accuracy: 0.4606\n",
            "Epoch 2/100, Loss: 193.2692, Validation Accuracy: 0.5703\n",
            "Epoch 3/100, Loss: 34.3265, Validation Accuracy: 0.4586\n",
            "Epoch 4/100, Loss: 31.9009, Validation Accuracy: 0.6211\n",
            "Epoch 5/100, Loss: 32.6147, Validation Accuracy: 0.5254\n",
            "Epoch 6/100, Loss: 182.6921, Validation Accuracy: 0.6281\n",
            "Epoch 7/100, Loss: 212.7425, Validation Accuracy: 0.6052\n",
            "Epoch 8/100, Loss: 70.6477, Validation Accuracy: 0.5613\n",
            "Epoch 9/100, Loss: 229.5575, Validation Accuracy: 0.5543\n",
            "Epoch 10/100, Loss: 90.8827, Validation Accuracy: 0.4845\n",
            "Epoch 11/100, Loss: 100.9775, Validation Accuracy: 0.4885\n",
            "Epoch 12/100, Loss: 308.8864, Validation Accuracy: 0.6800\n",
            "Epoch 13/100, Loss: 28.9773, Validation Accuracy: 0.1665\n",
            "Epoch 14/100, Loss: 192.9254, Validation Accuracy: 0.6201\n",
            "Epoch 15/100, Loss: 115.0675, Validation Accuracy: 0.5823\n",
            "Epoch 16/100, Loss: 73.3256, Validation Accuracy: 0.6560\n",
            "Epoch 17/100, Loss: 247.3121, Validation Accuracy: 0.5304\n",
            "Epoch 18/100, Loss: 366.2900, Validation Accuracy: 0.5852\n",
            "Epoch 19/100, Loss: 383.3370, Validation Accuracy: 0.3051\n",
            "Epoch 20/100, Loss: 145.5399, Validation Accuracy: 0.6281\n",
            "Epoch 21/100, Loss: 67.1624, Validation Accuracy: 0.6550\n",
            "Epoch 22/100, Loss: 282.8879, Validation Accuracy: 0.6441\n",
            "Epoch 23/100, Loss: 119.3176, Validation Accuracy: 0.5803\n",
            "Epoch 24/100, Loss: 318.0254, Validation Accuracy: 0.5284\n",
            "Epoch 25/100, Loss: 117.7022, Validation Accuracy: 0.3938\n",
            "Epoch 26/100, Loss: 113.6281, Validation Accuracy: 0.6481\n",
            "Epoch 27/100, Loss: 232.1021, Validation Accuracy: 0.5902\n",
            "Epoch 28/100, Loss: 148.0804, Validation Accuracy: 0.5673\n",
            "Epoch 29/100, Loss: 129.5850, Validation Accuracy: 0.4666\n",
            "Epoch 30/100, Loss: 440.8399, Validation Accuracy: 0.4995\n",
            "Epoch 31/100, Loss: 77.4578, Validation Accuracy: 0.3589\n",
            "Epoch 32/100, Loss: 321.6204, Validation Accuracy: 0.6640\n",
            "Epoch 33/100, Loss: 66.4331, Validation Accuracy: 0.6062\n",
            "Epoch 34/100, Loss: 126.1407, Validation Accuracy: 0.6311\n",
            "Epoch 35/100, Loss: 148.5646, Validation Accuracy: 0.5813\n",
            "Epoch 36/100, Loss: 140.0501, Validation Accuracy: 0.2772\n",
            "Epoch 37/100, Loss: 136.9700, Validation Accuracy: 0.4895\n",
            "Epoch 38/100, Loss: 110.6827, Validation Accuracy: 0.6491\n",
            "Epoch 39/100, Loss: 146.0704, Validation Accuracy: 0.6371\n",
            "Epoch 40/100, Loss: 141.2304, Validation Accuracy: 0.5813\n",
            "Epoch 41/100, Loss: 98.8340, Validation Accuracy: 0.4138\n",
            "Epoch 42/100, Loss: 230.2885, Validation Accuracy: 0.6331\n",
            "Epoch 43/100, Loss: 119.6213, Validation Accuracy: 0.5723\n",
            "Epoch 44/100, Loss: 86.5403, Validation Accuracy: 0.4816\n",
            "Epoch 45/100, Loss: 70.5498, Validation Accuracy: 0.4556\n",
            "Epoch 46/100, Loss: 127.5754, Validation Accuracy: 0.3360\n",
            "Epoch 47/100, Loss: 226.7842, Validation Accuracy: 0.5743\n",
            "Epoch 48/100, Loss: 145.9969, Validation Accuracy: 0.4816\n",
            "Epoch 49/100, Loss: 72.2841, Validation Accuracy: 0.5593\n",
            "Epoch 50/100, Loss: 148.6035, Validation Accuracy: 0.6231\n",
            "Epoch 51/100, Loss: 173.3818, Validation Accuracy: 0.6032\n",
            "Epoch 52/100, Loss: 143.5709, Validation Accuracy: 0.5095\n",
            "Epoch 53/100, Loss: 61.7203, Validation Accuracy: 0.5623\n",
            "Epoch 54/100, Loss: 276.6697, Validation Accuracy: 0.1765\n",
            "Epoch 55/100, Loss: 193.7991, Validation Accuracy: 0.6620\n",
            "Epoch 56/100, Loss: 58.0312, Validation Accuracy: 0.6112\n",
            "Epoch 57/100, Loss: 221.3405, Validation Accuracy: 0.6491\n",
            "Epoch 58/100, Loss: 86.2168, Validation Accuracy: 0.4397\n",
            "Epoch 59/100, Loss: 114.6042, Validation Accuracy: 0.6620\n",
            "Epoch 60/100, Loss: 145.6313, Validation Accuracy: 0.5105\n",
            "Epoch 61/100, Loss: 303.6113, Validation Accuracy: 0.6162\n",
            "Epoch 62/100, Loss: 136.8961, Validation Accuracy: 0.6191\n",
            "Epoch 63/100, Loss: 225.7160, Validation Accuracy: 0.6361\n",
            "Epoch 64/100, Loss: 251.0890, Validation Accuracy: 0.6231\n",
            "Epoch 65/100, Loss: 179.1359, Validation Accuracy: 0.5723\n",
            "Epoch 66/100, Loss: 172.8659, Validation Accuracy: 0.4098\n",
            "Epoch 67/100, Loss: 136.5446, Validation Accuracy: 0.5145\n",
            "Epoch 68/100, Loss: 126.6643, Validation Accuracy: 0.4885\n",
            "Epoch 69/100, Loss: 176.8075, Validation Accuracy: 0.4945\n",
            "Epoch 70/100, Loss: 316.4797, Validation Accuracy: 0.6271\n",
            "Epoch 71/100, Loss: 216.1419, Validation Accuracy: 0.4506\n",
            "Epoch 72/100, Loss: 171.9416, Validation Accuracy: 0.6032\n",
            "Epoch 73/100, Loss: 175.2948, Validation Accuracy: 0.6540\n",
            "Epoch 74/100, Loss: 253.8643, Validation Accuracy: 0.6620\n",
            "Epoch 75/100, Loss: 62.9333, Validation Accuracy: 0.3051\n",
            "Epoch 76/100, Loss: 169.9118, Validation Accuracy: 0.6520\n",
            "Epoch 77/100, Loss: 391.5735, Validation Accuracy: 0.6291\n",
            "Epoch 78/100, Loss: 282.2193, Validation Accuracy: 0.5922\n",
            "Epoch 79/100, Loss: 89.5954, Validation Accuracy: 0.5633\n",
            "Epoch 80/100, Loss: 86.4009, Validation Accuracy: 0.6471\n",
            "Epoch 81/100, Loss: 110.9913, Validation Accuracy: 0.6411\n",
            "Epoch 82/100, Loss: 256.1351, Validation Accuracy: 0.6062\n",
            "Epoch 83/100, Loss: 158.3533, Validation Accuracy: 0.3669\n",
            "Epoch 84/100, Loss: 158.8703, Validation Accuracy: 0.5703\n",
            "Epoch 85/100, Loss: 220.9682, Validation Accuracy: 0.6550\n",
            "Epoch 86/100, Loss: 172.6767, Validation Accuracy: 0.3410\n",
            "Epoch 87/100, Loss: 71.4466, Validation Accuracy: 0.6471\n",
            "Epoch 88/100, Loss: 175.3986, Validation Accuracy: 0.4437\n",
            "Epoch 89/100, Loss: 186.5126, Validation Accuracy: 0.6570\n",
            "Epoch 90/100, Loss: 31.2608, Validation Accuracy: 0.5434\n",
            "Epoch 91/100, Loss: 34.5080, Validation Accuracy: 0.6720\n",
            "Epoch 92/100, Loss: 184.3642, Validation Accuracy: 0.5424\n",
            "Epoch 93/100, Loss: 297.7426, Validation Accuracy: 0.4905\n",
            "Epoch 94/100, Loss: 265.2313, Validation Accuracy: 0.6102\n",
            "Epoch 95/100, Loss: 125.8386, Validation Accuracy: 0.5653\n",
            "Epoch 96/100, Loss: 145.2882, Validation Accuracy: 0.6122\n",
            "Epoch 97/100, Loss: 271.5818, Validation Accuracy: 0.6660\n",
            "Epoch 98/100, Loss: 252.8285, Validation Accuracy: 0.5842\n",
            "Epoch 99/100, Loss: 188.5937, Validation Accuracy: 0.6042\n",
            "Epoch 100/100, Loss: 201.9770, Validation Accuracy: 0.5623\n",
            "Epoch 101/100, Loss: 619.1541, Validation Accuracy: 0.5902\n",
            "Epoch 102/100, Loss: 218.7987, Validation Accuracy: 0.5833\n",
            "Epoch 103/100, Loss: 315.0712, Validation Accuracy: 0.3330\n",
            "Epoch 104/100, Loss: 186.2769, Validation Accuracy: 0.6162\n",
            "Epoch 105/100, Loss: 110.4603, Validation Accuracy: 0.6281\n",
            "Epoch 106/100, Loss: 219.9511, Validation Accuracy: 0.6281\n",
            "Epoch 107/100, Loss: 143.7459, Validation Accuracy: 0.5902\n",
            "Epoch 108/100, Loss: 44.8424, Validation Accuracy: 0.5663\n",
            "Epoch 109/100, Loss: 748.9747, Validation Accuracy: 0.5464\n",
            "Epoch 110/100, Loss: 778.5656, Validation Accuracy: 0.6281\n",
            "Epoch 111/100, Loss: 248.8065, Validation Accuracy: 0.3490\n",
            "Epoch 112/100, Loss: 189.1482, Validation Accuracy: 0.5842\n",
            "Epoch 113/100, Loss: 46.7850, Validation Accuracy: 0.5962\n",
            "Epoch 114/100, Loss: 103.8124, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 187.3134, Validation Accuracy: 0.6820\n",
            "Epoch 116/100, Loss: 411.3060, Validation Accuracy: 0.6411\n",
            "Epoch 117/100, Loss: 290.9384, Validation Accuracy: 0.5793\n",
            "Epoch 118/100, Loss: 159.3134, Validation Accuracy: 0.5613\n",
            "Epoch 119/100, Loss: 145.0342, Validation Accuracy: 0.5294\n",
            "Epoch 120/100, Loss: 256.7285, Validation Accuracy: 0.5533\n",
            "Epoch 121/100, Loss: 200.0814, Validation Accuracy: 0.6411\n",
            "Epoch 122/100, Loss: 183.5859, Validation Accuracy: 0.5833\n",
            "Epoch 123/100, Loss: 259.8308, Validation Accuracy: 0.6271\n",
            "Epoch 124/100, Loss: 132.5196, Validation Accuracy: 0.6630\n",
            "Epoch 125/100, Loss: 300.7737, Validation Accuracy: 0.6740\n",
            "Epoch 126/100, Loss: 482.9085, Validation Accuracy: 0.5165\n",
            "Epoch 127/100, Loss: 190.7398, Validation Accuracy: 0.5793\n",
            "Epoch 128/100, Loss: 325.1270, Validation Accuracy: 0.6441\n",
            "Epoch 129/100, Loss: 226.8279, Validation Accuracy: 0.6770\n",
            "Epoch 130/100, Loss: 153.6305, Validation Accuracy: 0.6431\n",
            "Epoch 131/100, Loss: 647.8555, Validation Accuracy: 0.5543\n",
            "Epoch 132/100, Loss: 138.1709, Validation Accuracy: 0.6132\n",
            "Epoch 133/100, Loss: 111.9016, Validation Accuracy: 0.6221\n",
            "Epoch 134/100, Loss: 161.6380, Validation Accuracy: 0.6251\n",
            "Epoch 135/100, Loss: 280.9072, Validation Accuracy: 0.6371\n",
            "Epoch 136/100, Loss: 399.6395, Validation Accuracy: 0.2004\n",
            "Epoch 137/100, Loss: 219.6602, Validation Accuracy: 0.6191\n",
            "Epoch 138/100, Loss: 334.8468, Validation Accuracy: 0.4985\n",
            "Epoch 139/100, Loss: 222.1382, Validation Accuracy: 0.5723\n",
            "Epoch 140/100, Loss: 421.6832, Validation Accuracy: 0.6381\n",
            "Epoch 141/100, Loss: 212.7259, Validation Accuracy: 0.6261\n",
            "Epoch 142/100, Loss: 113.6860, Validation Accuracy: 0.2662\n",
            "Epoch 143/100, Loss: 196.4356, Validation Accuracy: 0.3180\n",
            "Epoch 144/100, Loss: 330.9651, Validation Accuracy: 0.6181\n",
            "Epoch 145/100, Loss: 246.6873, Validation Accuracy: 0.6351\n",
            "Epoch 146/100, Loss: 205.2755, Validation Accuracy: 0.6032\n",
            "Epoch 147/100, Loss: 146.0126, Validation Accuracy: 0.6830\n",
            "Epoch 148/100, Loss: 136.3212, Validation Accuracy: 0.5065\n",
            "Epoch 149/100, Loss: 166.6107, Validation Accuracy: 0.6391\n",
            "Epoch 150/100, Loss: 192.2132, Validation Accuracy: 0.6570\n",
            "Epoch 151/100, Loss: 381.1606, Validation Accuracy: 0.5444\n",
            "Epoch 152/100, Loss: 177.9130, Validation Accuracy: 0.4257\n",
            "Epoch 153/100, Loss: 267.1656, Validation Accuracy: 0.5105\n",
            "Epoch 154/100, Loss: 336.4051, Validation Accuracy: 0.6770\n",
            "Epoch 155/100, Loss: 228.5167, Validation Accuracy: 0.6012\n",
            "Epoch 156/100, Loss: 231.0272, Validation Accuracy: 0.6710\n",
            "Epoch 157/100, Loss: 233.0003, Validation Accuracy: 0.4506\n",
            "Epoch 158/100, Loss: 123.3921, Validation Accuracy: 0.5962\n",
            "Epoch 159/100, Loss: 117.1052, Validation Accuracy: 0.5932\n",
            "Epoch 160/100, Loss: 237.8026, Validation Accuracy: 0.6191\n",
            "Epoch 161/100, Loss: 117.7047, Validation Accuracy: 0.4766\n",
            "Epoch 162/100, Loss: 157.3886, Validation Accuracy: 0.5334\n",
            "Epoch 163/100, Loss: 293.9386, Validation Accuracy: 0.6082\n",
            "Epoch 164/100, Loss: 174.1757, Validation Accuracy: 0.6251\n",
            "Epoch 165/100, Loss: 293.8072, Validation Accuracy: 0.6231\n",
            "Epoch 166/100, Loss: 207.2162, Validation Accuracy: 0.5972\n",
            "Epoch 167/100, Loss: 179.7734, Validation Accuracy: 0.6221\n",
            "Epoch 168/100, Loss: 459.3403, Validation Accuracy: 0.5902\n",
            "Epoch 169/100, Loss: 239.0715, Validation Accuracy: 0.6510\n",
            "Epoch 170/100, Loss: 188.6735, Validation Accuracy: 0.5135\n",
            "Epoch 171/100, Loss: 142.5158, Validation Accuracy: 0.6391\n",
            "Epoch 172/100, Loss: 410.2751, Validation Accuracy: 0.6401\n",
            "Epoch 173/100, Loss: 161.5342, Validation Accuracy: 0.4855\n",
            "Epoch 174/100, Loss: 116.2996, Validation Accuracy: 0.6431\n",
            "Epoch 175/100, Loss: 278.8730, Validation Accuracy: 0.4816\n",
            "Epoch 176/100, Loss: 73.4996, Validation Accuracy: 0.6560\n",
            "Epoch 177/100, Loss: 129.4864, Validation Accuracy: 0.6152\n",
            "Epoch 178/100, Loss: 273.5648, Validation Accuracy: 0.5055\n",
            "Epoch 179/100, Loss: 128.9059, Validation Accuracy: 0.6251\n",
            "Epoch 180/100, Loss: 163.5525, Validation Accuracy: 0.6321\n",
            "Epoch 181/100, Loss: 163.4004, Validation Accuracy: 0.5962\n",
            "Epoch 182/100, Loss: 157.7129, Validation Accuracy: 0.6660\n",
            "Epoch 183/100, Loss: 149.0871, Validation Accuracy: 0.5803\n",
            "Epoch 184/100, Loss: 162.7705, Validation Accuracy: 0.6441\n",
            "Epoch 185/100, Loss: 170.7906, Validation Accuracy: 0.4776\n",
            "Epoch 186/100, Loss: 385.2838, Validation Accuracy: 0.6780\n",
            "Epoch 187/100, Loss: 58.3082, Validation Accuracy: 0.5842\n",
            "Epoch 188/100, Loss: 479.4688, Validation Accuracy: 0.6211\n",
            "Epoch 189/100, Loss: 394.6404, Validation Accuracy: 0.6062\n",
            "Epoch 190/100, Loss: 570.7255, Validation Accuracy: 0.6122\n",
            "Epoch 191/100, Loss: 365.5340, Validation Accuracy: 0.6102\n",
            "Epoch 192/100, Loss: 197.0825, Validation Accuracy: 0.5174\n",
            "Epoch 193/100, Loss: 128.0284, Validation Accuracy: 0.6231\n",
            "Epoch 194/100, Loss: 91.4740, Validation Accuracy: 0.6301\n",
            "Epoch 195/100, Loss: 197.2982, Validation Accuracy: 0.5354\n",
            "Epoch 196/100, Loss: 33.4758, Validation Accuracy: 0.5364\n",
            "Epoch 197/100, Loss: 513.8815, Validation Accuracy: 0.6112\n",
            "Epoch 198/100, Loss: 114.0354, Validation Accuracy: 0.6132\n",
            "Epoch 199/100, Loss: 103.0353, Validation Accuracy: 0.6371\n",
            "Epoch 200/100, Loss: 226.6299, Validation Accuracy: 0.6341\n",
            "Reward for Child Model: 0.258582884321492\n",
            "Child_31:  {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, [2, 0, 2, 2, 1, 0, 0, 1, 1, 1, 1, 0, 2, 2, 1], 0.258582884321492\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 36, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(120, 24, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(72, 64, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=160160, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 26, 28]             360\n",
            "       BatchNorm2d-2           [-1, 36, 26, 28]              72\n",
            "            Conv2d-3           [-1, 48, 24, 28]           5,232\n",
            "       BatchNorm2d-4           [-1, 48, 24, 28]              96\n",
            "              ReLU-5           [-1, 48, 24, 28]               0\n",
            "            Conv2d-6           [-1, 36, 18, 26]          36,324\n",
            "       BatchNorm2d-7           [-1, 36, 18, 26]              72\n",
            "              ReLU-8           [-1, 36, 18, 26]               0\n",
            "            Conv2d-9           [-1, 24, 22, 22]         100,824\n",
            "      BatchNorm2d-10           [-1, 24, 22, 22]              48\n",
            "             ReLU-11           [-1, 24, 22, 22]               0\n",
            "           Conv2d-12           [-1, 64, 22, 28]          13,888\n",
            "      BatchNorm2d-13           [-1, 64, 22, 28]             128\n",
            "             ReLU-14           [-1, 64, 22, 28]               0\n",
            "           Linear-15                    [-1, 7]       1,121,127\n",
            "================================================================\n",
            "Total params: 1,278,171\n",
            "Trainable params: 1,278,171\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.69\n",
            "Params size (MB): 4.88\n",
            "Estimated Total Size (MB): 7.58\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 16.6591, Validation Accuracy: 0.4367\n",
            "Epoch 2/100, Loss: 1.3614, Validation Accuracy: 0.5045\n",
            "Epoch 3/100, Loss: 8.2200, Validation Accuracy: 0.2483\n",
            "Epoch 4/100, Loss: 54.0270, Validation Accuracy: 0.4078\n",
            "Epoch 5/100, Loss: 21.7723, Validation Accuracy: 0.6600\n",
            "Epoch 6/100, Loss: 22.3148, Validation Accuracy: 0.6391\n",
            "Epoch 7/100, Loss: 1694.5220, Validation Accuracy: 0.6201\n",
            "Epoch 8/100, Loss: 1284.6833, Validation Accuracy: 0.5454\n",
            "Epoch 9/100, Loss: 767.3934, Validation Accuracy: 0.6371\n",
            "Epoch 10/100, Loss: 761.8565, Validation Accuracy: 0.6241\n",
            "Epoch 11/100, Loss: 116.6977, Validation Accuracy: 0.6112\n",
            "Epoch 12/100, Loss: 196.7153, Validation Accuracy: 0.6171\n",
            "Epoch 13/100, Loss: 93.3000, Validation Accuracy: 0.5603\n",
            "Epoch 14/100, Loss: 158.5359, Validation Accuracy: 0.6580\n",
            "Epoch 15/100, Loss: 25.4562, Validation Accuracy: 0.6550\n",
            "Epoch 16/100, Loss: 21.1986, Validation Accuracy: 0.6012\n",
            "Epoch 17/100, Loss: 22.2423, Validation Accuracy: 0.6221\n",
            "Epoch 18/100, Loss: 28.4404, Validation Accuracy: 0.5633\n",
            "Epoch 19/100, Loss: 15.7328, Validation Accuracy: 0.6570\n",
            "Epoch 20/100, Loss: 7.3960, Validation Accuracy: 0.5254\n",
            "Epoch 21/100, Loss: 25.7068, Validation Accuracy: 0.5284\n",
            "Epoch 22/100, Loss: 4.2576, Validation Accuracy: 0.6461\n",
            "Epoch 23/100, Loss: 7.1773, Validation Accuracy: 0.6012\n",
            "Epoch 24/100, Loss: 15.9677, Validation Accuracy: 0.6311\n",
            "Epoch 25/100, Loss: 6.8125, Validation Accuracy: 0.6401\n",
            "Epoch 26/100, Loss: 8.7312, Validation Accuracy: 0.5643\n",
            "Epoch 27/100, Loss: 4.4139, Validation Accuracy: 0.6451\n",
            "Epoch 28/100, Loss: 4.8895, Validation Accuracy: 0.4865\n",
            "Epoch 29/100, Loss: 23.6336, Validation Accuracy: 0.6780\n",
            "Epoch 30/100, Loss: 20.9328, Validation Accuracy: 0.5035\n",
            "Epoch 31/100, Loss: 11.4577, Validation Accuracy: 0.5783\n",
            "Epoch 32/100, Loss: 10.6186, Validation Accuracy: 0.4307\n",
            "Epoch 33/100, Loss: 20.8953, Validation Accuracy: 0.4975\n",
            "Epoch 34/100, Loss: 39.5963, Validation Accuracy: 0.6680\n",
            "Epoch 35/100, Loss: 8.7246, Validation Accuracy: 0.6830\n",
            "Epoch 36/100, Loss: 23.9372, Validation Accuracy: 0.5015\n",
            "Epoch 37/100, Loss: 8.4907, Validation Accuracy: 0.6919\n",
            "Epoch 38/100, Loss: 19.7508, Validation Accuracy: 0.5982\n",
            "Epoch 39/100, Loss: 52.6456, Validation Accuracy: 0.5803\n",
            "Epoch 40/100, Loss: 20.6482, Validation Accuracy: 0.3500\n",
            "Epoch 41/100, Loss: 107.7519, Validation Accuracy: 0.6461\n",
            "Epoch 42/100, Loss: 32.8471, Validation Accuracy: 0.5623\n",
            "Epoch 43/100, Loss: 9.7022, Validation Accuracy: 0.4447\n",
            "Epoch 44/100, Loss: 183.3693, Validation Accuracy: 0.5184\n",
            "Epoch 45/100, Loss: 32.0080, Validation Accuracy: 0.5593\n",
            "Epoch 46/100, Loss: 20.6918, Validation Accuracy: 0.6082\n",
            "Epoch 47/100, Loss: 16.2935, Validation Accuracy: 0.4726\n",
            "Epoch 48/100, Loss: 11.7963, Validation Accuracy: 0.6221\n",
            "Epoch 49/100, Loss: 45.8768, Validation Accuracy: 0.6321\n",
            "Epoch 50/100, Loss: 10.2864, Validation Accuracy: 0.3908\n",
            "Epoch 51/100, Loss: 7.2798, Validation Accuracy: 0.5105\n",
            "Epoch 52/100, Loss: 43.4170, Validation Accuracy: 0.6132\n",
            "Epoch 53/100, Loss: 28.8866, Validation Accuracy: 0.4875\n",
            "Epoch 54/100, Loss: 84.4260, Validation Accuracy: 0.6481\n",
            "Epoch 55/100, Loss: 51.5714, Validation Accuracy: 0.6221\n",
            "Epoch 56/100, Loss: 14.9680, Validation Accuracy: 0.6152\n",
            "Epoch 57/100, Loss: 17.2371, Validation Accuracy: 0.6082\n",
            "Epoch 58/100, Loss: 29.7842, Validation Accuracy: 0.6171\n",
            "Epoch 59/100, Loss: 9.7585, Validation Accuracy: 0.6301\n",
            "Epoch 60/100, Loss: 9.9971, Validation Accuracy: 0.6630\n",
            "Epoch 61/100, Loss: 86.1513, Validation Accuracy: 0.4925\n",
            "Epoch 62/100, Loss: 51.6188, Validation Accuracy: 0.5753\n",
            "Epoch 63/100, Loss: 23.5645, Validation Accuracy: 0.3509\n",
            "Epoch 64/100, Loss: 53.8861, Validation Accuracy: 0.6610\n",
            "Epoch 65/100, Loss: 19.9882, Validation Accuracy: 0.6102\n",
            "Epoch 66/100, Loss: 30.3774, Validation Accuracy: 0.3699\n",
            "Epoch 67/100, Loss: 41.1004, Validation Accuracy: 0.6351\n",
            "Epoch 68/100, Loss: 34.3424, Validation Accuracy: 0.6839\n",
            "Epoch 69/100, Loss: 32.1780, Validation Accuracy: 0.4018\n",
            "Epoch 70/100, Loss: 34.1282, Validation Accuracy: 0.4467\n",
            "Epoch 71/100, Loss: 32.7801, Validation Accuracy: 0.4995\n",
            "Epoch 72/100, Loss: 27.4341, Validation Accuracy: 0.6331\n",
            "Epoch 73/100, Loss: 20.9351, Validation Accuracy: 0.6022\n",
            "Epoch 74/100, Loss: 29.1630, Validation Accuracy: 0.6740\n",
            "Epoch 75/100, Loss: 44.0142, Validation Accuracy: 0.5274\n",
            "Epoch 76/100, Loss: 22.4189, Validation Accuracy: 0.6620\n",
            "Epoch 77/100, Loss: 36.4800, Validation Accuracy: 0.5543\n",
            "Epoch 78/100, Loss: 56.7782, Validation Accuracy: 0.5693\n",
            "Epoch 79/100, Loss: 11.6348, Validation Accuracy: 0.6580\n",
            "Epoch 80/100, Loss: 47.1036, Validation Accuracy: 0.5284\n",
            "Epoch 81/100, Loss: 70.4664, Validation Accuracy: 0.4666\n",
            "Epoch 82/100, Loss: 32.9676, Validation Accuracy: 0.6301\n",
            "Epoch 83/100, Loss: 20.7464, Validation Accuracy: 0.6191\n",
            "Epoch 84/100, Loss: 24.6027, Validation Accuracy: 0.6201\n",
            "Epoch 85/100, Loss: 93.8904, Validation Accuracy: 0.5673\n",
            "Epoch 86/100, Loss: 21.1639, Validation Accuracy: 0.5404\n",
            "Epoch 87/100, Loss: 24.7856, Validation Accuracy: 0.6201\n",
            "Epoch 88/100, Loss: 53.3013, Validation Accuracy: 0.3141\n",
            "Epoch 89/100, Loss: 44.2896, Validation Accuracy: 0.6520\n",
            "Epoch 90/100, Loss: 58.7436, Validation Accuracy: 0.4427\n",
            "Epoch 91/100, Loss: 34.4419, Validation Accuracy: 0.6640\n",
            "Epoch 92/100, Loss: 43.7087, Validation Accuracy: 0.6431\n",
            "Epoch 93/100, Loss: 34.3792, Validation Accuracy: 0.3888\n",
            "Epoch 94/100, Loss: 33.7013, Validation Accuracy: 0.3240\n",
            "Epoch 95/100, Loss: 30.0212, Validation Accuracy: 0.4865\n",
            "Epoch 96/100, Loss: 51.0364, Validation Accuracy: 0.6311\n",
            "Epoch 97/100, Loss: 23.2761, Validation Accuracy: 0.6291\n",
            "Epoch 98/100, Loss: 40.2370, Validation Accuracy: 0.6191\n",
            "Epoch 99/100, Loss: 10.0478, Validation Accuracy: 0.6560\n",
            "Epoch 100/100, Loss: 18.3436, Validation Accuracy: 0.6122\n",
            "Epoch 101/100, Loss: 50.4334, Validation Accuracy: 0.3848\n",
            "Epoch 102/100, Loss: 54.2208, Validation Accuracy: 0.6301\n",
            "Epoch 103/100, Loss: 101.1055, Validation Accuracy: 0.6491\n",
            "Epoch 104/100, Loss: 8.0923, Validation Accuracy: 0.6102\n",
            "Epoch 105/100, Loss: 40.7486, Validation Accuracy: 0.6112\n",
            "Epoch 106/100, Loss: 19.4685, Validation Accuracy: 0.6670\n",
            "Epoch 107/100, Loss: 27.9407, Validation Accuracy: 0.6132\n",
            "Epoch 108/100, Loss: 26.2355, Validation Accuracy: 0.6321\n",
            "Epoch 109/100, Loss: 37.1779, Validation Accuracy: 0.6032\n",
            "Epoch 110/100, Loss: 34.7849, Validation Accuracy: 0.5962\n",
            "Epoch 111/100, Loss: 22.3947, Validation Accuracy: 0.6271\n",
            "Epoch 112/100, Loss: 6.7845, Validation Accuracy: 0.6520\n",
            "Epoch 113/100, Loss: 96.7866, Validation Accuracy: 0.6052\n",
            "Epoch 114/100, Loss: 22.0432, Validation Accuracy: 0.6082\n",
            "Epoch 115/100, Loss: 2.3799, Validation Accuracy: 0.6700\n",
            "Epoch 116/100, Loss: 47.1024, Validation Accuracy: 0.6530\n",
            "Epoch 117/100, Loss: 26.0673, Validation Accuracy: 0.6132\n",
            "Epoch 118/100, Loss: 34.3804, Validation Accuracy: 0.6510\n",
            "Epoch 119/100, Loss: 77.8602, Validation Accuracy: 0.5394\n",
            "Epoch 120/100, Loss: 25.3251, Validation Accuracy: 0.5284\n",
            "Epoch 121/100, Loss: 44.6807, Validation Accuracy: 0.6451\n",
            "Epoch 122/100, Loss: 93.5272, Validation Accuracy: 0.6311\n",
            "Epoch 123/100, Loss: 37.4051, Validation Accuracy: 0.5513\n",
            "Epoch 124/100, Loss: 31.2067, Validation Accuracy: 0.6221\n",
            "Epoch 125/100, Loss: 1.9455, Validation Accuracy: 0.6491\n",
            "Epoch 126/100, Loss: 30.5736, Validation Accuracy: 0.5763\n",
            "Epoch 127/100, Loss: 16.7042, Validation Accuracy: 0.6740\n",
            "Epoch 128/100, Loss: 56.8699, Validation Accuracy: 0.6431\n",
            "Epoch 129/100, Loss: 31.6515, Validation Accuracy: 0.5603\n",
            "Epoch 130/100, Loss: 31.8518, Validation Accuracy: 0.5364\n",
            "Epoch 131/100, Loss: 31.0403, Validation Accuracy: 0.6341\n",
            "Epoch 132/100, Loss: 57.5494, Validation Accuracy: 0.4187\n",
            "Epoch 133/100, Loss: 17.7719, Validation Accuracy: 0.6760\n",
            "Epoch 134/100, Loss: 36.2774, Validation Accuracy: 0.6540\n",
            "Epoch 135/100, Loss: 52.0110, Validation Accuracy: 0.5553\n",
            "Epoch 136/100, Loss: 97.2256, Validation Accuracy: 0.5354\n",
            "Epoch 137/100, Loss: 18.9256, Validation Accuracy: 0.6630\n",
            "Epoch 138/100, Loss: 66.7100, Validation Accuracy: 0.5234\n",
            "Epoch 139/100, Loss: 41.5115, Validation Accuracy: 0.5454\n",
            "Epoch 140/100, Loss: 14.9896, Validation Accuracy: 0.3490\n",
            "Epoch 141/100, Loss: 48.3072, Validation Accuracy: 0.5543\n",
            "Epoch 142/100, Loss: 35.6866, Validation Accuracy: 0.6510\n",
            "Epoch 143/100, Loss: 29.1152, Validation Accuracy: 0.6580\n",
            "Epoch 144/100, Loss: 58.9985, Validation Accuracy: 0.5922\n",
            "Epoch 145/100, Loss: 62.0233, Validation Accuracy: 0.6251\n",
            "Epoch 146/100, Loss: 54.8854, Validation Accuracy: 0.6142\n",
            "Epoch 147/100, Loss: 26.3618, Validation Accuracy: 0.6092\n",
            "Epoch 148/100, Loss: 49.5422, Validation Accuracy: 0.5035\n",
            "Epoch 149/100, Loss: 54.3260, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 35.9177, Validation Accuracy: 0.4716\n",
            "Epoch 151/100, Loss: 37.4103, Validation Accuracy: 0.6221\n",
            "Epoch 152/100, Loss: 82.7297, Validation Accuracy: 0.4796\n",
            "Epoch 153/100, Loss: 33.4393, Validation Accuracy: 0.6012\n",
            "Epoch 154/100, Loss: 18.4143, Validation Accuracy: 0.5254\n",
            "Epoch 155/100, Loss: 20.0724, Validation Accuracy: 0.4586\n",
            "Epoch 156/100, Loss: 20.8402, Validation Accuracy: 0.6481\n",
            "Epoch 157/100, Loss: 18.2648, Validation Accuracy: 0.6082\n",
            "Epoch 158/100, Loss: 70.2572, Validation Accuracy: 0.5494\n",
            "Epoch 159/100, Loss: 17.8067, Validation Accuracy: 0.5872\n",
            "Epoch 160/100, Loss: 65.9329, Validation Accuracy: 0.6441\n",
            "Epoch 161/100, Loss: 67.6752, Validation Accuracy: 0.5593\n",
            "Epoch 162/100, Loss: 17.0879, Validation Accuracy: 0.6670\n",
            "Epoch 163/100, Loss: 68.7097, Validation Accuracy: 0.4826\n",
            "Epoch 164/100, Loss: 103.3535, Validation Accuracy: 0.6510\n",
            "Epoch 165/100, Loss: 131.1707, Validation Accuracy: 0.6201\n",
            "Epoch 166/100, Loss: 16.9987, Validation Accuracy: 0.6152\n",
            "Epoch 167/100, Loss: 4.8323, Validation Accuracy: 0.6580\n",
            "Epoch 168/100, Loss: 48.5183, Validation Accuracy: 0.6022\n",
            "Epoch 169/100, Loss: 142.2872, Validation Accuracy: 0.6351\n",
            "Epoch 170/100, Loss: 23.9680, Validation Accuracy: 0.6251\n",
            "Epoch 171/100, Loss: 27.7389, Validation Accuracy: 0.6191\n",
            "Epoch 172/100, Loss: 17.5292, Validation Accuracy: 0.5912\n",
            "Epoch 173/100, Loss: 56.5402, Validation Accuracy: 0.5733\n",
            "Epoch 174/100, Loss: 98.1787, Validation Accuracy: 0.5813\n",
            "Epoch 175/100, Loss: 68.1524, Validation Accuracy: 0.5384\n",
            "Epoch 176/100, Loss: 50.3418, Validation Accuracy: 0.6052\n",
            "Epoch 177/100, Loss: 38.9260, Validation Accuracy: 0.6221\n",
            "Epoch 178/100, Loss: 90.9616, Validation Accuracy: 0.5813\n",
            "Epoch 179/100, Loss: 41.3145, Validation Accuracy: 0.4796\n",
            "Epoch 180/100, Loss: 110.4638, Validation Accuracy: 0.6102\n",
            "Epoch 181/100, Loss: 29.0657, Validation Accuracy: 0.5982\n",
            "Epoch 182/100, Loss: 33.2455, Validation Accuracy: 0.4855\n",
            "Epoch 183/100, Loss: 9.3969, Validation Accuracy: 0.5394\n",
            "Epoch 184/100, Loss: 33.8998, Validation Accuracy: 0.6301\n",
            "Epoch 185/100, Loss: 36.0835, Validation Accuracy: 0.6530\n",
            "Epoch 186/100, Loss: 26.0190, Validation Accuracy: 0.6550\n",
            "Epoch 187/100, Loss: 42.5391, Validation Accuracy: 0.5713\n",
            "Epoch 188/100, Loss: 46.0112, Validation Accuracy: 0.6451\n",
            "Epoch 189/100, Loss: 57.6969, Validation Accuracy: 0.6122\n",
            "Epoch 190/100, Loss: 31.5889, Validation Accuracy: 0.5553\n",
            "Epoch 191/100, Loss: 50.5627, Validation Accuracy: 0.5952\n",
            "Epoch 192/100, Loss: 45.2440, Validation Accuracy: 0.5593\n",
            "Epoch 193/100, Loss: 50.3908, Validation Accuracy: 0.6730\n",
            "Epoch 194/100, Loss: 23.4856, Validation Accuracy: 0.6231\n",
            "Epoch 195/100, Loss: 14.1492, Validation Accuracy: 0.5623\n",
            "Epoch 196/100, Loss: 42.2602, Validation Accuracy: 0.6331\n",
            "Epoch 197/100, Loss: 8.5774, Validation Accuracy: 0.6441\n",
            "Epoch 198/100, Loss: 45.7856, Validation Accuracy: 0.6421\n",
            "Epoch 199/100, Loss: 34.3896, Validation Accuracy: 0.6560\n",
            "Epoch 200/100, Loss: 11.2036, Validation Accuracy: 0.5773\n",
            "Reward for Child Model: 0.28234160669315744\n",
            "Child_32:  {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, [1, 0, 1, 1, 0, 2, 3, 1, 1, 2, 3, 0, 1, 0, 3], 0.28234160669315744\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 36, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(72, 48, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(48, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(120, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=103488, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 28, 22]             792\n",
            "       BatchNorm2d-2           [-1, 36, 28, 22]              72\n",
            "            Conv2d-3           [-1, 36, 22, 20]          27,252\n",
            "       BatchNorm2d-4           [-1, 36, 22, 20]              72\n",
            "              ReLU-5           [-1, 36, 22, 20]               0\n",
            "            Conv2d-6           [-1, 48, 24, 16]         121,008\n",
            "       BatchNorm2d-7           [-1, 48, 24, 16]              96\n",
            "              ReLU-8           [-1, 48, 24, 16]               0\n",
            "            Conv2d-9           [-1, 48, 24, 12]          11,568\n",
            "      BatchNorm2d-10           [-1, 48, 24, 12]              96\n",
            "             ReLU-11           [-1, 48, 24, 12]               0\n",
            "           Conv2d-12           [-1, 48, 22, 20]         121,008\n",
            "      BatchNorm2d-13           [-1, 48, 22, 20]              96\n",
            "             ReLU-14           [-1, 48, 22, 20]               0\n",
            "           Linear-15                    [-1, 7]         724,423\n",
            "================================================================\n",
            "Total params: 1,006,483\n",
            "Trainable params: 1,006,483\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.92\n",
            "Params size (MB): 3.84\n",
            "Estimated Total Size (MB): 5.77\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 15.3137, Validation Accuracy: 0.6520\n",
            "Epoch 2/100, Loss: 45.4659, Validation Accuracy: 0.5623\n",
            "Epoch 3/100, Loss: 4.7261, Validation Accuracy: 0.6431\n",
            "Epoch 4/100, Loss: 5.7257, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 2.4779, Validation Accuracy: 0.6341\n",
            "Epoch 6/100, Loss: 2.5395, Validation Accuracy: 0.4935\n",
            "Epoch 7/100, Loss: 243.3185, Validation Accuracy: 0.5593\n",
            "Epoch 8/100, Loss: 21.9578, Validation Accuracy: 0.5055\n",
            "Epoch 9/100, Loss: 13.3933, Validation Accuracy: 0.5394\n",
            "Epoch 10/100, Loss: 5.5828, Validation Accuracy: 0.5095\n",
            "Epoch 11/100, Loss: 9.9331, Validation Accuracy: 0.6271\n",
            "Epoch 12/100, Loss: 7.3960, Validation Accuracy: 0.5165\n",
            "Epoch 13/100, Loss: 12.6505, Validation Accuracy: 0.5344\n",
            "Epoch 14/100, Loss: 58.9418, Validation Accuracy: 0.6640\n",
            "Epoch 15/100, Loss: 34.9024, Validation Accuracy: 0.6491\n",
            "Epoch 16/100, Loss: 14.5076, Validation Accuracy: 0.6072\n",
            "Epoch 17/100, Loss: 9.7943, Validation Accuracy: 0.4835\n",
            "Epoch 18/100, Loss: 4.4580, Validation Accuracy: 0.6441\n",
            "Epoch 19/100, Loss: 23.9524, Validation Accuracy: 0.3649\n",
            "Epoch 20/100, Loss: 46.3696, Validation Accuracy: 0.5543\n",
            "Epoch 21/100, Loss: 31.0213, Validation Accuracy: 0.2921\n",
            "Epoch 22/100, Loss: 19.8549, Validation Accuracy: 0.6710\n",
            "Epoch 23/100, Loss: 14.0776, Validation Accuracy: 0.6441\n",
            "Epoch 24/100, Loss: 38.9313, Validation Accuracy: 0.4596\n",
            "Epoch 25/100, Loss: 160.2387, Validation Accuracy: 0.6052\n",
            "Epoch 26/100, Loss: 28.2495, Validation Accuracy: 0.6491\n",
            "Epoch 27/100, Loss: 20.3173, Validation Accuracy: 0.4945\n",
            "Epoch 28/100, Loss: 5.8634, Validation Accuracy: 0.6520\n",
            "Epoch 29/100, Loss: 8.1654, Validation Accuracy: 0.6371\n",
            "Epoch 30/100, Loss: 21.1125, Validation Accuracy: 0.5344\n",
            "Epoch 31/100, Loss: 48.0047, Validation Accuracy: 0.5833\n",
            "Epoch 32/100, Loss: 34.8675, Validation Accuracy: 0.5274\n",
            "Epoch 33/100, Loss: 8.7432, Validation Accuracy: 0.5932\n",
            "Epoch 34/100, Loss: 4.5701, Validation Accuracy: 0.5075\n",
            "Epoch 35/100, Loss: 16.1927, Validation Accuracy: 0.6251\n",
            "Epoch 36/100, Loss: 11.8583, Validation Accuracy: 0.5753\n",
            "Epoch 37/100, Loss: 3.4880, Validation Accuracy: 0.5813\n",
            "Epoch 38/100, Loss: 9.7590, Validation Accuracy: 0.6530\n",
            "Epoch 39/100, Loss: 9.9387, Validation Accuracy: 0.6162\n",
            "Epoch 40/100, Loss: 63.1934, Validation Accuracy: 0.6461\n",
            "Epoch 41/100, Loss: 37.4356, Validation Accuracy: 0.1815\n",
            "Epoch 42/100, Loss: 26.8587, Validation Accuracy: 0.6750\n",
            "Epoch 43/100, Loss: 22.5523, Validation Accuracy: 0.5224\n",
            "Epoch 44/100, Loss: 11.1197, Validation Accuracy: 0.3330\n",
            "Epoch 45/100, Loss: 26.2442, Validation Accuracy: 0.5783\n",
            "Epoch 46/100, Loss: 115.3978, Validation Accuracy: 0.6102\n",
            "Epoch 47/100, Loss: 24.5339, Validation Accuracy: 0.6301\n",
            "Epoch 48/100, Loss: 77.0184, Validation Accuracy: 0.5633\n",
            "Epoch 49/100, Loss: 23.8187, Validation Accuracy: 0.6002\n",
            "Epoch 50/100, Loss: 22.3678, Validation Accuracy: 0.6142\n",
            "Epoch 51/100, Loss: 8.0453, Validation Accuracy: 0.5115\n",
            "Epoch 52/100, Loss: 30.3165, Validation Accuracy: 0.5424\n",
            "Epoch 53/100, Loss: 16.9723, Validation Accuracy: 0.6680\n",
            "Epoch 54/100, Loss: 23.5279, Validation Accuracy: 0.6740\n",
            "Epoch 55/100, Loss: 73.3505, Validation Accuracy: 0.1904\n",
            "Epoch 56/100, Loss: 84.4395, Validation Accuracy: 0.5902\n",
            "Epoch 57/100, Loss: 28.1867, Validation Accuracy: 0.6550\n",
            "Epoch 58/100, Loss: 21.5487, Validation Accuracy: 0.5962\n",
            "Epoch 59/100, Loss: 8.6090, Validation Accuracy: 0.6231\n",
            "Epoch 60/100, Loss: 6.4429, Validation Accuracy: 0.5882\n",
            "Epoch 61/100, Loss: 65.3950, Validation Accuracy: 0.5743\n",
            "Epoch 62/100, Loss: 19.7524, Validation Accuracy: 0.5902\n",
            "Epoch 63/100, Loss: 13.8546, Validation Accuracy: 0.6102\n",
            "Epoch 64/100, Loss: 19.7816, Validation Accuracy: 0.5763\n",
            "Epoch 65/100, Loss: 17.4672, Validation Accuracy: 0.5733\n",
            "Epoch 66/100, Loss: 47.1701, Validation Accuracy: 0.6461\n",
            "Epoch 67/100, Loss: 28.0786, Validation Accuracy: 0.6680\n",
            "Epoch 68/100, Loss: 35.4300, Validation Accuracy: 0.5474\n",
            "Epoch 69/100, Loss: 45.5027, Validation Accuracy: 0.6510\n",
            "Epoch 70/100, Loss: 9.2657, Validation Accuracy: 0.6839\n",
            "Epoch 71/100, Loss: 25.0086, Validation Accuracy: 0.5803\n",
            "Epoch 72/100, Loss: 17.3854, Validation Accuracy: 0.6401\n",
            "Epoch 73/100, Loss: 27.7806, Validation Accuracy: 0.5444\n",
            "Epoch 74/100, Loss: 34.9067, Validation Accuracy: 0.5803\n",
            "Epoch 75/100, Loss: 29.8796, Validation Accuracy: 0.6341\n",
            "Epoch 76/100, Loss: 28.5673, Validation Accuracy: 0.4636\n",
            "Epoch 77/100, Loss: 25.0711, Validation Accuracy: 0.6680\n",
            "Epoch 78/100, Loss: 17.9672, Validation Accuracy: 0.6371\n",
            "Epoch 79/100, Loss: 33.2722, Validation Accuracy: 0.5354\n",
            "Epoch 80/100, Loss: 31.8862, Validation Accuracy: 0.5184\n",
            "Epoch 81/100, Loss: 17.3366, Validation Accuracy: 0.4995\n",
            "Epoch 82/100, Loss: 35.6149, Validation Accuracy: 0.6321\n",
            "Epoch 83/100, Loss: 17.8721, Validation Accuracy: 0.6600\n",
            "Epoch 84/100, Loss: 13.4725, Validation Accuracy: 0.6461\n",
            "Epoch 85/100, Loss: 13.7390, Validation Accuracy: 0.6421\n",
            "Epoch 86/100, Loss: 30.2741, Validation Accuracy: 0.6471\n",
            "Epoch 87/100, Loss: 73.9210, Validation Accuracy: 0.1396\n",
            "Epoch 88/100, Loss: 36.7585, Validation Accuracy: 0.5354\n",
            "Epoch 89/100, Loss: 18.4378, Validation Accuracy: 0.6042\n",
            "Epoch 90/100, Loss: 28.7994, Validation Accuracy: 0.5982\n",
            "Epoch 91/100, Loss: 11.5575, Validation Accuracy: 0.6291\n",
            "Epoch 92/100, Loss: 23.9151, Validation Accuracy: 0.4806\n",
            "Epoch 93/100, Loss: 27.9343, Validation Accuracy: 0.5523\n",
            "Epoch 94/100, Loss: 31.5661, Validation Accuracy: 0.6042\n",
            "Epoch 95/100, Loss: 24.6516, Validation Accuracy: 0.4965\n",
            "Epoch 96/100, Loss: 8.2562, Validation Accuracy: 0.6630\n",
            "Epoch 97/100, Loss: 23.6032, Validation Accuracy: 0.6351\n",
            "Epoch 98/100, Loss: 41.2775, Validation Accuracy: 0.5095\n",
            "Epoch 99/100, Loss: 38.4961, Validation Accuracy: 0.6301\n",
            "Epoch 100/100, Loss: 25.9096, Validation Accuracy: 0.4506\n",
            "Epoch 101/100, Loss: 37.3507, Validation Accuracy: 0.6411\n",
            "Epoch 102/100, Loss: 53.2305, Validation Accuracy: 0.5613\n",
            "Epoch 103/100, Loss: 32.5420, Validation Accuracy: 0.6520\n",
            "Epoch 104/100, Loss: 33.6965, Validation Accuracy: 0.5344\n",
            "Epoch 105/100, Loss: 29.2777, Validation Accuracy: 0.6171\n",
            "Epoch 106/100, Loss: 32.6285, Validation Accuracy: 0.6331\n",
            "Epoch 107/100, Loss: 26.3145, Validation Accuracy: 0.6211\n",
            "Epoch 108/100, Loss: 13.9630, Validation Accuracy: 0.6112\n",
            "Epoch 109/100, Loss: 33.4022, Validation Accuracy: 0.6221\n",
            "Epoch 110/100, Loss: 37.0510, Validation Accuracy: 0.5165\n",
            "Epoch 111/100, Loss: 35.1767, Validation Accuracy: 0.5543\n",
            "Epoch 112/100, Loss: 7.3541, Validation Accuracy: 0.6421\n",
            "Epoch 113/100, Loss: 173.9185, Validation Accuracy: 0.5942\n",
            "Epoch 114/100, Loss: 14.7308, Validation Accuracy: 0.6560\n",
            "Epoch 115/100, Loss: 12.0451, Validation Accuracy: 0.6500\n",
            "Epoch 116/100, Loss: 40.3369, Validation Accuracy: 0.6251\n",
            "Epoch 117/100, Loss: 87.8005, Validation Accuracy: 0.6092\n",
            "Epoch 118/100, Loss: 52.6337, Validation Accuracy: 0.5563\n",
            "Epoch 119/100, Loss: 38.4438, Validation Accuracy: 0.5683\n",
            "Epoch 120/100, Loss: 16.5537, Validation Accuracy: 0.5683\n",
            "Epoch 121/100, Loss: 28.1078, Validation Accuracy: 0.6171\n",
            "Epoch 122/100, Loss: 20.6798, Validation Accuracy: 0.5633\n",
            "Epoch 123/100, Loss: 22.3235, Validation Accuracy: 0.6002\n",
            "Epoch 124/100, Loss: 25.1250, Validation Accuracy: 0.6500\n",
            "Epoch 125/100, Loss: 29.6494, Validation Accuracy: 0.6580\n",
            "Epoch 126/100, Loss: 82.1872, Validation Accuracy: 0.6142\n",
            "Epoch 127/100, Loss: 13.7416, Validation Accuracy: 0.5823\n",
            "Epoch 128/100, Loss: 9.7291, Validation Accuracy: 0.6560\n",
            "Epoch 129/100, Loss: 27.5067, Validation Accuracy: 0.5454\n",
            "Epoch 130/100, Loss: 40.1334, Validation Accuracy: 0.5563\n",
            "Epoch 131/100, Loss: 21.7215, Validation Accuracy: 0.6361\n",
            "Epoch 132/100, Loss: 19.8458, Validation Accuracy: 0.6491\n",
            "Epoch 133/100, Loss: 28.5685, Validation Accuracy: 0.6471\n",
            "Epoch 134/100, Loss: 60.7117, Validation Accuracy: 0.5364\n",
            "Epoch 135/100, Loss: 75.7842, Validation Accuracy: 0.2961\n",
            "Epoch 136/100, Loss: 6.8815, Validation Accuracy: 0.6062\n",
            "Epoch 137/100, Loss: 14.3976, Validation Accuracy: 0.6201\n",
            "Epoch 138/100, Loss: 19.5261, Validation Accuracy: 0.5165\n",
            "Epoch 139/100, Loss: 29.3479, Validation Accuracy: 0.6251\n",
            "Epoch 140/100, Loss: 31.6103, Validation Accuracy: 0.3350\n",
            "Epoch 141/100, Loss: 82.1415, Validation Accuracy: 0.3450\n",
            "Epoch 142/100, Loss: 27.5478, Validation Accuracy: 0.6381\n",
            "Epoch 143/100, Loss: 38.4743, Validation Accuracy: 0.6271\n",
            "Epoch 144/100, Loss: 17.8194, Validation Accuracy: 0.6052\n",
            "Epoch 145/100, Loss: 10.7886, Validation Accuracy: 0.4955\n",
            "Epoch 146/100, Loss: 20.4068, Validation Accuracy: 0.5882\n",
            "Epoch 147/100, Loss: 38.4425, Validation Accuracy: 0.3938\n",
            "Epoch 148/100, Loss: 31.7395, Validation Accuracy: 0.5922\n",
            "Epoch 149/100, Loss: 17.5607, Validation Accuracy: 0.5474\n",
            "Epoch 150/100, Loss: 30.1464, Validation Accuracy: 0.5474\n",
            "Epoch 151/100, Loss: 29.5206, Validation Accuracy: 0.3779\n",
            "Epoch 152/100, Loss: 33.6164, Validation Accuracy: 0.5274\n",
            "Epoch 153/100, Loss: 24.5129, Validation Accuracy: 0.6401\n",
            "Epoch 154/100, Loss: 28.2639, Validation Accuracy: 0.5653\n",
            "Epoch 155/100, Loss: 10.6136, Validation Accuracy: 0.6700\n",
            "Epoch 156/100, Loss: 21.0645, Validation Accuracy: 0.6331\n",
            "Epoch 157/100, Loss: 52.3466, Validation Accuracy: 0.4227\n",
            "Epoch 158/100, Loss: 46.9944, Validation Accuracy: 0.6052\n",
            "Epoch 159/100, Loss: 44.7809, Validation Accuracy: 0.5603\n",
            "Epoch 160/100, Loss: 13.6607, Validation Accuracy: 0.5783\n",
            "Epoch 161/100, Loss: 35.7819, Validation Accuracy: 0.6720\n",
            "Epoch 162/100, Loss: 12.8099, Validation Accuracy: 0.6261\n",
            "Epoch 163/100, Loss: 25.3152, Validation Accuracy: 0.6281\n",
            "Epoch 164/100, Loss: 14.8611, Validation Accuracy: 0.6361\n",
            "Epoch 165/100, Loss: 132.0683, Validation Accuracy: 0.5972\n",
            "Epoch 166/100, Loss: 38.0440, Validation Accuracy: 0.6062\n",
            "Epoch 167/100, Loss: 19.6508, Validation Accuracy: 0.6660\n",
            "Epoch 168/100, Loss: 19.4141, Validation Accuracy: 0.6540\n",
            "Epoch 169/100, Loss: 47.1597, Validation Accuracy: 0.6600\n",
            "Epoch 170/100, Loss: 34.3187, Validation Accuracy: 0.6281\n",
            "Epoch 171/100, Loss: 23.3042, Validation Accuracy: 0.6491\n",
            "Epoch 172/100, Loss: 12.3871, Validation Accuracy: 0.6181\n",
            "Epoch 173/100, Loss: 20.6770, Validation Accuracy: 0.6790\n",
            "Epoch 174/100, Loss: 31.3864, Validation Accuracy: 0.5683\n",
            "Epoch 175/100, Loss: 42.1466, Validation Accuracy: 0.6451\n",
            "Epoch 176/100, Loss: 17.7498, Validation Accuracy: 0.5075\n",
            "Epoch 177/100, Loss: 29.8956, Validation Accuracy: 0.5653\n",
            "Epoch 178/100, Loss: 24.6915, Validation Accuracy: 0.6431\n",
            "Epoch 179/100, Loss: 37.6950, Validation Accuracy: 0.6221\n",
            "Epoch 180/100, Loss: 35.7721, Validation Accuracy: 0.6321\n",
            "Epoch 181/100, Loss: 74.2013, Validation Accuracy: 0.5533\n",
            "Epoch 182/100, Loss: 25.0002, Validation Accuracy: 0.5155\n",
            "Epoch 183/100, Loss: 16.5603, Validation Accuracy: 0.6550\n",
            "Epoch 184/100, Loss: 24.1170, Validation Accuracy: 0.6381\n",
            "Epoch 185/100, Loss: 39.4915, Validation Accuracy: 0.6391\n",
            "Epoch 186/100, Loss: 14.6018, Validation Accuracy: 0.6421\n",
            "Epoch 187/100, Loss: 15.6290, Validation Accuracy: 0.4347\n",
            "Epoch 188/100, Loss: 58.5291, Validation Accuracy: 0.5743\n",
            "Epoch 189/100, Loss: 41.7303, Validation Accuracy: 0.6012\n",
            "Epoch 190/100, Loss: 12.4140, Validation Accuracy: 0.5394\n",
            "Epoch 191/100, Loss: 5.1687, Validation Accuracy: 0.5284\n",
            "Epoch 192/100, Loss: 54.7740, Validation Accuracy: 0.5135\n",
            "Epoch 193/100, Loss: 26.6204, Validation Accuracy: 0.6550\n",
            "Epoch 194/100, Loss: 16.8656, Validation Accuracy: 0.6550\n",
            "Epoch 195/100, Loss: 50.1769, Validation Accuracy: 0.6560\n",
            "Epoch 196/100, Loss: 133.2138, Validation Accuracy: 0.6590\n",
            "Epoch 197/100, Loss: 35.0654, Validation Accuracy: 0.4796\n",
            "Epoch 198/100, Loss: 13.4498, Validation Accuracy: 0.6660\n",
            "Epoch 199/100, Loss: 30.7189, Validation Accuracy: 0.5733\n",
            "Epoch 200/100, Loss: 29.6666, Validation Accuracy: 0.3310\n",
            "Reward for Child Model: 0.2954109493838166\n",
            "Child_33:  {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, [0, 3, 1, 3, 1, 1, 2, 3, 2, 0, 2, 2, 3, 1, 2], 0.2954109493838166\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(100, 24, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(24, 36, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(136, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=152768, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 22, 28]           1,408\n",
            "       BatchNorm2d-2           [-1, 64, 22, 28]             128\n",
            "            Conv2d-3           [-1, 36, 22, 22]          16,164\n",
            "       BatchNorm2d-4           [-1, 36, 22, 22]              72\n",
            "              ReLU-5           [-1, 36, 22, 22]               0\n",
            "            Conv2d-6           [-1, 24, 18, 28]          12,024\n",
            "       BatchNorm2d-7           [-1, 24, 18, 28]              48\n",
            "              ReLU-8           [-1, 24, 18, 28]               0\n",
            "            Conv2d-9           [-1, 36, 12, 26]          18,180\n",
            "      BatchNorm2d-10           [-1, 36, 12, 26]              72\n",
            "             ReLU-11           [-1, 36, 12, 26]               0\n",
            "           Conv2d-12           [-1, 48, 16, 26]         137,136\n",
            "      BatchNorm2d-13           [-1, 48, 16, 26]              96\n",
            "             ReLU-14           [-1, 48, 16, 26]               0\n",
            "           Linear-15                    [-1, 7]       1,069,383\n",
            "================================================================\n",
            "Total params: 1,254,711\n",
            "Trainable params: 1,254,711\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.99\n",
            "Params size (MB): 4.79\n",
            "Estimated Total Size (MB): 6.79\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 55.6592, Validation Accuracy: 0.6012\n",
            "Epoch 2/100, Loss: 23.0576, Validation Accuracy: 0.4427\n",
            "Epoch 3/100, Loss: 46.0714, Validation Accuracy: 0.6610\n",
            "Epoch 4/100, Loss: 307.4990, Validation Accuracy: 0.4008\n",
            "Epoch 5/100, Loss: 56.5900, Validation Accuracy: 0.4467\n",
            "Epoch 6/100, Loss: 37.4610, Validation Accuracy: 0.6391\n",
            "Epoch 7/100, Loss: 69.8392, Validation Accuracy: 0.6481\n",
            "Epoch 8/100, Loss: 117.0334, Validation Accuracy: 0.5723\n",
            "Epoch 9/100, Loss: 249.5401, Validation Accuracy: 0.4158\n",
            "Epoch 10/100, Loss: 160.9886, Validation Accuracy: 0.5932\n",
            "Epoch 11/100, Loss: 303.5263, Validation Accuracy: 0.3978\n",
            "Epoch 12/100, Loss: 104.4135, Validation Accuracy: 0.3260\n",
            "Epoch 13/100, Loss: 48.0836, Validation Accuracy: 0.4895\n",
            "Epoch 14/100, Loss: 36.0499, Validation Accuracy: 0.6820\n",
            "Epoch 15/100, Loss: 111.1027, Validation Accuracy: 0.6181\n",
            "Epoch 16/100, Loss: 45.1290, Validation Accuracy: 0.6740\n",
            "Epoch 17/100, Loss: 101.2175, Validation Accuracy: 0.5294\n",
            "Epoch 18/100, Loss: 93.1679, Validation Accuracy: 0.4756\n",
            "Epoch 19/100, Loss: 335.9435, Validation Accuracy: 0.4427\n",
            "Epoch 20/100, Loss: 55.7430, Validation Accuracy: 0.5753\n",
            "Epoch 21/100, Loss: 112.6844, Validation Accuracy: 0.6491\n",
            "Epoch 22/100, Loss: 66.8877, Validation Accuracy: 0.6670\n",
            "Epoch 23/100, Loss: 111.8784, Validation Accuracy: 0.5972\n",
            "Epoch 24/100, Loss: 221.7079, Validation Accuracy: 0.3789\n",
            "Epoch 25/100, Loss: 71.6567, Validation Accuracy: 0.5503\n",
            "Epoch 26/100, Loss: 66.3540, Validation Accuracy: 0.6650\n",
            "Epoch 27/100, Loss: 174.0602, Validation Accuracy: 0.6680\n",
            "Epoch 28/100, Loss: 59.7017, Validation Accuracy: 0.6680\n",
            "Epoch 29/100, Loss: 51.3320, Validation Accuracy: 0.6800\n",
            "Epoch 30/100, Loss: 80.1896, Validation Accuracy: 0.4835\n",
            "Epoch 31/100, Loss: 104.4615, Validation Accuracy: 0.7029\n",
            "Epoch 32/100, Loss: 182.9513, Validation Accuracy: 0.5414\n",
            "Epoch 33/100, Loss: 97.1164, Validation Accuracy: 0.6351\n",
            "Epoch 34/100, Loss: 124.6088, Validation Accuracy: 0.6800\n",
            "Epoch 35/100, Loss: 56.2052, Validation Accuracy: 0.6471\n",
            "Epoch 36/100, Loss: 124.0652, Validation Accuracy: 0.6780\n",
            "Epoch 37/100, Loss: 121.9263, Validation Accuracy: 0.6610\n",
            "Epoch 38/100, Loss: 91.7810, Validation Accuracy: 0.6879\n",
            "Epoch 39/100, Loss: 184.7199, Validation Accuracy: 0.6391\n",
            "Epoch 40/100, Loss: 251.1259, Validation Accuracy: 0.6800\n",
            "Epoch 41/100, Loss: 95.1820, Validation Accuracy: 0.6730\n",
            "Epoch 42/100, Loss: 239.2096, Validation Accuracy: 0.5743\n",
            "Epoch 43/100, Loss: 131.2834, Validation Accuracy: 0.6660\n",
            "Epoch 44/100, Loss: 125.6814, Validation Accuracy: 0.6281\n",
            "Epoch 45/100, Loss: 209.9173, Validation Accuracy: 0.6810\n",
            "Epoch 46/100, Loss: 109.9054, Validation Accuracy: 0.6321\n",
            "Epoch 47/100, Loss: 141.6923, Validation Accuracy: 0.6461\n",
            "Epoch 48/100, Loss: 202.4357, Validation Accuracy: 0.6092\n",
            "Epoch 49/100, Loss: 122.8359, Validation Accuracy: 0.5743\n",
            "Epoch 50/100, Loss: 159.2995, Validation Accuracy: 0.6221\n",
            "Epoch 51/100, Loss: 75.8243, Validation Accuracy: 0.6102\n",
            "Epoch 52/100, Loss: 193.9266, Validation Accuracy: 0.6879\n",
            "Epoch 53/100, Loss: 156.2203, Validation Accuracy: 0.5823\n",
            "Epoch 54/100, Loss: 142.3172, Validation Accuracy: 0.5593\n",
            "Epoch 55/100, Loss: 145.1415, Validation Accuracy: 0.6750\n",
            "Epoch 56/100, Loss: 72.0303, Validation Accuracy: 0.6610\n",
            "Epoch 57/100, Loss: 136.7968, Validation Accuracy: 0.6889\n",
            "Epoch 58/100, Loss: 245.8557, Validation Accuracy: 0.5643\n",
            "Epoch 59/100, Loss: 69.6276, Validation Accuracy: 0.6191\n",
            "Epoch 60/100, Loss: 168.8387, Validation Accuracy: 0.6381\n",
            "Epoch 61/100, Loss: 157.6871, Validation Accuracy: 0.5324\n",
            "Epoch 62/100, Loss: 138.6515, Validation Accuracy: 0.6680\n",
            "Epoch 63/100, Loss: 64.9323, Validation Accuracy: 0.6162\n",
            "Epoch 64/100, Loss: 33.4529, Validation Accuracy: 0.6710\n",
            "Epoch 65/100, Loss: 121.4430, Validation Accuracy: 0.6600\n",
            "Epoch 66/100, Loss: 127.9487, Validation Accuracy: 0.5962\n",
            "Epoch 67/100, Loss: 67.4272, Validation Accuracy: 0.2203\n",
            "Epoch 68/100, Loss: 114.1456, Validation Accuracy: 0.7059\n",
            "Epoch 69/100, Loss: 217.8753, Validation Accuracy: 0.4317\n",
            "Epoch 70/100, Loss: 66.6681, Validation Accuracy: 0.5484\n",
            "Epoch 71/100, Loss: 339.7994, Validation Accuracy: 0.6321\n",
            "Epoch 72/100, Loss: 46.7447, Validation Accuracy: 0.6251\n",
            "Epoch 73/100, Loss: 108.8399, Validation Accuracy: 0.6939\n",
            "Epoch 74/100, Loss: 68.1567, Validation Accuracy: 0.6979\n",
            "Epoch 75/100, Loss: 155.4939, Validation Accuracy: 0.5005\n",
            "Epoch 76/100, Loss: 65.4460, Validation Accuracy: 0.6949\n",
            "Epoch 77/100, Loss: 149.9023, Validation Accuracy: 0.5723\n",
            "Epoch 78/100, Loss: 148.5853, Validation Accuracy: 0.6401\n",
            "Epoch 79/100, Loss: 144.8606, Validation Accuracy: 0.5882\n",
            "Epoch 80/100, Loss: 136.5183, Validation Accuracy: 0.6471\n",
            "Epoch 81/100, Loss: 74.7125, Validation Accuracy: 0.5922\n",
            "Epoch 82/100, Loss: 105.3952, Validation Accuracy: 0.6112\n",
            "Epoch 83/100, Loss: 95.4923, Validation Accuracy: 0.6879\n",
            "Epoch 84/100, Loss: 76.1366, Validation Accuracy: 0.6241\n",
            "Epoch 85/100, Loss: 104.5794, Validation Accuracy: 0.6291\n",
            "Epoch 86/100, Loss: 96.1371, Validation Accuracy: 0.4167\n",
            "Epoch 87/100, Loss: 203.4524, Validation Accuracy: 0.6331\n",
            "Epoch 88/100, Loss: 119.8132, Validation Accuracy: 0.6740\n",
            "Epoch 89/100, Loss: 62.9350, Validation Accuracy: 0.6879\n",
            "Epoch 90/100, Loss: 140.7553, Validation Accuracy: 0.6909\n",
            "Epoch 91/100, Loss: 127.4359, Validation Accuracy: 0.6271\n",
            "Epoch 92/100, Loss: 40.5298, Validation Accuracy: 0.6780\n",
            "Epoch 93/100, Loss: 104.7104, Validation Accuracy: 0.6760\n",
            "Epoch 94/100, Loss: 63.4463, Validation Accuracy: 0.6760\n",
            "Epoch 95/100, Loss: 90.7548, Validation Accuracy: 0.6471\n",
            "Epoch 96/100, Loss: 338.5295, Validation Accuracy: 0.6520\n",
            "Epoch 97/100, Loss: 266.1352, Validation Accuracy: 0.6830\n",
            "Epoch 98/100, Loss: 167.0798, Validation Accuracy: 0.5803\n",
            "Epoch 99/100, Loss: 435.4271, Validation Accuracy: 0.5972\n",
            "Epoch 100/100, Loss: 205.9275, Validation Accuracy: 0.6351\n",
            "Epoch 101/100, Loss: 225.7980, Validation Accuracy: 0.5833\n",
            "Epoch 102/100, Loss: 85.2877, Validation Accuracy: 0.5533\n",
            "Epoch 103/100, Loss: 66.9539, Validation Accuracy: 0.6530\n",
            "Epoch 104/100, Loss: 255.4357, Validation Accuracy: 0.6471\n",
            "Epoch 105/100, Loss: 120.3127, Validation Accuracy: 0.5992\n",
            "Epoch 106/100, Loss: 240.3193, Validation Accuracy: 0.6580\n",
            "Epoch 107/100, Loss: 207.8615, Validation Accuracy: 0.5155\n",
            "Epoch 108/100, Loss: 186.7999, Validation Accuracy: 0.6710\n",
            "Epoch 109/100, Loss: 158.8762, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 43.4126, Validation Accuracy: 0.6361\n",
            "Epoch 111/100, Loss: 82.1284, Validation Accuracy: 0.5892\n",
            "Epoch 112/100, Loss: 75.0360, Validation Accuracy: 0.6520\n",
            "Epoch 113/100, Loss: 99.7384, Validation Accuracy: 0.6530\n",
            "Epoch 114/100, Loss: 38.4736, Validation Accuracy: 0.6231\n",
            "Epoch 115/100, Loss: 54.6883, Validation Accuracy: 0.6301\n",
            "Epoch 116/100, Loss: 138.3561, Validation Accuracy: 0.6660\n",
            "Epoch 117/100, Loss: 120.0276, Validation Accuracy: 0.5464\n",
            "Epoch 118/100, Loss: 123.9516, Validation Accuracy: 0.5982\n",
            "Epoch 119/100, Loss: 86.7069, Validation Accuracy: 0.6082\n",
            "Epoch 120/100, Loss: 63.1878, Validation Accuracy: 0.6560\n",
            "Epoch 121/100, Loss: 163.5728, Validation Accuracy: 0.6570\n",
            "Epoch 122/100, Loss: 176.3981, Validation Accuracy: 0.6630\n",
            "Epoch 123/100, Loss: 97.6234, Validation Accuracy: 0.6261\n",
            "Epoch 124/100, Loss: 83.9807, Validation Accuracy: 0.5833\n",
            "Epoch 125/100, Loss: 254.7739, Validation Accuracy: 0.6610\n",
            "Epoch 126/100, Loss: 181.5776, Validation Accuracy: 0.5852\n",
            "Epoch 127/100, Loss: 347.5472, Validation Accuracy: 0.6181\n",
            "Epoch 128/100, Loss: 86.8021, Validation Accuracy: 0.6919\n",
            "Epoch 129/100, Loss: 110.1113, Validation Accuracy: 0.6381\n",
            "Epoch 130/100, Loss: 195.5943, Validation Accuracy: 0.5174\n",
            "Epoch 131/100, Loss: 75.8216, Validation Accuracy: 0.6839\n",
            "Epoch 132/100, Loss: 93.3019, Validation Accuracy: 0.6481\n",
            "Epoch 133/100, Loss: 79.7053, Validation Accuracy: 0.6181\n",
            "Epoch 134/100, Loss: 191.2967, Validation Accuracy: 0.6560\n",
            "Epoch 135/100, Loss: 196.2078, Validation Accuracy: 0.5354\n",
            "Epoch 136/100, Loss: 44.6172, Validation Accuracy: 0.6590\n",
            "Epoch 137/100, Loss: 47.3383, Validation Accuracy: 0.6750\n",
            "Epoch 138/100, Loss: 243.6891, Validation Accuracy: 0.6540\n",
            "Epoch 139/100, Loss: 156.1735, Validation Accuracy: 0.6431\n",
            "Epoch 140/100, Loss: 135.7306, Validation Accuracy: 0.6401\n",
            "Epoch 141/100, Loss: 156.1313, Validation Accuracy: 0.6820\n",
            "Epoch 142/100, Loss: 82.5961, Validation Accuracy: 0.6530\n",
            "Epoch 143/100, Loss: 72.1482, Validation Accuracy: 0.6201\n",
            "Epoch 144/100, Loss: 78.3256, Validation Accuracy: 0.6301\n",
            "Epoch 145/100, Loss: 114.8542, Validation Accuracy: 0.5912\n",
            "Epoch 146/100, Loss: 205.4586, Validation Accuracy: 0.5992\n",
            "Epoch 147/100, Loss: 131.0081, Validation Accuracy: 0.6820\n",
            "Epoch 148/100, Loss: 167.4680, Validation Accuracy: 0.6002\n",
            "Epoch 149/100, Loss: 315.6012, Validation Accuracy: 0.6670\n",
            "Epoch 150/100, Loss: 227.9008, Validation Accuracy: 0.6700\n",
            "Epoch 151/100, Loss: 23.0634, Validation Accuracy: 0.7029\n",
            "Epoch 152/100, Loss: 154.6445, Validation Accuracy: 0.5852\n",
            "Epoch 153/100, Loss: 46.8893, Validation Accuracy: 0.6401\n",
            "Epoch 154/100, Loss: 98.1862, Validation Accuracy: 0.5793\n",
            "Epoch 155/100, Loss: 114.6408, Validation Accuracy: 0.6301\n",
            "Epoch 156/100, Loss: 61.2177, Validation Accuracy: 0.6540\n",
            "Epoch 157/100, Loss: 117.4942, Validation Accuracy: 0.6251\n",
            "Epoch 158/100, Loss: 56.2846, Validation Accuracy: 0.5394\n",
            "Epoch 159/100, Loss: 122.1002, Validation Accuracy: 0.6640\n",
            "Epoch 160/100, Loss: 63.1760, Validation Accuracy: 0.5663\n",
            "Epoch 161/100, Loss: 144.9366, Validation Accuracy: 0.5833\n",
            "Epoch 162/100, Loss: 160.6553, Validation Accuracy: 0.5952\n",
            "Epoch 163/100, Loss: 128.6244, Validation Accuracy: 0.6271\n",
            "Epoch 164/100, Loss: 138.0885, Validation Accuracy: 0.5892\n",
            "Epoch 165/100, Loss: 199.4303, Validation Accuracy: 0.6461\n",
            "Epoch 166/100, Loss: 88.3092, Validation Accuracy: 0.6311\n",
            "Epoch 167/100, Loss: 101.6627, Validation Accuracy: 0.6082\n",
            "Epoch 168/100, Loss: 67.0778, Validation Accuracy: 0.5972\n",
            "Epoch 169/100, Loss: 216.8328, Validation Accuracy: 0.6481\n",
            "Epoch 170/100, Loss: 128.2249, Validation Accuracy: 0.6062\n",
            "Epoch 171/100, Loss: 143.5309, Validation Accuracy: 0.6510\n",
            "Epoch 172/100, Loss: 85.8650, Validation Accuracy: 0.5882\n",
            "Epoch 173/100, Loss: 80.1219, Validation Accuracy: 0.6830\n",
            "Epoch 174/100, Loss: 104.0721, Validation Accuracy: 0.5643\n",
            "Epoch 175/100, Loss: 153.4128, Validation Accuracy: 0.6879\n",
            "Epoch 176/100, Loss: 67.1628, Validation Accuracy: 0.5922\n",
            "Epoch 177/100, Loss: 82.2386, Validation Accuracy: 0.6441\n",
            "Epoch 178/100, Loss: 72.4433, Validation Accuracy: 0.6351\n",
            "Epoch 179/100, Loss: 216.4021, Validation Accuracy: 0.6670\n",
            "Epoch 180/100, Loss: 182.6562, Validation Accuracy: 0.6431\n",
            "Epoch 181/100, Loss: 315.4178, Validation Accuracy: 0.6251\n",
            "Epoch 182/100, Loss: 145.0092, Validation Accuracy: 0.6032\n",
            "Epoch 183/100, Loss: 104.5444, Validation Accuracy: 0.6630\n",
            "Epoch 184/100, Loss: 61.2976, Validation Accuracy: 0.6062\n",
            "Epoch 185/100, Loss: 199.8496, Validation Accuracy: 0.6152\n",
            "Epoch 186/100, Loss: 178.7310, Validation Accuracy: 0.6481\n",
            "Epoch 187/100, Loss: 95.8701, Validation Accuracy: 0.6371\n",
            "Epoch 188/100, Loss: 156.4676, Validation Accuracy: 0.5942\n",
            "Epoch 189/100, Loss: 137.9380, Validation Accuracy: 0.6600\n",
            "Epoch 190/100, Loss: 81.9017, Validation Accuracy: 0.6162\n",
            "Epoch 191/100, Loss: 100.3018, Validation Accuracy: 0.5543\n",
            "Epoch 192/100, Loss: 206.7089, Validation Accuracy: 0.6899\n",
            "Epoch 193/100, Loss: 276.8409, Validation Accuracy: 0.5922\n",
            "Epoch 194/100, Loss: 56.7877, Validation Accuracy: 0.6142\n",
            "Epoch 195/100, Loss: 136.2874, Validation Accuracy: 0.6401\n",
            "Epoch 196/100, Loss: 98.2185, Validation Accuracy: 0.6152\n",
            "Epoch 197/100, Loss: 108.8770, Validation Accuracy: 0.6211\n",
            "Epoch 198/100, Loss: 198.9346, Validation Accuracy: 0.6680\n",
            "Epoch 199/100, Loss: 92.7922, Validation Accuracy: 0.6451\n",
            "Epoch 200/100, Loss: 75.8937, Validation Accuracy: 0.5952\n",
            "Reward for Child Model: 0.2980722933598883\n",
            "Child_34:  {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, [3, 0, 3, 0, 3, 1, 2, 0, 0, 3, 1, 1, 3, 1, 2], 0.2980722933598883\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 36, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 24, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(60, 24, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(60, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=87360, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 28, 26]             360\n",
            "       BatchNorm2d-2           [-1, 36, 28, 26]              72\n",
            "            Conv2d-3           [-1, 36, 28, 24]           3,924\n",
            "       BatchNorm2d-4           [-1, 36, 28, 24]              72\n",
            "              ReLU-5           [-1, 36, 28, 24]               0\n",
            "            Conv2d-6           [-1, 24, 24, 18]          30,264\n",
            "       BatchNorm2d-7           [-1, 24, 24, 18]              48\n",
            "              ReLU-8           [-1, 24, 24, 18]               0\n",
            "            Conv2d-9           [-1, 24, 22, 26]          10,104\n",
            "      BatchNorm2d-10           [-1, 24, 22, 26]              48\n",
            "             ReLU-11           [-1, 24, 22, 26]               0\n",
            "           Conv2d-12           [-1, 48, 28, 22]          14,448\n",
            "      BatchNorm2d-13           [-1, 48, 28, 22]              96\n",
            "             ReLU-14           [-1, 48, 28, 22]               0\n",
            "           Linear-15                    [-1, 7]         611,527\n",
            "================================================================\n",
            "Total params: 670,963\n",
            "Trainable params: 670,963\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.18\n",
            "Params size (MB): 2.56\n",
            "Estimated Total Size (MB): 4.75\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 22.4866, Validation Accuracy: 0.4646\n",
            "Epoch 2/100, Loss: 20.4750, Validation Accuracy: 0.6600\n",
            "Epoch 3/100, Loss: 109.6575, Validation Accuracy: 0.6710\n",
            "Epoch 4/100, Loss: 4.3532, Validation Accuracy: 0.3131\n",
            "Epoch 5/100, Loss: 1.6900, Validation Accuracy: 0.6291\n",
            "Epoch 6/100, Loss: 3.5641, Validation Accuracy: 0.2632\n",
            "Epoch 7/100, Loss: 3.9123, Validation Accuracy: 0.6042\n",
            "Epoch 8/100, Loss: 271.3723, Validation Accuracy: 0.5573\n",
            "Epoch 9/100, Loss: 30.9387, Validation Accuracy: 0.6181\n",
            "Epoch 10/100, Loss: 11.7022, Validation Accuracy: 0.6610\n",
            "Epoch 11/100, Loss: 8.4351, Validation Accuracy: 0.6341\n",
            "Epoch 12/100, Loss: 16.2638, Validation Accuracy: 0.5264\n",
            "Epoch 13/100, Loss: 22.4004, Validation Accuracy: 0.6600\n",
            "Epoch 14/100, Loss: 8.1178, Validation Accuracy: 0.5823\n",
            "Epoch 15/100, Loss: 13.4876, Validation Accuracy: 0.5553\n",
            "Epoch 16/100, Loss: 33.8206, Validation Accuracy: 0.5713\n",
            "Epoch 17/100, Loss: 86.3019, Validation Accuracy: 0.6241\n",
            "Epoch 18/100, Loss: 30.2644, Validation Accuracy: 0.5942\n",
            "Epoch 19/100, Loss: 40.4385, Validation Accuracy: 0.6251\n",
            "Epoch 20/100, Loss: 16.7104, Validation Accuracy: 0.5035\n",
            "Epoch 21/100, Loss: 14.8424, Validation Accuracy: 0.3151\n",
            "Epoch 22/100, Loss: 38.6127, Validation Accuracy: 0.5035\n",
            "Epoch 23/100, Loss: 21.2304, Validation Accuracy: 0.6072\n",
            "Epoch 24/100, Loss: 23.7917, Validation Accuracy: 0.6331\n",
            "Epoch 25/100, Loss: 34.8307, Validation Accuracy: 0.6710\n",
            "Epoch 26/100, Loss: 20.8124, Validation Accuracy: 0.5374\n",
            "Epoch 27/100, Loss: 16.9750, Validation Accuracy: 0.4646\n",
            "Epoch 28/100, Loss: 38.5755, Validation Accuracy: 0.4078\n",
            "Epoch 29/100, Loss: 45.3978, Validation Accuracy: 0.4756\n",
            "Epoch 30/100, Loss: 56.8536, Validation Accuracy: 0.6321\n",
            "Epoch 31/100, Loss: 9.1185, Validation Accuracy: 0.6939\n",
            "Epoch 32/100, Loss: 61.5366, Validation Accuracy: 0.3310\n",
            "Epoch 33/100, Loss: 18.8026, Validation Accuracy: 0.6510\n",
            "Epoch 34/100, Loss: 54.1970, Validation Accuracy: 0.5464\n",
            "Epoch 35/100, Loss: 36.4028, Validation Accuracy: 0.5474\n",
            "Epoch 36/100, Loss: 18.3585, Validation Accuracy: 0.6241\n",
            "Epoch 37/100, Loss: 31.2693, Validation Accuracy: 0.5773\n",
            "Epoch 38/100, Loss: 17.0604, Validation Accuracy: 0.6201\n",
            "Epoch 39/100, Loss: 19.6524, Validation Accuracy: 0.5563\n",
            "Epoch 40/100, Loss: 39.4593, Validation Accuracy: 0.6211\n",
            "Epoch 41/100, Loss: 46.2817, Validation Accuracy: 0.5264\n",
            "Epoch 42/100, Loss: 16.2699, Validation Accuracy: 0.3420\n",
            "Epoch 43/100, Loss: 21.0805, Validation Accuracy: 0.6171\n",
            "Epoch 44/100, Loss: 37.9943, Validation Accuracy: 0.6201\n",
            "Epoch 45/100, Loss: 45.5827, Validation Accuracy: 0.6221\n",
            "Epoch 46/100, Loss: 114.8626, Validation Accuracy: 0.5862\n",
            "Epoch 47/100, Loss: 83.3354, Validation Accuracy: 0.6012\n",
            "Epoch 48/100, Loss: 23.3346, Validation Accuracy: 0.5663\n",
            "Epoch 49/100, Loss: 8.4247, Validation Accuracy: 0.6022\n",
            "Epoch 50/100, Loss: 34.4867, Validation Accuracy: 0.5663\n",
            "Epoch 51/100, Loss: 31.8315, Validation Accuracy: 0.5882\n",
            "Epoch 52/100, Loss: 7.0270, Validation Accuracy: 0.6451\n",
            "Epoch 53/100, Loss: 38.7008, Validation Accuracy: 0.6271\n",
            "Epoch 54/100, Loss: 15.1204, Validation Accuracy: 0.6012\n",
            "Epoch 55/100, Loss: 50.6052, Validation Accuracy: 0.6800\n",
            "Epoch 56/100, Loss: 11.6384, Validation Accuracy: 0.4855\n",
            "Epoch 57/100, Loss: 54.2883, Validation Accuracy: 0.5573\n",
            "Epoch 58/100, Loss: 12.0652, Validation Accuracy: 0.5344\n",
            "Epoch 59/100, Loss: 20.3369, Validation Accuracy: 0.6271\n",
            "Epoch 60/100, Loss: 39.9306, Validation Accuracy: 0.6550\n",
            "Epoch 61/100, Loss: 25.4413, Validation Accuracy: 0.5334\n",
            "Epoch 62/100, Loss: 47.4391, Validation Accuracy: 0.5892\n",
            "Epoch 63/100, Loss: 54.4035, Validation Accuracy: 0.6530\n",
            "Epoch 64/100, Loss: 38.4460, Validation Accuracy: 0.5414\n",
            "Epoch 65/100, Loss: 17.1389, Validation Accuracy: 0.5045\n",
            "Epoch 66/100, Loss: 6.2331, Validation Accuracy: 0.4746\n",
            "Epoch 67/100, Loss: 33.5750, Validation Accuracy: 0.4347\n",
            "Epoch 68/100, Loss: 17.2293, Validation Accuracy: 0.5553\n",
            "Epoch 69/100, Loss: 67.8164, Validation Accuracy: 0.5743\n",
            "Epoch 70/100, Loss: 31.2516, Validation Accuracy: 0.6102\n",
            "Epoch 71/100, Loss: 25.3534, Validation Accuracy: 0.5593\n",
            "Epoch 72/100, Loss: 26.1667, Validation Accuracy: 0.5793\n",
            "Epoch 73/100, Loss: 22.2579, Validation Accuracy: 0.6142\n",
            "Epoch 74/100, Loss: 20.8986, Validation Accuracy: 0.5533\n",
            "Epoch 75/100, Loss: 53.0466, Validation Accuracy: 0.6510\n",
            "Epoch 76/100, Loss: 27.3257, Validation Accuracy: 0.4546\n",
            "Epoch 77/100, Loss: 37.5479, Validation Accuracy: 0.6261\n",
            "Epoch 78/100, Loss: 15.4957, Validation Accuracy: 0.5543\n",
            "Epoch 79/100, Loss: 28.6751, Validation Accuracy: 0.5394\n",
            "Epoch 80/100, Loss: 9.6157, Validation Accuracy: 0.5464\n",
            "Epoch 81/100, Loss: 41.0135, Validation Accuracy: 0.5703\n",
            "Epoch 82/100, Loss: 17.7752, Validation Accuracy: 0.5364\n",
            "Epoch 83/100, Loss: 34.3124, Validation Accuracy: 0.6032\n",
            "Epoch 84/100, Loss: 36.1612, Validation Accuracy: 0.5862\n",
            "Epoch 85/100, Loss: 36.8605, Validation Accuracy: 0.3410\n",
            "Epoch 86/100, Loss: 26.7105, Validation Accuracy: 0.6411\n",
            "Epoch 87/100, Loss: 34.2602, Validation Accuracy: 0.4995\n",
            "Epoch 88/100, Loss: 18.6774, Validation Accuracy: 0.6839\n",
            "Epoch 89/100, Loss: 42.5768, Validation Accuracy: 0.5424\n",
            "Epoch 90/100, Loss: 24.3087, Validation Accuracy: 0.5264\n",
            "Epoch 91/100, Loss: 26.3258, Validation Accuracy: 0.6321\n",
            "Epoch 92/100, Loss: 22.3884, Validation Accuracy: 0.5842\n",
            "Epoch 93/100, Loss: 11.0682, Validation Accuracy: 0.4875\n",
            "Epoch 94/100, Loss: 67.4770, Validation Accuracy: 0.6481\n",
            "Epoch 95/100, Loss: 10.7960, Validation Accuracy: 0.5852\n",
            "Epoch 96/100, Loss: 63.3813, Validation Accuracy: 0.5733\n",
            "Epoch 97/100, Loss: 25.9685, Validation Accuracy: 0.6411\n",
            "Epoch 98/100, Loss: 20.6802, Validation Accuracy: 0.6281\n",
            "Epoch 99/100, Loss: 20.6321, Validation Accuracy: 0.5484\n",
            "Epoch 100/100, Loss: 11.3331, Validation Accuracy: 0.5922\n",
            "Epoch 101/100, Loss: 23.2776, Validation Accuracy: 0.5613\n",
            "Epoch 102/100, Loss: 86.9120, Validation Accuracy: 0.5623\n",
            "Epoch 103/100, Loss: 8.4171, Validation Accuracy: 0.6441\n",
            "Epoch 104/100, Loss: 21.5998, Validation Accuracy: 0.6451\n",
            "Epoch 105/100, Loss: 34.0057, Validation Accuracy: 0.5045\n",
            "Epoch 106/100, Loss: 38.0496, Validation Accuracy: 0.5633\n",
            "Epoch 107/100, Loss: 54.1323, Validation Accuracy: 0.6461\n",
            "Epoch 108/100, Loss: 86.7160, Validation Accuracy: 0.6560\n",
            "Epoch 109/100, Loss: 10.1383, Validation Accuracy: 0.6481\n",
            "Epoch 110/100, Loss: 48.5208, Validation Accuracy: 0.6281\n",
            "Epoch 111/100, Loss: 28.0304, Validation Accuracy: 0.6830\n",
            "Epoch 112/100, Loss: 35.2611, Validation Accuracy: 0.6830\n",
            "Epoch 113/100, Loss: 52.3211, Validation Accuracy: 0.6441\n",
            "Epoch 114/100, Loss: 26.9125, Validation Accuracy: 0.6580\n",
            "Epoch 115/100, Loss: 26.7630, Validation Accuracy: 0.4407\n",
            "Epoch 116/100, Loss: 21.4021, Validation Accuracy: 0.6271\n",
            "Epoch 117/100, Loss: 19.8113, Validation Accuracy: 0.6281\n",
            "Epoch 118/100, Loss: 61.1753, Validation Accuracy: 0.6162\n",
            "Epoch 119/100, Loss: 123.1447, Validation Accuracy: 0.5663\n",
            "Epoch 120/100, Loss: 42.3895, Validation Accuracy: 0.5872\n",
            "Epoch 121/100, Loss: 22.4520, Validation Accuracy: 0.6510\n",
            "Epoch 122/100, Loss: 23.8175, Validation Accuracy: 0.6471\n",
            "Epoch 123/100, Loss: 26.3479, Validation Accuracy: 0.5882\n",
            "Epoch 124/100, Loss: 31.3903, Validation Accuracy: 0.6670\n",
            "Epoch 125/100, Loss: 16.0502, Validation Accuracy: 0.6510\n",
            "Epoch 126/100, Loss: 44.2212, Validation Accuracy: 0.6052\n",
            "Epoch 127/100, Loss: 54.5120, Validation Accuracy: 0.6321\n",
            "Epoch 128/100, Loss: 32.5838, Validation Accuracy: 0.6670\n",
            "Epoch 129/100, Loss: 40.0146, Validation Accuracy: 0.6221\n",
            "Epoch 130/100, Loss: 41.4482, Validation Accuracy: 0.6461\n",
            "Epoch 131/100, Loss: 37.8415, Validation Accuracy: 0.5095\n",
            "Epoch 132/100, Loss: 33.8827, Validation Accuracy: 0.6152\n",
            "Epoch 133/100, Loss: 23.1654, Validation Accuracy: 0.5753\n",
            "Epoch 134/100, Loss: 67.8367, Validation Accuracy: 0.6261\n",
            "Epoch 135/100, Loss: 51.0664, Validation Accuracy: 0.5743\n",
            "Epoch 136/100, Loss: 40.5670, Validation Accuracy: 0.6072\n",
            "Epoch 137/100, Loss: 30.5875, Validation Accuracy: 0.5693\n",
            "Epoch 138/100, Loss: 19.4415, Validation Accuracy: 0.5304\n",
            "Epoch 139/100, Loss: 75.7850, Validation Accuracy: 0.6441\n",
            "Epoch 140/100, Loss: 44.3570, Validation Accuracy: 0.4397\n",
            "Epoch 141/100, Loss: 20.4886, Validation Accuracy: 0.5174\n",
            "Epoch 142/100, Loss: 80.9241, Validation Accuracy: 0.1047\n",
            "Epoch 143/100, Loss: 16.8895, Validation Accuracy: 0.5813\n",
            "Epoch 144/100, Loss: 20.6070, Validation Accuracy: 0.6291\n",
            "Epoch 145/100, Loss: 11.0009, Validation Accuracy: 0.5803\n",
            "Epoch 146/100, Loss: 40.0051, Validation Accuracy: 0.5384\n",
            "Epoch 147/100, Loss: 37.4807, Validation Accuracy: 0.6530\n",
            "Epoch 148/100, Loss: 15.2690, Validation Accuracy: 0.5603\n",
            "Epoch 149/100, Loss: 20.3777, Validation Accuracy: 0.6341\n",
            "Epoch 150/100, Loss: 16.0584, Validation Accuracy: 0.5942\n",
            "Epoch 151/100, Loss: 74.8524, Validation Accuracy: 0.5563\n",
            "Epoch 152/100, Loss: 51.4140, Validation Accuracy: 0.6171\n",
            "Epoch 153/100, Loss: 10.1887, Validation Accuracy: 0.5035\n",
            "Epoch 154/100, Loss: 17.6575, Validation Accuracy: 0.5214\n",
            "Epoch 155/100, Loss: 22.2032, Validation Accuracy: 0.5823\n",
            "Epoch 156/100, Loss: 36.5217, Validation Accuracy: 0.6500\n",
            "Epoch 157/100, Loss: 75.8294, Validation Accuracy: 0.5414\n",
            "Epoch 158/100, Loss: 40.8007, Validation Accuracy: 0.6471\n",
            "Epoch 159/100, Loss: 18.1709, Validation Accuracy: 0.6471\n",
            "Epoch 160/100, Loss: 84.5430, Validation Accuracy: 0.6510\n",
            "Epoch 161/100, Loss: 29.8511, Validation Accuracy: 0.6680\n",
            "Epoch 162/100, Loss: 50.9938, Validation Accuracy: 0.6441\n",
            "Epoch 163/100, Loss: 20.7479, Validation Accuracy: 0.6491\n",
            "Epoch 164/100, Loss: 36.5548, Validation Accuracy: 0.4536\n",
            "Epoch 165/100, Loss: 26.2405, Validation Accuracy: 0.5394\n",
            "Epoch 166/100, Loss: 11.8000, Validation Accuracy: 0.5813\n",
            "Epoch 167/100, Loss: 53.2325, Validation Accuracy: 0.5444\n",
            "Epoch 168/100, Loss: 13.1890, Validation Accuracy: 0.5942\n",
            "Epoch 169/100, Loss: 68.7793, Validation Accuracy: 0.5653\n",
            "Epoch 170/100, Loss: 24.0733, Validation Accuracy: 0.6092\n",
            "Epoch 171/100, Loss: 57.5800, Validation Accuracy: 0.5793\n",
            "Epoch 172/100, Loss: 33.3335, Validation Accuracy: 0.6670\n",
            "Epoch 173/100, Loss: 4.8943, Validation Accuracy: 0.6171\n",
            "Epoch 174/100, Loss: 28.0785, Validation Accuracy: 0.6072\n",
            "Epoch 175/100, Loss: 68.6198, Validation Accuracy: 0.5125\n",
            "Epoch 176/100, Loss: 51.4888, Validation Accuracy: 0.6939\n",
            "Epoch 177/100, Loss: 26.3969, Validation Accuracy: 0.6331\n",
            "Epoch 178/100, Loss: 34.0660, Validation Accuracy: 0.4925\n",
            "Epoch 179/100, Loss: 12.6529, Validation Accuracy: 0.5753\n",
            "Epoch 180/100, Loss: 49.6183, Validation Accuracy: 0.4337\n",
            "Epoch 181/100, Loss: 57.9901, Validation Accuracy: 0.6191\n",
            "Epoch 182/100, Loss: 45.7873, Validation Accuracy: 0.3011\n",
            "Epoch 183/100, Loss: 68.8743, Validation Accuracy: 0.5593\n",
            "Epoch 184/100, Loss: 17.4687, Validation Accuracy: 0.6381\n",
            "Epoch 185/100, Loss: 15.7945, Validation Accuracy: 0.5623\n",
            "Epoch 186/100, Loss: 29.9148, Validation Accuracy: 0.6421\n",
            "Epoch 187/100, Loss: 77.7244, Validation Accuracy: 0.5703\n",
            "Epoch 188/100, Loss: 9.3630, Validation Accuracy: 0.6261\n",
            "Epoch 189/100, Loss: 14.7488, Validation Accuracy: 0.6560\n",
            "Epoch 190/100, Loss: 37.9831, Validation Accuracy: 0.5793\n",
            "Epoch 191/100, Loss: 22.6716, Validation Accuracy: 0.5813\n",
            "Epoch 192/100, Loss: 16.6448, Validation Accuracy: 0.6082\n",
            "Epoch 193/100, Loss: 29.4605, Validation Accuracy: 0.6241\n",
            "Epoch 194/100, Loss: 63.3662, Validation Accuracy: 0.5673\n",
            "Epoch 195/100, Loss: 17.8570, Validation Accuracy: 0.6411\n",
            "Epoch 196/100, Loss: 30.4404, Validation Accuracy: 0.6062\n",
            "Epoch 197/100, Loss: 38.8066, Validation Accuracy: 0.5982\n",
            "Epoch 198/100, Loss: 41.5987, Validation Accuracy: 0.5683\n",
            "Epoch 199/100, Loss: 49.8219, Validation Accuracy: 0.6291\n",
            "Epoch 200/100, Loss: 23.0296, Validation Accuracy: 0.5952\n",
            "Reward for Child Model: 0.24899193408820353\n",
            "Child_35:  {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, [0, 1, 1, 0, 1, 1, 2, 3, 0, 3, 0, 0, 0, 2, 2], 0.24899193408820353\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 64, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(64, 24, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(112, 48, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(136, 64, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=123200, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 28, 22]             528\n",
            "       BatchNorm2d-2           [-1, 24, 28, 22]              48\n",
            "            Conv2d-3           [-1, 64, 24, 16]          53,824\n",
            "       BatchNorm2d-4           [-1, 64, 24, 16]             128\n",
            "              ReLU-5           [-1, 64, 24, 16]               0\n",
            "            Conv2d-6           [-1, 24, 22, 14]          13,848\n",
            "       BatchNorm2d-7           [-1, 24, 22, 14]              48\n",
            "              ReLU-8           [-1, 24, 22, 14]               0\n",
            "            Conv2d-9           [-1, 48, 26, 18]          80,688\n",
            "      BatchNorm2d-10           [-1, 48, 26, 18]              96\n",
            "             ReLU-11           [-1, 48, 26, 18]               0\n",
            "           Conv2d-12           [-1, 64, 22, 20]         182,848\n",
            "      BatchNorm2d-13           [-1, 64, 22, 20]             128\n",
            "             ReLU-14           [-1, 64, 22, 20]               0\n",
            "           Linear-15                    [-1, 7]         862,407\n",
            "================================================================\n",
            "Total params: 1,194,591\n",
            "Trainable params: 1,194,591\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.12\n",
            "Params size (MB): 4.56\n",
            "Estimated Total Size (MB): 6.68\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 11.6687, Validation Accuracy: 0.6281\n",
            "Epoch 2/100, Loss: 2.1654, Validation Accuracy: 0.4835\n",
            "Epoch 3/100, Loss: 24.4485, Validation Accuracy: 0.3101\n",
            "Epoch 4/100, Loss: 50.2176, Validation Accuracy: 0.5254\n",
            "Epoch 5/100, Loss: 16.0450, Validation Accuracy: 0.6560\n",
            "Epoch 6/100, Loss: 43.1023, Validation Accuracy: 0.3280\n",
            "Epoch 7/100, Loss: 13.2830, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 86.2175, Validation Accuracy: 0.4277\n",
            "Epoch 9/100, Loss: 6.7424, Validation Accuracy: 0.5055\n",
            "Epoch 10/100, Loss: 6.3928, Validation Accuracy: 0.6889\n",
            "Epoch 11/100, Loss: 11.2287, Validation Accuracy: 0.6441\n",
            "Epoch 12/100, Loss: 23.0874, Validation Accuracy: 0.4177\n",
            "Epoch 13/100, Loss: 39.7408, Validation Accuracy: 0.6620\n",
            "Epoch 14/100, Loss: 25.5294, Validation Accuracy: 0.6500\n",
            "Epoch 15/100, Loss: 11.6480, Validation Accuracy: 0.2453\n",
            "Epoch 16/100, Loss: 2.9158, Validation Accuracy: 0.3410\n",
            "Epoch 17/100, Loss: 6.4616, Validation Accuracy: 0.6022\n",
            "Epoch 18/100, Loss: 5.2765, Validation Accuracy: 0.6371\n",
            "Epoch 19/100, Loss: 3.5703, Validation Accuracy: 0.6391\n",
            "Epoch 20/100, Loss: 16.7515, Validation Accuracy: 0.6600\n",
            "Epoch 21/100, Loss: 20.2823, Validation Accuracy: 0.6590\n",
            "Epoch 22/100, Loss: 8.5018, Validation Accuracy: 0.3998\n",
            "Epoch 23/100, Loss: 7.1541, Validation Accuracy: 0.5932\n",
            "Epoch 24/100, Loss: 11.8493, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 29.5482, Validation Accuracy: 0.6481\n",
            "Epoch 26/100, Loss: 14.9151, Validation Accuracy: 0.6211\n",
            "Epoch 27/100, Loss: 14.6977, Validation Accuracy: 0.6411\n",
            "Epoch 28/100, Loss: 36.1523, Validation Accuracy: 0.6560\n",
            "Epoch 29/100, Loss: 53.5009, Validation Accuracy: 0.5075\n",
            "Epoch 30/100, Loss: 12.1678, Validation Accuracy: 0.3360\n",
            "Epoch 31/100, Loss: 12.9729, Validation Accuracy: 0.4516\n",
            "Epoch 32/100, Loss: 8.1818, Validation Accuracy: 0.5723\n",
            "Epoch 33/100, Loss: 15.0949, Validation Accuracy: 0.6142\n",
            "Epoch 34/100, Loss: 80.9142, Validation Accuracy: 0.5374\n",
            "Epoch 35/100, Loss: 7.9275, Validation Accuracy: 0.5274\n",
            "Epoch 36/100, Loss: 5.3050, Validation Accuracy: 0.4467\n",
            "Epoch 37/100, Loss: 25.5452, Validation Accuracy: 0.4197\n",
            "Epoch 38/100, Loss: 5.4368, Validation Accuracy: 0.3500\n",
            "Epoch 39/100, Loss: 89.7044, Validation Accuracy: 0.4546\n",
            "Epoch 40/100, Loss: 11.2576, Validation Accuracy: 0.6102\n",
            "Epoch 41/100, Loss: 4.7567, Validation Accuracy: 0.6670\n",
            "Epoch 42/100, Loss: 5.5210, Validation Accuracy: 0.6032\n",
            "Epoch 43/100, Loss: 6.7872, Validation Accuracy: 0.6560\n",
            "Epoch 44/100, Loss: 34.5993, Validation Accuracy: 0.5573\n",
            "Epoch 45/100, Loss: 53.1912, Validation Accuracy: 0.6441\n",
            "Epoch 46/100, Loss: 11.8794, Validation Accuracy: 0.5533\n",
            "Epoch 47/100, Loss: 17.3542, Validation Accuracy: 0.6281\n",
            "Epoch 48/100, Loss: 8.3875, Validation Accuracy: 0.6431\n",
            "Epoch 49/100, Loss: 7.6809, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 11.2182, Validation Accuracy: 0.6231\n",
            "Epoch 51/100, Loss: 12.7928, Validation Accuracy: 0.5304\n",
            "Epoch 52/100, Loss: 17.7312, Validation Accuracy: 0.5404\n",
            "Epoch 53/100, Loss: 8.4028, Validation Accuracy: 0.6082\n",
            "Epoch 54/100, Loss: 3.4787, Validation Accuracy: 0.6660\n",
            "Epoch 55/100, Loss: 3.3437, Validation Accuracy: 0.5314\n",
            "Epoch 56/100, Loss: 2.3775, Validation Accuracy: 0.6122\n",
            "Epoch 57/100, Loss: 9.9865, Validation Accuracy: 0.6790\n",
            "Epoch 58/100, Loss: 50.1674, Validation Accuracy: 0.6002\n",
            "Epoch 59/100, Loss: 29.6858, Validation Accuracy: 0.4467\n",
            "Epoch 60/100, Loss: 11.6811, Validation Accuracy: 0.6062\n",
            "Epoch 61/100, Loss: 7.5121, Validation Accuracy: 0.6550\n",
            "Epoch 62/100, Loss: 18.7553, Validation Accuracy: 0.4377\n",
            "Epoch 63/100, Loss: 27.0792, Validation Accuracy: 0.6620\n",
            "Epoch 64/100, Loss: 5.2704, Validation Accuracy: 0.6321\n",
            "Epoch 65/100, Loss: 6.6746, Validation Accuracy: 0.4666\n",
            "Epoch 66/100, Loss: 11.5251, Validation Accuracy: 0.4965\n",
            "Epoch 67/100, Loss: 9.7563, Validation Accuracy: 0.4536\n",
            "Epoch 68/100, Loss: 26.9604, Validation Accuracy: 0.5573\n",
            "Epoch 69/100, Loss: 21.8384, Validation Accuracy: 0.6670\n",
            "Epoch 70/100, Loss: 10.1248, Validation Accuracy: 0.6291\n",
            "Epoch 71/100, Loss: 64.8431, Validation Accuracy: 0.5324\n",
            "Epoch 72/100, Loss: 11.2539, Validation Accuracy: 0.6590\n",
            "Epoch 73/100, Loss: 17.2383, Validation Accuracy: 0.5803\n",
            "Epoch 74/100, Loss: 9.1120, Validation Accuracy: 0.6570\n",
            "Epoch 75/100, Loss: 22.9706, Validation Accuracy: 0.6191\n",
            "Epoch 76/100, Loss: 15.4371, Validation Accuracy: 0.3559\n",
            "Epoch 77/100, Loss: 33.1389, Validation Accuracy: 0.4835\n",
            "Epoch 78/100, Loss: 43.6535, Validation Accuracy: 0.3848\n",
            "Epoch 79/100, Loss: 9.6986, Validation Accuracy: 0.5942\n",
            "Epoch 80/100, Loss: 10.4491, Validation Accuracy: 0.5194\n",
            "Epoch 81/100, Loss: 16.6575, Validation Accuracy: 0.6291\n",
            "Epoch 82/100, Loss: 14.8484, Validation Accuracy: 0.6431\n",
            "Epoch 83/100, Loss: 19.7551, Validation Accuracy: 0.6481\n",
            "Epoch 84/100, Loss: 23.5935, Validation Accuracy: 0.6411\n",
            "Epoch 85/100, Loss: 17.9804, Validation Accuracy: 0.4945\n",
            "Epoch 86/100, Loss: 6.8343, Validation Accuracy: 0.6072\n",
            "Epoch 87/100, Loss: 21.5824, Validation Accuracy: 0.6500\n",
            "Epoch 88/100, Loss: 16.4936, Validation Accuracy: 0.4327\n",
            "Epoch 89/100, Loss: 29.4838, Validation Accuracy: 0.5533\n",
            "Epoch 90/100, Loss: 12.8367, Validation Accuracy: 0.5773\n",
            "Epoch 91/100, Loss: 8.0045, Validation Accuracy: 0.6291\n",
            "Epoch 92/100, Loss: 8.6725, Validation Accuracy: 0.6401\n",
            "Epoch 93/100, Loss: 14.6076, Validation Accuracy: 0.5663\n",
            "Epoch 94/100, Loss: 13.5808, Validation Accuracy: 0.5693\n",
            "Epoch 95/100, Loss: 41.2512, Validation Accuracy: 0.5872\n",
            "Epoch 96/100, Loss: 19.2611, Validation Accuracy: 0.4267\n",
            "Epoch 97/100, Loss: 9.6827, Validation Accuracy: 0.5633\n",
            "Epoch 98/100, Loss: 5.9516, Validation Accuracy: 0.5593\n",
            "Epoch 99/100, Loss: 5.4117, Validation Accuracy: 0.5374\n",
            "Epoch 100/100, Loss: 20.9340, Validation Accuracy: 0.3619\n",
            "Epoch 101/100, Loss: 11.5086, Validation Accuracy: 0.6630\n",
            "Epoch 102/100, Loss: 9.6651, Validation Accuracy: 0.5603\n",
            "Epoch 103/100, Loss: 4.0770, Validation Accuracy: 0.5155\n",
            "Epoch 104/100, Loss: 19.5381, Validation Accuracy: 0.5862\n",
            "Epoch 105/100, Loss: 19.2749, Validation Accuracy: 0.3958\n",
            "Epoch 106/100, Loss: 12.0639, Validation Accuracy: 0.5733\n",
            "Epoch 107/100, Loss: 31.5726, Validation Accuracy: 0.5434\n",
            "Epoch 108/100, Loss: 11.3991, Validation Accuracy: 0.6680\n",
            "Epoch 109/100, Loss: 15.0490, Validation Accuracy: 0.5852\n",
            "Epoch 110/100, Loss: 7.3149, Validation Accuracy: 0.6022\n",
            "Epoch 111/100, Loss: 8.0011, Validation Accuracy: 0.6570\n",
            "Epoch 112/100, Loss: 15.1703, Validation Accuracy: 0.6241\n",
            "Epoch 113/100, Loss: 17.2524, Validation Accuracy: 0.6710\n",
            "Epoch 114/100, Loss: 15.4410, Validation Accuracy: 0.4955\n",
            "Epoch 115/100, Loss: 51.3116, Validation Accuracy: 0.5015\n",
            "Epoch 116/100, Loss: 21.2299, Validation Accuracy: 0.6321\n",
            "Epoch 117/100, Loss: 18.1474, Validation Accuracy: 0.5972\n",
            "Epoch 118/100, Loss: 12.3320, Validation Accuracy: 0.6510\n",
            "Epoch 119/100, Loss: 20.4799, Validation Accuracy: 0.6171\n",
            "Epoch 120/100, Loss: 12.9421, Validation Accuracy: 0.6381\n",
            "Epoch 121/100, Loss: 42.0685, Validation Accuracy: 0.5952\n",
            "Epoch 122/100, Loss: 16.8729, Validation Accuracy: 0.6620\n",
            "Epoch 123/100, Loss: 13.5770, Validation Accuracy: 0.5912\n",
            "Epoch 124/100, Loss: 44.7797, Validation Accuracy: 0.5663\n",
            "Epoch 125/100, Loss: 9.0315, Validation Accuracy: 0.4816\n",
            "Epoch 126/100, Loss: 12.4497, Validation Accuracy: 0.6331\n",
            "Epoch 127/100, Loss: 23.8979, Validation Accuracy: 0.5454\n",
            "Epoch 128/100, Loss: 8.6745, Validation Accuracy: 0.6640\n",
            "Epoch 129/100, Loss: 13.3900, Validation Accuracy: 0.5643\n",
            "Epoch 130/100, Loss: 6.0241, Validation Accuracy: 0.5623\n",
            "Epoch 131/100, Loss: 69.3959, Validation Accuracy: 0.6092\n",
            "Epoch 132/100, Loss: 11.7576, Validation Accuracy: 0.6042\n",
            "Epoch 133/100, Loss: 38.7807, Validation Accuracy: 0.3061\n",
            "Epoch 134/100, Loss: 20.2223, Validation Accuracy: 0.6750\n",
            "Epoch 135/100, Loss: 26.4564, Validation Accuracy: 0.5474\n",
            "Epoch 136/100, Loss: 21.4331, Validation Accuracy: 0.4826\n",
            "Epoch 137/100, Loss: 26.4757, Validation Accuracy: 0.5763\n",
            "Epoch 138/100, Loss: 17.1296, Validation Accuracy: 0.5942\n",
            "Epoch 139/100, Loss: 23.0575, Validation Accuracy: 0.6391\n",
            "Epoch 140/100, Loss: 13.7629, Validation Accuracy: 0.6301\n",
            "Epoch 141/100, Loss: 9.9375, Validation Accuracy: 0.6401\n",
            "Epoch 142/100, Loss: 55.3681, Validation Accuracy: 0.5733\n",
            "Epoch 143/100, Loss: 27.7870, Validation Accuracy: 0.6361\n",
            "Epoch 144/100, Loss: 33.5329, Validation Accuracy: 0.5344\n",
            "Epoch 145/100, Loss: 16.8425, Validation Accuracy: 0.6321\n",
            "Epoch 146/100, Loss: 8.8155, Validation Accuracy: 0.3749\n",
            "Epoch 147/100, Loss: 15.4823, Validation Accuracy: 0.6391\n",
            "Epoch 148/100, Loss: 7.3474, Validation Accuracy: 0.6570\n",
            "Epoch 149/100, Loss: 12.2999, Validation Accuracy: 0.5015\n",
            "Epoch 150/100, Loss: 8.7133, Validation Accuracy: 0.6181\n",
            "Epoch 151/100, Loss: 28.3812, Validation Accuracy: 0.5234\n",
            "Epoch 152/100, Loss: 22.5298, Validation Accuracy: 0.6730\n",
            "Epoch 153/100, Loss: 19.1865, Validation Accuracy: 0.6321\n",
            "Epoch 154/100, Loss: 17.5058, Validation Accuracy: 0.5982\n",
            "Epoch 155/100, Loss: 45.7312, Validation Accuracy: 0.5703\n",
            "Epoch 156/100, Loss: 14.0711, Validation Accuracy: 0.4506\n",
            "Epoch 157/100, Loss: 6.8405, Validation Accuracy: 0.5823\n",
            "Epoch 158/100, Loss: 11.9878, Validation Accuracy: 0.5264\n",
            "Epoch 159/100, Loss: 18.2406, Validation Accuracy: 0.6072\n",
            "Epoch 160/100, Loss: 5.5086, Validation Accuracy: 0.6630\n",
            "Epoch 161/100, Loss: 17.4586, Validation Accuracy: 0.6630\n",
            "Epoch 162/100, Loss: 12.7662, Validation Accuracy: 0.4516\n",
            "Epoch 163/100, Loss: 11.9164, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 48.2037, Validation Accuracy: 0.2283\n",
            "Epoch 165/100, Loss: 18.1631, Validation Accuracy: 0.6271\n",
            "Epoch 166/100, Loss: 19.1972, Validation Accuracy: 0.6750\n",
            "Epoch 167/100, Loss: 7.6995, Validation Accuracy: 0.5494\n",
            "Epoch 168/100, Loss: 8.8905, Validation Accuracy: 0.4895\n",
            "Epoch 169/100, Loss: 10.0500, Validation Accuracy: 0.6630\n",
            "Epoch 170/100, Loss: 15.0863, Validation Accuracy: 0.6421\n",
            "Epoch 171/100, Loss: 8.0507, Validation Accuracy: 0.6062\n",
            "Epoch 172/100, Loss: 16.6703, Validation Accuracy: 0.5314\n",
            "Epoch 173/100, Loss: 6.9804, Validation Accuracy: 0.6640\n",
            "Epoch 174/100, Loss: 19.8389, Validation Accuracy: 0.5703\n",
            "Epoch 175/100, Loss: 11.5299, Validation Accuracy: 0.6281\n",
            "Epoch 176/100, Loss: 15.6690, Validation Accuracy: 0.6371\n",
            "Epoch 177/100, Loss: 11.3123, Validation Accuracy: 0.6610\n",
            "Epoch 178/100, Loss: 9.2068, Validation Accuracy: 0.6381\n",
            "Epoch 179/100, Loss: 22.1594, Validation Accuracy: 0.6351\n",
            "Epoch 180/100, Loss: 41.5371, Validation Accuracy: 0.5583\n",
            "Epoch 181/100, Loss: 7.1520, Validation Accuracy: 0.6181\n",
            "Epoch 182/100, Loss: 23.4336, Validation Accuracy: 0.6391\n",
            "Epoch 183/100, Loss: 21.1758, Validation Accuracy: 0.4756\n",
            "Epoch 184/100, Loss: 18.7726, Validation Accuracy: 0.4257\n",
            "Epoch 185/100, Loss: 44.1385, Validation Accuracy: 0.5384\n",
            "Epoch 186/100, Loss: 9.0379, Validation Accuracy: 0.5533\n",
            "Epoch 187/100, Loss: 20.7148, Validation Accuracy: 0.5105\n",
            "Epoch 188/100, Loss: 25.0913, Validation Accuracy: 0.5145\n",
            "Epoch 189/100, Loss: 21.6093, Validation Accuracy: 0.5523\n",
            "Epoch 190/100, Loss: 10.0733, Validation Accuracy: 0.6191\n",
            "Epoch 191/100, Loss: 9.2060, Validation Accuracy: 0.5105\n",
            "Epoch 192/100, Loss: 32.9263, Validation Accuracy: 0.6032\n",
            "Epoch 193/100, Loss: 11.7586, Validation Accuracy: 0.5045\n",
            "Epoch 194/100, Loss: 22.0506, Validation Accuracy: 0.6311\n",
            "Epoch 195/100, Loss: 30.5075, Validation Accuracy: 0.2363\n",
            "Epoch 196/100, Loss: 8.8187, Validation Accuracy: 0.5733\n",
            "Epoch 197/100, Loss: 18.5580, Validation Accuracy: 0.6132\n",
            "Epoch 198/100, Loss: 21.4323, Validation Accuracy: 0.6640\n",
            "Epoch 199/100, Loss: 8.6486, Validation Accuracy: 0.5434\n",
            "Epoch 200/100, Loss: 13.1578, Validation Accuracy: 0.3848\n",
            "Reward for Child Model: 0.2927654939811637\n",
            "Child_36:  {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, [0, 3, 0, 2, 3, 3, 1, 1, 0, 1, 2, 2, 3, 1, 3], 0.2927654939811637\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(112, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(224, 64, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(64, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=230400, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 24, 24]           4,864\n",
            "       BatchNorm2d-2           [-1, 64, 24, 24]             128\n",
            "            Conv2d-3           [-1, 48, 18, 22]          64,560\n",
            "       BatchNorm2d-4           [-1, 48, 18, 22]              96\n",
            "              ReLU-5           [-1, 48, 18, 22]               0\n",
            "            Conv2d-6           [-1, 48, 18, 22]         112,944\n",
            "       BatchNorm2d-7           [-1, 48, 18, 22]              96\n",
            "              ReLU-8           [-1, 48, 18, 22]               0\n",
            "            Conv2d-9           [-1, 64, 18, 20]         501,824\n",
            "      BatchNorm2d-10           [-1, 64, 18, 20]             128\n",
            "             ReLU-11           [-1, 64, 18, 20]               0\n",
            "           Conv2d-12           [-1, 48, 16, 20]           9,264\n",
            "      BatchNorm2d-13           [-1, 48, 16, 20]              96\n",
            "             ReLU-14           [-1, 48, 16, 20]               0\n",
            "           Linear-15                    [-1, 7]       1,612,807\n",
            "================================================================\n",
            "Total params: 2,306,807\n",
            "Trainable params: 2,306,807\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.31\n",
            "Params size (MB): 8.80\n",
            "Estimated Total Size (MB): 11.12\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 62.8174, Validation Accuracy: 0.4676\n",
            "Epoch 2/100, Loss: 23.2191, Validation Accuracy: 0.6750\n",
            "Epoch 3/100, Loss: 285.9745, Validation Accuracy: 0.6481\n",
            "Epoch 4/100, Loss: 70.0367, Validation Accuracy: 0.6660\n",
            "Epoch 5/100, Loss: 82.3675, Validation Accuracy: 0.5793\n",
            "Epoch 6/100, Loss: 38.7799, Validation Accuracy: 0.5892\n",
            "Epoch 7/100, Loss: 206.0404, Validation Accuracy: 0.6770\n",
            "Epoch 8/100, Loss: 139.5821, Validation Accuracy: 0.4796\n",
            "Epoch 9/100, Loss: 113.7997, Validation Accuracy: 0.5553\n",
            "Epoch 10/100, Loss: 83.2911, Validation Accuracy: 0.6401\n",
            "Epoch 11/100, Loss: 154.5531, Validation Accuracy: 0.6510\n",
            "Epoch 12/100, Loss: 463.5212, Validation Accuracy: 0.5414\n",
            "Epoch 13/100, Loss: 77.7230, Validation Accuracy: 0.6451\n",
            "Epoch 14/100, Loss: 37.2514, Validation Accuracy: 0.5055\n",
            "Epoch 15/100, Loss: 257.1890, Validation Accuracy: 0.5454\n",
            "Epoch 16/100, Loss: 256.0148, Validation Accuracy: 0.6231\n",
            "Epoch 17/100, Loss: 339.6497, Validation Accuracy: 0.4975\n",
            "Epoch 18/100, Loss: 58.1638, Validation Accuracy: 0.5314\n",
            "Epoch 19/100, Loss: 126.8225, Validation Accuracy: 0.6520\n",
            "Epoch 20/100, Loss: 102.5935, Validation Accuracy: 0.6162\n",
            "Epoch 21/100, Loss: 98.3220, Validation Accuracy: 0.6680\n",
            "Epoch 22/100, Loss: 581.2233, Validation Accuracy: 0.5982\n",
            "Epoch 23/100, Loss: 122.8945, Validation Accuracy: 0.6800\n",
            "Epoch 24/100, Loss: 380.5731, Validation Accuracy: 0.1864\n",
            "Epoch 25/100, Loss: 67.2951, Validation Accuracy: 0.6650\n",
            "Epoch 26/100, Loss: 195.0615, Validation Accuracy: 0.6311\n",
            "Epoch 27/100, Loss: 383.7766, Validation Accuracy: 0.5743\n",
            "Epoch 28/100, Loss: 92.5506, Validation Accuracy: 0.4925\n",
            "Epoch 29/100, Loss: 185.4355, Validation Accuracy: 0.6820\n",
            "Epoch 30/100, Loss: 43.9599, Validation Accuracy: 0.5922\n",
            "Epoch 31/100, Loss: 150.8083, Validation Accuracy: 0.5643\n",
            "Epoch 32/100, Loss: 387.1934, Validation Accuracy: 0.6221\n",
            "Epoch 33/100, Loss: 138.0200, Validation Accuracy: 0.6849\n",
            "Epoch 34/100, Loss: 74.5230, Validation Accuracy: 0.5135\n",
            "Epoch 35/100, Loss: 144.1301, Validation Accuracy: 0.6451\n",
            "Epoch 36/100, Loss: 73.8298, Validation Accuracy: 0.6849\n",
            "Epoch 37/100, Loss: 83.3337, Validation Accuracy: 0.5683\n",
            "Epoch 38/100, Loss: 165.3717, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 199.4066, Validation Accuracy: 0.5304\n",
            "Epoch 40/100, Loss: 195.8185, Validation Accuracy: 0.6540\n",
            "Epoch 41/100, Loss: 41.3271, Validation Accuracy: 0.6241\n",
            "Epoch 42/100, Loss: 179.6630, Validation Accuracy: 0.6640\n",
            "Epoch 43/100, Loss: 271.5508, Validation Accuracy: 0.6949\n",
            "Epoch 44/100, Loss: 137.9043, Validation Accuracy: 0.5503\n",
            "Epoch 45/100, Loss: 118.9217, Validation Accuracy: 0.6441\n",
            "Epoch 46/100, Loss: 135.9481, Validation Accuracy: 0.6550\n",
            "Epoch 47/100, Loss: 82.2556, Validation Accuracy: 0.6720\n",
            "Epoch 48/100, Loss: 143.0085, Validation Accuracy: 0.5803\n",
            "Epoch 49/100, Loss: 150.1424, Validation Accuracy: 0.6540\n",
            "Epoch 50/100, Loss: 115.4516, Validation Accuracy: 0.6790\n",
            "Epoch 51/100, Loss: 69.4194, Validation Accuracy: 0.6580\n",
            "Epoch 52/100, Loss: 114.7585, Validation Accuracy: 0.6171\n",
            "Epoch 53/100, Loss: 123.6120, Validation Accuracy: 0.5962\n",
            "Epoch 54/100, Loss: 189.0781, Validation Accuracy: 0.6311\n",
            "Epoch 55/100, Loss: 333.9987, Validation Accuracy: 0.6680\n",
            "Epoch 56/100, Loss: 409.3160, Validation Accuracy: 0.5922\n",
            "Epoch 57/100, Loss: 316.0510, Validation Accuracy: 0.6830\n",
            "Epoch 58/100, Loss: 52.0655, Validation Accuracy: 0.6211\n",
            "Epoch 59/100, Loss: 35.6278, Validation Accuracy: 0.6471\n",
            "Epoch 60/100, Loss: 90.0593, Validation Accuracy: 0.6540\n",
            "Epoch 61/100, Loss: 45.4319, Validation Accuracy: 0.6411\n",
            "Epoch 62/100, Loss: 327.9360, Validation Accuracy: 0.6839\n",
            "Epoch 63/100, Loss: 185.7691, Validation Accuracy: 0.6341\n",
            "Epoch 64/100, Loss: 80.8289, Validation Accuracy: 0.6770\n",
            "Epoch 65/100, Loss: 171.6731, Validation Accuracy: 0.6640\n",
            "Epoch 66/100, Loss: 83.4798, Validation Accuracy: 0.4088\n",
            "Epoch 67/100, Loss: 107.5853, Validation Accuracy: 0.5882\n",
            "Epoch 68/100, Loss: 210.0311, Validation Accuracy: 0.5753\n",
            "Epoch 69/100, Loss: 175.6308, Validation Accuracy: 0.6969\n",
            "Epoch 70/100, Loss: 78.4888, Validation Accuracy: 0.6710\n",
            "Epoch 71/100, Loss: 393.2135, Validation Accuracy: 0.6670\n",
            "Epoch 72/100, Loss: 43.7638, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 132.6863, Validation Accuracy: 0.5952\n",
            "Epoch 74/100, Loss: 722.2297, Validation Accuracy: 0.6740\n",
            "Epoch 75/100, Loss: 222.3560, Validation Accuracy: 0.5693\n",
            "Epoch 76/100, Loss: 95.4503, Validation Accuracy: 0.5703\n",
            "Epoch 77/100, Loss: 163.4345, Validation Accuracy: 0.6600\n",
            "Epoch 78/100, Loss: 144.7409, Validation Accuracy: 0.6500\n",
            "Epoch 79/100, Loss: 21.2109, Validation Accuracy: 0.6401\n",
            "Epoch 80/100, Loss: 218.6493, Validation Accuracy: 0.6919\n",
            "Epoch 81/100, Loss: 323.1311, Validation Accuracy: 0.5683\n",
            "Epoch 82/100, Loss: 206.1215, Validation Accuracy: 0.6660\n",
            "Epoch 83/100, Loss: 104.8335, Validation Accuracy: 0.6022\n",
            "Epoch 84/100, Loss: 59.8420, Validation Accuracy: 0.5723\n",
            "Epoch 85/100, Loss: 113.1741, Validation Accuracy: 0.6371\n",
            "Epoch 86/100, Loss: 312.0219, Validation Accuracy: 0.3151\n",
            "Epoch 87/100, Loss: 272.3296, Validation Accuracy: 0.5404\n",
            "Epoch 88/100, Loss: 208.5142, Validation Accuracy: 0.5683\n",
            "Epoch 89/100, Loss: 79.6695, Validation Accuracy: 0.5085\n",
            "Epoch 90/100, Loss: 65.0817, Validation Accuracy: 0.6491\n",
            "Epoch 91/100, Loss: 152.9019, Validation Accuracy: 0.6461\n",
            "Epoch 92/100, Loss: 158.0337, Validation Accuracy: 0.6780\n",
            "Epoch 93/100, Loss: 46.5331, Validation Accuracy: 0.6750\n",
            "Epoch 94/100, Loss: 131.8638, Validation Accuracy: 0.5823\n",
            "Epoch 95/100, Loss: 129.8280, Validation Accuracy: 0.5902\n",
            "Epoch 96/100, Loss: 164.1421, Validation Accuracy: 0.5314\n",
            "Epoch 97/100, Loss: 154.2980, Validation Accuracy: 0.6461\n",
            "Epoch 98/100, Loss: 215.8880, Validation Accuracy: 0.6640\n",
            "Epoch 99/100, Loss: 123.1301, Validation Accuracy: 0.6650\n",
            "Epoch 100/100, Loss: 197.2548, Validation Accuracy: 0.6201\n",
            "Epoch 101/100, Loss: 204.7232, Validation Accuracy: 0.6211\n",
            "Epoch 102/100, Loss: 140.0590, Validation Accuracy: 0.6241\n",
            "Epoch 103/100, Loss: 92.0972, Validation Accuracy: 0.4626\n",
            "Epoch 104/100, Loss: 83.9102, Validation Accuracy: 0.6700\n",
            "Epoch 105/100, Loss: 181.2870, Validation Accuracy: 0.6082\n",
            "Epoch 106/100, Loss: 125.8757, Validation Accuracy: 0.6052\n",
            "Epoch 107/100, Loss: 126.8981, Validation Accuracy: 0.6072\n",
            "Epoch 108/100, Loss: 150.8472, Validation Accuracy: 0.3769\n",
            "Epoch 109/100, Loss: 74.9913, Validation Accuracy: 0.6839\n",
            "Epoch 110/100, Loss: 189.2845, Validation Accuracy: 0.4756\n",
            "Epoch 111/100, Loss: 328.8114, Validation Accuracy: 0.5982\n",
            "Epoch 112/100, Loss: 82.1050, Validation Accuracy: 0.4207\n",
            "Epoch 113/100, Loss: 38.9009, Validation Accuracy: 0.6191\n",
            "Epoch 114/100, Loss: 134.2651, Validation Accuracy: 0.6012\n",
            "Epoch 115/100, Loss: 123.5098, Validation Accuracy: 0.6171\n",
            "Epoch 116/100, Loss: 184.5439, Validation Accuracy: 0.6720\n",
            "Epoch 117/100, Loss: 189.2101, Validation Accuracy: 0.6191\n",
            "Epoch 118/100, Loss: 96.1556, Validation Accuracy: 0.5523\n",
            "Epoch 119/100, Loss: 136.0167, Validation Accuracy: 0.6620\n",
            "Epoch 120/100, Loss: 151.9376, Validation Accuracy: 0.6859\n",
            "Epoch 121/100, Loss: 297.6583, Validation Accuracy: 0.6451\n",
            "Epoch 122/100, Loss: 430.6054, Validation Accuracy: 0.6780\n",
            "Epoch 123/100, Loss: 164.9909, Validation Accuracy: 0.4716\n",
            "Epoch 124/100, Loss: 78.3171, Validation Accuracy: 0.5912\n",
            "Epoch 125/100, Loss: 190.5225, Validation Accuracy: 0.6451\n",
            "Epoch 126/100, Loss: 178.5432, Validation Accuracy: 0.5713\n",
            "Epoch 127/100, Loss: 76.5492, Validation Accuracy: 0.6032\n",
            "Epoch 128/100, Loss: 148.5923, Validation Accuracy: 0.5962\n",
            "Epoch 129/100, Loss: 211.0917, Validation Accuracy: 0.4716\n",
            "Epoch 130/100, Loss: 179.3724, Validation Accuracy: 0.6361\n",
            "Epoch 131/100, Loss: 71.2204, Validation Accuracy: 0.5055\n",
            "Epoch 132/100, Loss: 559.3552, Validation Accuracy: 0.6750\n",
            "Epoch 133/100, Loss: 99.8019, Validation Accuracy: 0.5793\n",
            "Epoch 134/100, Loss: 103.8705, Validation Accuracy: 0.6780\n",
            "Epoch 135/100, Loss: 108.3607, Validation Accuracy: 0.6351\n",
            "Epoch 136/100, Loss: 96.7338, Validation Accuracy: 0.6869\n",
            "Epoch 137/100, Loss: 316.8328, Validation Accuracy: 0.5992\n",
            "Epoch 138/100, Loss: 130.0220, Validation Accuracy: 0.5713\n",
            "Epoch 139/100, Loss: 186.3173, Validation Accuracy: 0.5474\n",
            "Epoch 140/100, Loss: 241.7808, Validation Accuracy: 0.5803\n",
            "Epoch 141/100, Loss: 64.1473, Validation Accuracy: 0.5005\n",
            "Epoch 142/100, Loss: 119.2222, Validation Accuracy: 0.6341\n",
            "Epoch 143/100, Loss: 167.2124, Validation Accuracy: 0.5962\n",
            "Epoch 144/100, Loss: 80.4297, Validation Accuracy: 0.6231\n",
            "Epoch 145/100, Loss: 99.4660, Validation Accuracy: 0.6780\n",
            "Epoch 146/100, Loss: 124.7932, Validation Accuracy: 0.6461\n",
            "Epoch 147/100, Loss: 426.8851, Validation Accuracy: 0.6640\n",
            "Epoch 148/100, Loss: 58.6822, Validation Accuracy: 0.5394\n",
            "Epoch 149/100, Loss: 165.8718, Validation Accuracy: 0.5793\n",
            "Epoch 150/100, Loss: 174.2679, Validation Accuracy: 0.5155\n",
            "Epoch 151/100, Loss: 44.1585, Validation Accuracy: 0.6142\n",
            "Epoch 152/100, Loss: 253.0665, Validation Accuracy: 0.6620\n",
            "Epoch 153/100, Loss: 108.3726, Validation Accuracy: 0.6431\n",
            "Epoch 154/100, Loss: 441.7585, Validation Accuracy: 0.4347\n",
            "Epoch 155/100, Loss: 126.4144, Validation Accuracy: 0.6879\n",
            "Epoch 156/100, Loss: 194.1758, Validation Accuracy: 0.6371\n",
            "Epoch 157/100, Loss: 519.9575, Validation Accuracy: 0.6570\n",
            "Epoch 158/100, Loss: 68.1502, Validation Accuracy: 0.5932\n",
            "Epoch 159/100, Loss: 157.7883, Validation Accuracy: 0.5813\n",
            "Epoch 160/100, Loss: 140.2452, Validation Accuracy: 0.5543\n",
            "Epoch 161/100, Loss: 236.4129, Validation Accuracy: 0.6680\n",
            "Epoch 162/100, Loss: 103.0210, Validation Accuracy: 0.5833\n",
            "Epoch 163/100, Loss: 167.4906, Validation Accuracy: 0.5573\n",
            "Epoch 164/100, Loss: 153.9444, Validation Accuracy: 0.6750\n",
            "Epoch 165/100, Loss: 107.7893, Validation Accuracy: 0.6650\n",
            "Epoch 166/100, Loss: 225.6484, Validation Accuracy: 0.6012\n",
            "Epoch 167/100, Loss: 212.7909, Validation Accuracy: 0.6640\n",
            "Epoch 168/100, Loss: 135.4321, Validation Accuracy: 0.4885\n",
            "Epoch 169/100, Loss: 26.6685, Validation Accuracy: 0.6839\n",
            "Epoch 170/100, Loss: 87.2063, Validation Accuracy: 0.5882\n",
            "Epoch 171/100, Loss: 127.5757, Validation Accuracy: 0.6730\n",
            "Epoch 172/100, Loss: 147.7201, Validation Accuracy: 0.5882\n",
            "Epoch 173/100, Loss: 128.1265, Validation Accuracy: 0.6431\n",
            "Epoch 174/100, Loss: 207.7645, Validation Accuracy: 0.6680\n",
            "Epoch 175/100, Loss: 210.3327, Validation Accuracy: 0.6660\n",
            "Epoch 176/100, Loss: 80.6700, Validation Accuracy: 0.6142\n",
            "Epoch 177/100, Loss: 159.5093, Validation Accuracy: 0.5823\n",
            "Epoch 178/100, Loss: 175.9830, Validation Accuracy: 0.5882\n",
            "Epoch 179/100, Loss: 73.7932, Validation Accuracy: 0.6610\n",
            "Epoch 180/100, Loss: 136.2384, Validation Accuracy: 0.5155\n",
            "Epoch 181/100, Loss: 131.5191, Validation Accuracy: 0.5573\n",
            "Epoch 182/100, Loss: 212.3746, Validation Accuracy: 0.6082\n",
            "Epoch 183/100, Loss: 204.0499, Validation Accuracy: 0.5982\n",
            "Epoch 184/100, Loss: 519.5881, Validation Accuracy: 0.6461\n",
            "Epoch 185/100, Loss: 285.5659, Validation Accuracy: 0.6800\n",
            "Epoch 186/100, Loss: 123.1698, Validation Accuracy: 0.6421\n",
            "Epoch 187/100, Loss: 317.9895, Validation Accuracy: 0.6062\n",
            "Epoch 188/100, Loss: 200.3284, Validation Accuracy: 0.6620\n",
            "Epoch 189/100, Loss: 91.7976, Validation Accuracy: 0.6191\n",
            "Epoch 190/100, Loss: 115.3159, Validation Accuracy: 0.5573\n",
            "Epoch 191/100, Loss: 135.6938, Validation Accuracy: 0.5523\n",
            "Epoch 192/100, Loss: 690.9871, Validation Accuracy: 0.6560\n",
            "Epoch 193/100, Loss: 201.9358, Validation Accuracy: 0.5623\n",
            "Epoch 194/100, Loss: 117.4678, Validation Accuracy: 0.6710\n",
            "Epoch 195/100, Loss: 75.2403, Validation Accuracy: 0.5673\n",
            "Epoch 196/100, Loss: 109.2100, Validation Accuracy: 0.5872\n",
            "Epoch 197/100, Loss: 165.9585, Validation Accuracy: 0.6022\n",
            "Epoch 198/100, Loss: 99.7829, Validation Accuracy: 0.6022\n",
            "Epoch 199/100, Loss: 73.3420, Validation Accuracy: 0.6421\n",
            "Epoch 200/100, Loss: 179.9256, Validation Accuracy: 0.6610\n",
            "Reward for Child Model: 0.2888269978917027\n",
            "Child_37:  {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, [2, 2, 3, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 0, 2], 0.2888269978917027\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 36, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(60, 48, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(132, 48, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(108, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=105952, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 22, 28]             528\n",
            "       BatchNorm2d-2           [-1, 24, 22, 28]              48\n",
            "            Conv2d-3           [-1, 36, 20, 26]           7,812\n",
            "       BatchNorm2d-4           [-1, 36, 20, 26]              72\n",
            "              ReLU-5           [-1, 36, 20, 26]               0\n",
            "            Conv2d-6           [-1, 48, 18, 28]          14,448\n",
            "       BatchNorm2d-7           [-1, 48, 18, 28]              96\n",
            "              ReLU-8           [-1, 48, 18, 28]               0\n",
            "            Conv2d-9           [-1, 48, 16, 22]         310,512\n",
            "      BatchNorm2d-10           [-1, 48, 16, 22]              96\n",
            "             ReLU-11           [-1, 48, 16, 22]               0\n",
            "           Conv2d-12           [-1, 64, 18, 24]         172,864\n",
            "      BatchNorm2d-13           [-1, 64, 18, 24]             128\n",
            "             ReLU-14           [-1, 64, 18, 24]               0\n",
            "           Linear-15                    [-1, 7]         741,671\n",
            "================================================================\n",
            "Total params: 1,248,275\n",
            "Trainable params: 1,248,275\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.23\n",
            "Params size (MB): 4.76\n",
            "Estimated Total Size (MB): 7.00\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 4.8762, Validation Accuracy: 0.4138\n",
            "Epoch 2/100, Loss: 1.5631, Validation Accuracy: 0.6341\n",
            "Epoch 3/100, Loss: 2.2767, Validation Accuracy: 0.6012\n",
            "Epoch 4/100, Loss: 1.6429, Validation Accuracy: 0.6660\n",
            "Epoch 5/100, Loss: 187.5741, Validation Accuracy: 0.6660\n",
            "Epoch 6/100, Loss: 11.4938, Validation Accuracy: 0.6451\n",
            "Epoch 7/100, Loss: 7.6198, Validation Accuracy: 0.6461\n",
            "Epoch 8/100, Loss: 1.8453, Validation Accuracy: 0.5244\n",
            "Epoch 9/100, Loss: 2.2275, Validation Accuracy: 0.5852\n",
            "Epoch 10/100, Loss: 2.6067, Validation Accuracy: 0.6221\n",
            "Epoch 11/100, Loss: 1.2782, Validation Accuracy: 0.6550\n",
            "Epoch 12/100, Loss: 2.8718, Validation Accuracy: 0.6012\n",
            "Epoch 13/100, Loss: 2.5532, Validation Accuracy: 0.6311\n",
            "Epoch 14/100, Loss: 24.8646, Validation Accuracy: 0.6560\n",
            "Epoch 15/100, Loss: 12.0685, Validation Accuracy: 0.6042\n",
            "Epoch 16/100, Loss: 5.0945, Validation Accuracy: 0.6122\n",
            "Epoch 17/100, Loss: 3.4535, Validation Accuracy: 0.4626\n",
            "Epoch 18/100, Loss: 3.4409, Validation Accuracy: 0.5593\n",
            "Epoch 19/100, Loss: 9.1363, Validation Accuracy: 0.3719\n",
            "Epoch 20/100, Loss: 93.8942, Validation Accuracy: 0.6022\n",
            "Epoch 21/100, Loss: 10.6262, Validation Accuracy: 0.6491\n",
            "Epoch 22/100, Loss: 4.3176, Validation Accuracy: 0.6301\n",
            "Epoch 23/100, Loss: 3.8663, Validation Accuracy: 0.5713\n",
            "Epoch 24/100, Loss: 3.8912, Validation Accuracy: 0.5823\n",
            "Epoch 25/100, Loss: 45.4198, Validation Accuracy: 0.5833\n",
            "Epoch 26/100, Loss: 15.5726, Validation Accuracy: 0.6650\n",
            "Epoch 27/100, Loss: 20.2936, Validation Accuracy: 0.6311\n",
            "Epoch 28/100, Loss: 15.2340, Validation Accuracy: 0.6839\n",
            "Epoch 29/100, Loss: 7.0172, Validation Accuracy: 0.5922\n",
            "Epoch 30/100, Loss: 18.2743, Validation Accuracy: 0.4128\n",
            "Epoch 31/100, Loss: 22.9961, Validation Accuracy: 0.3858\n",
            "Epoch 32/100, Loss: 22.2019, Validation Accuracy: 0.5842\n",
            "Epoch 33/100, Loss: 18.3633, Validation Accuracy: 0.5025\n",
            "Epoch 34/100, Loss: 18.4597, Validation Accuracy: 0.6261\n",
            "Epoch 35/100, Loss: 10.6974, Validation Accuracy: 0.3838\n",
            "Epoch 36/100, Loss: 13.3434, Validation Accuracy: 0.6142\n",
            "Epoch 37/100, Loss: 23.7851, Validation Accuracy: 0.6471\n",
            "Epoch 38/100, Loss: 86.8207, Validation Accuracy: 0.3928\n",
            "Epoch 39/100, Loss: 26.6265, Validation Accuracy: 0.6431\n",
            "Epoch 40/100, Loss: 3.6481, Validation Accuracy: 0.6600\n",
            "Epoch 41/100, Loss: 7.2572, Validation Accuracy: 0.4636\n",
            "Epoch 42/100, Loss: 5.4652, Validation Accuracy: 0.4845\n",
            "Epoch 43/100, Loss: 14.0976, Validation Accuracy: 0.6550\n",
            "Epoch 44/100, Loss: 29.5872, Validation Accuracy: 0.5244\n",
            "Epoch 45/100, Loss: 36.9830, Validation Accuracy: 0.6411\n",
            "Epoch 46/100, Loss: 26.1954, Validation Accuracy: 0.6451\n",
            "Epoch 47/100, Loss: 9.6331, Validation Accuracy: 0.5833\n",
            "Epoch 48/100, Loss: 5.8422, Validation Accuracy: 0.6640\n",
            "Epoch 49/100, Loss: 5.1179, Validation Accuracy: 0.5852\n",
            "Epoch 50/100, Loss: 10.8755, Validation Accuracy: 0.4377\n",
            "Epoch 51/100, Loss: 54.2615, Validation Accuracy: 0.5364\n",
            "Epoch 52/100, Loss: 23.9907, Validation Accuracy: 0.5783\n",
            "Epoch 53/100, Loss: 4.1324, Validation Accuracy: 0.2353\n",
            "Epoch 54/100, Loss: 15.6022, Validation Accuracy: 0.4995\n",
            "Epoch 55/100, Loss: 15.7049, Validation Accuracy: 0.5803\n",
            "Epoch 56/100, Loss: 11.1827, Validation Accuracy: 0.5693\n",
            "Epoch 57/100, Loss: 31.9918, Validation Accuracy: 0.5992\n",
            "Epoch 58/100, Loss: 6.1960, Validation Accuracy: 0.4277\n",
            "Epoch 59/100, Loss: 12.3433, Validation Accuracy: 0.5344\n",
            "Epoch 60/100, Loss: 49.3919, Validation Accuracy: 0.6570\n",
            "Epoch 61/100, Loss: 10.8406, Validation Accuracy: 0.6471\n",
            "Epoch 62/100, Loss: 20.8220, Validation Accuracy: 0.5434\n",
            "Epoch 63/100, Loss: 8.8963, Validation Accuracy: 0.5932\n",
            "Epoch 64/100, Loss: 5.2127, Validation Accuracy: 0.6630\n",
            "Epoch 65/100, Loss: 9.0914, Validation Accuracy: 0.6530\n",
            "Epoch 66/100, Loss: 35.8007, Validation Accuracy: 0.5643\n",
            "Epoch 67/100, Loss: 36.8197, Validation Accuracy: 0.6032\n",
            "Epoch 68/100, Loss: 8.6176, Validation Accuracy: 0.6311\n",
            "Epoch 69/100, Loss: 10.5371, Validation Accuracy: 0.6301\n",
            "Epoch 70/100, Loss: 15.8777, Validation Accuracy: 0.6152\n",
            "Epoch 71/100, Loss: 7.3057, Validation Accuracy: 0.5982\n",
            "Epoch 72/100, Loss: 7.1027, Validation Accuracy: 0.6102\n",
            "Epoch 73/100, Loss: 5.1436, Validation Accuracy: 0.6441\n",
            "Epoch 74/100, Loss: 32.8138, Validation Accuracy: 0.5294\n",
            "Epoch 75/100, Loss: 43.3408, Validation Accuracy: 0.6142\n",
            "Epoch 76/100, Loss: 49.6197, Validation Accuracy: 0.5334\n",
            "Epoch 77/100, Loss: 14.8406, Validation Accuracy: 0.5533\n",
            "Epoch 78/100, Loss: 8.8697, Validation Accuracy: 0.6351\n",
            "Epoch 79/100, Loss: 2.5617, Validation Accuracy: 0.6800\n",
            "Epoch 80/100, Loss: 10.0904, Validation Accuracy: 0.6311\n",
            "Epoch 81/100, Loss: 64.5858, Validation Accuracy: 0.6062\n",
            "Epoch 82/100, Loss: 51.8182, Validation Accuracy: 0.4995\n",
            "Epoch 83/100, Loss: 15.8685, Validation Accuracy: 0.6740\n",
            "Epoch 84/100, Loss: 10.9618, Validation Accuracy: 0.6560\n",
            "Epoch 85/100, Loss: 48.2608, Validation Accuracy: 0.6610\n",
            "Epoch 86/100, Loss: 16.4248, Validation Accuracy: 0.5663\n",
            "Epoch 87/100, Loss: 10.2273, Validation Accuracy: 0.4865\n",
            "Epoch 88/100, Loss: 40.5882, Validation Accuracy: 0.6491\n",
            "Epoch 89/100, Loss: 33.2884, Validation Accuracy: 0.6849\n",
            "Epoch 90/100, Loss: 17.9099, Validation Accuracy: 0.4925\n",
            "Epoch 91/100, Loss: 10.7357, Validation Accuracy: 0.5643\n",
            "Epoch 92/100, Loss: 7.7677, Validation Accuracy: 0.5833\n",
            "Epoch 93/100, Loss: 37.6536, Validation Accuracy: 0.6441\n",
            "Epoch 94/100, Loss: 8.8499, Validation Accuracy: 0.6680\n",
            "Epoch 95/100, Loss: 15.5172, Validation Accuracy: 0.5454\n",
            "Epoch 96/100, Loss: 60.2956, Validation Accuracy: 0.5713\n",
            "Epoch 97/100, Loss: 1.9600, Validation Accuracy: 0.5862\n",
            "Epoch 98/100, Loss: 10.4947, Validation Accuracy: 0.6251\n",
            "Epoch 99/100, Loss: 5.2976, Validation Accuracy: 0.6341\n",
            "Epoch 100/100, Loss: 4.0883, Validation Accuracy: 0.5982\n",
            "Epoch 101/100, Loss: 15.7601, Validation Accuracy: 0.5533\n",
            "Epoch 102/100, Loss: 17.8104, Validation Accuracy: 0.6371\n",
            "Epoch 103/100, Loss: 36.6234, Validation Accuracy: 0.6520\n",
            "Epoch 104/100, Loss: 9.4810, Validation Accuracy: 0.6251\n",
            "Epoch 105/100, Loss: 14.6554, Validation Accuracy: 0.4686\n",
            "Epoch 106/100, Loss: 16.0959, Validation Accuracy: 0.5823\n",
            "Epoch 107/100, Loss: 27.7671, Validation Accuracy: 0.6002\n",
            "Epoch 108/100, Loss: 21.3928, Validation Accuracy: 0.4646\n",
            "Epoch 109/100, Loss: 9.3795, Validation Accuracy: 0.5543\n",
            "Epoch 110/100, Loss: 34.5083, Validation Accuracy: 0.6750\n",
            "Epoch 111/100, Loss: 11.2331, Validation Accuracy: 0.6191\n",
            "Epoch 112/100, Loss: 19.9842, Validation Accuracy: 0.6481\n",
            "Epoch 113/100, Loss: 18.3109, Validation Accuracy: 0.4357\n",
            "Epoch 114/100, Loss: 11.2022, Validation Accuracy: 0.5882\n",
            "Epoch 115/100, Loss: 23.5385, Validation Accuracy: 0.6820\n",
            "Epoch 116/100, Loss: 35.0010, Validation Accuracy: 0.6391\n",
            "Epoch 117/100, Loss: 14.1817, Validation Accuracy: 0.6650\n",
            "Epoch 118/100, Loss: 40.4733, Validation Accuracy: 0.6042\n",
            "Epoch 119/100, Loss: 15.0187, Validation Accuracy: 0.6201\n",
            "Epoch 120/100, Loss: 22.9872, Validation Accuracy: 0.4287\n",
            "Epoch 121/100, Loss: 10.7449, Validation Accuracy: 0.5823\n",
            "Epoch 122/100, Loss: 14.7214, Validation Accuracy: 0.6421\n",
            "Epoch 123/100, Loss: 48.0977, Validation Accuracy: 0.6421\n",
            "Epoch 124/100, Loss: 5.2148, Validation Accuracy: 0.6052\n",
            "Epoch 125/100, Loss: 5.6706, Validation Accuracy: 0.5683\n",
            "Epoch 126/100, Loss: 10.9986, Validation Accuracy: 0.6670\n",
            "Epoch 127/100, Loss: 13.4852, Validation Accuracy: 0.5424\n",
            "Epoch 128/100, Loss: 8.7416, Validation Accuracy: 0.4895\n",
            "Epoch 129/100, Loss: 3.7300, Validation Accuracy: 0.6849\n",
            "Epoch 130/100, Loss: 10.9936, Validation Accuracy: 0.6421\n",
            "Epoch 131/100, Loss: 29.8774, Validation Accuracy: 0.5882\n",
            "Epoch 132/100, Loss: 31.9432, Validation Accuracy: 0.6191\n",
            "Epoch 133/100, Loss: 17.8934, Validation Accuracy: 0.6660\n",
            "Epoch 134/100, Loss: 28.6324, Validation Accuracy: 0.6590\n",
            "Epoch 135/100, Loss: 44.7355, Validation Accuracy: 0.6491\n",
            "Epoch 136/100, Loss: 17.7734, Validation Accuracy: 0.5693\n",
            "Epoch 137/100, Loss: 7.9231, Validation Accuracy: 0.5852\n",
            "Epoch 138/100, Loss: 13.0424, Validation Accuracy: 0.4098\n",
            "Epoch 139/100, Loss: 35.2584, Validation Accuracy: 0.5653\n",
            "Epoch 140/100, Loss: 23.2661, Validation Accuracy: 0.6530\n",
            "Epoch 141/100, Loss: 16.9157, Validation Accuracy: 0.5743\n",
            "Epoch 142/100, Loss: 29.3586, Validation Accuracy: 0.5982\n",
            "Epoch 143/100, Loss: 22.2907, Validation Accuracy: 0.5753\n",
            "Epoch 144/100, Loss: 16.6161, Validation Accuracy: 0.6650\n",
            "Epoch 145/100, Loss: 9.6276, Validation Accuracy: 0.5793\n",
            "Epoch 146/100, Loss: 21.3392, Validation Accuracy: 0.4167\n",
            "Epoch 147/100, Loss: 19.8498, Validation Accuracy: 0.6231\n",
            "Epoch 148/100, Loss: 13.6214, Validation Accuracy: 0.5753\n",
            "Epoch 149/100, Loss: 26.1274, Validation Accuracy: 0.6062\n",
            "Epoch 150/100, Loss: 7.3636, Validation Accuracy: 0.5932\n",
            "Epoch 151/100, Loss: 64.2572, Validation Accuracy: 0.6570\n",
            "Epoch 152/100, Loss: 43.3717, Validation Accuracy: 0.6590\n",
            "Epoch 153/100, Loss: 13.8349, Validation Accuracy: 0.4626\n",
            "Epoch 154/100, Loss: 9.4512, Validation Accuracy: 0.4636\n",
            "Epoch 155/100, Loss: 21.5204, Validation Accuracy: 0.6351\n",
            "Epoch 156/100, Loss: 8.1472, Validation Accuracy: 0.6630\n",
            "Epoch 157/100, Loss: 21.0241, Validation Accuracy: 0.6142\n",
            "Epoch 158/100, Loss: 203.0391, Validation Accuracy: 0.6630\n",
            "Epoch 159/100, Loss: 40.6207, Validation Accuracy: 0.6281\n",
            "Epoch 160/100, Loss: 10.4712, Validation Accuracy: 0.5294\n",
            "Epoch 161/100, Loss: 12.4437, Validation Accuracy: 0.4915\n",
            "Epoch 162/100, Loss: 5.6764, Validation Accuracy: 0.5803\n",
            "Epoch 163/100, Loss: 19.7596, Validation Accuracy: 0.4297\n",
            "Epoch 164/100, Loss: 9.2701, Validation Accuracy: 0.6341\n",
            "Epoch 165/100, Loss: 57.9994, Validation Accuracy: 0.5314\n",
            "Epoch 166/100, Loss: 63.7177, Validation Accuracy: 0.5354\n",
            "Epoch 167/100, Loss: 9.4020, Validation Accuracy: 0.6391\n",
            "Epoch 168/100, Loss: 7.7122, Validation Accuracy: 0.6780\n",
            "Epoch 169/100, Loss: 21.5840, Validation Accuracy: 0.5244\n",
            "Epoch 170/100, Loss: 15.8470, Validation Accuracy: 0.6181\n",
            "Epoch 171/100, Loss: 23.6522, Validation Accuracy: 0.6371\n",
            "Epoch 172/100, Loss: 22.6267, Validation Accuracy: 0.5583\n",
            "Epoch 173/100, Loss: 15.7132, Validation Accuracy: 0.6181\n",
            "Epoch 174/100, Loss: 12.5056, Validation Accuracy: 0.6351\n",
            "Epoch 175/100, Loss: 15.5456, Validation Accuracy: 0.6849\n",
            "Epoch 176/100, Loss: 34.9394, Validation Accuracy: 0.5414\n",
            "Epoch 177/100, Loss: 2.2805, Validation Accuracy: 0.5743\n",
            "Epoch 178/100, Loss: 10.1378, Validation Accuracy: 0.5862\n",
            "Epoch 179/100, Loss: 19.7439, Validation Accuracy: 0.6241\n",
            "Epoch 180/100, Loss: 12.4803, Validation Accuracy: 0.6162\n",
            "Epoch 181/100, Loss: 7.2521, Validation Accuracy: 0.6670\n",
            "Epoch 182/100, Loss: 21.9036, Validation Accuracy: 0.6231\n",
            "Epoch 183/100, Loss: 17.9605, Validation Accuracy: 0.6500\n",
            "Epoch 184/100, Loss: 15.5852, Validation Accuracy: 0.6570\n",
            "Epoch 185/100, Loss: 13.0330, Validation Accuracy: 0.6132\n",
            "Epoch 186/100, Loss: 20.1843, Validation Accuracy: 0.6191\n",
            "Epoch 187/100, Loss: 36.8397, Validation Accuracy: 0.5543\n",
            "Epoch 188/100, Loss: 25.3262, Validation Accuracy: 0.5404\n",
            "Epoch 189/100, Loss: 37.7105, Validation Accuracy: 0.5035\n",
            "Epoch 190/100, Loss: 12.7903, Validation Accuracy: 0.5783\n",
            "Epoch 191/100, Loss: 9.6619, Validation Accuracy: 0.5344\n",
            "Epoch 192/100, Loss: 18.3445, Validation Accuracy: 0.5882\n",
            "Epoch 193/100, Loss: 16.4123, Validation Accuracy: 0.5872\n",
            "Epoch 194/100, Loss: 18.4855, Validation Accuracy: 0.6321\n",
            "Epoch 195/100, Loss: 16.7480, Validation Accuracy: 0.6062\n",
            "Epoch 196/100, Loss: 40.0249, Validation Accuracy: 0.6630\n",
            "Epoch 197/100, Loss: 21.0035, Validation Accuracy: 0.6510\n",
            "Epoch 198/100, Loss: 12.9764, Validation Accuracy: 0.6311\n",
            "Epoch 199/100, Loss: 10.4025, Validation Accuracy: 0.6171\n",
            "Epoch 200/100, Loss: 28.4984, Validation Accuracy: 0.6271\n",
            "Reward for Child Model: 0.2914487096290633\n",
            "Child_38:  {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, [3, 0, 0, 1, 1, 1, 2, 0, 2, 3, 3, 2, 2, 2, 3], 0.2914487096290633\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(88, 48, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(160, 36, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(284, 36, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=445312, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 28, 28]              96\n",
            "       BatchNorm2d-2           [-1, 24, 28, 28]              48\n",
            "            Conv2d-3           [-1, 64, 24, 28]           7,744\n",
            "       BatchNorm2d-4           [-1, 64, 24, 28]             128\n",
            "              ReLU-5           [-1, 64, 24, 28]               0\n",
            "            Conv2d-6           [-1, 48, 24, 24]         105,648\n",
            "       BatchNorm2d-7           [-1, 48, 24, 24]              96\n",
            "              ReLU-8           [-1, 48, 24, 24]               0\n",
            "            Conv2d-9           [-1, 36, 26, 24]          86,436\n",
            "      BatchNorm2d-10           [-1, 36, 26, 24]              72\n",
            "             ReLU-11           [-1, 36, 26, 24]               0\n",
            "           Conv2d-12           [-1, 36, 28, 24]          51,156\n",
            "      BatchNorm2d-13           [-1, 36, 28, 24]              72\n",
            "             ReLU-14           [-1, 36, 28, 24]               0\n",
            "           Linear-15                    [-1, 7]       3,117,191\n",
            "================================================================\n",
            "Total params: 3,368,687\n",
            "Trainable params: 3,368,687\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.97\n",
            "Params size (MB): 12.85\n",
            "Estimated Total Size (MB): 15.83\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 45.4538, Validation Accuracy: 0.5833\n",
            "Epoch 2/100, Loss: 82.4894, Validation Accuracy: 0.4945\n",
            "Epoch 3/100, Loss: 148.3781, Validation Accuracy: 0.6231\n",
            "Epoch 4/100, Loss: 111.5308, Validation Accuracy: 0.6112\n",
            "Epoch 5/100, Loss: 67.7753, Validation Accuracy: 0.5334\n",
            "Epoch 6/100, Loss: 130.0591, Validation Accuracy: 0.4167\n",
            "Epoch 7/100, Loss: 771.1580, Validation Accuracy: 0.4237\n",
            "Epoch 8/100, Loss: 74.1011, Validation Accuracy: 0.4945\n",
            "Epoch 9/100, Loss: 49.3192, Validation Accuracy: 0.6491\n",
            "Epoch 10/100, Loss: 22.1534, Validation Accuracy: 0.5553\n",
            "Epoch 11/100, Loss: 53.2033, Validation Accuracy: 0.5563\n",
            "Epoch 12/100, Loss: 75.1042, Validation Accuracy: 0.5703\n",
            "Epoch 13/100, Loss: 129.7367, Validation Accuracy: 0.4158\n",
            "Epoch 14/100, Loss: 109.2249, Validation Accuracy: 0.6630\n",
            "Epoch 15/100, Loss: 152.7470, Validation Accuracy: 0.5982\n",
            "Epoch 16/100, Loss: 101.6306, Validation Accuracy: 0.6022\n",
            "Epoch 17/100, Loss: 432.9998, Validation Accuracy: 0.5823\n",
            "Epoch 18/100, Loss: 12.2547, Validation Accuracy: 0.5922\n",
            "Epoch 19/100, Loss: 84.1587, Validation Accuracy: 0.6700\n",
            "Epoch 20/100, Loss: 161.1143, Validation Accuracy: 0.5444\n",
            "Epoch 21/100, Loss: 112.8307, Validation Accuracy: 0.6162\n",
            "Epoch 22/100, Loss: 118.2561, Validation Accuracy: 0.6700\n",
            "Epoch 23/100, Loss: 209.4994, Validation Accuracy: 0.4965\n",
            "Epoch 24/100, Loss: 135.8210, Validation Accuracy: 0.6620\n",
            "Epoch 25/100, Loss: 52.0219, Validation Accuracy: 0.5523\n",
            "Epoch 26/100, Loss: 157.7336, Validation Accuracy: 0.6211\n",
            "Epoch 27/100, Loss: 189.8060, Validation Accuracy: 0.4746\n",
            "Epoch 28/100, Loss: 258.4223, Validation Accuracy: 0.6152\n",
            "Epoch 29/100, Loss: 129.5264, Validation Accuracy: 0.5324\n",
            "Epoch 30/100, Loss: 86.6798, Validation Accuracy: 0.6869\n",
            "Epoch 31/100, Loss: 46.4913, Validation Accuracy: 0.6660\n",
            "Epoch 32/100, Loss: 55.1679, Validation Accuracy: 0.4586\n",
            "Epoch 33/100, Loss: 51.7625, Validation Accuracy: 0.5842\n",
            "Epoch 34/100, Loss: 451.9856, Validation Accuracy: 0.6191\n",
            "Epoch 35/100, Loss: 524.9953, Validation Accuracy: 0.5523\n",
            "Epoch 36/100, Loss: 81.6053, Validation Accuracy: 0.6191\n",
            "Epoch 37/100, Loss: 18.1675, Validation Accuracy: 0.5693\n",
            "Epoch 38/100, Loss: 56.8162, Validation Accuracy: 0.6371\n",
            "Epoch 39/100, Loss: 244.0219, Validation Accuracy: 0.6291\n",
            "Epoch 40/100, Loss: 82.0033, Validation Accuracy: 0.6401\n",
            "Epoch 41/100, Loss: 255.1339, Validation Accuracy: 0.6311\n",
            "Epoch 42/100, Loss: 826.4734, Validation Accuracy: 0.6700\n",
            "Epoch 43/100, Loss: 228.3061, Validation Accuracy: 0.6750\n",
            "Epoch 44/100, Loss: 115.2672, Validation Accuracy: 0.6271\n",
            "Epoch 45/100, Loss: 117.0003, Validation Accuracy: 0.6401\n",
            "Epoch 46/100, Loss: 82.8392, Validation Accuracy: 0.3729\n",
            "Epoch 47/100, Loss: 211.0672, Validation Accuracy: 0.6471\n",
            "Epoch 48/100, Loss: 40.0480, Validation Accuracy: 0.6371\n",
            "Epoch 49/100, Loss: 54.0104, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 55.4131, Validation Accuracy: 0.6132\n",
            "Epoch 51/100, Loss: 20.2526, Validation Accuracy: 0.6570\n",
            "Epoch 52/100, Loss: 94.8386, Validation Accuracy: 0.5902\n",
            "Epoch 53/100, Loss: 255.7354, Validation Accuracy: 0.5314\n",
            "Epoch 54/100, Loss: 484.4300, Validation Accuracy: 0.4995\n",
            "Epoch 55/100, Loss: 54.1021, Validation Accuracy: 0.6321\n",
            "Epoch 56/100, Loss: 54.2342, Validation Accuracy: 0.5354\n",
            "Epoch 57/100, Loss: 20.1544, Validation Accuracy: 0.5304\n",
            "Epoch 58/100, Loss: 64.7246, Validation Accuracy: 0.6520\n",
            "Epoch 59/100, Loss: 162.7800, Validation Accuracy: 0.6670\n",
            "Epoch 60/100, Loss: 253.2932, Validation Accuracy: 0.6261\n",
            "Epoch 61/100, Loss: 47.6575, Validation Accuracy: 0.6580\n",
            "Epoch 62/100, Loss: 193.1635, Validation Accuracy: 0.5384\n",
            "Epoch 63/100, Loss: 56.5881, Validation Accuracy: 0.5583\n",
            "Epoch 64/100, Loss: 153.9865, Validation Accuracy: 0.5912\n",
            "Epoch 65/100, Loss: 70.0410, Validation Accuracy: 0.4935\n",
            "Epoch 66/100, Loss: 82.9967, Validation Accuracy: 0.3928\n",
            "Epoch 67/100, Loss: 128.5274, Validation Accuracy: 0.4855\n",
            "Epoch 68/100, Loss: 119.9372, Validation Accuracy: 0.6052\n",
            "Epoch 69/100, Loss: 44.3466, Validation Accuracy: 0.5234\n",
            "Epoch 70/100, Loss: 142.2935, Validation Accuracy: 0.6032\n",
            "Epoch 71/100, Loss: 48.3977, Validation Accuracy: 0.4875\n",
            "Epoch 72/100, Loss: 43.1951, Validation Accuracy: 0.7019\n",
            "Epoch 73/100, Loss: 191.2321, Validation Accuracy: 0.5145\n",
            "Epoch 74/100, Loss: 146.0390, Validation Accuracy: 0.6590\n",
            "Epoch 75/100, Loss: 133.8697, Validation Accuracy: 0.6680\n",
            "Epoch 76/100, Loss: 109.7255, Validation Accuracy: 0.5264\n",
            "Epoch 77/100, Loss: 56.9828, Validation Accuracy: 0.6770\n",
            "Epoch 78/100, Loss: 543.0385, Validation Accuracy: 0.6401\n",
            "Epoch 79/100, Loss: 101.9878, Validation Accuracy: 0.5763\n",
            "Epoch 80/100, Loss: 68.8910, Validation Accuracy: 0.6620\n",
            "Epoch 81/100, Loss: 52.2754, Validation Accuracy: 0.5683\n",
            "Epoch 82/100, Loss: 72.5285, Validation Accuracy: 0.5254\n",
            "Epoch 83/100, Loss: 67.6603, Validation Accuracy: 0.6042\n",
            "Epoch 84/100, Loss: 224.9235, Validation Accuracy: 0.5234\n",
            "Epoch 85/100, Loss: 193.3486, Validation Accuracy: 0.5294\n",
            "Epoch 86/100, Loss: 229.1493, Validation Accuracy: 0.5982\n",
            "Epoch 87/100, Loss: 68.8778, Validation Accuracy: 0.6271\n",
            "Epoch 88/100, Loss: 55.7152, Validation Accuracy: 0.5922\n",
            "Epoch 89/100, Loss: 83.3991, Validation Accuracy: 0.5224\n",
            "Epoch 90/100, Loss: 46.0548, Validation Accuracy: 0.5882\n",
            "Epoch 91/100, Loss: 62.5744, Validation Accuracy: 0.4616\n",
            "Epoch 92/100, Loss: 262.5931, Validation Accuracy: 0.4447\n",
            "Epoch 93/100, Loss: 244.7156, Validation Accuracy: 0.6261\n",
            "Epoch 94/100, Loss: 73.3321, Validation Accuracy: 0.5992\n",
            "Epoch 95/100, Loss: 232.4429, Validation Accuracy: 0.6700\n",
            "Epoch 96/100, Loss: 90.7684, Validation Accuracy: 0.6491\n",
            "Epoch 97/100, Loss: 142.7300, Validation Accuracy: 0.6750\n",
            "Epoch 98/100, Loss: 275.5576, Validation Accuracy: 0.6321\n",
            "Epoch 99/100, Loss: 116.9457, Validation Accuracy: 0.6012\n",
            "Epoch 100/100, Loss: 156.2081, Validation Accuracy: 0.6361\n",
            "Epoch 101/100, Loss: 573.9060, Validation Accuracy: 0.6570\n",
            "Epoch 102/100, Loss: 147.7643, Validation Accuracy: 0.5214\n",
            "Epoch 103/100, Loss: 91.5735, Validation Accuracy: 0.5842\n",
            "Epoch 104/100, Loss: 75.7200, Validation Accuracy: 0.6680\n",
            "Epoch 105/100, Loss: 267.0090, Validation Accuracy: 0.4995\n",
            "Epoch 106/100, Loss: 143.0911, Validation Accuracy: 0.6750\n",
            "Epoch 107/100, Loss: 36.7958, Validation Accuracy: 0.5783\n",
            "Epoch 108/100, Loss: 25.4515, Validation Accuracy: 0.5384\n",
            "Epoch 109/100, Loss: 136.3497, Validation Accuracy: 0.6790\n",
            "Epoch 110/100, Loss: 193.0473, Validation Accuracy: 0.5105\n",
            "Epoch 111/100, Loss: 136.7899, Validation Accuracy: 0.5793\n",
            "Epoch 112/100, Loss: 166.6525, Validation Accuracy: 0.6142\n",
            "Epoch 113/100, Loss: 63.3856, Validation Accuracy: 0.5932\n",
            "Epoch 114/100, Loss: 160.9352, Validation Accuracy: 0.4477\n",
            "Epoch 115/100, Loss: 225.1601, Validation Accuracy: 0.4686\n",
            "Epoch 116/100, Loss: 101.7967, Validation Accuracy: 0.6600\n",
            "Epoch 117/100, Loss: 82.1682, Validation Accuracy: 0.4746\n",
            "Epoch 118/100, Loss: 138.4503, Validation Accuracy: 0.6680\n",
            "Epoch 119/100, Loss: 140.7338, Validation Accuracy: 0.5464\n",
            "Epoch 120/100, Loss: 111.9407, Validation Accuracy: 0.5663\n",
            "Epoch 121/100, Loss: 234.3553, Validation Accuracy: 0.4387\n",
            "Epoch 122/100, Loss: 16.6017, Validation Accuracy: 0.5693\n",
            "Epoch 123/100, Loss: 837.7504, Validation Accuracy: 0.5165\n",
            "Epoch 124/100, Loss: 306.2531, Validation Accuracy: 0.4197\n",
            "Epoch 125/100, Loss: 81.4324, Validation Accuracy: 0.5673\n",
            "Epoch 126/100, Loss: 48.8095, Validation Accuracy: 0.6032\n",
            "Epoch 127/100, Loss: 52.2564, Validation Accuracy: 0.6241\n",
            "Epoch 128/100, Loss: 62.2818, Validation Accuracy: 0.6830\n",
            "Epoch 129/100, Loss: 77.8960, Validation Accuracy: 0.5773\n",
            "Epoch 130/100, Loss: 392.1787, Validation Accuracy: 0.6261\n",
            "Epoch 131/100, Loss: 215.4005, Validation Accuracy: 0.6102\n",
            "Epoch 132/100, Loss: 386.6903, Validation Accuracy: 0.6331\n",
            "Epoch 133/100, Loss: 74.4668, Validation Accuracy: 0.5593\n",
            "Epoch 134/100, Loss: 155.0447, Validation Accuracy: 0.5573\n",
            "Epoch 135/100, Loss: 260.3351, Validation Accuracy: 0.5015\n",
            "Epoch 136/100, Loss: 89.5725, Validation Accuracy: 0.6670\n",
            "Epoch 137/100, Loss: 17.5566, Validation Accuracy: 0.5523\n",
            "Epoch 138/100, Loss: 55.0342, Validation Accuracy: 0.6770\n",
            "Epoch 139/100, Loss: 256.6042, Validation Accuracy: 0.5434\n",
            "Epoch 140/100, Loss: 107.8647, Validation Accuracy: 0.6391\n",
            "Epoch 141/100, Loss: 367.6437, Validation Accuracy: 0.4686\n",
            "Epoch 142/100, Loss: 261.3072, Validation Accuracy: 0.4536\n",
            "Epoch 143/100, Loss: 117.9474, Validation Accuracy: 0.5663\n",
            "Epoch 144/100, Loss: 91.6328, Validation Accuracy: 0.6381\n",
            "Epoch 145/100, Loss: 82.8255, Validation Accuracy: 0.2233\n",
            "Epoch 146/100, Loss: 125.3389, Validation Accuracy: 0.6082\n",
            "Epoch 147/100, Loss: 154.5260, Validation Accuracy: 0.6750\n",
            "Epoch 148/100, Loss: 228.5126, Validation Accuracy: 0.5613\n",
            "Epoch 149/100, Loss: 129.2305, Validation Accuracy: 0.6461\n",
            "Epoch 150/100, Loss: 248.3785, Validation Accuracy: 0.6580\n",
            "Epoch 151/100, Loss: 283.1795, Validation Accuracy: 0.5135\n",
            "Epoch 152/100, Loss: 48.5251, Validation Accuracy: 0.6191\n",
            "Epoch 153/100, Loss: 95.5210, Validation Accuracy: 0.6630\n",
            "Epoch 154/100, Loss: 97.7749, Validation Accuracy: 0.5284\n",
            "Epoch 155/100, Loss: 74.2804, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 347.2460, Validation Accuracy: 0.5593\n",
            "Epoch 157/100, Loss: 203.5082, Validation Accuracy: 0.6411\n",
            "Epoch 158/100, Loss: 49.0243, Validation Accuracy: 0.6720\n",
            "Epoch 159/100, Loss: 74.7885, Validation Accuracy: 0.5892\n",
            "Epoch 160/100, Loss: 133.2628, Validation Accuracy: 0.6301\n",
            "Epoch 161/100, Loss: 276.8106, Validation Accuracy: 0.5743\n",
            "Epoch 162/100, Loss: 203.7503, Validation Accuracy: 0.6600\n",
            "Epoch 163/100, Loss: 128.8710, Validation Accuracy: 0.6132\n",
            "Epoch 164/100, Loss: 289.7978, Validation Accuracy: 0.4397\n",
            "Epoch 165/100, Loss: 353.9811, Validation Accuracy: 0.5982\n",
            "Epoch 166/100, Loss: 128.5372, Validation Accuracy: 0.6391\n",
            "Epoch 167/100, Loss: 92.9723, Validation Accuracy: 0.6122\n",
            "Epoch 168/100, Loss: 32.3184, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 68.7697, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 141.5237, Validation Accuracy: 0.5813\n",
            "Epoch 171/100, Loss: 173.4358, Validation Accuracy: 0.6241\n",
            "Epoch 172/100, Loss: 107.8286, Validation Accuracy: 0.6052\n",
            "Epoch 173/100, Loss: 74.3911, Validation Accuracy: 0.5882\n",
            "Epoch 174/100, Loss: 157.7911, Validation Accuracy: 0.5852\n",
            "Epoch 175/100, Loss: 83.8288, Validation Accuracy: 0.6181\n",
            "Epoch 176/100, Loss: 108.5756, Validation Accuracy: 0.6600\n",
            "Epoch 177/100, Loss: 241.4377, Validation Accuracy: 0.5992\n",
            "Epoch 178/100, Loss: 219.3148, Validation Accuracy: 0.6321\n",
            "Epoch 179/100, Loss: 65.3341, Validation Accuracy: 0.6530\n",
            "Epoch 180/100, Loss: 42.9761, Validation Accuracy: 0.6540\n",
            "Epoch 181/100, Loss: 238.1696, Validation Accuracy: 0.6491\n",
            "Epoch 182/100, Loss: 182.2996, Validation Accuracy: 0.4626\n",
            "Epoch 183/100, Loss: 79.5094, Validation Accuracy: 0.6201\n",
            "Epoch 184/100, Loss: 46.4013, Validation Accuracy: 0.6311\n",
            "Epoch 185/100, Loss: 118.5269, Validation Accuracy: 0.5015\n",
            "Epoch 186/100, Loss: 85.7237, Validation Accuracy: 0.5862\n",
            "Epoch 187/100, Loss: 122.1357, Validation Accuracy: 0.5115\n",
            "Epoch 188/100, Loss: 263.8925, Validation Accuracy: 0.6152\n",
            "Epoch 189/100, Loss: 307.5667, Validation Accuracy: 0.3390\n",
            "Epoch 190/100, Loss: 148.1528, Validation Accuracy: 0.5424\n",
            "Epoch 191/100, Loss: 72.2936, Validation Accuracy: 0.6471\n",
            "Epoch 192/100, Loss: 202.4167, Validation Accuracy: 0.5115\n",
            "Epoch 193/100, Loss: 333.6888, Validation Accuracy: 0.3310\n",
            "Epoch 194/100, Loss: 308.7360, Validation Accuracy: 0.6451\n",
            "Epoch 195/100, Loss: 75.7895, Validation Accuracy: 0.5922\n",
            "Epoch 196/100, Loss: 48.1796, Validation Accuracy: 0.5633\n",
            "Epoch 197/100, Loss: 132.1336, Validation Accuracy: 0.5972\n",
            "Epoch 198/100, Loss: 63.0802, Validation Accuracy: 0.6102\n",
            "Epoch 199/100, Loss: 139.5408, Validation Accuracy: 0.4816\n",
            "Epoch 200/100, Loss: 406.1013, Validation Accuracy: 0.5693\n",
            "Reward for Child Model: 0.22717025596579984\n",
            "Child_39:  {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, [0, 0, 0, 2, 0, 3, 2, 2, 2, 1, 2, 1, 0, 2, 1], 0.22717025596579984\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 36, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(100, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(148, 48, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(48, 24, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=28800, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 24, 26]           2,944\n",
            "       BatchNorm2d-2           [-1, 64, 24, 26]             128\n",
            "            Conv2d-3           [-1, 36, 24, 22]          11,556\n",
            "       BatchNorm2d-4           [-1, 36, 24, 22]              72\n",
            "              ReLU-5           [-1, 36, 24, 22]               0\n",
            "            Conv2d-6           [-1, 48, 18, 24]         100,848\n",
            "       BatchNorm2d-7           [-1, 48, 18, 24]              96\n",
            "              ReLU-8           [-1, 48, 18, 24]               0\n",
            "            Conv2d-9           [-1, 48, 20, 20]         248,688\n",
            "      BatchNorm2d-10           [-1, 48, 20, 20]              96\n",
            "             ReLU-11           [-1, 48, 20, 20]               0\n",
            "           Conv2d-12           [-1, 24, 16, 16]          28,824\n",
            "      BatchNorm2d-13           [-1, 24, 16, 16]              48\n",
            "             ReLU-14           [-1, 24, 16, 16]               0\n",
            "           Linear-15                    [-1, 7]         201,607\n",
            "================================================================\n",
            "Total params: 594,907\n",
            "Trainable params: 594,907\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.10\n",
            "Params size (MB): 2.27\n",
            "Estimated Total Size (MB): 4.38\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 0.9843, Validation Accuracy: 0.6690\n",
            "Epoch 2/100, Loss: 1.2109, Validation Accuracy: 0.6690\n",
            "Epoch 3/100, Loss: 1.1412, Validation Accuracy: 0.6690\n",
            "Epoch 4/100, Loss: 1.3371, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 1.0453, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 1.1234, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 1.2732, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 1.0915, Validation Accuracy: 0.6690\n",
            "Epoch 9/100, Loss: 1.1320, Validation Accuracy: 0.6690\n",
            "Epoch 10/100, Loss: 1.2384, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 1.3941, Validation Accuracy: 0.6680\n",
            "Epoch 12/100, Loss: 1.1081, Validation Accuracy: 0.6660\n",
            "Epoch 13/100, Loss: 1.1339, Validation Accuracy: 0.6690\n",
            "Epoch 14/100, Loss: 1.1260, Validation Accuracy: 0.6690\n",
            "Epoch 15/100, Loss: 1.0817, Validation Accuracy: 0.6690\n",
            "Epoch 16/100, Loss: 1.0731, Validation Accuracy: 0.6690\n",
            "Epoch 17/100, Loss: 1.1398, Validation Accuracy: 0.6690\n",
            "Epoch 18/100, Loss: 1.4394, Validation Accuracy: 0.6690\n",
            "Epoch 19/100, Loss: 1.2504, Validation Accuracy: 0.6690\n",
            "Epoch 20/100, Loss: 0.7513, Validation Accuracy: 0.6690\n",
            "Epoch 21/100, Loss: 1.3789, Validation Accuracy: 0.6690\n",
            "Epoch 22/100, Loss: 1.4582, Validation Accuracy: 0.6690\n",
            "Epoch 23/100, Loss: 1.0161, Validation Accuracy: 0.6690\n",
            "Epoch 24/100, Loss: 1.1550, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 1.1760, Validation Accuracy: 0.6690\n",
            "Epoch 26/100, Loss: 1.4916, Validation Accuracy: 0.6690\n",
            "Epoch 27/100, Loss: 0.9413, Validation Accuracy: 0.6690\n",
            "Epoch 28/100, Loss: 1.1526, Validation Accuracy: 0.6690\n",
            "Epoch 29/100, Loss: 1.1177, Validation Accuracy: 0.6690\n",
            "Epoch 30/100, Loss: 1.1976, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 0.6747, Validation Accuracy: 0.6690\n",
            "Epoch 32/100, Loss: 1.5372, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 1.3038, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 0.9524, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 1.1902, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 0.9931, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 1.1364, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 1.0510, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 1.0921, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 1.1508, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 0.9830, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 1.0062, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 1.1221, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 1.1037, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 1.4353, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 1.0353, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 1.2352, Validation Accuracy: 0.6690\n",
            "Epoch 48/100, Loss: 1.0849, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 1.3413, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 0.8691, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 1.3955, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 0.8302, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 1.1415, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 1.3359, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 1.0023, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 0.9617, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 1.3211, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 1.3819, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 1.1369, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 0.9840, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 1.5317, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 1.1283, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 1.1608, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 1.0818, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 1.0906, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 1.3768, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 1.7081, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 1.1638, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 1.2931, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 1.3899, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 0.9027, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 0.9901, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 1.4071, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 1.2296, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 1.7370, Validation Accuracy: 0.6690\n",
            "Epoch 76/100, Loss: 1.2305, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 1.0814, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 0.8235, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 1.2026, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 1.3367, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 1.4205, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 0.8964, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 0.9766, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 1.1062, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 1.2413, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 1.2149, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 1.0857, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 1.1124, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 1.4296, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 1.1532, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 1.1050, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 1.3058, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 1.1344, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 0.9104, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 1.2145, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 1.2429, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 0.9978, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 1.0322, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 0.7495, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 1.1301, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 1.0926, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 1.2379, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 1.3234, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 1.5126, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 0.8967, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 1.2476, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 1.0950, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 0.9499, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 1.0953, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 1.8364, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.0323, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 0.8892, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 1.1189, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 1.4111, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 1.2509, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 1.3127, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 0.9164, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 0.6974, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 1.2545, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 0.9356, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 1.0699, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.0853, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 1.2564, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 1.2910, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 1.4151, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 1.1759, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 0.9988, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 1.1776, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 1.0699, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 1.1457, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 1.2997, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 0.9077, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 1.0806, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 0.9903, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 1.0044, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 1.4050, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 0.9985, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 1.1423, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 1.2686, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 1.1742, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 1.5600, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 0.9096, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 0.7564, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 1.2763, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 1.3222, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 1.4125, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 1.2621, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 1.3144, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 1.2385, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 1.3788, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 0.9518, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 1.0834, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 1.1821, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 0.9918, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 0.8195, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 1.1557, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 1.0732, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 1.0898, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 1.3212, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 1.1308, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 0.9665, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 1.4189, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 1.1420, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 0.9824, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 0.9925, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 1.4131, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 1.1041, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 1.2349, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 1.2974, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 0.9993, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 1.1526, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 0.8837, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 1.0728, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 0.9073, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 1.2706, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 1.1870, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 1.2108, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 0.8430, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 1.2489, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 0.9990, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 1.2825, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 1.2598, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 1.1642, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 1.1881, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 1.2412, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 0.9402, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 0.6827, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 1.2182, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 1.1138, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 1.2148, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 1.3819, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 0.8708, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 1.5476, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 0.9927, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 1.0947, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 0.8915, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 1.0935, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 1.3043, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 1.2192, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 0.9148, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_40:  {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, [2, 1, 3, 0, 2, 1, 3, 1, 2, 2, 3, 2, 2, 2, 0], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 36, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(108, 64, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(244, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=279552, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 26, 24]           1,104\n",
            "       BatchNorm2d-2           [-1, 24, 26, 24]              48\n",
            "            Conv2d-3           [-1, 48, 20, 22]          24,240\n",
            "       BatchNorm2d-4           [-1, 48, 20, 22]              96\n",
            "              ReLU-5           [-1, 48, 20, 22]               0\n",
            "            Conv2d-6           [-1, 36, 20, 20]           5,220\n",
            "       BatchNorm2d-7           [-1, 36, 20, 20]              72\n",
            "              ReLU-8           [-1, 36, 20, 20]               0\n",
            "            Conv2d-9           [-1, 64, 24, 24]          20,800\n",
            "      BatchNorm2d-10           [-1, 64, 24, 24]             128\n",
            "             ReLU-11           [-1, 64, 24, 24]               0\n",
            "           Conv2d-12           [-1, 48, 26, 24]          11,760\n",
            "      BatchNorm2d-13           [-1, 48, 26, 24]              96\n",
            "             ReLU-14           [-1, 48, 26, 24]               0\n",
            "           Linear-15                    [-1, 7]       1,956,871\n",
            "================================================================\n",
            "Total params: 2,020,435\n",
            "Trainable params: 2,020,435\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.57\n",
            "Params size (MB): 7.71\n",
            "Estimated Total Size (MB): 10.29\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 35.4119, Validation Accuracy: 0.6560\n",
            "Epoch 2/100, Loss: 26.9282, Validation Accuracy: 0.4427\n",
            "Epoch 3/100, Loss: 120.5008, Validation Accuracy: 0.6660\n",
            "Epoch 4/100, Loss: 469.6061, Validation Accuracy: 0.3330\n",
            "Epoch 5/100, Loss: 104.4686, Validation Accuracy: 0.6251\n",
            "Epoch 6/100, Loss: 9.1934, Validation Accuracy: 0.6291\n",
            "Epoch 7/100, Loss: 1228.8689, Validation Accuracy: 0.4227\n",
            "Epoch 8/100, Loss: 218.6456, Validation Accuracy: 0.5165\n",
            "Epoch 9/100, Loss: 673.1417, Validation Accuracy: 0.6481\n",
            "Epoch 10/100, Loss: 29.1600, Validation Accuracy: 0.6171\n",
            "Epoch 11/100, Loss: 94.7358, Validation Accuracy: 0.4417\n",
            "Epoch 12/100, Loss: 27.7148, Validation Accuracy: 0.5015\n",
            "Epoch 13/100, Loss: 750.2242, Validation Accuracy: 0.3161\n",
            "Epoch 14/100, Loss: 26.8101, Validation Accuracy: 0.5374\n",
            "Epoch 15/100, Loss: 23.3575, Validation Accuracy: 0.6162\n",
            "Epoch 16/100, Loss: 8.9735, Validation Accuracy: 0.2722\n",
            "Epoch 17/100, Loss: 27.5569, Validation Accuracy: 0.6331\n",
            "Epoch 18/100, Loss: 37.9592, Validation Accuracy: 0.6471\n",
            "Epoch 19/100, Loss: 9.7582, Validation Accuracy: 0.5533\n",
            "Epoch 20/100, Loss: 305.7961, Validation Accuracy: 0.6022\n",
            "Epoch 21/100, Loss: 18.6646, Validation Accuracy: 0.6032\n",
            "Epoch 22/100, Loss: 43.0328, Validation Accuracy: 0.6062\n",
            "Epoch 23/100, Loss: 50.5675, Validation Accuracy: 0.5294\n",
            "Epoch 24/100, Loss: 1051.6674, Validation Accuracy: 0.4965\n",
            "Epoch 25/100, Loss: 48.0179, Validation Accuracy: 0.4626\n",
            "Epoch 26/100, Loss: 51.6278, Validation Accuracy: 0.3858\n",
            "Epoch 27/100, Loss: 263.5083, Validation Accuracy: 0.6042\n",
            "Epoch 28/100, Loss: 10.0603, Validation Accuracy: 0.5354\n",
            "Epoch 29/100, Loss: 46.8043, Validation Accuracy: 0.3988\n",
            "Epoch 30/100, Loss: 11.3045, Validation Accuracy: 0.6381\n",
            "Epoch 31/100, Loss: 12.0477, Validation Accuracy: 0.6710\n",
            "Epoch 32/100, Loss: 38.3531, Validation Accuracy: 0.6122\n",
            "Epoch 33/100, Loss: 31.9941, Validation Accuracy: 0.6291\n",
            "Epoch 34/100, Loss: 28.1865, Validation Accuracy: 0.6590\n",
            "Epoch 35/100, Loss: 28.4402, Validation Accuracy: 0.6291\n",
            "Epoch 36/100, Loss: 25.7870, Validation Accuracy: 0.5862\n",
            "Epoch 37/100, Loss: 93.9579, Validation Accuracy: 0.5264\n",
            "Epoch 38/100, Loss: 28.1746, Validation Accuracy: 0.4786\n",
            "Epoch 39/100, Loss: 7.3383, Validation Accuracy: 0.4626\n",
            "Epoch 40/100, Loss: 23.8525, Validation Accuracy: 0.4746\n",
            "Epoch 41/100, Loss: 15.0947, Validation Accuracy: 0.6271\n",
            "Epoch 42/100, Loss: 8.2004, Validation Accuracy: 0.6022\n",
            "Epoch 43/100, Loss: 11.0188, Validation Accuracy: 0.4197\n",
            "Epoch 44/100, Loss: 19.1752, Validation Accuracy: 0.6241\n",
            "Epoch 45/100, Loss: 24.1482, Validation Accuracy: 0.6092\n",
            "Epoch 46/100, Loss: 40.7085, Validation Accuracy: 0.3948\n",
            "Epoch 47/100, Loss: 10.6451, Validation Accuracy: 0.5573\n",
            "Epoch 48/100, Loss: 79.7478, Validation Accuracy: 0.2812\n",
            "Epoch 49/100, Loss: 9.9210, Validation Accuracy: 0.5922\n",
            "Epoch 50/100, Loss: 111.7291, Validation Accuracy: 0.5723\n",
            "Epoch 51/100, Loss: 677.0593, Validation Accuracy: 0.4427\n",
            "Epoch 52/100, Loss: 68.9124, Validation Accuracy: 0.1107\n",
            "Epoch 53/100, Loss: 27.3589, Validation Accuracy: 0.5503\n",
            "Epoch 54/100, Loss: 35.8621, Validation Accuracy: 0.5872\n",
            "Epoch 55/100, Loss: 50.9077, Validation Accuracy: 0.6660\n",
            "Epoch 56/100, Loss: 78.0101, Validation Accuracy: 0.5922\n",
            "Epoch 57/100, Loss: 75.3385, Validation Accuracy: 0.6510\n",
            "Epoch 58/100, Loss: 144.0293, Validation Accuracy: 0.5882\n",
            "Epoch 59/100, Loss: 15.1632, Validation Accuracy: 0.6540\n",
            "Epoch 60/100, Loss: 111.2198, Validation Accuracy: 0.6012\n",
            "Epoch 61/100, Loss: 121.1313, Validation Accuracy: 0.6072\n",
            "Epoch 62/100, Loss: 103.0963, Validation Accuracy: 0.5264\n",
            "Epoch 63/100, Loss: 1362.6334, Validation Accuracy: 0.6062\n",
            "Epoch 64/100, Loss: 64.0580, Validation Accuracy: 0.5025\n",
            "Epoch 65/100, Loss: 18.5409, Validation Accuracy: 0.5095\n",
            "Epoch 66/100, Loss: 197.5966, Validation Accuracy: 0.4826\n",
            "Epoch 67/100, Loss: 83.9318, Validation Accuracy: 0.5254\n",
            "Epoch 68/100, Loss: 7.4481, Validation Accuracy: 0.4945\n",
            "Epoch 69/100, Loss: 145.8582, Validation Accuracy: 0.6421\n",
            "Epoch 70/100, Loss: 16.0752, Validation Accuracy: 0.2732\n",
            "Epoch 71/100, Loss: 147.9296, Validation Accuracy: 0.4497\n",
            "Epoch 72/100, Loss: 62.8566, Validation Accuracy: 0.1595\n",
            "Epoch 73/100, Loss: 26.6579, Validation Accuracy: 0.5344\n",
            "Epoch 74/100, Loss: 15.9953, Validation Accuracy: 0.4726\n",
            "Epoch 75/100, Loss: 5.5233, Validation Accuracy: 0.5962\n",
            "Epoch 76/100, Loss: 12.7358, Validation Accuracy: 0.3420\n",
            "Epoch 77/100, Loss: 33.6262, Validation Accuracy: 0.6052\n",
            "Epoch 78/100, Loss: 26.4051, Validation Accuracy: 0.4606\n",
            "Epoch 79/100, Loss: 11.8879, Validation Accuracy: 0.6032\n",
            "Epoch 80/100, Loss: 24.9869, Validation Accuracy: 0.5603\n",
            "Epoch 81/100, Loss: 129.0691, Validation Accuracy: 0.6700\n",
            "Epoch 82/100, Loss: 54.0875, Validation Accuracy: 0.5703\n",
            "Epoch 83/100, Loss: 16.7197, Validation Accuracy: 0.6530\n",
            "Epoch 84/100, Loss: 35.5118, Validation Accuracy: 0.4806\n",
            "Epoch 85/100, Loss: 77.3072, Validation Accuracy: 0.6481\n",
            "Epoch 86/100, Loss: 89.8143, Validation Accuracy: 0.6311\n",
            "Epoch 87/100, Loss: 10.9087, Validation Accuracy: 0.6580\n",
            "Epoch 88/100, Loss: 2756.9041, Validation Accuracy: 0.6012\n",
            "Epoch 89/100, Loss: 298.7434, Validation Accuracy: 0.5833\n",
            "Epoch 90/100, Loss: 64.4338, Validation Accuracy: 0.5992\n",
            "Epoch 91/100, Loss: 31.5811, Validation Accuracy: 0.5733\n",
            "Epoch 92/100, Loss: 21.3170, Validation Accuracy: 0.5972\n",
            "Epoch 93/100, Loss: 26.2930, Validation Accuracy: 0.5952\n",
            "Epoch 94/100, Loss: 10.2029, Validation Accuracy: 0.5823\n",
            "Epoch 95/100, Loss: 22.6526, Validation Accuracy: 0.6032\n",
            "Epoch 96/100, Loss: 18.3801, Validation Accuracy: 0.6401\n",
            "Epoch 97/100, Loss: 209.5646, Validation Accuracy: 0.2413\n",
            "Epoch 98/100, Loss: 16.9441, Validation Accuracy: 0.5623\n",
            "Epoch 99/100, Loss: 8.3084, Validation Accuracy: 0.6162\n",
            "Epoch 100/100, Loss: 10.6950, Validation Accuracy: 0.5573\n",
            "Epoch 101/100, Loss: 24.0189, Validation Accuracy: 0.5922\n",
            "Epoch 102/100, Loss: 68.3630, Validation Accuracy: 0.3180\n",
            "Epoch 103/100, Loss: 50.6051, Validation Accuracy: 0.4457\n",
            "Epoch 104/100, Loss: 27.5148, Validation Accuracy: 0.5693\n",
            "Epoch 105/100, Loss: 40.1227, Validation Accuracy: 0.6919\n",
            "Epoch 106/100, Loss: 45.1208, Validation Accuracy: 0.6301\n",
            "Epoch 107/100, Loss: 110.4162, Validation Accuracy: 0.5723\n",
            "Epoch 108/100, Loss: 42.0627, Validation Accuracy: 0.6461\n",
            "Epoch 109/100, Loss: 32.7015, Validation Accuracy: 0.6371\n",
            "Epoch 110/100, Loss: 28.3053, Validation Accuracy: 0.6072\n",
            "Epoch 111/100, Loss: 24.6587, Validation Accuracy: 0.6261\n",
            "Epoch 112/100, Loss: 14.3323, Validation Accuracy: 0.5793\n",
            "Epoch 113/100, Loss: 36.4713, Validation Accuracy: 0.5254\n",
            "Epoch 114/100, Loss: 128.5989, Validation Accuracy: 0.4756\n",
            "Epoch 115/100, Loss: 542.9353, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 62.2218, Validation Accuracy: 0.5972\n",
            "Epoch 117/100, Loss: 17.5092, Validation Accuracy: 0.5065\n",
            "Epoch 118/100, Loss: 15.2257, Validation Accuracy: 0.6550\n",
            "Epoch 119/100, Loss: 95.0721, Validation Accuracy: 0.5573\n",
            "Epoch 120/100, Loss: 12.8331, Validation Accuracy: 0.5294\n",
            "Epoch 121/100, Loss: 12.4536, Validation Accuracy: 0.6650\n",
            "Epoch 122/100, Loss: 13.7622, Validation Accuracy: 0.6211\n",
            "Epoch 123/100, Loss: 7.9173, Validation Accuracy: 0.6052\n",
            "Epoch 124/100, Loss: 57.7909, Validation Accuracy: 0.3549\n",
            "Epoch 125/100, Loss: 12.6097, Validation Accuracy: 0.5454\n",
            "Epoch 126/100, Loss: 12.9711, Validation Accuracy: 0.5972\n",
            "Epoch 127/100, Loss: 30.5870, Validation Accuracy: 0.5902\n",
            "Epoch 128/100, Loss: 37.0581, Validation Accuracy: 0.5793\n",
            "Epoch 129/100, Loss: 47.1687, Validation Accuracy: 0.6341\n",
            "Epoch 130/100, Loss: 21.4909, Validation Accuracy: 0.5384\n",
            "Epoch 131/100, Loss: 17.4463, Validation Accuracy: 0.6600\n",
            "Epoch 132/100, Loss: 159.9121, Validation Accuracy: 0.4875\n",
            "Epoch 133/100, Loss: 114.9799, Validation Accuracy: 0.5553\n",
            "Epoch 134/100, Loss: 21.7565, Validation Accuracy: 0.4596\n",
            "Epoch 135/100, Loss: 17.1295, Validation Accuracy: 0.5135\n",
            "Epoch 136/100, Loss: 25.4647, Validation Accuracy: 0.6132\n",
            "Epoch 137/100, Loss: 22.7655, Validation Accuracy: 0.3918\n",
            "Epoch 138/100, Loss: 105.3852, Validation Accuracy: 0.5434\n",
            "Epoch 139/100, Loss: 135.4868, Validation Accuracy: 0.6560\n",
            "Epoch 140/100, Loss: 110.1007, Validation Accuracy: 0.5743\n",
            "Epoch 141/100, Loss: 30.3007, Validation Accuracy: 0.6032\n",
            "Epoch 142/100, Loss: 42.3691, Validation Accuracy: 0.6680\n",
            "Epoch 143/100, Loss: 3.6164, Validation Accuracy: 0.6311\n",
            "Epoch 144/100, Loss: 12.2994, Validation Accuracy: 0.6770\n",
            "Epoch 145/100, Loss: 40.7809, Validation Accuracy: 0.6680\n",
            "Epoch 146/100, Loss: 17.6390, Validation Accuracy: 0.4506\n",
            "Epoch 147/100, Loss: 30.2493, Validation Accuracy: 0.5972\n",
            "Epoch 148/100, Loss: 84.9601, Validation Accuracy: 0.6042\n",
            "Epoch 149/100, Loss: 60.3745, Validation Accuracy: 0.4806\n",
            "Epoch 150/100, Loss: 39.8421, Validation Accuracy: 0.5513\n",
            "Epoch 151/100, Loss: 525.9182, Validation Accuracy: 0.6411\n",
            "Epoch 152/100, Loss: 61.6790, Validation Accuracy: 0.6132\n",
            "Epoch 153/100, Loss: 10.3713, Validation Accuracy: 0.4387\n",
            "Epoch 154/100, Loss: 30.0301, Validation Accuracy: 0.6451\n",
            "Epoch 155/100, Loss: 25.4525, Validation Accuracy: 0.4586\n",
            "Epoch 156/100, Loss: 18.3078, Validation Accuracy: 0.5284\n",
            "Epoch 157/100, Loss: 15.8372, Validation Accuracy: 0.5194\n",
            "Epoch 158/100, Loss: 8.7038, Validation Accuracy: 0.5962\n",
            "Epoch 159/100, Loss: 46.7876, Validation Accuracy: 0.5454\n",
            "Epoch 160/100, Loss: 244.5155, Validation Accuracy: 0.3350\n",
            "Epoch 161/100, Loss: 65.4872, Validation Accuracy: 0.3978\n",
            "Epoch 162/100, Loss: 10.0716, Validation Accuracy: 0.5434\n",
            "Epoch 163/100, Loss: 14.1015, Validation Accuracy: 0.6301\n",
            "Epoch 164/100, Loss: 19.2921, Validation Accuracy: 0.5892\n",
            "Epoch 165/100, Loss: 15.8375, Validation Accuracy: 0.6082\n",
            "Epoch 166/100, Loss: 57.6838, Validation Accuracy: 0.4855\n",
            "Epoch 167/100, Loss: 43.4980, Validation Accuracy: 0.6122\n",
            "Epoch 168/100, Loss: 143.2982, Validation Accuracy: 0.2084\n",
            "Epoch 169/100, Loss: 61.3976, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 178.1389, Validation Accuracy: 0.5085\n",
            "Epoch 171/100, Loss: 13.1259, Validation Accuracy: 0.6401\n",
            "Epoch 172/100, Loss: 28.8947, Validation Accuracy: 0.5284\n",
            "Epoch 173/100, Loss: 8.6446, Validation Accuracy: 0.6361\n",
            "Epoch 174/100, Loss: 9.3811, Validation Accuracy: 0.5633\n",
            "Epoch 175/100, Loss: 16.2012, Validation Accuracy: 0.5503\n",
            "Epoch 176/100, Loss: 13.2351, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 24.8298, Validation Accuracy: 0.6102\n",
            "Epoch 178/100, Loss: 28.4165, Validation Accuracy: 0.6461\n",
            "Epoch 179/100, Loss: 67.9129, Validation Accuracy: 0.5972\n",
            "Epoch 180/100, Loss: 47.1881, Validation Accuracy: 0.6341\n",
            "Epoch 181/100, Loss: 19.7747, Validation Accuracy: 0.6800\n",
            "Epoch 182/100, Loss: 28.1898, Validation Accuracy: 0.6540\n",
            "Epoch 183/100, Loss: 112.1492, Validation Accuracy: 0.5723\n",
            "Epoch 184/100, Loss: 52.0638, Validation Accuracy: 0.5284\n",
            "Epoch 185/100, Loss: 51.2878, Validation Accuracy: 0.6361\n",
            "Epoch 186/100, Loss: 19.0204, Validation Accuracy: 0.5444\n",
            "Epoch 187/100, Loss: 31.0894, Validation Accuracy: 0.6351\n",
            "Epoch 188/100, Loss: 638.3663, Validation Accuracy: 0.5254\n",
            "Epoch 189/100, Loss: 35.1465, Validation Accuracy: 0.6241\n",
            "Epoch 190/100, Loss: 41.9519, Validation Accuracy: 0.6351\n",
            "Epoch 191/100, Loss: 42.5820, Validation Accuracy: 0.6630\n",
            "Epoch 192/100, Loss: 6.4673, Validation Accuracy: 0.4895\n",
            "Epoch 193/100, Loss: 51.4542, Validation Accuracy: 0.4437\n",
            "Epoch 194/100, Loss: 43.5376, Validation Accuracy: 0.5125\n",
            "Epoch 195/100, Loss: 29.1072, Validation Accuracy: 0.4536\n",
            "Epoch 196/100, Loss: 84.3618, Validation Accuracy: 0.6411\n",
            "Epoch 197/100, Loss: 15.8449, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 302.0007, Validation Accuracy: 0.4995\n",
            "Epoch 199/100, Loss: 70.0040, Validation Accuracy: 0.5573\n",
            "Epoch 200/100, Loss: 38.7599, Validation Accuracy: 0.6660\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_41:  {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, [1, 2, 0, 3, 1, 2, 0, 1, 1, 1, 0, 3, 0, 0, 2], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(112, 64, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(240, 36, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(388, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=79872, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 26, 24]           2,944\n",
            "       BatchNorm2d-2           [-1, 64, 26, 24]             128\n",
            "            Conv2d-3           [-1, 48, 26, 20]          15,408\n",
            "       BatchNorm2d-4           [-1, 48, 26, 20]              96\n",
            "              ReLU-5           [-1, 48, 26, 20]               0\n",
            "            Conv2d-6           [-1, 64, 20, 22]         150,592\n",
            "       BatchNorm2d-7           [-1, 64, 20, 22]             128\n",
            "              ReLU-8           [-1, 64, 20, 22]               0\n",
            "            Conv2d-9           [-1, 36, 24, 18]         181,476\n",
            "      BatchNorm2d-10           [-1, 36, 24, 18]              72\n",
            "             ReLU-11           [-1, 36, 24, 18]               0\n",
            "           Conv2d-12           [-1, 64, 20, 18]       1,216,832\n",
            "      BatchNorm2d-13           [-1, 64, 20, 18]             128\n",
            "             ReLU-14           [-1, 64, 20, 18]               0\n",
            "           Linear-15                    [-1, 7]         559,111\n",
            "================================================================\n",
            "Total params: 2,126,915\n",
            "Trainable params: 2,126,915\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.71\n",
            "Params size (MB): 8.11\n",
            "Estimated Total Size (MB): 10.83\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 180.7668, Validation Accuracy: 0.0748\n",
            "Epoch 2/100, Loss: 9.6110, Validation Accuracy: 0.6491\n",
            "Epoch 3/100, Loss: 31.4745, Validation Accuracy: 0.5085\n",
            "Epoch 4/100, Loss: 395.3860, Validation Accuracy: 0.5653\n",
            "Epoch 5/100, Loss: 31.0354, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 6.9595, Validation Accuracy: 0.6231\n",
            "Epoch 7/100, Loss: 6.0723, Validation Accuracy: 0.6580\n",
            "Epoch 8/100, Loss: 11.8726, Validation Accuracy: 0.5274\n",
            "Epoch 9/100, Loss: 12.4894, Validation Accuracy: 0.4766\n",
            "Epoch 10/100, Loss: 6.4778, Validation Accuracy: 0.6760\n",
            "Epoch 11/100, Loss: 44.7332, Validation Accuracy: 0.6570\n",
            "Epoch 12/100, Loss: 51.9834, Validation Accuracy: 0.3978\n",
            "Epoch 13/100, Loss: 12.1068, Validation Accuracy: 0.6122\n",
            "Epoch 14/100, Loss: 35.6338, Validation Accuracy: 0.6520\n",
            "Epoch 15/100, Loss: 50.7752, Validation Accuracy: 0.5773\n",
            "Epoch 16/100, Loss: 48.4912, Validation Accuracy: 0.6730\n",
            "Epoch 17/100, Loss: 42.6897, Validation Accuracy: 0.6510\n",
            "Epoch 18/100, Loss: 73.7093, Validation Accuracy: 0.4616\n",
            "Epoch 19/100, Loss: 70.9843, Validation Accuracy: 0.6341\n",
            "Epoch 20/100, Loss: 32.4129, Validation Accuracy: 0.4875\n",
            "Epoch 21/100, Loss: 35.0827, Validation Accuracy: 0.6790\n",
            "Epoch 22/100, Loss: 64.8031, Validation Accuracy: 0.5344\n",
            "Epoch 23/100, Loss: 263.2820, Validation Accuracy: 0.4696\n",
            "Epoch 24/100, Loss: 79.2718, Validation Accuracy: 0.5783\n",
            "Epoch 25/100, Loss: 63.1430, Validation Accuracy: 0.5404\n",
            "Epoch 26/100, Loss: 109.8321, Validation Accuracy: 0.5174\n",
            "Epoch 27/100, Loss: 24.9432, Validation Accuracy: 0.6780\n",
            "Epoch 28/100, Loss: 70.7580, Validation Accuracy: 0.6201\n",
            "Epoch 29/100, Loss: 34.6669, Validation Accuracy: 0.6730\n",
            "Epoch 30/100, Loss: 48.0079, Validation Accuracy: 0.5494\n",
            "Epoch 31/100, Loss: 58.2629, Validation Accuracy: 0.5793\n",
            "Epoch 32/100, Loss: 24.7891, Validation Accuracy: 0.6401\n",
            "Epoch 33/100, Loss: 68.3392, Validation Accuracy: 0.6820\n",
            "Epoch 34/100, Loss: 13.6812, Validation Accuracy: 0.5783\n",
            "Epoch 35/100, Loss: 89.2817, Validation Accuracy: 0.6022\n",
            "Epoch 36/100, Loss: 37.1280, Validation Accuracy: 0.6650\n",
            "Epoch 37/100, Loss: 85.5713, Validation Accuracy: 0.5484\n",
            "Epoch 38/100, Loss: 83.1164, Validation Accuracy: 0.6271\n",
            "Epoch 39/100, Loss: 47.9785, Validation Accuracy: 0.5972\n",
            "Epoch 40/100, Loss: 64.6160, Validation Accuracy: 0.6540\n",
            "Epoch 41/100, Loss: 5.7821, Validation Accuracy: 0.6401\n",
            "Epoch 42/100, Loss: 60.5802, Validation Accuracy: 0.5304\n",
            "Epoch 43/100, Loss: 108.3246, Validation Accuracy: 0.6281\n",
            "Epoch 44/100, Loss: 64.3671, Validation Accuracy: 0.5234\n",
            "Epoch 45/100, Loss: 44.5388, Validation Accuracy: 0.6451\n",
            "Epoch 46/100, Loss: 29.3740, Validation Accuracy: 0.6500\n",
            "Epoch 47/100, Loss: 10.8963, Validation Accuracy: 0.7089\n",
            "Epoch 48/100, Loss: 37.4023, Validation Accuracy: 0.6790\n",
            "Epoch 49/100, Loss: 45.8234, Validation Accuracy: 0.5294\n",
            "Epoch 50/100, Loss: 67.7809, Validation Accuracy: 0.6211\n",
            "Epoch 51/100, Loss: 44.4620, Validation Accuracy: 0.6461\n",
            "Epoch 52/100, Loss: 66.1817, Validation Accuracy: 0.6371\n",
            "Epoch 53/100, Loss: 142.3974, Validation Accuracy: 0.6052\n",
            "Epoch 54/100, Loss: 17.8829, Validation Accuracy: 0.6999\n",
            "Epoch 55/100, Loss: 34.5251, Validation Accuracy: 0.5852\n",
            "Epoch 56/100, Loss: 35.5111, Validation Accuracy: 0.6830\n",
            "Epoch 57/100, Loss: 63.3095, Validation Accuracy: 0.5902\n",
            "Epoch 58/100, Loss: 42.6811, Validation Accuracy: 0.6590\n",
            "Epoch 59/100, Loss: 61.0386, Validation Accuracy: 0.6451\n",
            "Epoch 60/100, Loss: 117.2991, Validation Accuracy: 0.6820\n",
            "Epoch 61/100, Loss: 127.2505, Validation Accuracy: 0.6919\n",
            "Epoch 62/100, Loss: 56.7103, Validation Accuracy: 0.6162\n",
            "Epoch 63/100, Loss: 50.2012, Validation Accuracy: 0.5693\n",
            "Epoch 64/100, Loss: 37.9854, Validation Accuracy: 0.6421\n",
            "Epoch 65/100, Loss: 118.0568, Validation Accuracy: 0.5992\n",
            "Epoch 66/100, Loss: 24.9230, Validation Accuracy: 0.6650\n",
            "Epoch 67/100, Loss: 30.3577, Validation Accuracy: 0.6341\n",
            "Epoch 68/100, Loss: 37.2882, Validation Accuracy: 0.5653\n",
            "Epoch 69/100, Loss: 114.2353, Validation Accuracy: 0.6401\n",
            "Epoch 70/100, Loss: 101.4493, Validation Accuracy: 0.5793\n",
            "Epoch 71/100, Loss: 39.0331, Validation Accuracy: 0.6132\n",
            "Epoch 72/100, Loss: 28.7486, Validation Accuracy: 0.6092\n",
            "Epoch 73/100, Loss: 207.9749, Validation Accuracy: 0.6311\n",
            "Epoch 74/100, Loss: 33.6298, Validation Accuracy: 0.5813\n",
            "Epoch 75/100, Loss: 41.9714, Validation Accuracy: 0.5733\n",
            "Epoch 76/100, Loss: 33.1427, Validation Accuracy: 0.6421\n",
            "Epoch 77/100, Loss: 38.5342, Validation Accuracy: 0.6132\n",
            "Epoch 78/100, Loss: 157.8188, Validation Accuracy: 0.6869\n",
            "Epoch 79/100, Loss: 39.3220, Validation Accuracy: 0.6570\n",
            "Epoch 80/100, Loss: 77.5515, Validation Accuracy: 0.6830\n",
            "Epoch 81/100, Loss: 56.1570, Validation Accuracy: 0.6032\n",
            "Epoch 82/100, Loss: 96.0097, Validation Accuracy: 0.5852\n",
            "Epoch 83/100, Loss: 36.2996, Validation Accuracy: 0.6441\n",
            "Epoch 84/100, Loss: 31.1163, Validation Accuracy: 0.5723\n",
            "Epoch 85/100, Loss: 51.2715, Validation Accuracy: 0.5972\n",
            "Epoch 86/100, Loss: 39.7644, Validation Accuracy: 0.6530\n",
            "Epoch 87/100, Loss: 42.7662, Validation Accuracy: 0.6241\n",
            "Epoch 88/100, Loss: 35.4874, Validation Accuracy: 0.6899\n",
            "Epoch 89/100, Loss: 26.3027, Validation Accuracy: 0.6301\n",
            "Epoch 90/100, Loss: 23.8906, Validation Accuracy: 0.6959\n",
            "Epoch 91/100, Loss: 36.1795, Validation Accuracy: 0.6839\n",
            "Epoch 92/100, Loss: 80.5597, Validation Accuracy: 0.5394\n",
            "Epoch 93/100, Loss: 87.0642, Validation Accuracy: 0.5314\n",
            "Epoch 94/100, Loss: 46.9549, Validation Accuracy: 0.7029\n",
            "Epoch 95/100, Loss: 43.6580, Validation Accuracy: 0.6072\n",
            "Epoch 96/100, Loss: 27.2196, Validation Accuracy: 0.6171\n",
            "Epoch 97/100, Loss: 23.1283, Validation Accuracy: 0.6002\n",
            "Epoch 98/100, Loss: 55.2501, Validation Accuracy: 0.5234\n",
            "Epoch 99/100, Loss: 64.0508, Validation Accuracy: 0.6869\n",
            "Epoch 100/100, Loss: 54.8115, Validation Accuracy: 0.6929\n",
            "Epoch 101/100, Loss: 239.2476, Validation Accuracy: 0.7029\n",
            "Epoch 102/100, Loss: 48.4860, Validation Accuracy: 0.6072\n",
            "Epoch 103/100, Loss: 22.9492, Validation Accuracy: 0.5912\n",
            "Epoch 104/100, Loss: 29.5609, Validation Accuracy: 0.5563\n",
            "Epoch 105/100, Loss: 61.6183, Validation Accuracy: 0.3908\n",
            "Epoch 106/100, Loss: 69.7619, Validation Accuracy: 0.6002\n",
            "Epoch 107/100, Loss: 47.0244, Validation Accuracy: 0.6451\n",
            "Epoch 108/100, Loss: 44.5300, Validation Accuracy: 0.6142\n",
            "Epoch 109/100, Loss: 31.7809, Validation Accuracy: 0.6580\n",
            "Epoch 110/100, Loss: 27.7984, Validation Accuracy: 0.6830\n",
            "Epoch 111/100, Loss: 24.2387, Validation Accuracy: 0.6092\n",
            "Epoch 112/100, Loss: 23.8307, Validation Accuracy: 0.6142\n",
            "Epoch 113/100, Loss: 76.6049, Validation Accuracy: 0.6341\n",
            "Epoch 114/100, Loss: 152.0893, Validation Accuracy: 0.6680\n",
            "Epoch 115/100, Loss: 58.2476, Validation Accuracy: 0.5135\n",
            "Epoch 116/100, Loss: 79.1013, Validation Accuracy: 0.6919\n",
            "Epoch 117/100, Loss: 93.1063, Validation Accuracy: 0.6580\n",
            "Epoch 118/100, Loss: 66.2973, Validation Accuracy: 0.6879\n",
            "Epoch 119/100, Loss: 8.8950, Validation Accuracy: 0.6540\n",
            "Epoch 120/100, Loss: 52.4432, Validation Accuracy: 0.6720\n",
            "Epoch 121/100, Loss: 22.6902, Validation Accuracy: 0.6790\n",
            "Epoch 122/100, Loss: 38.2531, Validation Accuracy: 0.6640\n",
            "Epoch 123/100, Loss: 68.0231, Validation Accuracy: 0.6461\n",
            "Epoch 124/100, Loss: 35.9619, Validation Accuracy: 0.6859\n",
            "Epoch 125/100, Loss: 86.6585, Validation Accuracy: 0.6899\n",
            "Epoch 126/100, Loss: 132.0660, Validation Accuracy: 0.6570\n",
            "Epoch 127/100, Loss: 94.7758, Validation Accuracy: 0.6760\n",
            "Epoch 128/100, Loss: 47.2212, Validation Accuracy: 0.5773\n",
            "Epoch 129/100, Loss: 51.8325, Validation Accuracy: 0.6780\n",
            "Epoch 130/100, Loss: 42.3273, Validation Accuracy: 0.6162\n",
            "Epoch 131/100, Loss: 50.8317, Validation Accuracy: 0.6929\n",
            "Epoch 132/100, Loss: 88.4317, Validation Accuracy: 0.5962\n",
            "Epoch 133/100, Loss: 108.3565, Validation Accuracy: 0.6510\n",
            "Epoch 134/100, Loss: 44.7174, Validation Accuracy: 0.6740\n",
            "Epoch 135/100, Loss: 17.5838, Validation Accuracy: 0.6889\n",
            "Epoch 136/100, Loss: 171.6403, Validation Accuracy: 0.6301\n",
            "Epoch 137/100, Loss: 6.7944, Validation Accuracy: 0.6231\n",
            "Epoch 138/100, Loss: 58.5057, Validation Accuracy: 0.7039\n",
            "Epoch 139/100, Loss: 81.5965, Validation Accuracy: 0.6431\n",
            "Epoch 140/100, Loss: 50.4748, Validation Accuracy: 0.6171\n",
            "Epoch 141/100, Loss: 69.0860, Validation Accuracy: 0.6879\n",
            "Epoch 142/100, Loss: 64.0739, Validation Accuracy: 0.6830\n",
            "Epoch 143/100, Loss: 77.7081, Validation Accuracy: 0.6939\n",
            "Epoch 144/100, Loss: 58.1922, Validation Accuracy: 0.7009\n",
            "Epoch 145/100, Loss: 44.4289, Validation Accuracy: 0.5573\n",
            "Epoch 146/100, Loss: 70.9212, Validation Accuracy: 0.6311\n",
            "Epoch 147/100, Loss: 41.9875, Validation Accuracy: 0.6899\n",
            "Epoch 148/100, Loss: 143.6526, Validation Accuracy: 0.6979\n",
            "Epoch 149/100, Loss: 55.2375, Validation Accuracy: 0.6461\n",
            "Epoch 150/100, Loss: 153.2872, Validation Accuracy: 0.6012\n",
            "Epoch 151/100, Loss: 47.8588, Validation Accuracy: 0.6191\n",
            "Epoch 152/100, Loss: 72.0203, Validation Accuracy: 0.6062\n",
            "Epoch 153/100, Loss: 42.1113, Validation Accuracy: 0.6560\n",
            "Epoch 154/100, Loss: 51.7795, Validation Accuracy: 0.7009\n",
            "Epoch 155/100, Loss: 59.0787, Validation Accuracy: 0.6830\n",
            "Epoch 156/100, Loss: 64.9220, Validation Accuracy: 0.5803\n",
            "Epoch 157/100, Loss: 103.2168, Validation Accuracy: 0.6800\n",
            "Epoch 158/100, Loss: 44.2155, Validation Accuracy: 0.6909\n",
            "Epoch 159/100, Loss: 60.6329, Validation Accuracy: 0.6600\n",
            "Epoch 160/100, Loss: 34.9790, Validation Accuracy: 0.6062\n",
            "Epoch 161/100, Loss: 23.4663, Validation Accuracy: 0.5763\n",
            "Epoch 162/100, Loss: 87.0308, Validation Accuracy: 0.6500\n",
            "Epoch 163/100, Loss: 57.5333, Validation Accuracy: 0.6859\n",
            "Epoch 164/100, Loss: 119.3411, Validation Accuracy: 0.6500\n",
            "Epoch 165/100, Loss: 125.1836, Validation Accuracy: 0.6650\n",
            "Epoch 166/100, Loss: 80.4510, Validation Accuracy: 0.6670\n",
            "Epoch 167/100, Loss: 26.8143, Validation Accuracy: 0.6939\n",
            "Epoch 168/100, Loss: 48.3652, Validation Accuracy: 0.6969\n",
            "Epoch 169/100, Loss: 67.6815, Validation Accuracy: 0.6520\n",
            "Epoch 170/100, Loss: 74.4379, Validation Accuracy: 0.5583\n",
            "Epoch 171/100, Loss: 72.4990, Validation Accuracy: 0.7059\n",
            "Epoch 172/100, Loss: 92.4318, Validation Accuracy: 0.5972\n",
            "Epoch 173/100, Loss: 30.2129, Validation Accuracy: 0.6680\n",
            "Epoch 174/100, Loss: 77.3723, Validation Accuracy: 0.6849\n",
            "Epoch 175/100, Loss: 62.2431, Validation Accuracy: 0.6421\n",
            "Epoch 176/100, Loss: 51.6699, Validation Accuracy: 0.7039\n",
            "Epoch 177/100, Loss: 34.8319, Validation Accuracy: 0.6510\n",
            "Epoch 178/100, Loss: 42.8855, Validation Accuracy: 0.6879\n",
            "Epoch 179/100, Loss: 68.2802, Validation Accuracy: 0.6530\n",
            "Epoch 180/100, Loss: 55.0940, Validation Accuracy: 0.6530\n",
            "Epoch 181/100, Loss: 26.1872, Validation Accuracy: 0.6660\n",
            "Epoch 182/100, Loss: 57.2139, Validation Accuracy: 0.6650\n",
            "Epoch 183/100, Loss: 143.4003, Validation Accuracy: 0.6720\n",
            "Epoch 184/100, Loss: 45.1750, Validation Accuracy: 0.6191\n",
            "Epoch 185/100, Loss: 132.9124, Validation Accuracy: 0.5912\n",
            "Epoch 186/100, Loss: 72.3100, Validation Accuracy: 0.7009\n",
            "Epoch 187/100, Loss: 35.2926, Validation Accuracy: 0.6580\n",
            "Epoch 188/100, Loss: 32.6134, Validation Accuracy: 0.6879\n",
            "Epoch 189/100, Loss: 63.1065, Validation Accuracy: 0.6461\n",
            "Epoch 190/100, Loss: 84.9995, Validation Accuracy: 0.6640\n",
            "Epoch 191/100, Loss: 34.5657, Validation Accuracy: 0.6979\n",
            "Epoch 192/100, Loss: 89.5659, Validation Accuracy: 0.6869\n",
            "Epoch 193/100, Loss: 51.0516, Validation Accuracy: 0.6879\n",
            "Epoch 194/100, Loss: 103.4370, Validation Accuracy: 0.6461\n",
            "Epoch 195/100, Loss: 75.4704, Validation Accuracy: 0.5892\n",
            "Epoch 196/100, Loss: 13.3177, Validation Accuracy: 0.6610\n",
            "Epoch 197/100, Loss: 29.0670, Validation Accuracy: 0.6221\n",
            "Epoch 198/100, Loss: 127.2107, Validation Accuracy: 0.6181\n",
            "Epoch 199/100, Loss: 55.5186, Validation Accuracy: 0.6102\n",
            "Epoch 200/100, Loss: 91.7727, Validation Accuracy: 0.6231\n",
            "Reward for Child Model: 0.2888269978917027\n",
            "Child_42:  {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, [1, 2, 3, 0, 2, 2, 3, 1, 3, 1, 3, 1, 3, 3, 3], 0.2888269978917027\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 24, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(72, 64, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(136, 64, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(320, 36, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=330624, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 28, 24]             768\n",
            "       BatchNorm2d-2           [-1, 48, 28, 24]              96\n",
            "            Conv2d-3           [-1, 24, 28, 20]           5,784\n",
            "       BatchNorm2d-4           [-1, 24, 28, 20]              48\n",
            "              ReLU-5           [-1, 24, 28, 20]               0\n",
            "            Conv2d-6           [-1, 64, 26, 18]          96,832\n",
            "       BatchNorm2d-7           [-1, 64, 26, 18]             128\n",
            "              ReLU-8           [-1, 64, 26, 18]               0\n",
            "            Conv2d-9           [-1, 64, 24, 18]         304,704\n",
            "      BatchNorm2d-10           [-1, 64, 24, 18]             128\n",
            "             ReLU-11           [-1, 64, 24, 18]               0\n",
            "           Conv2d-12           [-1, 36, 26, 18]         241,956\n",
            "      BatchNorm2d-13           [-1, 36, 26, 18]              72\n",
            "             ReLU-14           [-1, 36, 26, 18]               0\n",
            "           Linear-15                    [-1, 7]       2,314,375\n",
            "================================================================\n",
            "Total params: 2,964,891\n",
            "Trainable params: 2,964,891\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.50\n",
            "Params size (MB): 11.31\n",
            "Estimated Total Size (MB): 13.82\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 62.7192, Validation Accuracy: 0.4357\n",
            "Epoch 2/100, Loss: 18.5313, Validation Accuracy: 0.4058\n",
            "Epoch 3/100, Loss: 39.2569, Validation Accuracy: 0.6391\n",
            "Epoch 4/100, Loss: 225.1946, Validation Accuracy: 0.5902\n",
            "Epoch 5/100, Loss: 112.6235, Validation Accuracy: 0.6102\n",
            "Epoch 6/100, Loss: 128.0631, Validation Accuracy: 0.3938\n",
            "Epoch 7/100, Loss: 102.9816, Validation Accuracy: 0.6022\n",
            "Epoch 8/100, Loss: 93.2355, Validation Accuracy: 0.5723\n",
            "Epoch 9/100, Loss: 200.8074, Validation Accuracy: 0.6331\n",
            "Epoch 10/100, Loss: 200.2437, Validation Accuracy: 0.6271\n",
            "Epoch 11/100, Loss: 114.3142, Validation Accuracy: 0.4267\n",
            "Epoch 12/100, Loss: 57.8412, Validation Accuracy: 0.6730\n",
            "Epoch 13/100, Loss: 87.7863, Validation Accuracy: 0.6580\n",
            "Epoch 14/100, Loss: 53.7975, Validation Accuracy: 0.5513\n",
            "Epoch 15/100, Loss: 102.6349, Validation Accuracy: 0.4925\n",
            "Epoch 16/100, Loss: 148.3106, Validation Accuracy: 0.6780\n",
            "Epoch 17/100, Loss: 110.5810, Validation Accuracy: 0.6082\n",
            "Epoch 18/100, Loss: 451.0223, Validation Accuracy: 0.5354\n",
            "Epoch 19/100, Loss: 174.0644, Validation Accuracy: 0.4915\n",
            "Epoch 20/100, Loss: 152.0922, Validation Accuracy: 0.6351\n",
            "Epoch 21/100, Loss: 188.2603, Validation Accuracy: 0.6102\n",
            "Epoch 22/100, Loss: 57.9039, Validation Accuracy: 0.6500\n",
            "Epoch 23/100, Loss: 82.7520, Validation Accuracy: 0.4497\n",
            "Epoch 24/100, Loss: 173.9181, Validation Accuracy: 0.6321\n",
            "Epoch 25/100, Loss: 85.1308, Validation Accuracy: 0.6052\n",
            "Epoch 26/100, Loss: 586.4694, Validation Accuracy: 0.5693\n",
            "Epoch 27/100, Loss: 146.8437, Validation Accuracy: 0.5474\n",
            "Epoch 28/100, Loss: 95.4524, Validation Accuracy: 0.6092\n",
            "Epoch 29/100, Loss: 233.4614, Validation Accuracy: 0.6540\n",
            "Epoch 30/100, Loss: 165.6497, Validation Accuracy: 0.4447\n",
            "Epoch 31/100, Loss: 266.6572, Validation Accuracy: 0.5075\n",
            "Epoch 32/100, Loss: 97.9644, Validation Accuracy: 0.6830\n",
            "Epoch 33/100, Loss: 58.0538, Validation Accuracy: 0.6401\n",
            "Epoch 34/100, Loss: 122.0655, Validation Accuracy: 0.6700\n",
            "Epoch 35/100, Loss: 128.4955, Validation Accuracy: 0.6341\n",
            "Epoch 36/100, Loss: 82.7736, Validation Accuracy: 0.6560\n",
            "Epoch 37/100, Loss: 163.5723, Validation Accuracy: 0.6361\n",
            "Epoch 38/100, Loss: 185.8642, Validation Accuracy: 0.6371\n",
            "Epoch 39/100, Loss: 150.5677, Validation Accuracy: 0.4417\n",
            "Epoch 40/100, Loss: 192.7012, Validation Accuracy: 0.6391\n",
            "Epoch 41/100, Loss: 107.8452, Validation Accuracy: 0.6600\n",
            "Epoch 42/100, Loss: 227.2329, Validation Accuracy: 0.5294\n",
            "Epoch 43/100, Loss: 338.4121, Validation Accuracy: 0.6481\n",
            "Epoch 44/100, Loss: 182.3992, Validation Accuracy: 0.6291\n",
            "Epoch 45/100, Loss: 184.9657, Validation Accuracy: 0.6630\n",
            "Epoch 46/100, Loss: 416.6489, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 792.4062, Validation Accuracy: 0.3400\n",
            "Epoch 48/100, Loss: 59.1300, Validation Accuracy: 0.5573\n",
            "Epoch 49/100, Loss: 142.8506, Validation Accuracy: 0.5165\n",
            "Epoch 50/100, Loss: 94.9115, Validation Accuracy: 0.6301\n",
            "Epoch 51/100, Loss: 61.1786, Validation Accuracy: 0.5932\n",
            "Epoch 52/100, Loss: 182.8507, Validation Accuracy: 0.5553\n",
            "Epoch 53/100, Loss: 311.0682, Validation Accuracy: 0.6251\n",
            "Epoch 54/100, Loss: 136.9524, Validation Accuracy: 0.5773\n",
            "Epoch 55/100, Loss: 467.4124, Validation Accuracy: 0.5603\n",
            "Epoch 56/100, Loss: 440.9421, Validation Accuracy: 0.6251\n",
            "Epoch 57/100, Loss: 108.8631, Validation Accuracy: 0.5932\n",
            "Epoch 58/100, Loss: 152.2779, Validation Accuracy: 0.5434\n",
            "Epoch 59/100, Loss: 348.0486, Validation Accuracy: 0.5862\n",
            "Epoch 60/100, Loss: 77.5241, Validation Accuracy: 0.5992\n",
            "Epoch 61/100, Loss: 272.5236, Validation Accuracy: 0.6660\n",
            "Epoch 62/100, Loss: 117.6141, Validation Accuracy: 0.6022\n",
            "Epoch 63/100, Loss: 151.3089, Validation Accuracy: 0.6680\n",
            "Epoch 64/100, Loss: 333.3862, Validation Accuracy: 0.5793\n",
            "Epoch 65/100, Loss: 180.9081, Validation Accuracy: 0.4925\n",
            "Epoch 66/100, Loss: 205.0965, Validation Accuracy: 0.6750\n",
            "Epoch 67/100, Loss: 274.5704, Validation Accuracy: 0.6540\n",
            "Epoch 68/100, Loss: 223.8542, Validation Accuracy: 0.5823\n",
            "Epoch 69/100, Loss: 254.5540, Validation Accuracy: 0.6171\n",
            "Epoch 70/100, Loss: 188.3690, Validation Accuracy: 0.6481\n",
            "Epoch 71/100, Loss: 179.4884, Validation Accuracy: 0.6500\n",
            "Epoch 72/100, Loss: 173.9472, Validation Accuracy: 0.6610\n",
            "Epoch 73/100, Loss: 239.1152, Validation Accuracy: 0.6800\n",
            "Epoch 74/100, Loss: 86.3918, Validation Accuracy: 0.5753\n",
            "Epoch 75/100, Loss: 238.3687, Validation Accuracy: 0.5992\n",
            "Epoch 76/100, Loss: 235.8931, Validation Accuracy: 0.5823\n",
            "Epoch 77/100, Loss: 204.2098, Validation Accuracy: 0.6700\n",
            "Epoch 78/100, Loss: 251.2223, Validation Accuracy: 0.6421\n",
            "Epoch 79/100, Loss: 212.7058, Validation Accuracy: 0.4806\n",
            "Epoch 80/100, Loss: 58.2339, Validation Accuracy: 0.5733\n",
            "Epoch 81/100, Loss: 169.4278, Validation Accuracy: 0.4497\n",
            "Epoch 82/100, Loss: 299.6989, Validation Accuracy: 0.5583\n",
            "Epoch 83/100, Loss: 96.1650, Validation Accuracy: 0.6311\n",
            "Epoch 84/100, Loss: 159.1222, Validation Accuracy: 0.5763\n",
            "Epoch 85/100, Loss: 64.3142, Validation Accuracy: 0.5444\n",
            "Epoch 86/100, Loss: 183.7823, Validation Accuracy: 0.6221\n",
            "Epoch 87/100, Loss: 199.2023, Validation Accuracy: 0.6201\n",
            "Epoch 88/100, Loss: 380.8358, Validation Accuracy: 0.4217\n",
            "Epoch 89/100, Loss: 137.1499, Validation Accuracy: 0.5743\n",
            "Epoch 90/100, Loss: 173.4328, Validation Accuracy: 0.5005\n",
            "Epoch 91/100, Loss: 129.1920, Validation Accuracy: 0.6032\n",
            "Epoch 92/100, Loss: 148.9984, Validation Accuracy: 0.6570\n",
            "Epoch 93/100, Loss: 222.4560, Validation Accuracy: 0.6471\n",
            "Epoch 94/100, Loss: 247.7936, Validation Accuracy: 0.6082\n",
            "Epoch 95/100, Loss: 621.8979, Validation Accuracy: 0.6022\n",
            "Epoch 96/100, Loss: 64.3245, Validation Accuracy: 0.6550\n",
            "Epoch 97/100, Loss: 204.3991, Validation Accuracy: 0.5324\n",
            "Epoch 98/100, Loss: 167.8441, Validation Accuracy: 0.6152\n",
            "Epoch 99/100, Loss: 433.1975, Validation Accuracy: 0.4317\n",
            "Epoch 100/100, Loss: 150.4071, Validation Accuracy: 0.6650\n",
            "Epoch 101/100, Loss: 350.1096, Validation Accuracy: 0.5653\n",
            "Epoch 102/100, Loss: 67.5326, Validation Accuracy: 0.6022\n",
            "Epoch 103/100, Loss: 120.3623, Validation Accuracy: 0.5613\n",
            "Epoch 104/100, Loss: 143.3581, Validation Accuracy: 0.6191\n",
            "Epoch 105/100, Loss: 361.5370, Validation Accuracy: 0.6132\n",
            "Epoch 106/100, Loss: 36.6546, Validation Accuracy: 0.6331\n",
            "Epoch 107/100, Loss: 115.0064, Validation Accuracy: 0.6152\n",
            "Epoch 108/100, Loss: 129.9846, Validation Accuracy: 0.5284\n",
            "Epoch 109/100, Loss: 161.9719, Validation Accuracy: 0.5125\n",
            "Epoch 110/100, Loss: 221.5579, Validation Accuracy: 0.6421\n",
            "Epoch 111/100, Loss: 332.3953, Validation Accuracy: 0.6162\n",
            "Epoch 112/100, Loss: 146.9803, Validation Accuracy: 0.6720\n",
            "Epoch 113/100, Loss: 167.7310, Validation Accuracy: 0.5523\n",
            "Epoch 114/100, Loss: 124.9992, Validation Accuracy: 0.5992\n",
            "Epoch 115/100, Loss: 125.7319, Validation Accuracy: 0.6201\n",
            "Epoch 116/100, Loss: 99.4586, Validation Accuracy: 0.5952\n",
            "Epoch 117/100, Loss: 229.6436, Validation Accuracy: 0.5892\n",
            "Epoch 118/100, Loss: 124.0634, Validation Accuracy: 0.5793\n",
            "Epoch 119/100, Loss: 140.5526, Validation Accuracy: 0.5005\n",
            "Epoch 120/100, Loss: 129.6792, Validation Accuracy: 0.5045\n",
            "Epoch 121/100, Loss: 123.9066, Validation Accuracy: 0.5454\n",
            "Epoch 122/100, Loss: 74.1103, Validation Accuracy: 0.5713\n",
            "Epoch 123/100, Loss: 192.1967, Validation Accuracy: 0.6201\n",
            "Epoch 124/100, Loss: 254.3898, Validation Accuracy: 0.6820\n",
            "Epoch 125/100, Loss: 401.2534, Validation Accuracy: 0.6062\n",
            "Epoch 126/100, Loss: 208.4230, Validation Accuracy: 0.4786\n",
            "Epoch 127/100, Loss: 478.2898, Validation Accuracy: 0.5743\n",
            "Epoch 128/100, Loss: 90.8606, Validation Accuracy: 0.5713\n",
            "Epoch 129/100, Loss: 70.4247, Validation Accuracy: 0.5972\n",
            "Epoch 130/100, Loss: 199.0704, Validation Accuracy: 0.6102\n",
            "Epoch 131/100, Loss: 318.2549, Validation Accuracy: 0.6520\n",
            "Epoch 132/100, Loss: 69.1750, Validation Accuracy: 0.6590\n",
            "Epoch 133/100, Loss: 152.4819, Validation Accuracy: 0.5643\n",
            "Epoch 134/100, Loss: 137.2679, Validation Accuracy: 0.6142\n",
            "Epoch 135/100, Loss: 120.4234, Validation Accuracy: 0.5733\n",
            "Epoch 136/100, Loss: 63.7825, Validation Accuracy: 0.6371\n",
            "Epoch 137/100, Loss: 213.8691, Validation Accuracy: 0.5842\n",
            "Epoch 138/100, Loss: 256.3866, Validation Accuracy: 0.4835\n",
            "Epoch 139/100, Loss: 301.8803, Validation Accuracy: 0.4806\n",
            "Epoch 140/100, Loss: 469.9651, Validation Accuracy: 0.6580\n",
            "Epoch 141/100, Loss: 54.0908, Validation Accuracy: 0.6720\n",
            "Epoch 142/100, Loss: 184.6463, Validation Accuracy: 0.6002\n",
            "Epoch 143/100, Loss: 97.8001, Validation Accuracy: 0.3978\n",
            "Epoch 144/100, Loss: 296.2666, Validation Accuracy: 0.5583\n",
            "Epoch 145/100, Loss: 261.0698, Validation Accuracy: 0.6590\n",
            "Epoch 146/100, Loss: 533.7823, Validation Accuracy: 0.5783\n",
            "Epoch 147/100, Loss: 223.7236, Validation Accuracy: 0.6859\n",
            "Epoch 148/100, Loss: 86.2371, Validation Accuracy: 0.4816\n",
            "Epoch 149/100, Loss: 98.6469, Validation Accuracy: 0.6132\n",
            "Epoch 150/100, Loss: 59.7098, Validation Accuracy: 0.6481\n",
            "Epoch 151/100, Loss: 589.3049, Validation Accuracy: 0.5693\n",
            "Epoch 152/100, Loss: 109.9765, Validation Accuracy: 0.6301\n",
            "Epoch 153/100, Loss: 99.3086, Validation Accuracy: 0.6810\n",
            "Epoch 154/100, Loss: 92.0415, Validation Accuracy: 0.6311\n",
            "Epoch 155/100, Loss: 138.7912, Validation Accuracy: 0.3749\n",
            "Epoch 156/100, Loss: 707.0699, Validation Accuracy: 0.5882\n",
            "Epoch 157/100, Loss: 189.8403, Validation Accuracy: 0.6142\n",
            "Epoch 158/100, Loss: 78.7956, Validation Accuracy: 0.6221\n",
            "Epoch 159/100, Loss: 155.5089, Validation Accuracy: 0.6191\n",
            "Epoch 160/100, Loss: 125.5087, Validation Accuracy: 0.5394\n",
            "Epoch 161/100, Loss: 113.0882, Validation Accuracy: 0.6540\n",
            "Epoch 162/100, Loss: 445.2624, Validation Accuracy: 0.6301\n",
            "Epoch 163/100, Loss: 200.0561, Validation Accuracy: 0.5992\n",
            "Epoch 164/100, Loss: 168.6296, Validation Accuracy: 0.6381\n",
            "Epoch 165/100, Loss: 315.2949, Validation Accuracy: 0.6351\n",
            "Epoch 166/100, Loss: 65.5546, Validation Accuracy: 0.5623\n",
            "Epoch 167/100, Loss: 212.9786, Validation Accuracy: 0.4606\n",
            "Epoch 168/100, Loss: 169.1980, Validation Accuracy: 0.6740\n",
            "Epoch 169/100, Loss: 71.9965, Validation Accuracy: 0.6451\n",
            "Epoch 170/100, Loss: 121.8825, Validation Accuracy: 0.5813\n",
            "Epoch 171/100, Loss: 102.6067, Validation Accuracy: 0.6481\n",
            "Epoch 172/100, Loss: 185.4731, Validation Accuracy: 0.6181\n",
            "Epoch 173/100, Loss: 222.3676, Validation Accuracy: 0.4217\n",
            "Epoch 174/100, Loss: 467.2345, Validation Accuracy: 0.6201\n",
            "Epoch 175/100, Loss: 261.8359, Validation Accuracy: 0.6032\n",
            "Epoch 176/100, Loss: 154.2051, Validation Accuracy: 0.6351\n",
            "Epoch 177/100, Loss: 131.4886, Validation Accuracy: 0.6491\n",
            "Epoch 178/100, Loss: 74.7471, Validation Accuracy: 0.6072\n",
            "Epoch 179/100, Loss: 478.8483, Validation Accuracy: 0.6102\n",
            "Epoch 180/100, Loss: 255.5611, Validation Accuracy: 0.5563\n",
            "Epoch 181/100, Loss: 154.7592, Validation Accuracy: 0.6271\n",
            "Epoch 182/100, Loss: 109.1081, Validation Accuracy: 0.4826\n",
            "Epoch 183/100, Loss: 82.7069, Validation Accuracy: 0.5533\n",
            "Epoch 184/100, Loss: 177.7101, Validation Accuracy: 0.6580\n",
            "Epoch 185/100, Loss: 237.2486, Validation Accuracy: 0.6321\n",
            "Epoch 186/100, Loss: 126.0550, Validation Accuracy: 0.5583\n",
            "Epoch 187/100, Loss: 30.3144, Validation Accuracy: 0.6461\n",
            "Epoch 188/100, Loss: 154.5690, Validation Accuracy: 0.5194\n",
            "Epoch 189/100, Loss: 139.4805, Validation Accuracy: 0.6271\n",
            "Epoch 190/100, Loss: 158.4404, Validation Accuracy: 0.5823\n",
            "Epoch 191/100, Loss: 153.2616, Validation Accuracy: 0.5484\n",
            "Epoch 192/100, Loss: 169.7673, Validation Accuracy: 0.6321\n",
            "Epoch 193/100, Loss: 235.5900, Validation Accuracy: 0.6251\n",
            "Epoch 194/100, Loss: 206.2202, Validation Accuracy: 0.6670\n",
            "Epoch 195/100, Loss: 112.5314, Validation Accuracy: 0.5972\n",
            "Epoch 196/100, Loss: 157.4507, Validation Accuracy: 0.5354\n",
            "Epoch 197/100, Loss: 250.7747, Validation Accuracy: 0.3589\n",
            "Epoch 198/100, Loss: 63.5430, Validation Accuracy: 0.6201\n",
            "Epoch 199/100, Loss: 111.7213, Validation Accuracy: 0.6670\n",
            "Epoch 200/100, Loss: 188.4355, Validation Accuracy: 0.5573\n",
            "Reward for Child Model: 0.2967396323270139\n",
            "Child_43:  {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, [0, 2, 2, 0, 2, 0, 1, 3, 3, 2, 3, 3, 1, 3, 1], 0.2967396323270139\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 64, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(112, 24, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(232, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=197472, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 22, 22]           7,104\n",
            "       BatchNorm2d-2           [-1, 48, 22, 22]              96\n",
            "            Conv2d-3           [-1, 48, 22, 22]           2,352\n",
            "       BatchNorm2d-4           [-1, 48, 22, 22]              96\n",
            "              ReLU-5           [-1, 48, 22, 22]               0\n",
            "            Conv2d-6           [-1, 64, 20, 18]          46,144\n",
            "       BatchNorm2d-7           [-1, 64, 20, 18]             128\n",
            "              ReLU-8           [-1, 64, 20, 18]               0\n",
            "            Conv2d-9           [-1, 24, 22, 18]          13,464\n",
            "      BatchNorm2d-10           [-1, 24, 22, 18]              48\n",
            "             ReLU-11           [-1, 24, 22, 18]               0\n",
            "           Conv2d-12           [-1, 64, 20, 20]         133,696\n",
            "      BatchNorm2d-13           [-1, 64, 20, 20]             128\n",
            "             ReLU-14           [-1, 64, 20, 20]               0\n",
            "           Linear-15                    [-1, 7]       1,382,311\n",
            "================================================================\n",
            "Total params: 1,585,567\n",
            "Trainable params: 1,585,567\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.22\n",
            "Params size (MB): 6.05\n",
            "Estimated Total Size (MB): 8.27\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 19.2820, Validation Accuracy: 0.5025\n",
            "Epoch 2/100, Loss: 161.5888, Validation Accuracy: 0.5603\n",
            "Epoch 3/100, Loss: 5.6160, Validation Accuracy: 0.5673\n",
            "Epoch 4/100, Loss: 28.5764, Validation Accuracy: 0.4875\n",
            "Epoch 5/100, Loss: 13.3015, Validation Accuracy: 0.6072\n",
            "Epoch 6/100, Loss: 62.1542, Validation Accuracy: 0.5733\n",
            "Epoch 7/100, Loss: 72.7745, Validation Accuracy: 0.6062\n",
            "Epoch 8/100, Loss: 141.7707, Validation Accuracy: 0.6241\n",
            "Epoch 9/100, Loss: 945.3185, Validation Accuracy: 0.6341\n",
            "Epoch 10/100, Loss: 124.0417, Validation Accuracy: 0.6640\n",
            "Epoch 11/100, Loss: 25.4744, Validation Accuracy: 0.6211\n",
            "Epoch 12/100, Loss: 55.7898, Validation Accuracy: 0.6132\n",
            "Epoch 13/100, Loss: 12.9554, Validation Accuracy: 0.6062\n",
            "Epoch 14/100, Loss: 27.7436, Validation Accuracy: 0.5464\n",
            "Epoch 15/100, Loss: 116.1905, Validation Accuracy: 0.4985\n",
            "Epoch 16/100, Loss: 10.1642, Validation Accuracy: 0.6421\n",
            "Epoch 17/100, Loss: 5.1448, Validation Accuracy: 0.5503\n",
            "Epoch 18/100, Loss: 889.1805, Validation Accuracy: 0.6550\n",
            "Epoch 19/100, Loss: 165.2498, Validation Accuracy: 0.5683\n",
            "Epoch 20/100, Loss: 73.8945, Validation Accuracy: 0.6431\n",
            "Epoch 21/100, Loss: 18.9851, Validation Accuracy: 0.5503\n",
            "Epoch 22/100, Loss: 8.7701, Validation Accuracy: 0.5862\n",
            "Epoch 23/100, Loss: 29.4401, Validation Accuracy: 0.6291\n",
            "Epoch 24/100, Loss: 30.9061, Validation Accuracy: 0.4885\n",
            "Epoch 25/100, Loss: 10.5797, Validation Accuracy: 0.6291\n",
            "Epoch 26/100, Loss: 5.4383, Validation Accuracy: 0.5773\n",
            "Epoch 27/100, Loss: 6.7041, Validation Accuracy: 0.6221\n",
            "Epoch 28/100, Loss: 487.7085, Validation Accuracy: 0.6012\n",
            "Epoch 29/100, Loss: 34.8792, Validation Accuracy: 0.5723\n",
            "Epoch 30/100, Loss: 4.1154, Validation Accuracy: 0.4716\n",
            "Epoch 31/100, Loss: 7.1507, Validation Accuracy: 0.6321\n",
            "Epoch 32/100, Loss: 3.8760, Validation Accuracy: 0.5743\n",
            "Epoch 33/100, Loss: 3.5457, Validation Accuracy: 0.5803\n",
            "Epoch 34/100, Loss: 6.5648, Validation Accuracy: 0.4347\n",
            "Epoch 35/100, Loss: 6.5179, Validation Accuracy: 0.5932\n",
            "Epoch 36/100, Loss: 3.7726, Validation Accuracy: 0.6730\n",
            "Epoch 37/100, Loss: 5.8074, Validation Accuracy: 0.6600\n",
            "Epoch 38/100, Loss: 3.3794, Validation Accuracy: 0.5852\n",
            "Epoch 39/100, Loss: 3142.4294, Validation Accuracy: 0.3948\n",
            "Epoch 40/100, Loss: 413.9169, Validation Accuracy: 0.6112\n",
            "Epoch 41/100, Loss: 116.5754, Validation Accuracy: 0.5045\n",
            "Epoch 42/100, Loss: 47.3486, Validation Accuracy: 0.6520\n",
            "Epoch 43/100, Loss: 74.2954, Validation Accuracy: 0.6271\n",
            "Epoch 44/100, Loss: 185.7843, Validation Accuracy: 0.6221\n",
            "Epoch 45/100, Loss: 84.7549, Validation Accuracy: 0.5135\n",
            "Epoch 46/100, Loss: 63.5357, Validation Accuracy: 0.6162\n",
            "Epoch 47/100, Loss: 23.9547, Validation Accuracy: 0.6082\n",
            "Epoch 48/100, Loss: 27.1016, Validation Accuracy: 0.6680\n",
            "Epoch 49/100, Loss: 38.4005, Validation Accuracy: 0.6171\n",
            "Epoch 50/100, Loss: 15.6823, Validation Accuracy: 0.6062\n",
            "Epoch 51/100, Loss: 8.8580, Validation Accuracy: 0.6710\n",
            "Epoch 52/100, Loss: 22.7078, Validation Accuracy: 0.6451\n",
            "Epoch 53/100, Loss: 6.0638, Validation Accuracy: 0.5543\n",
            "Epoch 54/100, Loss: 16.5175, Validation Accuracy: 0.6171\n",
            "Epoch 55/100, Loss: 10.9608, Validation Accuracy: 0.6181\n",
            "Epoch 56/100, Loss: 4.6629, Validation Accuracy: 0.5135\n",
            "Epoch 57/100, Loss: 4.2030, Validation Accuracy: 0.5533\n",
            "Epoch 58/100, Loss: 18.4331, Validation Accuracy: 0.5125\n",
            "Epoch 59/100, Loss: 21.5556, Validation Accuracy: 0.5095\n",
            "Epoch 60/100, Loss: 110.3288, Validation Accuracy: 0.3220\n",
            "Epoch 61/100, Loss: 7.3754, Validation Accuracy: 0.5424\n",
            "Epoch 62/100, Loss: 22.1260, Validation Accuracy: 0.6381\n",
            "Epoch 63/100, Loss: 420.7648, Validation Accuracy: 0.6052\n",
            "Epoch 64/100, Loss: 121.8869, Validation Accuracy: 0.6241\n",
            "Epoch 65/100, Loss: 13.6817, Validation Accuracy: 0.5703\n",
            "Epoch 66/100, Loss: 17.4940, Validation Accuracy: 0.5982\n",
            "Epoch 67/100, Loss: 3.3382, Validation Accuracy: 0.6351\n",
            "Epoch 68/100, Loss: 17.2502, Validation Accuracy: 0.4915\n",
            "Epoch 69/100, Loss: 1754.7686, Validation Accuracy: 0.6381\n",
            "Epoch 70/100, Loss: 11.4793, Validation Accuracy: 0.5274\n",
            "Epoch 71/100, Loss: 3.3958, Validation Accuracy: 0.6411\n",
            "Epoch 72/100, Loss: 6.7165, Validation Accuracy: 0.6221\n",
            "Epoch 73/100, Loss: 71.4835, Validation Accuracy: 0.6261\n",
            "Epoch 74/100, Loss: 11.5132, Validation Accuracy: 0.6082\n",
            "Epoch 75/100, Loss: 7.7842, Validation Accuracy: 0.4497\n",
            "Epoch 76/100, Loss: 6.9094, Validation Accuracy: 0.5992\n",
            "Epoch 77/100, Loss: 4.7578, Validation Accuracy: 0.6401\n",
            "Epoch 78/100, Loss: 7.2102, Validation Accuracy: 0.6750\n",
            "Epoch 79/100, Loss: 3.6769, Validation Accuracy: 0.5653\n",
            "Epoch 80/100, Loss: 7.0647, Validation Accuracy: 0.5942\n",
            "Epoch 81/100, Loss: 7.8554, Validation Accuracy: 0.6590\n",
            "Epoch 82/100, Loss: 58.1252, Validation Accuracy: 0.5773\n",
            "Epoch 83/100, Loss: 6.1263, Validation Accuracy: 0.5653\n",
            "Epoch 84/100, Loss: 18.0031, Validation Accuracy: 0.4377\n",
            "Epoch 85/100, Loss: 7.5607, Validation Accuracy: 0.6271\n",
            "Epoch 86/100, Loss: 2.8493, Validation Accuracy: 0.5703\n",
            "Epoch 87/100, Loss: 47.2903, Validation Accuracy: 0.6849\n",
            "Epoch 88/100, Loss: 17.4357, Validation Accuracy: 0.6491\n",
            "Epoch 89/100, Loss: 20.0563, Validation Accuracy: 0.6491\n",
            "Epoch 90/100, Loss: 9.8788, Validation Accuracy: 0.6431\n",
            "Epoch 91/100, Loss: 10.5368, Validation Accuracy: 0.4088\n",
            "Epoch 92/100, Loss: 18.6250, Validation Accuracy: 0.4885\n",
            "Epoch 93/100, Loss: 29.3204, Validation Accuracy: 0.6351\n",
            "Epoch 94/100, Loss: 388.7784, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 19.3051, Validation Accuracy: 0.5543\n",
            "Epoch 96/100, Loss: 69.4311, Validation Accuracy: 0.5882\n",
            "Epoch 97/100, Loss: 52.8315, Validation Accuracy: 0.4736\n",
            "Epoch 98/100, Loss: 34.2648, Validation Accuracy: 0.6640\n",
            "Epoch 99/100, Loss: 11.9097, Validation Accuracy: 0.5374\n",
            "Epoch 100/100, Loss: 19.2494, Validation Accuracy: 0.5803\n",
            "Epoch 101/100, Loss: 16.4361, Validation Accuracy: 0.5025\n",
            "Epoch 102/100, Loss: 6.3814, Validation Accuracy: 0.6042\n",
            "Epoch 103/100, Loss: 22.0615, Validation Accuracy: 0.5743\n",
            "Epoch 104/100, Loss: 3.5289, Validation Accuracy: 0.4826\n",
            "Epoch 105/100, Loss: 15.3757, Validation Accuracy: 0.5454\n",
            "Epoch 106/100, Loss: 7.2411, Validation Accuracy: 0.6311\n",
            "Epoch 107/100, Loss: 16.0913, Validation Accuracy: 0.4566\n",
            "Epoch 108/100, Loss: 10.3976, Validation Accuracy: 0.4536\n",
            "Epoch 109/100, Loss: 6.3873, Validation Accuracy: 0.6351\n",
            "Epoch 110/100, Loss: 12.1637, Validation Accuracy: 0.4307\n",
            "Epoch 111/100, Loss: 31.9193, Validation Accuracy: 0.6042\n",
            "Epoch 112/100, Loss: 22.2580, Validation Accuracy: 0.6640\n",
            "Epoch 113/100, Loss: 43.6964, Validation Accuracy: 0.1406\n",
            "Epoch 114/100, Loss: 25.1898, Validation Accuracy: 0.3061\n",
            "Epoch 115/100, Loss: 9.7998, Validation Accuracy: 0.4257\n",
            "Epoch 116/100, Loss: 11.1646, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 64.7577, Validation Accuracy: 0.4786\n",
            "Epoch 118/100, Loss: 158.4355, Validation Accuracy: 0.6301\n",
            "Epoch 119/100, Loss: 13.4669, Validation Accuracy: 0.6630\n",
            "Epoch 120/100, Loss: 22.7984, Validation Accuracy: 0.3838\n",
            "Epoch 121/100, Loss: 15.9176, Validation Accuracy: 0.5095\n",
            "Epoch 122/100, Loss: 30.2021, Validation Accuracy: 0.5464\n",
            "Epoch 123/100, Loss: 202.7044, Validation Accuracy: 0.4596\n",
            "Epoch 124/100, Loss: 17.8766, Validation Accuracy: 0.6042\n",
            "Epoch 125/100, Loss: 20.2640, Validation Accuracy: 0.5105\n",
            "Epoch 126/100, Loss: 17.5511, Validation Accuracy: 0.5992\n",
            "Epoch 127/100, Loss: 41.1476, Validation Accuracy: 0.6321\n",
            "Epoch 128/100, Loss: 601.8732, Validation Accuracy: 0.6171\n",
            "Epoch 129/100, Loss: 1273.5554, Validation Accuracy: 0.6142\n",
            "Epoch 130/100, Loss: 284.5050, Validation Accuracy: 0.5952\n",
            "Epoch 131/100, Loss: 242.7404, Validation Accuracy: 0.6052\n",
            "Epoch 132/100, Loss: 136.3506, Validation Accuracy: 0.6042\n",
            "Epoch 133/100, Loss: 123.6026, Validation Accuracy: 0.6092\n",
            "Epoch 134/100, Loss: 67.2069, Validation Accuracy: 0.6341\n",
            "Epoch 135/100, Loss: 49.4154, Validation Accuracy: 0.6251\n",
            "Epoch 136/100, Loss: 32.8447, Validation Accuracy: 0.5773\n",
            "Epoch 137/100, Loss: 41.5914, Validation Accuracy: 0.5145\n",
            "Epoch 138/100, Loss: 16.5444, Validation Accuracy: 0.5194\n",
            "Epoch 139/100, Loss: 23.0540, Validation Accuracy: 0.5404\n",
            "Epoch 140/100, Loss: 14.9283, Validation Accuracy: 0.6411\n",
            "Epoch 141/100, Loss: 3.9795, Validation Accuracy: 0.6471\n",
            "Epoch 142/100, Loss: 10.5627, Validation Accuracy: 0.5932\n",
            "Epoch 143/100, Loss: 6.5975, Validation Accuracy: 0.5833\n",
            "Epoch 144/100, Loss: 22.5964, Validation Accuracy: 0.6520\n",
            "Epoch 145/100, Loss: 25.0374, Validation Accuracy: 0.6162\n",
            "Epoch 146/100, Loss: 10.7887, Validation Accuracy: 0.5912\n",
            "Epoch 147/100, Loss: 9.1864, Validation Accuracy: 0.6102\n",
            "Epoch 148/100, Loss: 4.3700, Validation Accuracy: 0.4726\n",
            "Epoch 149/100, Loss: 3.9933, Validation Accuracy: 0.4497\n",
            "Epoch 150/100, Loss: 23.5582, Validation Accuracy: 0.6221\n",
            "Epoch 151/100, Loss: 31.9053, Validation Accuracy: 0.5194\n",
            "Epoch 152/100, Loss: 41.1000, Validation Accuracy: 0.5155\n",
            "Epoch 153/100, Loss: 11.0172, Validation Accuracy: 0.6830\n",
            "Epoch 154/100, Loss: 3.7214, Validation Accuracy: 0.6520\n",
            "Epoch 155/100, Loss: 369.1714, Validation Accuracy: 0.6092\n",
            "Epoch 156/100, Loss: 159.5493, Validation Accuracy: 0.5773\n",
            "Epoch 157/100, Loss: 13.6751, Validation Accuracy: 0.4816\n",
            "Epoch 158/100, Loss: 208.8652, Validation Accuracy: 0.5015\n",
            "Epoch 159/100, Loss: 39.1127, Validation Accuracy: 0.6351\n",
            "Epoch 160/100, Loss: 817.9998, Validation Accuracy: 0.5962\n",
            "Epoch 161/100, Loss: 86.0841, Validation Accuracy: 0.6022\n",
            "Epoch 162/100, Loss: 12.0458, Validation Accuracy: 0.5902\n",
            "Epoch 163/100, Loss: 5.8815, Validation Accuracy: 0.6082\n",
            "Epoch 164/100, Loss: 14.3518, Validation Accuracy: 0.5763\n",
            "Epoch 165/100, Loss: 346.5783, Validation Accuracy: 0.6062\n",
            "Epoch 166/100, Loss: 12.7624, Validation Accuracy: 0.4925\n",
            "Epoch 167/100, Loss: 15.8069, Validation Accuracy: 0.6181\n",
            "Epoch 168/100, Loss: 22.9166, Validation Accuracy: 0.6570\n",
            "Epoch 169/100, Loss: 112.9790, Validation Accuracy: 0.6491\n",
            "Epoch 170/100, Loss: 14.0313, Validation Accuracy: 0.4397\n",
            "Epoch 171/100, Loss: 368.6982, Validation Accuracy: 0.5145\n",
            "Epoch 172/100, Loss: 1235.8292, Validation Accuracy: 0.5613\n",
            "Epoch 173/100, Loss: 42.9483, Validation Accuracy: 0.6451\n",
            "Epoch 174/100, Loss: 9.3049, Validation Accuracy: 0.4985\n",
            "Epoch 175/100, Loss: 286.9439, Validation Accuracy: 0.4187\n",
            "Epoch 176/100, Loss: 15.1946, Validation Accuracy: 0.6351\n",
            "Epoch 177/100, Loss: 5.6395, Validation Accuracy: 0.6471\n",
            "Epoch 178/100, Loss: 3.3528, Validation Accuracy: 0.5703\n",
            "Epoch 179/100, Loss: 9.4998, Validation Accuracy: 0.5813\n",
            "Epoch 180/100, Loss: 3982.2803, Validation Accuracy: 0.5414\n",
            "Epoch 181/100, Loss: 712.7263, Validation Accuracy: 0.5095\n",
            "Epoch 182/100, Loss: 1681.9723, Validation Accuracy: 0.6012\n",
            "Epoch 183/100, Loss: 689.5493, Validation Accuracy: 0.5793\n",
            "Epoch 184/100, Loss: 296.0074, Validation Accuracy: 0.6451\n",
            "Epoch 185/100, Loss: 507.8577, Validation Accuracy: 0.4786\n",
            "Epoch 186/100, Loss: 649.5875, Validation Accuracy: 0.6540\n",
            "Epoch 187/100, Loss: 628.0247, Validation Accuracy: 0.5833\n",
            "Epoch 188/100, Loss: 416.4794, Validation Accuracy: 0.6560\n",
            "Epoch 189/100, Loss: 1109.8801, Validation Accuracy: 0.5743\n",
            "Epoch 190/100, Loss: 580.7890, Validation Accuracy: 0.5414\n",
            "Epoch 191/100, Loss: 873.3930, Validation Accuracy: 0.6969\n",
            "Epoch 192/100, Loss: 644.9530, Validation Accuracy: 0.6271\n",
            "Epoch 193/100, Loss: 469.6453, Validation Accuracy: 0.6241\n",
            "Epoch 194/100, Loss: 593.5142, Validation Accuracy: 0.5833\n",
            "Epoch 195/100, Loss: 486.7300, Validation Accuracy: 0.5813\n",
            "Epoch 196/100, Loss: 342.6939, Validation Accuracy: 0.6839\n",
            "Epoch 197/100, Loss: 403.1486, Validation Accuracy: 0.6301\n",
            "Epoch 198/100, Loss: 356.2700, Validation Accuracy: 0.6471\n",
            "Epoch 199/100, Loss: 296.3659, Validation Accuracy: 0.5982\n",
            "Epoch 200/100, Loss: 398.1654, Validation Accuracy: 0.6680\n",
            "Reward for Child Model: 0.31994074228102914\n",
            "Child_44:  {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, [3, 3, 2, 0, 0, 2, 1, 2, 3, 0, 2, 0, 1, 1, 3], 0.31994074228102914\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 24, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 36, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(60, 36, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(84, 48, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=104544, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 22, 22]           3,552\n",
            "       BatchNorm2d-2           [-1, 24, 22, 22]              48\n",
            "            Conv2d-3           [-1, 24, 18, 16]          20,184\n",
            "       BatchNorm2d-4           [-1, 24, 18, 16]              48\n",
            "              ReLU-5           [-1, 24, 18, 16]               0\n",
            "            Conv2d-6           [-1, 36, 14, 10]          30,276\n",
            "       BatchNorm2d-7           [-1, 36, 14, 10]              72\n",
            "              ReLU-8           [-1, 36, 14, 10]               0\n",
            "            Conv2d-9           [-1, 36, 20, 18]          32,436\n",
            "      BatchNorm2d-10           [-1, 36, 20, 18]              72\n",
            "             ReLU-11           [-1, 36, 20, 18]               0\n",
            "           Conv2d-12           [-1, 48, 20, 18]          60,528\n",
            "      BatchNorm2d-13           [-1, 48, 20, 18]              96\n",
            "             ReLU-14           [-1, 48, 20, 18]               0\n",
            "           Linear-15                    [-1, 7]         731,815\n",
            "================================================================\n",
            "Total params: 879,127\n",
            "Trainable params: 879,127\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.14\n",
            "Params size (MB): 3.35\n",
            "Estimated Total Size (MB): 4.51\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 36.9502, Validation Accuracy: 0.6680\n",
            "Epoch 2/100, Loss: 18.0070, Validation Accuracy: 0.6152\n",
            "Epoch 3/100, Loss: 15.5791, Validation Accuracy: 0.4078\n",
            "Epoch 4/100, Loss: 43.3227, Validation Accuracy: 0.4088\n",
            "Epoch 5/100, Loss: 8.0717, Validation Accuracy: 0.6052\n",
            "Epoch 6/100, Loss: 2319.6235, Validation Accuracy: 0.6321\n",
            "Epoch 7/100, Loss: 24.6776, Validation Accuracy: 0.6461\n",
            "Epoch 8/100, Loss: 10.6946, Validation Accuracy: 0.6052\n",
            "Epoch 9/100, Loss: 2.8836, Validation Accuracy: 0.6162\n",
            "Epoch 10/100, Loss: 2.3961, Validation Accuracy: 0.6431\n",
            "Epoch 11/100, Loss: 2.5697, Validation Accuracy: 0.6052\n",
            "Epoch 12/100, Loss: 4.7642, Validation Accuracy: 0.4606\n",
            "Epoch 13/100, Loss: 45.3221, Validation Accuracy: 0.5942\n",
            "Epoch 14/100, Loss: 24.5675, Validation Accuracy: 0.5543\n",
            "Epoch 15/100, Loss: 9.6277, Validation Accuracy: 0.5882\n",
            "Epoch 16/100, Loss: 56.4045, Validation Accuracy: 0.6391\n",
            "Epoch 17/100, Loss: 45.4971, Validation Accuracy: 0.3819\n",
            "Epoch 18/100, Loss: 13.8064, Validation Accuracy: 0.6481\n",
            "Epoch 19/100, Loss: 3.8317, Validation Accuracy: 0.5304\n",
            "Epoch 20/100, Loss: 8.3942, Validation Accuracy: 0.6211\n",
            "Epoch 21/100, Loss: 4.3842, Validation Accuracy: 0.5284\n",
            "Epoch 22/100, Loss: 2.2934, Validation Accuracy: 0.6341\n",
            "Epoch 23/100, Loss: 44.1691, Validation Accuracy: 0.4965\n",
            "Epoch 24/100, Loss: 93.5816, Validation Accuracy: 0.5972\n",
            "Epoch 25/100, Loss: 11.3523, Validation Accuracy: 0.6550\n",
            "Epoch 26/100, Loss: 13.5760, Validation Accuracy: 0.5833\n",
            "Epoch 27/100, Loss: 4.8678, Validation Accuracy: 0.5673\n",
            "Epoch 28/100, Loss: 5.7986, Validation Accuracy: 0.5703\n",
            "Epoch 29/100, Loss: 15.6178, Validation Accuracy: 0.5025\n",
            "Epoch 30/100, Loss: 16.2611, Validation Accuracy: 0.6082\n",
            "Epoch 31/100, Loss: 42.5730, Validation Accuracy: 0.5733\n",
            "Epoch 32/100, Loss: 89.3481, Validation Accuracy: 0.5324\n",
            "Epoch 33/100, Loss: 34.6337, Validation Accuracy: 0.6600\n",
            "Epoch 34/100, Loss: 8.6784, Validation Accuracy: 0.6102\n",
            "Epoch 35/100, Loss: 5.1139, Validation Accuracy: 0.5932\n",
            "Epoch 36/100, Loss: 9.0542, Validation Accuracy: 0.5743\n",
            "Epoch 37/100, Loss: 3.5757, Validation Accuracy: 0.6321\n",
            "Epoch 38/100, Loss: 8.0361, Validation Accuracy: 0.5404\n",
            "Epoch 39/100, Loss: 40.0920, Validation Accuracy: 0.5444\n",
            "Epoch 40/100, Loss: 35.0101, Validation Accuracy: 0.6201\n",
            "Epoch 41/100, Loss: 9.8176, Validation Accuracy: 0.5763\n",
            "Epoch 42/100, Loss: 5.9330, Validation Accuracy: 0.6171\n",
            "Epoch 43/100, Loss: 4.4061, Validation Accuracy: 0.5942\n",
            "Epoch 44/100, Loss: 9.9569, Validation Accuracy: 0.6411\n",
            "Epoch 45/100, Loss: 39.0611, Validation Accuracy: 0.4367\n",
            "Epoch 46/100, Loss: 9.6683, Validation Accuracy: 0.6092\n",
            "Epoch 47/100, Loss: 40.0139, Validation Accuracy: 0.5533\n",
            "Epoch 48/100, Loss: 49.1684, Validation Accuracy: 0.3699\n",
            "Epoch 49/100, Loss: 6.8575, Validation Accuracy: 0.5513\n",
            "Epoch 50/100, Loss: 147.3410, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 13.6688, Validation Accuracy: 0.5852\n",
            "Epoch 52/100, Loss: 30.4064, Validation Accuracy: 0.6102\n",
            "Epoch 53/100, Loss: 9.4440, Validation Accuracy: 0.5344\n",
            "Epoch 54/100, Loss: 4.8717, Validation Accuracy: 0.4257\n",
            "Epoch 55/100, Loss: 9.9251, Validation Accuracy: 0.2493\n",
            "Epoch 56/100, Loss: 62.8795, Validation Accuracy: 0.4865\n",
            "Epoch 57/100, Loss: 24.9761, Validation Accuracy: 0.6271\n",
            "Epoch 58/100, Loss: 38.1897, Validation Accuracy: 0.4995\n",
            "Epoch 59/100, Loss: 21.4749, Validation Accuracy: 0.6102\n",
            "Epoch 60/100, Loss: 4.9976, Validation Accuracy: 0.6331\n",
            "Epoch 61/100, Loss: 14.3843, Validation Accuracy: 0.6660\n",
            "Epoch 62/100, Loss: 22.4142, Validation Accuracy: 0.4337\n",
            "Epoch 63/100, Loss: 103.1084, Validation Accuracy: 0.6261\n",
            "Epoch 64/100, Loss: 18.8032, Validation Accuracy: 0.0140\n",
            "Epoch 65/100, Loss: 12.3985, Validation Accuracy: 0.4845\n",
            "Epoch 66/100, Loss: 17.0180, Validation Accuracy: 0.6012\n",
            "Epoch 67/100, Loss: 6.9306, Validation Accuracy: 0.6341\n",
            "Epoch 68/100, Loss: 7.7408, Validation Accuracy: 0.6361\n",
            "Epoch 69/100, Loss: 12.3768, Validation Accuracy: 0.4546\n",
            "Epoch 70/100, Loss: 118.6831, Validation Accuracy: 0.5384\n",
            "Epoch 71/100, Loss: 11.2810, Validation Accuracy: 0.5085\n",
            "Epoch 72/100, Loss: 8.3466, Validation Accuracy: 0.6650\n",
            "Epoch 73/100, Loss: 6.0840, Validation Accuracy: 0.5085\n",
            "Epoch 74/100, Loss: 5.4434, Validation Accuracy: 0.6022\n",
            "Epoch 75/100, Loss: 10.6389, Validation Accuracy: 0.6221\n",
            "Epoch 76/100, Loss: 112.3925, Validation Accuracy: 0.6720\n",
            "Epoch 77/100, Loss: 14.8302, Validation Accuracy: 0.5733\n",
            "Epoch 78/100, Loss: 11.1115, Validation Accuracy: 0.6391\n",
            "Epoch 79/100, Loss: 6.3068, Validation Accuracy: 0.5952\n",
            "Epoch 80/100, Loss: 5.0843, Validation Accuracy: 0.5314\n",
            "Epoch 81/100, Loss: 23.9643, Validation Accuracy: 0.6361\n",
            "Epoch 82/100, Loss: 36.2124, Validation Accuracy: 0.6261\n",
            "Epoch 83/100, Loss: 5.7358, Validation Accuracy: 0.6520\n",
            "Epoch 84/100, Loss: 11.1839, Validation Accuracy: 0.6660\n",
            "Epoch 85/100, Loss: 73.0835, Validation Accuracy: 0.3170\n",
            "Epoch 86/100, Loss: 11.8439, Validation Accuracy: 0.4826\n",
            "Epoch 87/100, Loss: 13.3465, Validation Accuracy: 0.5613\n",
            "Epoch 88/100, Loss: 9.2641, Validation Accuracy: 0.6211\n",
            "Epoch 89/100, Loss: 14.3877, Validation Accuracy: 0.3589\n",
            "Epoch 90/100, Loss: 10.3803, Validation Accuracy: 0.6401\n",
            "Epoch 91/100, Loss: 16.4874, Validation Accuracy: 0.6152\n",
            "Epoch 92/100, Loss: 15.7859, Validation Accuracy: 0.5174\n",
            "Epoch 93/100, Loss: 96.4676, Validation Accuracy: 0.6730\n",
            "Epoch 94/100, Loss: 28.3245, Validation Accuracy: 0.6590\n",
            "Epoch 95/100, Loss: 8.6488, Validation Accuracy: 0.4915\n",
            "Epoch 96/100, Loss: 6.8025, Validation Accuracy: 0.5643\n",
            "Epoch 97/100, Loss: 10.6771, Validation Accuracy: 0.5932\n",
            "Epoch 98/100, Loss: 15.3712, Validation Accuracy: 0.5244\n",
            "Epoch 99/100, Loss: 4.5232, Validation Accuracy: 0.6062\n",
            "Epoch 100/100, Loss: 16.0185, Validation Accuracy: 0.5643\n",
            "Epoch 101/100, Loss: 50.8702, Validation Accuracy: 0.6660\n",
            "Epoch 102/100, Loss: 260.7794, Validation Accuracy: 0.0518\n",
            "Epoch 103/100, Loss: 7.8082, Validation Accuracy: 0.5623\n",
            "Epoch 104/100, Loss: 9.2501, Validation Accuracy: 0.5304\n",
            "Epoch 105/100, Loss: 5.8507, Validation Accuracy: 0.6720\n",
            "Epoch 106/100, Loss: 4.4432, Validation Accuracy: 0.6002\n",
            "Epoch 107/100, Loss: 9.0340, Validation Accuracy: 0.5882\n",
            "Epoch 108/100, Loss: 8.8726, Validation Accuracy: 0.5743\n",
            "Epoch 109/100, Loss: 20.6229, Validation Accuracy: 0.4786\n",
            "Epoch 110/100, Loss: 15.7821, Validation Accuracy: 0.6221\n",
            "Epoch 111/100, Loss: 116.7485, Validation Accuracy: 0.6261\n",
            "Epoch 112/100, Loss: 24.6830, Validation Accuracy: 0.2253\n",
            "Epoch 113/100, Loss: 13.9222, Validation Accuracy: 0.6620\n",
            "Epoch 114/100, Loss: 16.0189, Validation Accuracy: 0.6580\n",
            "Epoch 115/100, Loss: 15.4909, Validation Accuracy: 0.2433\n",
            "Epoch 116/100, Loss: 13.4567, Validation Accuracy: 0.5384\n",
            "Epoch 117/100, Loss: 49.3397, Validation Accuracy: 0.4427\n",
            "Epoch 118/100, Loss: 46.3207, Validation Accuracy: 0.6042\n",
            "Epoch 119/100, Loss: 18.7831, Validation Accuracy: 0.6560\n",
            "Epoch 120/100, Loss: 8.3451, Validation Accuracy: 0.5135\n",
            "Epoch 121/100, Loss: 20.7366, Validation Accuracy: 0.3918\n",
            "Epoch 122/100, Loss: 18.0143, Validation Accuracy: 0.5444\n",
            "Epoch 123/100, Loss: 92.1573, Validation Accuracy: 0.5005\n",
            "Epoch 124/100, Loss: 30.2986, Validation Accuracy: 0.6251\n",
            "Epoch 125/100, Loss: 14.0465, Validation Accuracy: 0.5015\n",
            "Epoch 126/100, Loss: 136.0433, Validation Accuracy: 0.4626\n",
            "Epoch 127/100, Loss: 26.2268, Validation Accuracy: 0.0140\n",
            "Epoch 128/100, Loss: 162.2557, Validation Accuracy: 0.6481\n",
            "Epoch 129/100, Loss: 13.0444, Validation Accuracy: 0.5683\n",
            "Epoch 130/100, Loss: 8.2366, Validation Accuracy: 0.6510\n",
            "Epoch 131/100, Loss: 11.5177, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 5.1127, Validation Accuracy: 0.5852\n",
            "Epoch 133/100, Loss: 6.4853, Validation Accuracy: 0.6201\n",
            "Epoch 134/100, Loss: 16.7359, Validation Accuracy: 0.6062\n",
            "Epoch 135/100, Loss: 612.3587, Validation Accuracy: 0.5025\n",
            "Epoch 136/100, Loss: 29.6770, Validation Accuracy: 0.5982\n",
            "Epoch 137/100, Loss: 2.3943, Validation Accuracy: 0.6899\n",
            "Epoch 138/100, Loss: 93.8330, Validation Accuracy: 0.5972\n",
            "Epoch 139/100, Loss: 18.7271, Validation Accuracy: 0.6171\n",
            "Epoch 140/100, Loss: 15.2707, Validation Accuracy: 0.5434\n",
            "Epoch 141/100, Loss: 7.6705, Validation Accuracy: 0.5773\n",
            "Epoch 142/100, Loss: 5.3821, Validation Accuracy: 0.6730\n",
            "Epoch 143/100, Loss: 4.8175, Validation Accuracy: 0.5234\n",
            "Epoch 144/100, Loss: 6.8378, Validation Accuracy: 0.6082\n",
            "Epoch 145/100, Loss: 10.2370, Validation Accuracy: 0.6700\n",
            "Epoch 146/100, Loss: 13.9717, Validation Accuracy: 0.6710\n",
            "Epoch 147/100, Loss: 22.8202, Validation Accuracy: 0.2692\n",
            "Epoch 148/100, Loss: 56.0628, Validation Accuracy: 0.5005\n",
            "Epoch 149/100, Loss: 6.2983, Validation Accuracy: 0.6012\n",
            "Epoch 150/100, Loss: 8.2246, Validation Accuracy: 0.6072\n",
            "Epoch 151/100, Loss: 6.0853, Validation Accuracy: 0.4816\n",
            "Epoch 152/100, Loss: 63.7226, Validation Accuracy: 0.5892\n",
            "Epoch 153/100, Loss: 104.5787, Validation Accuracy: 0.5234\n",
            "Epoch 154/100, Loss: 12.0822, Validation Accuracy: 0.5294\n",
            "Epoch 155/100, Loss: 12.7606, Validation Accuracy: 0.6740\n",
            "Epoch 156/100, Loss: 10.0338, Validation Accuracy: 0.5314\n",
            "Epoch 157/100, Loss: 47.7527, Validation Accuracy: 0.2911\n",
            "Epoch 158/100, Loss: 10.7939, Validation Accuracy: 0.6191\n",
            "Epoch 159/100, Loss: 13.0762, Validation Accuracy: 0.6441\n",
            "Epoch 160/100, Loss: 16.9625, Validation Accuracy: 0.6510\n",
            "Epoch 161/100, Loss: 6.9446, Validation Accuracy: 0.5803\n",
            "Epoch 162/100, Loss: 10.7351, Validation Accuracy: 0.5095\n",
            "Epoch 163/100, Loss: 6.0653, Validation Accuracy: 0.4826\n",
            "Epoch 164/100, Loss: 7.3595, Validation Accuracy: 0.5643\n",
            "Epoch 165/100, Loss: 11.3823, Validation Accuracy: 0.5404\n",
            "Epoch 166/100, Loss: 15.7025, Validation Accuracy: 0.4158\n",
            "Epoch 167/100, Loss: 66.5978, Validation Accuracy: 0.6032\n",
            "Epoch 168/100, Loss: 37.7200, Validation Accuracy: 0.5703\n",
            "Epoch 169/100, Loss: 44.4115, Validation Accuracy: 0.4875\n",
            "Epoch 170/100, Loss: 20.3251, Validation Accuracy: 0.5902\n",
            "Epoch 171/100, Loss: 7.3783, Validation Accuracy: 0.6221\n",
            "Epoch 172/100, Loss: 170.9722, Validation Accuracy: 0.5414\n",
            "Epoch 173/100, Loss: 28.7288, Validation Accuracy: 0.5334\n",
            "Epoch 174/100, Loss: 6.9048, Validation Accuracy: 0.6201\n",
            "Epoch 175/100, Loss: 14.0116, Validation Accuracy: 0.6082\n",
            "Epoch 176/100, Loss: 10.1280, Validation Accuracy: 0.6640\n",
            "Epoch 177/100, Loss: 15.5929, Validation Accuracy: 0.6032\n",
            "Epoch 178/100, Loss: 16.0338, Validation Accuracy: 0.5583\n",
            "Epoch 179/100, Loss: 43.8816, Validation Accuracy: 0.6042\n",
            "Epoch 180/100, Loss: 28.2502, Validation Accuracy: 0.6012\n",
            "Epoch 181/100, Loss: 16.4666, Validation Accuracy: 0.5713\n",
            "Epoch 182/100, Loss: 26.9481, Validation Accuracy: 0.6530\n",
            "Epoch 183/100, Loss: 24.2820, Validation Accuracy: 0.5284\n",
            "Epoch 184/100, Loss: 48.6106, Validation Accuracy: 0.5244\n",
            "Epoch 185/100, Loss: 46.4590, Validation Accuracy: 0.5214\n",
            "Epoch 186/100, Loss: 94.7214, Validation Accuracy: 0.4277\n",
            "Epoch 187/100, Loss: 20.8143, Validation Accuracy: 0.6520\n",
            "Epoch 188/100, Loss: 13.7891, Validation Accuracy: 0.5972\n",
            "Epoch 189/100, Loss: 1.8761, Validation Accuracy: 0.6361\n",
            "Epoch 190/100, Loss: 12.8769, Validation Accuracy: 0.4995\n",
            "Epoch 191/100, Loss: 9.5026, Validation Accuracy: 0.6770\n",
            "Epoch 192/100, Loss: 32.2170, Validation Accuracy: 0.6201\n",
            "Epoch 193/100, Loss: 24.8847, Validation Accuracy: 0.6730\n",
            "Epoch 194/100, Loss: 14.6516, Validation Accuracy: 0.6162\n",
            "Epoch 195/100, Loss: 94.8032, Validation Accuracy: 0.6520\n",
            "Epoch 196/100, Loss: 44.9723, Validation Accuracy: 0.6291\n",
            "Epoch 197/100, Loss: 12.9072, Validation Accuracy: 0.6431\n",
            "Epoch 198/100, Loss: 21.5414, Validation Accuracy: 0.5992\n",
            "Epoch 199/100, Loss: 44.2920, Validation Accuracy: 0.5354\n",
            "Epoch 200/100, Loss: 33.2277, Validation Accuracy: 0.6221\n",
            "Reward for Child Model: 0.26593551789966074\n",
            "Child_45:  {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, [3, 3, 0, 2, 3, 0, 2, 3, 1, 1, 2, 1, 1, 2, 2], 0.26593551789966074\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(88, 36, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(148, 64, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(64, 24, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=38720, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 26, 24]           1,104\n",
            "       BatchNorm2d-2           [-1, 24, 26, 24]              48\n",
            "            Conv2d-3           [-1, 64, 20, 18]          75,328\n",
            "       BatchNorm2d-4           [-1, 64, 20, 18]             128\n",
            "              ReLU-5           [-1, 64, 20, 18]               0\n",
            "            Conv2d-6           [-1, 36, 22, 22]          47,556\n",
            "       BatchNorm2d-7           [-1, 36, 22, 22]              72\n",
            "              ReLU-8           [-1, 36, 22, 22]               0\n",
            "            Conv2d-9           [-1, 64, 20, 22]         198,976\n",
            "      BatchNorm2d-10           [-1, 64, 20, 22]             128\n",
            "             ReLU-11           [-1, 64, 20, 22]               0\n",
            "           Conv2d-12           [-1, 24, 20, 18]           7,704\n",
            "      BatchNorm2d-13           [-1, 24, 20, 18]              48\n",
            "             ReLU-14           [-1, 24, 20, 18]               0\n",
            "           Linear-15                    [-1, 7]         271,047\n",
            "================================================================\n",
            "Total params: 602,139\n",
            "Trainable params: 602,139\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.00\n",
            "Params size (MB): 2.30\n",
            "Estimated Total Size (MB): 4.30\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 1.1034, Validation Accuracy: 0.6690\n",
            "Epoch 2/100, Loss: 1.1624, Validation Accuracy: 0.6690\n",
            "Epoch 3/100, Loss: 0.9538, Validation Accuracy: 0.6690\n",
            "Epoch 4/100, Loss: 0.9525, Validation Accuracy: 0.1107\n",
            "Epoch 5/100, Loss: 1.1030, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 1.1816, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 0.9722, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 1.2865, Validation Accuracy: 0.6690\n",
            "Epoch 9/100, Loss: 1.2060, Validation Accuracy: 0.6690\n",
            "Epoch 10/100, Loss: 0.8572, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 1.1244, Validation Accuracy: 0.6690\n",
            "Epoch 12/100, Loss: 1.2324, Validation Accuracy: 0.1107\n",
            "Epoch 13/100, Loss: 0.9999, Validation Accuracy: 0.6650\n",
            "Epoch 14/100, Loss: 1.0385, Validation Accuracy: 0.6690\n",
            "Epoch 15/100, Loss: 0.9231, Validation Accuracy: 0.6690\n",
            "Epoch 16/100, Loss: 1.0686, Validation Accuracy: 0.6690\n",
            "Epoch 17/100, Loss: 0.9533, Validation Accuracy: 0.6690\n",
            "Epoch 18/100, Loss: 1.6289, Validation Accuracy: 0.6690\n",
            "Epoch 19/100, Loss: 0.9252, Validation Accuracy: 0.6690\n",
            "Epoch 20/100, Loss: 0.9896, Validation Accuracy: 0.6690\n",
            "Epoch 21/100, Loss: 1.2786, Validation Accuracy: 0.6690\n",
            "Epoch 22/100, Loss: 1.4879, Validation Accuracy: 0.6690\n",
            "Epoch 23/100, Loss: 1.1089, Validation Accuracy: 0.6690\n",
            "Epoch 24/100, Loss: 1.2119, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 1.2865, Validation Accuracy: 0.6690\n",
            "Epoch 26/100, Loss: 1.3289, Validation Accuracy: 0.6690\n",
            "Epoch 27/100, Loss: 1.3380, Validation Accuracy: 0.6690\n",
            "Epoch 28/100, Loss: 0.9768, Validation Accuracy: 0.6690\n",
            "Epoch 29/100, Loss: 0.9755, Validation Accuracy: 0.6690\n",
            "Epoch 30/100, Loss: 1.1791, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 1.1915, Validation Accuracy: 0.6690\n",
            "Epoch 32/100, Loss: 0.9584, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 1.1893, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 1.3508, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 1.1167, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 1.3826, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 0.8497, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 0.9725, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 1.1887, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 0.9754, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 1.4187, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 1.2323, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 1.4299, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 1.2923, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 1.2549, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 1.1492, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 1.1785, Validation Accuracy: 0.6690\n",
            "Epoch 48/100, Loss: 1.1373, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 0.8413, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 1.2448, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 1.2121, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 1.3518, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 1.2989, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 1.0322, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 1.6885, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 1.5655, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 1.2209, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 0.9459, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 0.9430, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 1.4845, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 1.2777, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 0.8741, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 1.5767, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 1.0543, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 1.2324, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 1.2308, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 1.2449, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 1.0827, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 1.2549, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 1.0967, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 1.1685, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 0.8555, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 1.2727, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 1.0487, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 1.0799, Validation Accuracy: 0.6690\n",
            "Epoch 76/100, Loss: 1.0781, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 1.0100, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 1.0868, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 1.0133, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 1.0198, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 1.4404, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 1.0121, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 1.1681, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 0.9713, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 1.1576, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 0.9749, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 0.7598, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 0.9173, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 1.0410, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 1.0389, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 1.1806, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 1.0201, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 1.3411, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 0.7935, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 1.0046, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 1.2230, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 1.3452, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 1.2734, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 1.2304, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 1.1544, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 1.1753, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 1.1215, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 1.2323, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 1.1028, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 1.0008, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 1.5882, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 0.7134, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 1.3527, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 0.9868, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 1.6927, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.0128, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 1.2889, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 1.1564, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 1.0058, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 1.1998, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 1.6938, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 1.2480, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 1.1658, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 0.9199, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 1.3241, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 1.2055, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.1827, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 1.3045, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 0.9738, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 1.1794, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 1.0072, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 0.9123, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 1.2680, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 1.3768, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 1.0417, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 0.7562, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 1.2684, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 1.0803, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 0.8096, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 1.3571, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 0.6643, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 1.1028, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 1.2081, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 0.9724, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 1.0807, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 1.3647, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 1.4531, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 0.8414, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 0.8259, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 1.0995, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 1.6438, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 1.1841, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 1.5385, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 1.0483, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 1.4595, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 1.1907, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 1.0535, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 0.8906, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 0.7853, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 1.2583, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 0.7854, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 0.9636, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 1.1960, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 0.8076, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 1.3422, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 0.9371, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 1.1005, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 1.4859, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 1.2520, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 1.2477, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 0.8676, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 0.9979, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 0.9238, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 1.1621, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 1.5406, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 1.1667, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 0.8522, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 1.7539, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 1.0028, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 0.8817, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 1.0621, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 1.0375, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 1.1023, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 1.0652, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 0.8070, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 0.8507, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 1.0735, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 1.0841, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 0.9768, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 1.1967, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 1.2447, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 1.2176, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 1.0021, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 0.6846, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 0.9460, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 0.9935, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 0.8278, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 1.3621, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 1.0316, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 1.3702, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 1.3405, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 1.1407, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 1.1988, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 1.0847, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 1.3163, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_46:  {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, [1, 2, 0, 3, 3, 3, 2, 1, 1, 3, 1, 3, 0, 2, 0], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 36, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(84, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(148, 48, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(280, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=238784, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 28, 26]             480\n",
            "       BatchNorm2d-2           [-1, 48, 28, 26]              96\n",
            "            Conv2d-3           [-1, 36, 26, 20]          36,324\n",
            "       BatchNorm2d-4           [-1, 36, 26, 20]              72\n",
            "              ReLU-5           [-1, 36, 26, 20]               0\n",
            "            Conv2d-6           [-1, 64, 24, 22]         134,464\n",
            "       BatchNorm2d-7           [-1, 64, 24, 22]             128\n",
            "              ReLU-8           [-1, 64, 24, 22]               0\n",
            "            Conv2d-9           [-1, 48, 24, 26]          35,568\n",
            "      BatchNorm2d-10           [-1, 48, 24, 26]              96\n",
            "             ReLU-11           [-1, 48, 24, 26]               0\n",
            "           Conv2d-12           [-1, 48, 26, 26]          40,368\n",
            "      BatchNorm2d-13           [-1, 48, 26, 26]              96\n",
            "             ReLU-14           [-1, 48, 26, 26]               0\n",
            "           Linear-15                    [-1, 7]       1,671,495\n",
            "================================================================\n",
            "Total params: 1,919,187\n",
            "Trainable params: 1,919,187\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.16\n",
            "Params size (MB): 7.32\n",
            "Estimated Total Size (MB): 10.49\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 18.1027, Validation Accuracy: 0.6520\n",
            "Epoch 2/100, Loss: 69.9980, Validation Accuracy: 0.6122\n",
            "Epoch 3/100, Loss: 21.2967, Validation Accuracy: 0.5543\n",
            "Epoch 4/100, Loss: 128.0614, Validation Accuracy: 0.4935\n",
            "Epoch 5/100, Loss: 16.5964, Validation Accuracy: 0.4945\n",
            "Epoch 6/100, Loss: 14.6684, Validation Accuracy: 0.6271\n",
            "Epoch 7/100, Loss: 43.3014, Validation Accuracy: 0.6112\n",
            "Epoch 8/100, Loss: 44.5935, Validation Accuracy: 0.4457\n",
            "Epoch 9/100, Loss: 185.7128, Validation Accuracy: 0.6431\n",
            "Epoch 10/100, Loss: 64.9921, Validation Accuracy: 0.3190\n",
            "Epoch 11/100, Loss: 70.7008, Validation Accuracy: 0.6421\n",
            "Epoch 12/100, Loss: 12.3656, Validation Accuracy: 0.4826\n",
            "Epoch 13/100, Loss: 129.7051, Validation Accuracy: 0.4307\n",
            "Epoch 14/100, Loss: 191.6275, Validation Accuracy: 0.5922\n",
            "Epoch 15/100, Loss: 80.4166, Validation Accuracy: 0.6171\n",
            "Epoch 16/100, Loss: 176.1639, Validation Accuracy: 0.3091\n",
            "Epoch 17/100, Loss: 60.2071, Validation Accuracy: 0.5753\n",
            "Epoch 18/100, Loss: 82.5299, Validation Accuracy: 0.6391\n",
            "Epoch 19/100, Loss: 58.6365, Validation Accuracy: 0.6421\n",
            "Epoch 20/100, Loss: 60.6437, Validation Accuracy: 0.6461\n",
            "Epoch 21/100, Loss: 116.6541, Validation Accuracy: 0.5673\n",
            "Epoch 22/100, Loss: 42.2378, Validation Accuracy: 0.6052\n",
            "Epoch 23/100, Loss: 161.8183, Validation Accuracy: 0.4756\n",
            "Epoch 24/100, Loss: 185.3887, Validation Accuracy: 0.6381\n",
            "Epoch 25/100, Loss: 75.7956, Validation Accuracy: 0.6381\n",
            "Epoch 26/100, Loss: 59.7880, Validation Accuracy: 0.4706\n",
            "Epoch 27/100, Loss: 181.3951, Validation Accuracy: 0.6700\n",
            "Epoch 28/100, Loss: 178.1667, Validation Accuracy: 0.6540\n",
            "Epoch 29/100, Loss: 75.3752, Validation Accuracy: 0.6181\n",
            "Epoch 30/100, Loss: 69.2875, Validation Accuracy: 0.4148\n",
            "Epoch 31/100, Loss: 175.7133, Validation Accuracy: 0.5862\n",
            "Epoch 32/100, Loss: 46.2213, Validation Accuracy: 0.6301\n",
            "Epoch 33/100, Loss: 54.1787, Validation Accuracy: 0.2373\n",
            "Epoch 34/100, Loss: 61.1403, Validation Accuracy: 0.6271\n",
            "Epoch 35/100, Loss: 106.7799, Validation Accuracy: 0.6730\n",
            "Epoch 36/100, Loss: 205.6097, Validation Accuracy: 0.6650\n",
            "Epoch 37/100, Loss: 101.5367, Validation Accuracy: 0.6261\n",
            "Epoch 38/100, Loss: 139.6745, Validation Accuracy: 0.6540\n",
            "Epoch 39/100, Loss: 141.9218, Validation Accuracy: 0.6321\n",
            "Epoch 40/100, Loss: 27.3857, Validation Accuracy: 0.6281\n",
            "Epoch 41/100, Loss: 105.1894, Validation Accuracy: 0.6381\n",
            "Epoch 42/100, Loss: 66.4054, Validation Accuracy: 0.6022\n",
            "Epoch 43/100, Loss: 202.6638, Validation Accuracy: 0.6281\n",
            "Epoch 44/100, Loss: 62.2002, Validation Accuracy: 0.6271\n",
            "Epoch 45/100, Loss: 102.6879, Validation Accuracy: 0.5703\n",
            "Epoch 46/100, Loss: 130.8072, Validation Accuracy: 0.6132\n",
            "Epoch 47/100, Loss: 170.9678, Validation Accuracy: 0.6580\n",
            "Epoch 48/100, Loss: 44.2927, Validation Accuracy: 0.5414\n",
            "Epoch 49/100, Loss: 89.3899, Validation Accuracy: 0.6381\n",
            "Epoch 50/100, Loss: 68.3604, Validation Accuracy: 0.4516\n",
            "Epoch 51/100, Loss: 57.8933, Validation Accuracy: 0.4626\n",
            "Epoch 52/100, Loss: 121.9956, Validation Accuracy: 0.6550\n",
            "Epoch 53/100, Loss: 37.5408, Validation Accuracy: 0.6580\n",
            "Epoch 54/100, Loss: 101.1498, Validation Accuracy: 0.5932\n",
            "Epoch 55/100, Loss: 151.4945, Validation Accuracy: 0.4397\n",
            "Epoch 56/100, Loss: 91.0854, Validation Accuracy: 0.6720\n",
            "Epoch 57/100, Loss: 96.3910, Validation Accuracy: 0.6421\n",
            "Epoch 58/100, Loss: 131.5867, Validation Accuracy: 0.6441\n",
            "Epoch 59/100, Loss: 80.3940, Validation Accuracy: 0.5603\n",
            "Epoch 60/100, Loss: 134.0575, Validation Accuracy: 0.5693\n",
            "Epoch 61/100, Loss: 61.6738, Validation Accuracy: 0.6590\n",
            "Epoch 62/100, Loss: 160.1024, Validation Accuracy: 0.5444\n",
            "Epoch 63/100, Loss: 311.9046, Validation Accuracy: 0.6510\n",
            "Epoch 64/100, Loss: 206.0159, Validation Accuracy: 0.6570\n",
            "Epoch 65/100, Loss: 198.5957, Validation Accuracy: 0.5653\n",
            "Epoch 66/100, Loss: 56.5137, Validation Accuracy: 0.6381\n",
            "Epoch 67/100, Loss: 110.8728, Validation Accuracy: 0.6311\n",
            "Epoch 68/100, Loss: 81.6049, Validation Accuracy: 0.4546\n",
            "Epoch 69/100, Loss: 59.7983, Validation Accuracy: 0.6251\n",
            "Epoch 70/100, Loss: 82.4678, Validation Accuracy: 0.5713\n",
            "Epoch 71/100, Loss: 113.5688, Validation Accuracy: 0.6530\n",
            "Epoch 72/100, Loss: 267.8199, Validation Accuracy: 0.6989\n",
            "Epoch 73/100, Loss: 78.9267, Validation Accuracy: 0.2273\n",
            "Epoch 74/100, Loss: 80.4385, Validation Accuracy: 0.5733\n",
            "Epoch 75/100, Loss: 108.5186, Validation Accuracy: 0.5494\n",
            "Epoch 76/100, Loss: 49.5801, Validation Accuracy: 0.4497\n",
            "Epoch 77/100, Loss: 109.9800, Validation Accuracy: 0.5194\n",
            "Epoch 78/100, Loss: 210.1779, Validation Accuracy: 0.3958\n",
            "Epoch 79/100, Loss: 141.0195, Validation Accuracy: 0.6062\n",
            "Epoch 80/100, Loss: 120.7796, Validation Accuracy: 0.6650\n",
            "Epoch 81/100, Loss: 46.3436, Validation Accuracy: 0.4975\n",
            "Epoch 82/100, Loss: 33.7435, Validation Accuracy: 0.3848\n",
            "Epoch 83/100, Loss: 87.6474, Validation Accuracy: 0.6730\n",
            "Epoch 84/100, Loss: 130.4182, Validation Accuracy: 0.5803\n",
            "Epoch 85/100, Loss: 162.4101, Validation Accuracy: 0.4636\n",
            "Epoch 86/100, Loss: 25.9036, Validation Accuracy: 0.6142\n",
            "Epoch 87/100, Loss: 71.5217, Validation Accuracy: 0.6201\n",
            "Epoch 88/100, Loss: 147.7528, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 66.7956, Validation Accuracy: 0.6710\n",
            "Epoch 90/100, Loss: 190.4600, Validation Accuracy: 0.6421\n",
            "Epoch 91/100, Loss: 225.4455, Validation Accuracy: 0.6241\n",
            "Epoch 92/100, Loss: 83.8159, Validation Accuracy: 0.4696\n",
            "Epoch 93/100, Loss: 47.1906, Validation Accuracy: 0.5733\n",
            "Epoch 94/100, Loss: 35.5028, Validation Accuracy: 0.5184\n",
            "Epoch 95/100, Loss: 23.6363, Validation Accuracy: 0.4845\n",
            "Epoch 96/100, Loss: 178.3788, Validation Accuracy: 0.6640\n",
            "Epoch 97/100, Loss: 269.2723, Validation Accuracy: 0.5693\n",
            "Epoch 98/100, Loss: 32.4817, Validation Accuracy: 0.6550\n",
            "Epoch 99/100, Loss: 291.1431, Validation Accuracy: 0.6102\n",
            "Epoch 100/100, Loss: 71.9717, Validation Accuracy: 0.6381\n",
            "Epoch 101/100, Loss: 52.2100, Validation Accuracy: 0.6750\n",
            "Epoch 102/100, Loss: 85.5253, Validation Accuracy: 0.5663\n",
            "Epoch 103/100, Loss: 109.3646, Validation Accuracy: 0.6620\n",
            "Epoch 104/100, Loss: 117.9362, Validation Accuracy: 0.6431\n",
            "Epoch 105/100, Loss: 74.2300, Validation Accuracy: 0.5274\n",
            "Epoch 106/100, Loss: 74.3676, Validation Accuracy: 0.6351\n",
            "Epoch 107/100, Loss: 39.8521, Validation Accuracy: 0.5763\n",
            "Epoch 108/100, Loss: 60.8737, Validation Accuracy: 0.6241\n",
            "Epoch 109/100, Loss: 412.5853, Validation Accuracy: 0.5354\n",
            "Epoch 110/100, Loss: 400.6980, Validation Accuracy: 0.6052\n",
            "Epoch 111/100, Loss: 107.6185, Validation Accuracy: 0.6610\n",
            "Epoch 112/100, Loss: 91.7816, Validation Accuracy: 0.5244\n",
            "Epoch 113/100, Loss: 35.7938, Validation Accuracy: 0.5513\n",
            "Epoch 114/100, Loss: 73.9795, Validation Accuracy: 0.6321\n",
            "Epoch 115/100, Loss: 145.4835, Validation Accuracy: 0.5852\n",
            "Epoch 116/100, Loss: 147.1213, Validation Accuracy: 0.5424\n",
            "Epoch 117/100, Loss: 42.5159, Validation Accuracy: 0.6032\n",
            "Epoch 118/100, Loss: 235.8143, Validation Accuracy: 0.5992\n",
            "Epoch 119/100, Loss: 170.2677, Validation Accuracy: 0.5952\n",
            "Epoch 120/100, Loss: 82.0449, Validation Accuracy: 0.4397\n",
            "Epoch 121/100, Loss: 32.0510, Validation Accuracy: 0.6660\n",
            "Epoch 122/100, Loss: 133.2023, Validation Accuracy: 0.6082\n",
            "Epoch 123/100, Loss: 155.3808, Validation Accuracy: 0.5324\n",
            "Epoch 124/100, Loss: 211.6445, Validation Accuracy: 0.6082\n",
            "Epoch 125/100, Loss: 18.6325, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 282.4014, Validation Accuracy: 0.5733\n",
            "Epoch 127/100, Loss: 111.5234, Validation Accuracy: 0.6570\n",
            "Epoch 128/100, Loss: 79.3191, Validation Accuracy: 0.6301\n",
            "Epoch 129/100, Loss: 109.7538, Validation Accuracy: 0.6471\n",
            "Epoch 130/100, Loss: 80.0551, Validation Accuracy: 0.6271\n",
            "Epoch 131/100, Loss: 79.6120, Validation Accuracy: 0.5354\n",
            "Epoch 132/100, Loss: 53.8376, Validation Accuracy: 0.5424\n",
            "Epoch 133/100, Loss: 89.0811, Validation Accuracy: 0.5882\n",
            "Epoch 134/100, Loss: 183.6416, Validation Accuracy: 0.6451\n",
            "Epoch 135/100, Loss: 156.6263, Validation Accuracy: 0.6600\n",
            "Epoch 136/100, Loss: 61.4712, Validation Accuracy: 0.6251\n",
            "Epoch 137/100, Loss: 56.4360, Validation Accuracy: 0.5464\n",
            "Epoch 138/100, Loss: 262.4297, Validation Accuracy: 0.6162\n",
            "Epoch 139/100, Loss: 114.3181, Validation Accuracy: 0.6411\n",
            "Epoch 140/100, Loss: 140.2012, Validation Accuracy: 0.6102\n",
            "Epoch 141/100, Loss: 91.7046, Validation Accuracy: 0.6191\n",
            "Epoch 142/100, Loss: 224.0671, Validation Accuracy: 0.6281\n",
            "Epoch 143/100, Loss: 128.8790, Validation Accuracy: 0.5543\n",
            "Epoch 144/100, Loss: 105.8548, Validation Accuracy: 0.6211\n",
            "Epoch 145/100, Loss: 149.1078, Validation Accuracy: 0.6471\n",
            "Epoch 146/100, Loss: 106.1467, Validation Accuracy: 0.6491\n",
            "Epoch 147/100, Loss: 70.9149, Validation Accuracy: 0.4526\n",
            "Epoch 148/100, Loss: 115.5386, Validation Accuracy: 0.6311\n",
            "Epoch 149/100, Loss: 71.5224, Validation Accuracy: 0.5842\n",
            "Epoch 150/100, Loss: 206.4214, Validation Accuracy: 0.5434\n",
            "Epoch 151/100, Loss: 142.5942, Validation Accuracy: 0.6221\n",
            "Epoch 152/100, Loss: 33.5727, Validation Accuracy: 0.4207\n",
            "Epoch 153/100, Loss: 90.6355, Validation Accuracy: 0.6670\n",
            "Epoch 154/100, Loss: 108.8778, Validation Accuracy: 0.6391\n",
            "Epoch 155/100, Loss: 7.6122, Validation Accuracy: 0.6191\n",
            "Epoch 156/100, Loss: 250.4257, Validation Accuracy: 0.5922\n",
            "Epoch 157/100, Loss: 97.7509, Validation Accuracy: 0.5593\n",
            "Epoch 158/100, Loss: 125.0727, Validation Accuracy: 0.5494\n",
            "Epoch 159/100, Loss: 110.1710, Validation Accuracy: 0.6839\n",
            "Epoch 160/100, Loss: 84.1753, Validation Accuracy: 0.5503\n",
            "Epoch 161/100, Loss: 212.8097, Validation Accuracy: 0.6321\n",
            "Epoch 162/100, Loss: 39.8628, Validation Accuracy: 0.6211\n",
            "Epoch 163/100, Loss: 326.1436, Validation Accuracy: 0.3809\n",
            "Epoch 164/100, Loss: 187.6440, Validation Accuracy: 0.6760\n",
            "Epoch 165/100, Loss: 246.0369, Validation Accuracy: 0.5693\n",
            "Epoch 166/100, Loss: 96.0079, Validation Accuracy: 0.5733\n",
            "Epoch 167/100, Loss: 55.9556, Validation Accuracy: 0.6331\n",
            "Epoch 168/100, Loss: 124.3615, Validation Accuracy: 0.5454\n",
            "Epoch 169/100, Loss: 71.4050, Validation Accuracy: 0.6092\n",
            "Epoch 170/100, Loss: 187.1001, Validation Accuracy: 0.6570\n",
            "Epoch 171/100, Loss: 66.4132, Validation Accuracy: 0.5294\n",
            "Epoch 172/100, Loss: 98.3479, Validation Accuracy: 0.5214\n",
            "Epoch 173/100, Loss: 87.8639, Validation Accuracy: 0.5793\n",
            "Epoch 174/100, Loss: 96.8974, Validation Accuracy: 0.4167\n",
            "Epoch 175/100, Loss: 160.8166, Validation Accuracy: 0.6291\n",
            "Epoch 176/100, Loss: 132.0996, Validation Accuracy: 0.5962\n",
            "Epoch 177/100, Loss: 73.9101, Validation Accuracy: 0.6062\n",
            "Epoch 178/100, Loss: 107.6580, Validation Accuracy: 0.6341\n",
            "Epoch 179/100, Loss: 271.3373, Validation Accuracy: 0.6461\n",
            "Epoch 180/100, Loss: 68.6741, Validation Accuracy: 0.5623\n",
            "Epoch 181/100, Loss: 122.8662, Validation Accuracy: 0.6301\n",
            "Epoch 182/100, Loss: 40.3944, Validation Accuracy: 0.6181\n",
            "Epoch 183/100, Loss: 68.4219, Validation Accuracy: 0.6181\n",
            "Epoch 184/100, Loss: 211.6763, Validation Accuracy: 0.6152\n",
            "Epoch 185/100, Loss: 60.9271, Validation Accuracy: 0.5882\n",
            "Epoch 186/100, Loss: 160.1667, Validation Accuracy: 0.5842\n",
            "Epoch 187/100, Loss: 81.2470, Validation Accuracy: 0.6261\n",
            "Epoch 188/100, Loss: 119.0215, Validation Accuracy: 0.5992\n",
            "Epoch 189/100, Loss: 78.7348, Validation Accuracy: 0.6401\n",
            "Epoch 190/100, Loss: 146.6152, Validation Accuracy: 0.4776\n",
            "Epoch 191/100, Loss: 70.3872, Validation Accuracy: 0.6002\n",
            "Epoch 192/100, Loss: 116.7945, Validation Accuracy: 0.6301\n",
            "Epoch 193/100, Loss: 9.0223, Validation Accuracy: 0.6481\n",
            "Epoch 194/100, Loss: 94.5349, Validation Accuracy: 0.5862\n",
            "Epoch 195/100, Loss: 154.5034, Validation Accuracy: 0.6610\n",
            "Epoch 196/100, Loss: 88.8205, Validation Accuracy: 0.4905\n",
            "Epoch 197/100, Loss: 186.3232, Validation Accuracy: 0.5613\n",
            "Epoch 198/100, Loss: 142.1296, Validation Accuracy: 0.5912\n",
            "Epoch 199/100, Loss: 202.6918, Validation Accuracy: 0.5783\n",
            "Epoch 200/100, Loss: 255.4245, Validation Accuracy: 0.5553\n",
            "Reward for Child Model: 0.20666231074105806\n",
            "Child_47:  {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, [0, 1, 2, 1, 3, 1, 2, 2, 3, 2, 0, 2, 1, 0, 2], 0.20666231074105806\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 64, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(128, 36, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(164, 36, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=179712, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 24, 26]           2,944\n",
            "       BatchNorm2d-2           [-1, 64, 24, 26]             128\n",
            "            Conv2d-3           [-1, 24, 24, 26]           1,560\n",
            "       BatchNorm2d-4           [-1, 24, 24, 26]              48\n",
            "              ReLU-5           [-1, 24, 24, 26]               0\n",
            "            Conv2d-6           [-1, 64, 22, 20]          32,320\n",
            "       BatchNorm2d-7           [-1, 64, 22, 20]             128\n",
            "              ReLU-8           [-1, 64, 22, 20]               0\n",
            "            Conv2d-9           [-1, 36, 20, 26]          23,076\n",
            "      BatchNorm2d-10           [-1, 36, 20, 26]              72\n",
            "             ReLU-11           [-1, 36, 20, 26]               0\n",
            "           Conv2d-12           [-1, 36, 18, 20]         289,332\n",
            "      BatchNorm2d-13           [-1, 36, 18, 20]              72\n",
            "             ReLU-14           [-1, 36, 18, 20]               0\n",
            "           Linear-15                    [-1, 7]       1,257,991\n",
            "================================================================\n",
            "Total params: 1,607,671\n",
            "Trainable params: 1,607,671\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.32\n",
            "Params size (MB): 6.13\n",
            "Estimated Total Size (MB): 8.46\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 20.5710, Validation Accuracy: 0.6540\n",
            "Epoch 2/100, Loss: 11.7549, Validation Accuracy: 0.6052\n",
            "Epoch 3/100, Loss: 128.7708, Validation Accuracy: 0.5005\n",
            "Epoch 4/100, Loss: 21.6515, Validation Accuracy: 0.3509\n",
            "Epoch 5/100, Loss: 44.1226, Validation Accuracy: 0.4487\n",
            "Epoch 6/100, Loss: 66.5489, Validation Accuracy: 0.5314\n",
            "Epoch 7/100, Loss: 152.0843, Validation Accuracy: 0.1874\n",
            "Epoch 8/100, Loss: 92.9537, Validation Accuracy: 0.5244\n",
            "Epoch 9/100, Loss: 93.9353, Validation Accuracy: 0.6401\n",
            "Epoch 10/100, Loss: 86.4997, Validation Accuracy: 0.6810\n",
            "Epoch 11/100, Loss: 122.3732, Validation Accuracy: 0.6610\n",
            "Epoch 12/100, Loss: 138.8429, Validation Accuracy: 0.4656\n",
            "Epoch 13/100, Loss: 91.1941, Validation Accuracy: 0.5633\n",
            "Epoch 14/100, Loss: 113.8643, Validation Accuracy: 0.6740\n",
            "Epoch 15/100, Loss: 225.3810, Validation Accuracy: 0.5813\n",
            "Epoch 16/100, Loss: 212.9723, Validation Accuracy: 0.4207\n",
            "Epoch 17/100, Loss: 88.6682, Validation Accuracy: 0.6032\n",
            "Epoch 18/100, Loss: 77.2805, Validation Accuracy: 0.5743\n",
            "Epoch 19/100, Loss: 344.4783, Validation Accuracy: 0.4367\n",
            "Epoch 20/100, Loss: 35.9993, Validation Accuracy: 0.4606\n",
            "Epoch 21/100, Loss: 67.7543, Validation Accuracy: 0.6500\n",
            "Epoch 22/100, Loss: 119.7568, Validation Accuracy: 0.5773\n",
            "Epoch 23/100, Loss: 65.9735, Validation Accuracy: 0.6451\n",
            "Epoch 24/100, Loss: 108.4688, Validation Accuracy: 0.6491\n",
            "Epoch 25/100, Loss: 80.8314, Validation Accuracy: 0.6919\n",
            "Epoch 26/100, Loss: 179.2573, Validation Accuracy: 0.5882\n",
            "Epoch 27/100, Loss: 150.9810, Validation Accuracy: 0.6889\n",
            "Epoch 28/100, Loss: 26.1520, Validation Accuracy: 0.5743\n",
            "Epoch 29/100, Loss: 82.9862, Validation Accuracy: 0.4935\n",
            "Epoch 30/100, Loss: 42.0033, Validation Accuracy: 0.6441\n",
            "Epoch 31/100, Loss: 54.6105, Validation Accuracy: 0.5633\n",
            "Epoch 32/100, Loss: 287.6331, Validation Accuracy: 0.5962\n",
            "Epoch 33/100, Loss: 139.5425, Validation Accuracy: 0.6620\n",
            "Epoch 34/100, Loss: 134.3442, Validation Accuracy: 0.5593\n",
            "Epoch 35/100, Loss: 133.3543, Validation Accuracy: 0.6839\n",
            "Epoch 36/100, Loss: 153.3989, Validation Accuracy: 0.5533\n",
            "Epoch 37/100, Loss: 214.9862, Validation Accuracy: 0.6211\n",
            "Epoch 38/100, Loss: 275.8519, Validation Accuracy: 0.6211\n",
            "Epoch 39/100, Loss: 240.8971, Validation Accuracy: 0.4307\n",
            "Epoch 40/100, Loss: 80.4661, Validation Accuracy: 0.6251\n",
            "Epoch 41/100, Loss: 112.8405, Validation Accuracy: 0.6032\n",
            "Epoch 42/100, Loss: 57.6559, Validation Accuracy: 0.6052\n",
            "Epoch 43/100, Loss: 154.2713, Validation Accuracy: 0.5902\n",
            "Epoch 44/100, Loss: 214.2449, Validation Accuracy: 0.6391\n",
            "Epoch 45/100, Loss: 65.4029, Validation Accuracy: 0.6291\n",
            "Epoch 46/100, Loss: 370.3864, Validation Accuracy: 0.6301\n",
            "Epoch 47/100, Loss: 87.1159, Validation Accuracy: 0.5374\n",
            "Epoch 48/100, Loss: 54.2965, Validation Accuracy: 0.6720\n",
            "Epoch 49/100, Loss: 34.7302, Validation Accuracy: 0.6431\n",
            "Epoch 50/100, Loss: 109.2071, Validation Accuracy: 0.6251\n",
            "Epoch 51/100, Loss: 202.7558, Validation Accuracy: 0.6869\n",
            "Epoch 52/100, Loss: 60.0551, Validation Accuracy: 0.6181\n",
            "Epoch 53/100, Loss: 223.2577, Validation Accuracy: 0.6441\n",
            "Epoch 54/100, Loss: 74.0869, Validation Accuracy: 0.6092\n",
            "Epoch 55/100, Loss: 58.1001, Validation Accuracy: 0.6720\n",
            "Epoch 56/100, Loss: 74.8216, Validation Accuracy: 0.6720\n",
            "Epoch 57/100, Loss: 255.4997, Validation Accuracy: 0.4576\n",
            "Epoch 58/100, Loss: 144.6945, Validation Accuracy: 0.6341\n",
            "Epoch 59/100, Loss: 192.4214, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 78.6886, Validation Accuracy: 0.4676\n",
            "Epoch 61/100, Loss: 45.8872, Validation Accuracy: 0.6451\n",
            "Epoch 62/100, Loss: 36.6910, Validation Accuracy: 0.6471\n",
            "Epoch 63/100, Loss: 142.1782, Validation Accuracy: 0.5972\n",
            "Epoch 64/100, Loss: 82.2571, Validation Accuracy: 0.5803\n",
            "Epoch 65/100, Loss: 27.0680, Validation Accuracy: 0.5643\n",
            "Epoch 66/100, Loss: 70.5781, Validation Accuracy: 0.6341\n",
            "Epoch 67/100, Loss: 98.2313, Validation Accuracy: 0.6171\n",
            "Epoch 68/100, Loss: 86.6651, Validation Accuracy: 0.5484\n",
            "Epoch 69/100, Loss: 94.9301, Validation Accuracy: 0.3330\n",
            "Epoch 70/100, Loss: 96.4134, Validation Accuracy: 0.6052\n",
            "Epoch 71/100, Loss: 226.6273, Validation Accuracy: 0.6341\n",
            "Epoch 72/100, Loss: 71.3983, Validation Accuracy: 0.6909\n",
            "Epoch 73/100, Loss: 80.4152, Validation Accuracy: 0.5334\n",
            "Epoch 74/100, Loss: 145.2552, Validation Accuracy: 0.6082\n",
            "Epoch 75/100, Loss: 62.7274, Validation Accuracy: 0.6560\n",
            "Epoch 76/100, Loss: 61.5596, Validation Accuracy: 0.6012\n",
            "Epoch 77/100, Loss: 167.6349, Validation Accuracy: 0.6600\n",
            "Epoch 78/100, Loss: 128.2168, Validation Accuracy: 0.5165\n",
            "Epoch 79/100, Loss: 124.8998, Validation Accuracy: 0.6710\n",
            "Epoch 80/100, Loss: 84.4727, Validation Accuracy: 0.6580\n",
            "Epoch 81/100, Loss: 280.1004, Validation Accuracy: 0.5703\n",
            "Epoch 82/100, Loss: 189.9342, Validation Accuracy: 0.6381\n",
            "Epoch 83/100, Loss: 72.1904, Validation Accuracy: 0.4566\n",
            "Epoch 84/100, Loss: 76.5775, Validation Accuracy: 0.6620\n",
            "Epoch 85/100, Loss: 82.2266, Validation Accuracy: 0.6152\n",
            "Epoch 86/100, Loss: 56.4429, Validation Accuracy: 0.5543\n",
            "Epoch 87/100, Loss: 130.9447, Validation Accuracy: 0.6042\n",
            "Epoch 88/100, Loss: 65.2069, Validation Accuracy: 0.6162\n",
            "Epoch 89/100, Loss: 106.6723, Validation Accuracy: 0.4487\n",
            "Epoch 90/100, Loss: 55.8867, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 122.1282, Validation Accuracy: 0.4855\n",
            "Epoch 92/100, Loss: 56.3915, Validation Accuracy: 0.6102\n",
            "Epoch 93/100, Loss: 179.9300, Validation Accuracy: 0.5793\n",
            "Epoch 94/100, Loss: 296.1257, Validation Accuracy: 0.5763\n",
            "Epoch 95/100, Loss: 62.8257, Validation Accuracy: 0.6301\n",
            "Epoch 96/100, Loss: 140.3957, Validation Accuracy: 0.6650\n",
            "Epoch 97/100, Loss: 139.7518, Validation Accuracy: 0.5394\n",
            "Epoch 98/100, Loss: 74.0699, Validation Accuracy: 0.6680\n",
            "Epoch 99/100, Loss: 50.0177, Validation Accuracy: 0.6381\n",
            "Epoch 100/100, Loss: 70.0279, Validation Accuracy: 0.6311\n",
            "Epoch 101/100, Loss: 78.2982, Validation Accuracy: 0.6042\n",
            "Epoch 102/100, Loss: 91.0222, Validation Accuracy: 0.5862\n",
            "Epoch 103/100, Loss: 113.1440, Validation Accuracy: 0.5862\n",
            "Epoch 104/100, Loss: 65.4197, Validation Accuracy: 0.5872\n",
            "Epoch 105/100, Loss: 163.9792, Validation Accuracy: 0.6700\n",
            "Epoch 106/100, Loss: 136.4541, Validation Accuracy: 0.6181\n",
            "Epoch 107/100, Loss: 271.4770, Validation Accuracy: 0.5912\n",
            "Epoch 108/100, Loss: 108.9715, Validation Accuracy: 0.6181\n",
            "Epoch 109/100, Loss: 277.2317, Validation Accuracy: 0.5653\n",
            "Epoch 110/100, Loss: 115.9981, Validation Accuracy: 0.5713\n",
            "Epoch 111/100, Loss: 119.3416, Validation Accuracy: 0.5513\n",
            "Epoch 112/100, Loss: 65.1418, Validation Accuracy: 0.6341\n",
            "Epoch 113/100, Loss: 58.0934, Validation Accuracy: 0.6102\n",
            "Epoch 114/100, Loss: 106.0976, Validation Accuracy: 0.6491\n",
            "Epoch 115/100, Loss: 291.0113, Validation Accuracy: 0.4955\n",
            "Epoch 116/100, Loss: 299.9444, Validation Accuracy: 0.5833\n",
            "Epoch 117/100, Loss: 123.3791, Validation Accuracy: 0.6092\n",
            "Epoch 118/100, Loss: 121.9824, Validation Accuracy: 0.5813\n",
            "Epoch 119/100, Loss: 155.2334, Validation Accuracy: 0.4905\n",
            "Epoch 120/100, Loss: 124.1420, Validation Accuracy: 0.5513\n",
            "Epoch 121/100, Loss: 59.7578, Validation Accuracy: 0.6540\n",
            "Epoch 122/100, Loss: 70.9666, Validation Accuracy: 0.6800\n",
            "Epoch 123/100, Loss: 66.1655, Validation Accuracy: 0.6610\n",
            "Epoch 124/100, Loss: 44.6130, Validation Accuracy: 0.6231\n",
            "Epoch 125/100, Loss: 145.1265, Validation Accuracy: 0.6371\n",
            "Epoch 126/100, Loss: 75.7229, Validation Accuracy: 0.5982\n",
            "Epoch 127/100, Loss: 131.1039, Validation Accuracy: 0.6401\n",
            "Epoch 128/100, Loss: 269.3307, Validation Accuracy: 0.6610\n",
            "Epoch 129/100, Loss: 264.5020, Validation Accuracy: 0.6800\n",
            "Epoch 130/100, Loss: 202.2109, Validation Accuracy: 0.6411\n",
            "Epoch 131/100, Loss: 48.7723, Validation Accuracy: 0.6251\n",
            "Epoch 132/100, Loss: 72.0018, Validation Accuracy: 0.6481\n",
            "Epoch 133/100, Loss: 117.1182, Validation Accuracy: 0.6112\n",
            "Epoch 134/100, Loss: 194.9378, Validation Accuracy: 0.5683\n",
            "Epoch 135/100, Loss: 207.1250, Validation Accuracy: 0.6042\n",
            "Epoch 136/100, Loss: 74.0335, Validation Accuracy: 0.4985\n",
            "Epoch 137/100, Loss: 176.0445, Validation Accuracy: 0.5992\n",
            "Epoch 138/100, Loss: 120.4735, Validation Accuracy: 0.5902\n",
            "Epoch 139/100, Loss: 53.0273, Validation Accuracy: 0.5414\n",
            "Epoch 140/100, Loss: 107.1654, Validation Accuracy: 0.6281\n",
            "Epoch 141/100, Loss: 153.4822, Validation Accuracy: 0.6660\n",
            "Epoch 142/100, Loss: 199.0804, Validation Accuracy: 0.6301\n",
            "Epoch 143/100, Loss: 331.6334, Validation Accuracy: 0.5384\n",
            "Epoch 144/100, Loss: 85.4622, Validation Accuracy: 0.6291\n",
            "Epoch 145/100, Loss: 40.7183, Validation Accuracy: 0.6331\n",
            "Epoch 146/100, Loss: 104.4014, Validation Accuracy: 0.4776\n",
            "Epoch 147/100, Loss: 64.6059, Validation Accuracy: 0.6002\n",
            "Epoch 148/100, Loss: 76.1548, Validation Accuracy: 0.5753\n",
            "Epoch 149/100, Loss: 75.4716, Validation Accuracy: 0.6152\n",
            "Epoch 150/100, Loss: 97.2681, Validation Accuracy: 0.5593\n",
            "Epoch 151/100, Loss: 85.5536, Validation Accuracy: 0.6062\n",
            "Epoch 152/100, Loss: 191.8045, Validation Accuracy: 0.5095\n",
            "Epoch 153/100, Loss: 128.9988, Validation Accuracy: 0.6082\n",
            "Epoch 154/100, Loss: 197.5557, Validation Accuracy: 0.5912\n",
            "Epoch 155/100, Loss: 103.8627, Validation Accuracy: 0.6241\n",
            "Epoch 156/100, Loss: 73.3633, Validation Accuracy: 0.6012\n",
            "Epoch 157/100, Loss: 49.3696, Validation Accuracy: 0.5733\n",
            "Epoch 158/100, Loss: 95.5434, Validation Accuracy: 0.5852\n",
            "Epoch 159/100, Loss: 98.0431, Validation Accuracy: 0.5902\n",
            "Epoch 160/100, Loss: 100.7121, Validation Accuracy: 0.6331\n",
            "Epoch 161/100, Loss: 123.3696, Validation Accuracy: 0.6570\n",
            "Epoch 162/100, Loss: 95.1682, Validation Accuracy: 0.5912\n",
            "Epoch 163/100, Loss: 238.6505, Validation Accuracy: 0.5603\n",
            "Epoch 164/100, Loss: 69.7707, Validation Accuracy: 0.6750\n",
            "Epoch 165/100, Loss: 36.5280, Validation Accuracy: 0.6301\n",
            "Epoch 166/100, Loss: 21.2777, Validation Accuracy: 0.5155\n",
            "Epoch 167/100, Loss: 30.3806, Validation Accuracy: 0.5733\n",
            "Epoch 168/100, Loss: 66.7367, Validation Accuracy: 0.6281\n",
            "Epoch 169/100, Loss: 117.5024, Validation Accuracy: 0.5434\n",
            "Epoch 170/100, Loss: 165.2312, Validation Accuracy: 0.5673\n",
            "Epoch 171/100, Loss: 79.4665, Validation Accuracy: 0.6650\n",
            "Epoch 172/100, Loss: 63.2910, Validation Accuracy: 0.6162\n",
            "Epoch 173/100, Loss: 69.1099, Validation Accuracy: 0.6201\n",
            "Epoch 174/100, Loss: 91.2334, Validation Accuracy: 0.6152\n",
            "Epoch 175/100, Loss: 90.0592, Validation Accuracy: 0.6500\n",
            "Epoch 176/100, Loss: 173.3488, Validation Accuracy: 0.6092\n",
            "Epoch 177/100, Loss: 93.6232, Validation Accuracy: 0.6550\n",
            "Epoch 178/100, Loss: 92.2699, Validation Accuracy: 0.5982\n",
            "Epoch 179/100, Loss: 73.1712, Validation Accuracy: 0.4367\n",
            "Epoch 180/100, Loss: 126.3622, Validation Accuracy: 0.5833\n",
            "Epoch 181/100, Loss: 68.4998, Validation Accuracy: 0.6311\n",
            "Epoch 182/100, Loss: 193.4634, Validation Accuracy: 0.6102\n",
            "Epoch 183/100, Loss: 44.5795, Validation Accuracy: 0.6839\n",
            "Epoch 184/100, Loss: 126.6727, Validation Accuracy: 0.5912\n",
            "Epoch 185/100, Loss: 126.5777, Validation Accuracy: 0.5494\n",
            "Epoch 186/100, Loss: 97.6542, Validation Accuracy: 0.5872\n",
            "Epoch 187/100, Loss: 65.3888, Validation Accuracy: 0.6321\n",
            "Epoch 188/100, Loss: 20.5255, Validation Accuracy: 0.6251\n",
            "Epoch 189/100, Loss: 54.3901, Validation Accuracy: 0.5374\n",
            "Epoch 190/100, Loss: 82.8604, Validation Accuracy: 0.6451\n",
            "Epoch 191/100, Loss: 52.3992, Validation Accuracy: 0.6730\n",
            "Epoch 192/100, Loss: 213.4864, Validation Accuracy: 0.5872\n",
            "Epoch 193/100, Loss: 109.2238, Validation Accuracy: 0.6560\n",
            "Epoch 194/100, Loss: 60.7722, Validation Accuracy: 0.6570\n",
            "Epoch 195/100, Loss: 129.2012, Validation Accuracy: 0.6680\n",
            "Epoch 196/100, Loss: 37.1467, Validation Accuracy: 0.5663\n",
            "Epoch 197/100, Loss: 94.0316, Validation Accuracy: 0.6291\n",
            "Epoch 198/100, Loss: 634.2343, Validation Accuracy: 0.6291\n",
            "Epoch 199/100, Loss: 70.8593, Validation Accuracy: 0.6271\n",
            "Epoch 200/100, Loss: 140.7330, Validation Accuracy: 0.6540\n",
            "Reward for Child Model: 0.2797748805989118\n",
            "Child_48:  {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, [2, 1, 3, 0, 0, 0, 1, 3, 3, 2, 0, 1, 3, 3, 1], 0.2797748805989118\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(128, 24, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(152, 48, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(392, 64, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=459264, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 26, 24]           2,944\n",
            "       BatchNorm2d-2           [-1, 64, 26, 24]             128\n",
            "            Conv2d-3           [-1, 64, 22, 24]          20,544\n",
            "       BatchNorm2d-4           [-1, 64, 22, 24]             128\n",
            "              ReLU-5           [-1, 64, 22, 24]               0\n",
            "            Conv2d-6           [-1, 24, 20, 22]          64,536\n",
            "       BatchNorm2d-7           [-1, 24, 20, 22]              48\n",
            "              ReLU-8           [-1, 24, 20, 22]               0\n",
            "            Conv2d-9           [-1, 48, 24, 22]          65,712\n",
            "      BatchNorm2d-10           [-1, 48, 24, 22]              96\n",
            "             ReLU-11           [-1, 48, 24, 22]               0\n",
            "           Conv2d-12           [-1, 64, 20, 20]         878,144\n",
            "      BatchNorm2d-13           [-1, 64, 20, 20]             128\n",
            "             ReLU-14           [-1, 64, 20, 20]               0\n",
            "           Linear-15                    [-1, 7]       3,214,855\n",
            "================================================================\n",
            "Total params: 4,247,263\n",
            "Trainable params: 4,247,263\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.79\n",
            "Params size (MB): 16.20\n",
            "Estimated Total Size (MB): 19.00\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 94.2961, Validation Accuracy: 0.6142\n",
            "Epoch 2/100, Loss: 300.4695, Validation Accuracy: 0.3410\n",
            "Epoch 3/100, Loss: 507.6671, Validation Accuracy: 0.6181\n",
            "Epoch 4/100, Loss: 237.8968, Validation Accuracy: 0.5513\n",
            "Epoch 5/100, Loss: 186.1146, Validation Accuracy: 0.6680\n",
            "Epoch 6/100, Loss: 400.0596, Validation Accuracy: 0.5962\n",
            "Epoch 7/100, Loss: 170.9149, Validation Accuracy: 0.5882\n",
            "Epoch 8/100, Loss: 104.2432, Validation Accuracy: 0.6680\n",
            "Epoch 9/100, Loss: 218.3720, Validation Accuracy: 0.6810\n",
            "Epoch 10/100, Loss: 517.9136, Validation Accuracy: 0.6710\n",
            "Epoch 11/100, Loss: 348.8449, Validation Accuracy: 0.5513\n",
            "Epoch 12/100, Loss: 189.8858, Validation Accuracy: 0.4965\n",
            "Epoch 13/100, Loss: 183.3253, Validation Accuracy: 0.6251\n",
            "Epoch 14/100, Loss: 325.0820, Validation Accuracy: 0.6411\n",
            "Epoch 15/100, Loss: 255.6966, Validation Accuracy: 0.5932\n",
            "Epoch 16/100, Loss: 231.8934, Validation Accuracy: 0.6660\n",
            "Epoch 17/100, Loss: 835.1682, Validation Accuracy: 0.5573\n",
            "Epoch 18/100, Loss: 164.2688, Validation Accuracy: 0.5264\n",
            "Epoch 19/100, Loss: 246.5485, Validation Accuracy: 0.4915\n",
            "Epoch 20/100, Loss: 315.2406, Validation Accuracy: 0.6311\n",
            "Epoch 21/100, Loss: 123.7029, Validation Accuracy: 0.5274\n",
            "Epoch 22/100, Loss: 171.2962, Validation Accuracy: 0.6520\n",
            "Epoch 23/100, Loss: 287.6135, Validation Accuracy: 0.5304\n",
            "Epoch 24/100, Loss: 346.2366, Validation Accuracy: 0.6790\n",
            "Epoch 25/100, Loss: 456.0075, Validation Accuracy: 0.6002\n",
            "Epoch 26/100, Loss: 217.2047, Validation Accuracy: 0.4287\n",
            "Epoch 27/100, Loss: 109.6402, Validation Accuracy: 0.6720\n",
            "Epoch 28/100, Loss: 934.3055, Validation Accuracy: 0.4676\n",
            "Epoch 29/100, Loss: 227.3050, Validation Accuracy: 0.6381\n",
            "Epoch 30/100, Loss: 317.1138, Validation Accuracy: 0.6132\n",
            "Epoch 31/100, Loss: 244.7523, Validation Accuracy: 0.5803\n",
            "Epoch 32/100, Loss: 298.7568, Validation Accuracy: 0.6610\n",
            "Epoch 33/100, Loss: 281.0880, Validation Accuracy: 0.5234\n",
            "Epoch 34/100, Loss: 146.9569, Validation Accuracy: 0.6321\n",
            "Epoch 35/100, Loss: 314.8278, Validation Accuracy: 0.5364\n",
            "Epoch 36/100, Loss: 177.1726, Validation Accuracy: 0.6610\n",
            "Epoch 37/100, Loss: 759.4485, Validation Accuracy: 0.6341\n",
            "Epoch 38/100, Loss: 475.3634, Validation Accuracy: 0.6869\n",
            "Epoch 39/100, Loss: 326.8263, Validation Accuracy: 0.5454\n",
            "Epoch 40/100, Loss: 222.5252, Validation Accuracy: 0.6481\n",
            "Epoch 41/100, Loss: 626.7012, Validation Accuracy: 0.6919\n",
            "Epoch 42/100, Loss: 412.8184, Validation Accuracy: 0.5852\n",
            "Epoch 43/100, Loss: 313.3106, Validation Accuracy: 0.6999\n",
            "Epoch 44/100, Loss: 357.7536, Validation Accuracy: 0.5613\n",
            "Epoch 45/100, Loss: 408.1445, Validation Accuracy: 0.6421\n",
            "Epoch 46/100, Loss: 81.5155, Validation Accuracy: 0.5673\n",
            "Epoch 47/100, Loss: 309.0147, Validation Accuracy: 0.6381\n",
            "Epoch 48/100, Loss: 450.2630, Validation Accuracy: 0.6560\n",
            "Epoch 49/100, Loss: 108.7964, Validation Accuracy: 0.5603\n",
            "Epoch 50/100, Loss: 184.0542, Validation Accuracy: 0.6371\n",
            "Epoch 51/100, Loss: 174.4573, Validation Accuracy: 0.4457\n",
            "Epoch 52/100, Loss: 263.0877, Validation Accuracy: 0.6510\n",
            "Epoch 53/100, Loss: 280.2628, Validation Accuracy: 0.6730\n",
            "Epoch 54/100, Loss: 136.9774, Validation Accuracy: 0.6411\n",
            "Epoch 55/100, Loss: 309.9691, Validation Accuracy: 0.6680\n",
            "Epoch 56/100, Loss: 131.4965, Validation Accuracy: 0.6899\n",
            "Epoch 57/100, Loss: 429.3041, Validation Accuracy: 0.4935\n",
            "Epoch 58/100, Loss: 211.7128, Validation Accuracy: 0.6810\n",
            "Epoch 59/100, Loss: 293.6677, Validation Accuracy: 0.6500\n",
            "Epoch 60/100, Loss: 200.3726, Validation Accuracy: 0.6530\n",
            "Epoch 61/100, Loss: 113.4259, Validation Accuracy: 0.6949\n",
            "Epoch 62/100, Loss: 290.8867, Validation Accuracy: 0.5823\n",
            "Epoch 63/100, Loss: 209.4954, Validation Accuracy: 0.6092\n",
            "Epoch 64/100, Loss: 272.0980, Validation Accuracy: 0.6471\n",
            "Epoch 65/100, Loss: 487.9740, Validation Accuracy: 0.5274\n",
            "Epoch 66/100, Loss: 253.7149, Validation Accuracy: 0.6022\n",
            "Epoch 67/100, Loss: 408.0553, Validation Accuracy: 0.6610\n",
            "Epoch 68/100, Loss: 189.5301, Validation Accuracy: 0.6830\n",
            "Epoch 69/100, Loss: 216.2204, Validation Accuracy: 0.7019\n",
            "Epoch 70/100, Loss: 281.8939, Validation Accuracy: 0.6251\n",
            "Epoch 71/100, Loss: 295.8464, Validation Accuracy: 0.6162\n",
            "Epoch 72/100, Loss: 526.9626, Validation Accuracy: 0.5793\n",
            "Epoch 73/100, Loss: 244.2210, Validation Accuracy: 0.4995\n",
            "Epoch 74/100, Loss: 954.6551, Validation Accuracy: 0.6580\n",
            "Epoch 75/100, Loss: 301.1534, Validation Accuracy: 0.6132\n",
            "Epoch 76/100, Loss: 202.3459, Validation Accuracy: 0.5713\n",
            "Epoch 77/100, Loss: 379.4398, Validation Accuracy: 0.6869\n",
            "Epoch 78/100, Loss: 450.7741, Validation Accuracy: 0.6770\n",
            "Epoch 79/100, Loss: 298.4595, Validation Accuracy: 0.6481\n",
            "Epoch 80/100, Loss: 591.7845, Validation Accuracy: 0.5354\n",
            "Epoch 81/100, Loss: 482.5385, Validation Accuracy: 0.6580\n",
            "Epoch 82/100, Loss: 272.8278, Validation Accuracy: 0.5494\n",
            "Epoch 83/100, Loss: 308.8893, Validation Accuracy: 0.5783\n",
            "Epoch 84/100, Loss: 243.3066, Validation Accuracy: 0.5484\n",
            "Epoch 85/100, Loss: 121.9044, Validation Accuracy: 0.4935\n",
            "Epoch 86/100, Loss: 352.0055, Validation Accuracy: 0.6909\n",
            "Epoch 87/100, Loss: 376.8632, Validation Accuracy: 0.6271\n",
            "Epoch 88/100, Loss: 548.0196, Validation Accuracy: 0.6152\n",
            "Epoch 89/100, Loss: 303.3876, Validation Accuracy: 0.6271\n",
            "Epoch 90/100, Loss: 392.5634, Validation Accuracy: 0.6301\n",
            "Epoch 91/100, Loss: 331.8384, Validation Accuracy: 0.6849\n",
            "Epoch 92/100, Loss: 342.7405, Validation Accuracy: 0.5992\n",
            "Epoch 93/100, Loss: 224.0914, Validation Accuracy: 0.6660\n",
            "Epoch 94/100, Loss: 219.5813, Validation Accuracy: 0.6351\n",
            "Epoch 95/100, Loss: 373.5992, Validation Accuracy: 0.6421\n",
            "Epoch 96/100, Loss: 343.2755, Validation Accuracy: 0.6500\n",
            "Epoch 97/100, Loss: 536.1973, Validation Accuracy: 0.5813\n",
            "Epoch 98/100, Loss: 371.2149, Validation Accuracy: 0.6790\n",
            "Epoch 99/100, Loss: 169.2150, Validation Accuracy: 0.6879\n",
            "Epoch 100/100, Loss: 162.7416, Validation Accuracy: 0.6859\n",
            "Epoch 101/100, Loss: 173.2913, Validation Accuracy: 0.6381\n",
            "Epoch 102/100, Loss: 150.1189, Validation Accuracy: 0.6720\n",
            "Epoch 103/100, Loss: 95.1253, Validation Accuracy: 0.6610\n",
            "Epoch 104/100, Loss: 800.9919, Validation Accuracy: 0.6580\n",
            "Epoch 105/100, Loss: 429.5869, Validation Accuracy: 0.5972\n",
            "Epoch 106/100, Loss: 238.7289, Validation Accuracy: 0.6231\n",
            "Epoch 107/100, Loss: 242.9603, Validation Accuracy: 0.6730\n",
            "Epoch 108/100, Loss: 240.8880, Validation Accuracy: 0.6710\n",
            "Epoch 109/100, Loss: 553.0015, Validation Accuracy: 0.6321\n",
            "Epoch 110/100, Loss: 398.2515, Validation Accuracy: 0.6361\n",
            "Epoch 111/100, Loss: 414.6307, Validation Accuracy: 0.5035\n",
            "Epoch 112/100, Loss: 394.5735, Validation Accuracy: 0.5803\n",
            "Epoch 113/100, Loss: 153.0784, Validation Accuracy: 0.6540\n",
            "Epoch 114/100, Loss: 623.3992, Validation Accuracy: 0.6411\n",
            "Epoch 115/100, Loss: 177.0639, Validation Accuracy: 0.6271\n",
            "Epoch 116/100, Loss: 306.8555, Validation Accuracy: 0.6510\n",
            "Epoch 117/100, Loss: 301.6920, Validation Accuracy: 0.6550\n",
            "Epoch 118/100, Loss: 313.1061, Validation Accuracy: 0.6142\n",
            "Epoch 119/100, Loss: 657.1701, Validation Accuracy: 0.6461\n",
            "Epoch 120/100, Loss: 142.9272, Validation Accuracy: 0.6042\n",
            "Epoch 121/100, Loss: 39.7792, Validation Accuracy: 0.6371\n",
            "Epoch 122/100, Loss: 93.8691, Validation Accuracy: 0.6191\n",
            "Epoch 123/100, Loss: 456.5420, Validation Accuracy: 0.6889\n",
            "Epoch 124/100, Loss: 800.0366, Validation Accuracy: 0.5474\n",
            "Epoch 125/100, Loss: 296.7691, Validation Accuracy: 0.5972\n",
            "Epoch 126/100, Loss: 215.7772, Validation Accuracy: 0.6780\n",
            "Epoch 127/100, Loss: 104.7001, Validation Accuracy: 0.6720\n",
            "Epoch 128/100, Loss: 877.6319, Validation Accuracy: 0.6620\n",
            "Epoch 129/100, Loss: 117.0574, Validation Accuracy: 0.5922\n",
            "Epoch 130/100, Loss: 276.2911, Validation Accuracy: 0.6680\n",
            "Epoch 131/100, Loss: 510.6723, Validation Accuracy: 0.6590\n",
            "Epoch 132/100, Loss: 405.2184, Validation Accuracy: 0.6072\n",
            "Epoch 133/100, Loss: 284.0599, Validation Accuracy: 0.6889\n",
            "Epoch 134/100, Loss: 235.7320, Validation Accuracy: 0.6630\n",
            "Epoch 135/100, Loss: 344.8198, Validation Accuracy: 0.6830\n",
            "Epoch 136/100, Loss: 333.0941, Validation Accuracy: 0.6560\n",
            "Epoch 137/100, Loss: 396.4944, Validation Accuracy: 0.6760\n",
            "Epoch 138/100, Loss: 444.5856, Validation Accuracy: 0.6839\n",
            "Epoch 139/100, Loss: 247.3797, Validation Accuracy: 0.6491\n",
            "Epoch 140/100, Loss: 279.6588, Validation Accuracy: 0.6371\n",
            "Epoch 141/100, Loss: 357.8376, Validation Accuracy: 0.6520\n",
            "Epoch 142/100, Loss: 669.5170, Validation Accuracy: 0.5623\n",
            "Epoch 143/100, Loss: 380.1755, Validation Accuracy: 0.6590\n",
            "Epoch 144/100, Loss: 84.3061, Validation Accuracy: 0.6361\n",
            "Epoch 145/100, Loss: 344.9740, Validation Accuracy: 0.6740\n",
            "Epoch 146/100, Loss: 149.0697, Validation Accuracy: 0.6670\n",
            "Epoch 147/100, Loss: 426.6573, Validation Accuracy: 0.6590\n",
            "Epoch 148/100, Loss: 112.8327, Validation Accuracy: 0.5753\n",
            "Epoch 149/100, Loss: 89.2613, Validation Accuracy: 0.5803\n",
            "Epoch 150/100, Loss: 252.3151, Validation Accuracy: 0.6540\n",
            "Epoch 151/100, Loss: 158.6010, Validation Accuracy: 0.6062\n",
            "Epoch 152/100, Loss: 297.3911, Validation Accuracy: 0.6770\n",
            "Epoch 153/100, Loss: 219.9911, Validation Accuracy: 0.7019\n",
            "Epoch 154/100, Loss: 430.6930, Validation Accuracy: 0.6451\n",
            "Epoch 155/100, Loss: 292.2340, Validation Accuracy: 0.5942\n",
            "Epoch 156/100, Loss: 103.8534, Validation Accuracy: 0.6839\n",
            "Epoch 157/100, Loss: 825.2549, Validation Accuracy: 0.6760\n",
            "Epoch 158/100, Loss: 472.1313, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 161.4781, Validation Accuracy: 0.5922\n",
            "Epoch 160/100, Loss: 280.9107, Validation Accuracy: 0.6092\n",
            "Epoch 161/100, Loss: 133.9954, Validation Accuracy: 0.6152\n",
            "Epoch 162/100, Loss: 189.3101, Validation Accuracy: 0.6311\n",
            "Epoch 163/100, Loss: 319.6958, Validation Accuracy: 0.6421\n",
            "Epoch 164/100, Loss: 347.1656, Validation Accuracy: 0.6301\n",
            "Epoch 165/100, Loss: 560.2090, Validation Accuracy: 0.6800\n",
            "Epoch 166/100, Loss: 647.0807, Validation Accuracy: 0.6600\n",
            "Epoch 167/100, Loss: 340.3133, Validation Accuracy: 0.6770\n",
            "Epoch 168/100, Loss: 213.8327, Validation Accuracy: 0.6810\n",
            "Epoch 169/100, Loss: 244.1435, Validation Accuracy: 0.6630\n",
            "Epoch 170/100, Loss: 610.9708, Validation Accuracy: 0.6132\n",
            "Epoch 171/100, Loss: 697.2121, Validation Accuracy: 0.6710\n",
            "Epoch 172/100, Loss: 421.2179, Validation Accuracy: 0.6710\n",
            "Epoch 173/100, Loss: 198.8507, Validation Accuracy: 0.6510\n",
            "Epoch 174/100, Loss: 363.1581, Validation Accuracy: 0.6291\n",
            "Epoch 175/100, Loss: 393.3991, Validation Accuracy: 0.6879\n",
            "Epoch 176/100, Loss: 288.7364, Validation Accuracy: 0.6660\n",
            "Epoch 177/100, Loss: 118.7668, Validation Accuracy: 0.6810\n",
            "Epoch 178/100, Loss: 336.0606, Validation Accuracy: 0.6371\n",
            "Epoch 179/100, Loss: 881.6286, Validation Accuracy: 0.5703\n",
            "Epoch 180/100, Loss: 243.1051, Validation Accuracy: 0.6421\n",
            "Epoch 181/100, Loss: 344.1055, Validation Accuracy: 0.6620\n",
            "Epoch 182/100, Loss: 481.2392, Validation Accuracy: 0.5783\n",
            "Epoch 183/100, Loss: 411.7590, Validation Accuracy: 0.6710\n",
            "Epoch 184/100, Loss: 222.2545, Validation Accuracy: 0.6760\n",
            "Epoch 185/100, Loss: 573.5895, Validation Accuracy: 0.5623\n",
            "Epoch 186/100, Loss: 296.6201, Validation Accuracy: 0.6241\n",
            "Epoch 187/100, Loss: 327.6621, Validation Accuracy: 0.5763\n",
            "Epoch 188/100, Loss: 1209.2933, Validation Accuracy: 0.6321\n",
            "Epoch 189/100, Loss: 134.0883, Validation Accuracy: 0.6311\n",
            "Epoch 190/100, Loss: 34.2586, Validation Accuracy: 0.6610\n",
            "Epoch 191/100, Loss: 168.9977, Validation Accuracy: 0.6441\n",
            "Epoch 192/100, Loss: 48.1299, Validation Accuracy: 0.6221\n",
            "Epoch 193/100, Loss: 292.9681, Validation Accuracy: 0.5852\n",
            "Epoch 194/100, Loss: 595.8320, Validation Accuracy: 0.6261\n",
            "Epoch 195/100, Loss: 332.7545, Validation Accuracy: 0.6859\n",
            "Epoch 196/100, Loss: 303.3210, Validation Accuracy: 0.6650\n",
            "Epoch 197/100, Loss: 282.1022, Validation Accuracy: 0.6650\n",
            "Epoch 198/100, Loss: 82.5163, Validation Accuracy: 0.6560\n",
            "Epoch 199/100, Loss: 285.3710, Validation Accuracy: 0.6291\n",
            "Epoch 200/100, Loss: 219.3486, Validation Accuracy: 0.6311\n",
            "Reward for Child Model: 0.294086238583974\n",
            "Child_49:  {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, [1, 2, 3, 2, 0, 3, 3, 1, 0, 1, 1, 2, 3, 2, 3], 0.294086238583974\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(64, 36, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(100, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(264, 36, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=171600, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 22, 26]           4,096\n",
            "       BatchNorm2d-2           [-1, 64, 22, 26]             128\n",
            "            Conv2d-3           [-1, 64, 16, 26]          28,736\n",
            "       BatchNorm2d-4           [-1, 64, 16, 26]             128\n",
            "              ReLU-5           [-1, 64, 16, 26]               0\n",
            "            Conv2d-6           [-1, 36, 10, 26]          16,164\n",
            "       BatchNorm2d-7           [-1, 36, 10, 26]              72\n",
            "              ReLU-8           [-1, 36, 10, 26]               0\n",
            "            Conv2d-9           [-1, 36, 16, 20]          25,236\n",
            "      BatchNorm2d-10           [-1, 36, 16, 20]              72\n",
            "             ReLU-11           [-1, 36, 16, 20]               0\n",
            "           Conv2d-12           [-1, 36, 18, 24]         142,596\n",
            "      BatchNorm2d-13           [-1, 36, 18, 24]              72\n",
            "             ReLU-14           [-1, 36, 18, 24]               0\n",
            "           Linear-15                    [-1, 7]       1,201,207\n",
            "================================================================\n",
            "Total params: 1,418,507\n",
            "Trainable params: 1,418,507\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.00\n",
            "Params size (MB): 5.41\n",
            "Estimated Total Size (MB): 7.42\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 14.3598, Validation Accuracy: 0.5563\n",
            "Epoch 2/100, Loss: 137.9381, Validation Accuracy: 0.3519\n",
            "Epoch 3/100, Loss: 85.6196, Validation Accuracy: 0.5813\n",
            "Epoch 4/100, Loss: 53.0020, Validation Accuracy: 0.5723\n",
            "Epoch 5/100, Loss: 1612.1117, Validation Accuracy: 0.6142\n",
            "Epoch 6/100, Loss: 434.8180, Validation Accuracy: 0.6471\n",
            "Epoch 7/100, Loss: 344.3206, Validation Accuracy: 0.6491\n",
            "Epoch 8/100, Loss: 90.3584, Validation Accuracy: 0.6261\n",
            "Epoch 9/100, Loss: 90.9858, Validation Accuracy: 0.5962\n",
            "Epoch 10/100, Loss: 52.1070, Validation Accuracy: 0.5464\n",
            "Epoch 11/100, Loss: 18.9374, Validation Accuracy: 0.6580\n",
            "Epoch 12/100, Loss: 14.0334, Validation Accuracy: 0.5344\n",
            "Epoch 13/100, Loss: 9.4053, Validation Accuracy: 0.6500\n",
            "Epoch 14/100, Loss: 21.5797, Validation Accuracy: 0.5932\n",
            "Epoch 15/100, Loss: 11.8918, Validation Accuracy: 0.5484\n",
            "Epoch 16/100, Loss: 12.8704, Validation Accuracy: 0.6361\n",
            "Epoch 17/100, Loss: 32.9238, Validation Accuracy: 0.6461\n",
            "Epoch 18/100, Loss: 9.8406, Validation Accuracy: 0.5294\n",
            "Epoch 19/100, Loss: 6.3496, Validation Accuracy: 0.6431\n",
            "Epoch 20/100, Loss: 5.9545, Validation Accuracy: 0.4995\n",
            "Epoch 21/100, Loss: 8.1434, Validation Accuracy: 0.4247\n",
            "Epoch 22/100, Loss: 10.5128, Validation Accuracy: 0.5703\n",
            "Epoch 23/100, Loss: 55.3600, Validation Accuracy: 0.2453\n",
            "Epoch 24/100, Loss: 15.3631, Validation Accuracy: 0.6461\n",
            "Epoch 25/100, Loss: 29.0896, Validation Accuracy: 0.5254\n",
            "Epoch 26/100, Loss: 56.2476, Validation Accuracy: 0.6102\n",
            "Epoch 27/100, Loss: 352.6465, Validation Accuracy: 0.2951\n",
            "Epoch 28/100, Loss: 26.8931, Validation Accuracy: 0.6132\n",
            "Epoch 29/100, Loss: 10.9798, Validation Accuracy: 0.4726\n",
            "Epoch 30/100, Loss: 10.4169, Validation Accuracy: 0.6281\n",
            "Epoch 31/100, Loss: 5.3450, Validation Accuracy: 0.5613\n",
            "Epoch 32/100, Loss: 52.7966, Validation Accuracy: 0.5434\n",
            "Epoch 33/100, Loss: 12.5417, Validation Accuracy: 0.6241\n",
            "Epoch 34/100, Loss: 687.4179, Validation Accuracy: 0.6650\n",
            "Epoch 35/100, Loss: 66.7791, Validation Accuracy: 0.4895\n",
            "Epoch 36/100, Loss: 21.3642, Validation Accuracy: 0.6181\n",
            "Epoch 37/100, Loss: 130.7746, Validation Accuracy: 0.6520\n",
            "Epoch 38/100, Loss: 14.8062, Validation Accuracy: 0.6211\n",
            "Epoch 39/100, Loss: 33.1780, Validation Accuracy: 0.6441\n",
            "Epoch 40/100, Loss: 31.7045, Validation Accuracy: 0.6431\n",
            "Epoch 41/100, Loss: 9.6876, Validation Accuracy: 0.5982\n",
            "Epoch 42/100, Loss: 102.1341, Validation Accuracy: 0.4776\n",
            "Epoch 43/100, Loss: 19.0467, Validation Accuracy: 0.5982\n",
            "Epoch 44/100, Loss: 14.9332, Validation Accuracy: 0.6411\n",
            "Epoch 45/100, Loss: 28.4650, Validation Accuracy: 0.5254\n",
            "Epoch 46/100, Loss: 20.0791, Validation Accuracy: 0.5444\n",
            "Epoch 47/100, Loss: 37.4306, Validation Accuracy: 0.6780\n",
            "Epoch 48/100, Loss: 41.5083, Validation Accuracy: 0.6311\n",
            "Epoch 49/100, Loss: 54.5663, Validation Accuracy: 0.5663\n",
            "Epoch 50/100, Loss: 629.3940, Validation Accuracy: 0.5723\n",
            "Epoch 51/100, Loss: 53.1653, Validation Accuracy: 0.6530\n",
            "Epoch 52/100, Loss: 18.8201, Validation Accuracy: 0.4955\n",
            "Epoch 53/100, Loss: 1071.5466, Validation Accuracy: 0.1097\n",
            "Epoch 54/100, Loss: 28.3397, Validation Accuracy: 0.6311\n",
            "Epoch 55/100, Loss: 21.9317, Validation Accuracy: 0.5055\n",
            "Epoch 56/100, Loss: 13.4236, Validation Accuracy: 0.5563\n",
            "Epoch 57/100, Loss: 19.3995, Validation Accuracy: 0.6859\n",
            "Epoch 58/100, Loss: 9.3708, Validation Accuracy: 0.6361\n",
            "Epoch 59/100, Loss: 14.0407, Validation Accuracy: 0.6421\n",
            "Epoch 60/100, Loss: 20.2766, Validation Accuracy: 0.4915\n",
            "Epoch 61/100, Loss: 22.9217, Validation Accuracy: 0.5563\n",
            "Epoch 62/100, Loss: 15.3711, Validation Accuracy: 0.6042\n",
            "Epoch 63/100, Loss: 29.8089, Validation Accuracy: 0.6610\n",
            "Epoch 64/100, Loss: 46.3868, Validation Accuracy: 0.6720\n",
            "Epoch 65/100, Loss: 62.5404, Validation Accuracy: 0.6191\n",
            "Epoch 66/100, Loss: 444.5485, Validation Accuracy: 0.5284\n",
            "Epoch 67/100, Loss: 18.3448, Validation Accuracy: 0.5543\n",
            "Epoch 68/100, Loss: 74.7091, Validation Accuracy: 0.6520\n",
            "Epoch 69/100, Loss: 11.1520, Validation Accuracy: 0.5922\n",
            "Epoch 70/100, Loss: 15.7535, Validation Accuracy: 0.4955\n",
            "Epoch 71/100, Loss: 10.7463, Validation Accuracy: 0.6889\n",
            "Epoch 72/100, Loss: 1429.1464, Validation Accuracy: 0.6500\n",
            "Epoch 73/100, Loss: 26.1109, Validation Accuracy: 0.6142\n",
            "Epoch 74/100, Loss: 13.4708, Validation Accuracy: 0.6640\n",
            "Epoch 75/100, Loss: 8.3785, Validation Accuracy: 0.5414\n",
            "Epoch 76/100, Loss: 3.6784, Validation Accuracy: 0.6152\n",
            "Epoch 77/100, Loss: 10.4865, Validation Accuracy: 0.5912\n",
            "Epoch 78/100, Loss: 14.8221, Validation Accuracy: 0.4457\n",
            "Epoch 79/100, Loss: 9.2281, Validation Accuracy: 0.6301\n",
            "Epoch 80/100, Loss: 60.7990, Validation Accuracy: 0.6002\n",
            "Epoch 81/100, Loss: 21.2035, Validation Accuracy: 0.6750\n",
            "Epoch 82/100, Loss: 16.2575, Validation Accuracy: 0.5603\n",
            "Epoch 83/100, Loss: 303.7112, Validation Accuracy: 0.0538\n",
            "Epoch 84/100, Loss: 27.9554, Validation Accuracy: 0.6211\n",
            "Epoch 85/100, Loss: 15.9805, Validation Accuracy: 0.4497\n",
            "Epoch 86/100, Loss: 20.1281, Validation Accuracy: 0.5244\n",
            "Epoch 87/100, Loss: 16.4536, Validation Accuracy: 0.6341\n",
            "Epoch 88/100, Loss: 9.2473, Validation Accuracy: 0.5174\n",
            "Epoch 89/100, Loss: 14.6608, Validation Accuracy: 0.3958\n",
            "Epoch 90/100, Loss: 15.1075, Validation Accuracy: 0.6241\n",
            "Epoch 91/100, Loss: 48.0373, Validation Accuracy: 0.6421\n",
            "Epoch 92/100, Loss: 50.9540, Validation Accuracy: 0.4626\n",
            "Epoch 93/100, Loss: 28.2964, Validation Accuracy: 0.5962\n",
            "Epoch 94/100, Loss: 31.3742, Validation Accuracy: 0.5813\n",
            "Epoch 95/100, Loss: 34.2011, Validation Accuracy: 0.5344\n",
            "Epoch 96/100, Loss: 44.0877, Validation Accuracy: 0.6500\n",
            "Epoch 97/100, Loss: 48.8607, Validation Accuracy: 0.6650\n",
            "Epoch 98/100, Loss: 45.7215, Validation Accuracy: 0.6181\n",
            "Epoch 99/100, Loss: 37.4309, Validation Accuracy: 0.5563\n",
            "Epoch 100/100, Loss: 18.1642, Validation Accuracy: 0.5593\n",
            "Epoch 101/100, Loss: 125.2378, Validation Accuracy: 0.6750\n",
            "Epoch 102/100, Loss: 35.1624, Validation Accuracy: 0.6201\n",
            "Epoch 103/100, Loss: 12.1169, Validation Accuracy: 0.3968\n",
            "Epoch 104/100, Loss: 30.0177, Validation Accuracy: 0.6251\n",
            "Epoch 105/100, Loss: 44.3807, Validation Accuracy: 0.6261\n",
            "Epoch 106/100, Loss: 28.7555, Validation Accuracy: 0.6780\n",
            "Epoch 107/100, Loss: 21.0036, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 58.5791, Validation Accuracy: 0.5952\n",
            "Epoch 109/100, Loss: 57.2673, Validation Accuracy: 0.4696\n",
            "Epoch 110/100, Loss: 60.1729, Validation Accuracy: 0.3340\n",
            "Epoch 111/100, Loss: 18.7753, Validation Accuracy: 0.5803\n",
            "Epoch 112/100, Loss: 97.0296, Validation Accuracy: 0.6042\n",
            "Epoch 113/100, Loss: 16.0175, Validation Accuracy: 0.6241\n",
            "Epoch 114/100, Loss: 23.1824, Validation Accuracy: 0.4556\n",
            "Epoch 115/100, Loss: 35.4742, Validation Accuracy: 0.5992\n",
            "Epoch 116/100, Loss: 12.6950, Validation Accuracy: 0.6520\n",
            "Epoch 117/100, Loss: 25.5739, Validation Accuracy: 0.4756\n",
            "Epoch 118/100, Loss: 24.8479, Validation Accuracy: 0.6630\n",
            "Epoch 119/100, Loss: 16.9828, Validation Accuracy: 0.4935\n",
            "Epoch 120/100, Loss: 1.6696, Validation Accuracy: 0.6770\n",
            "Epoch 121/100, Loss: 11.8473, Validation Accuracy: 0.5464\n",
            "Epoch 122/100, Loss: 17.2766, Validation Accuracy: 0.6072\n",
            "Epoch 123/100, Loss: 45.2630, Validation Accuracy: 0.3500\n",
            "Epoch 124/100, Loss: 17.9551, Validation Accuracy: 0.5364\n",
            "Epoch 125/100, Loss: 133.8179, Validation Accuracy: 0.5922\n",
            "Epoch 126/100, Loss: 48.9265, Validation Accuracy: 0.5793\n",
            "Epoch 127/100, Loss: 32.1598, Validation Accuracy: 0.5813\n",
            "Epoch 128/100, Loss: 232.9394, Validation Accuracy: 0.6351\n",
            "Epoch 129/100, Loss: 18.9508, Validation Accuracy: 0.6451\n",
            "Epoch 130/100, Loss: 51.1042, Validation Accuracy: 0.5833\n",
            "Epoch 131/100, Loss: 60.8548, Validation Accuracy: 0.5673\n",
            "Epoch 132/100, Loss: 107.1244, Validation Accuracy: 0.5783\n",
            "Epoch 133/100, Loss: 747.4149, Validation Accuracy: 0.6351\n",
            "Epoch 134/100, Loss: 107.6989, Validation Accuracy: 0.6341\n",
            "Epoch 135/100, Loss: 58.9469, Validation Accuracy: 0.5673\n",
            "Epoch 136/100, Loss: 54.5912, Validation Accuracy: 0.5882\n",
            "Epoch 137/100, Loss: 22.9769, Validation Accuracy: 0.6959\n",
            "Epoch 138/100, Loss: 4.1662, Validation Accuracy: 0.5912\n",
            "Epoch 139/100, Loss: 22.1524, Validation Accuracy: 0.5743\n",
            "Epoch 140/100, Loss: 10.3382, Validation Accuracy: 0.5872\n",
            "Epoch 141/100, Loss: 19.5206, Validation Accuracy: 0.5813\n",
            "Epoch 142/100, Loss: 10.8082, Validation Accuracy: 0.5314\n",
            "Epoch 143/100, Loss: 99.1715, Validation Accuracy: 0.6560\n",
            "Epoch 144/100, Loss: 23.7772, Validation Accuracy: 0.5942\n",
            "Epoch 145/100, Loss: 27.0026, Validation Accuracy: 0.5125\n",
            "Epoch 146/100, Loss: 8.0825, Validation Accuracy: 0.6620\n",
            "Epoch 147/100, Loss: 19.7855, Validation Accuracy: 0.6500\n",
            "Epoch 148/100, Loss: 20.8333, Validation Accuracy: 0.6540\n",
            "Epoch 149/100, Loss: 65.5816, Validation Accuracy: 0.6411\n",
            "Epoch 150/100, Loss: 49.8920, Validation Accuracy: 0.4995\n",
            "Epoch 151/100, Loss: 169.9238, Validation Accuracy: 0.4457\n",
            "Epoch 152/100, Loss: 20.1740, Validation Accuracy: 0.6540\n",
            "Epoch 153/100, Loss: 13.2504, Validation Accuracy: 0.5543\n",
            "Epoch 154/100, Loss: 50.4467, Validation Accuracy: 0.5912\n",
            "Epoch 155/100, Loss: 101.5493, Validation Accuracy: 0.5464\n",
            "Epoch 156/100, Loss: 16.0163, Validation Accuracy: 0.6720\n",
            "Epoch 157/100, Loss: 39.4084, Validation Accuracy: 0.5783\n",
            "Epoch 158/100, Loss: 54.1515, Validation Accuracy: 0.6162\n",
            "Epoch 159/100, Loss: 47.7762, Validation Accuracy: 0.6421\n",
            "Epoch 160/100, Loss: 52.0972, Validation Accuracy: 0.6441\n",
            "Epoch 161/100, Loss: 23.3901, Validation Accuracy: 0.4546\n",
            "Epoch 162/100, Loss: 21.5099, Validation Accuracy: 0.5354\n",
            "Epoch 163/100, Loss: 91.8262, Validation Accuracy: 0.6471\n",
            "Epoch 164/100, Loss: 589.3595, Validation Accuracy: 0.6391\n",
            "Epoch 165/100, Loss: 496.8387, Validation Accuracy: 0.4915\n",
            "Epoch 166/100, Loss: 89.0318, Validation Accuracy: 0.6122\n",
            "Epoch 167/100, Loss: 56.6540, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 25.4289, Validation Accuracy: 0.5613\n",
            "Epoch 169/100, Loss: 8.6773, Validation Accuracy: 0.6142\n",
            "Epoch 170/100, Loss: 16.0163, Validation Accuracy: 0.5882\n",
            "Epoch 171/100, Loss: 4.3724, Validation Accuracy: 0.5972\n",
            "Epoch 172/100, Loss: 12.5108, Validation Accuracy: 0.5982\n",
            "Epoch 173/100, Loss: 220.5343, Validation Accuracy: 0.6281\n",
            "Epoch 174/100, Loss: 11.3664, Validation Accuracy: 0.6431\n",
            "Epoch 175/100, Loss: 6.7228, Validation Accuracy: 0.6510\n",
            "Epoch 176/100, Loss: 8.2336, Validation Accuracy: 0.6371\n",
            "Epoch 177/100, Loss: 16.0941, Validation Accuracy: 0.6770\n",
            "Epoch 178/100, Loss: 81.1054, Validation Accuracy: 0.6152\n",
            "Epoch 179/100, Loss: 64.5637, Validation Accuracy: 0.6231\n",
            "Epoch 180/100, Loss: 30.9266, Validation Accuracy: 0.6002\n",
            "Epoch 181/100, Loss: 23.7174, Validation Accuracy: 0.6311\n",
            "Epoch 182/100, Loss: 34.9046, Validation Accuracy: 0.5314\n",
            "Epoch 183/100, Loss: 12.1482, Validation Accuracy: 0.4576\n",
            "Epoch 184/100, Loss: 21.2489, Validation Accuracy: 0.6750\n",
            "Epoch 185/100, Loss: 35.8608, Validation Accuracy: 0.6112\n",
            "Epoch 186/100, Loss: 29.4506, Validation Accuracy: 0.6680\n",
            "Epoch 187/100, Loss: 18.9818, Validation Accuracy: 0.6411\n",
            "Epoch 188/100, Loss: 33.3280, Validation Accuracy: 0.6580\n",
            "Epoch 189/100, Loss: 274.5375, Validation Accuracy: 0.6740\n",
            "Epoch 190/100, Loss: 629.4805, Validation Accuracy: 0.5344\n",
            "Epoch 191/100, Loss: 74.1977, Validation Accuracy: 0.5803\n",
            "Epoch 192/100, Loss: 19.2659, Validation Accuracy: 0.6500\n",
            "Epoch 193/100, Loss: 8.3654, Validation Accuracy: 0.5823\n",
            "Epoch 194/100, Loss: 15.6558, Validation Accuracy: 0.6162\n",
            "Epoch 195/100, Loss: 17.0248, Validation Accuracy: 0.6640\n",
            "Epoch 196/100, Loss: 15.2639, Validation Accuracy: 0.6361\n",
            "Epoch 197/100, Loss: 11.7171, Validation Accuracy: 0.5922\n",
            "Epoch 198/100, Loss: 1485.6106, Validation Accuracy: 0.6640\n",
            "Epoch 199/100, Loss: 49.2529, Validation Accuracy: 0.5892\n",
            "Epoch 200/100, Loss: 20.1744, Validation Accuracy: 0.6391\n",
            "Reward for Child Model: 0.2927654939811637\n",
            "Child_50:  {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, [3, 1, 3, 3, 0, 3, 3, 0, 1, 0, 3, 1, 2, 1, 1], 0.2927654939811637\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 64, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(152, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(152, 36, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=208208, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 22, 26]           1,536\n",
            "       BatchNorm2d-2           [-1, 24, 22, 26]              48\n",
            "            Conv2d-3           [-1, 64, 18, 24]          23,104\n",
            "       BatchNorm2d-4           [-1, 64, 18, 24]             128\n",
            "              ReLU-5           [-1, 64, 18, 24]               0\n",
            "            Conv2d-6           [-1, 64, 12, 18]         200,768\n",
            "       BatchNorm2d-7           [-1, 64, 12, 18]             128\n",
            "              ReLU-8           [-1, 64, 12, 18]               0\n",
            "            Conv2d-9           [-1, 64, 22, 26]           9,792\n",
            "      BatchNorm2d-10           [-1, 64, 22, 26]             128\n",
            "             ReLU-11           [-1, 64, 22, 26]               0\n",
            "           Conv2d-12           [-1, 36, 22, 26]           5,508\n",
            "      BatchNorm2d-13           [-1, 36, 22, 26]              72\n",
            "             ReLU-14           [-1, 36, 22, 26]               0\n",
            "           Linear-15                    [-1, 7]       1,457,463\n",
            "================================================================\n",
            "Total params: 1,698,675\n",
            "Trainable params: 1,698,675\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.47\n",
            "Params size (MB): 6.48\n",
            "Estimated Total Size (MB): 8.96\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 34.7236, Validation Accuracy: 0.5394\n",
            "Epoch 2/100, Loss: 65.3136, Validation Accuracy: 0.3938\n",
            "Epoch 3/100, Loss: 36.8258, Validation Accuracy: 0.4945\n",
            "Epoch 4/100, Loss: 106.5659, Validation Accuracy: 0.3719\n",
            "Epoch 5/100, Loss: 551.4038, Validation Accuracy: 0.6072\n",
            "Epoch 6/100, Loss: 257.2779, Validation Accuracy: 0.5823\n",
            "Epoch 7/100, Loss: 32.0846, Validation Accuracy: 0.5274\n",
            "Epoch 8/100, Loss: 168.4085, Validation Accuracy: 0.4935\n",
            "Epoch 9/100, Loss: 15.0823, Validation Accuracy: 0.6052\n",
            "Epoch 10/100, Loss: 48.8916, Validation Accuracy: 0.6191\n",
            "Epoch 11/100, Loss: 10.0593, Validation Accuracy: 0.5344\n",
            "Epoch 12/100, Loss: 37.7036, Validation Accuracy: 0.6231\n",
            "Epoch 13/100, Loss: 18.8677, Validation Accuracy: 0.6520\n",
            "Epoch 14/100, Loss: 119.2915, Validation Accuracy: 0.4955\n",
            "Epoch 15/100, Loss: 10.0978, Validation Accuracy: 0.5852\n",
            "Epoch 16/100, Loss: 11.8919, Validation Accuracy: 0.4417\n",
            "Epoch 17/100, Loss: 7.7087, Validation Accuracy: 0.6461\n",
            "Epoch 18/100, Loss: 80.5660, Validation Accuracy: 0.4656\n",
            "Epoch 19/100, Loss: 26.2684, Validation Accuracy: 0.5414\n",
            "Epoch 20/100, Loss: 23.8423, Validation Accuracy: 0.5454\n",
            "Epoch 21/100, Loss: 10.3031, Validation Accuracy: 0.5274\n",
            "Epoch 22/100, Loss: 4.5964, Validation Accuracy: 0.5314\n",
            "Epoch 23/100, Loss: 16.4062, Validation Accuracy: 0.6640\n",
            "Epoch 24/100, Loss: 17.7006, Validation Accuracy: 0.5394\n",
            "Epoch 25/100, Loss: 47.5021, Validation Accuracy: 0.6750\n",
            "Epoch 26/100, Loss: 85.5751, Validation Accuracy: 0.4187\n",
            "Epoch 27/100, Loss: 19.7721, Validation Accuracy: 0.6002\n",
            "Epoch 28/100, Loss: 10.0170, Validation Accuracy: 0.6281\n",
            "Epoch 29/100, Loss: 25.1138, Validation Accuracy: 0.6321\n",
            "Epoch 30/100, Loss: 20.1371, Validation Accuracy: 0.6510\n",
            "Epoch 31/100, Loss: 102.7500, Validation Accuracy: 0.6371\n",
            "Epoch 32/100, Loss: 24.3176, Validation Accuracy: 0.5942\n",
            "Epoch 33/100, Loss: 93.6934, Validation Accuracy: 0.6361\n",
            "Epoch 34/100, Loss: 38.6260, Validation Accuracy: 0.5892\n",
            "Epoch 35/100, Loss: 17.2586, Validation Accuracy: 0.4138\n",
            "Epoch 36/100, Loss: 73.0105, Validation Accuracy: 0.5613\n",
            "Epoch 37/100, Loss: 404.3065, Validation Accuracy: 0.5842\n",
            "Epoch 38/100, Loss: 173.5206, Validation Accuracy: 0.5045\n",
            "Epoch 39/100, Loss: 1902.1010, Validation Accuracy: 0.6590\n",
            "Epoch 40/100, Loss: 1157.0529, Validation Accuracy: 0.6391\n",
            "Epoch 41/100, Loss: 1467.5953, Validation Accuracy: 0.6191\n",
            "Epoch 42/100, Loss: 984.8521, Validation Accuracy: 0.6431\n",
            "Epoch 43/100, Loss: 316.2821, Validation Accuracy: 0.6002\n",
            "Epoch 44/100, Loss: 232.6134, Validation Accuracy: 0.6201\n",
            "Epoch 45/100, Loss: 51.2398, Validation Accuracy: 0.6381\n",
            "Epoch 46/100, Loss: 534.8113, Validation Accuracy: 0.6570\n",
            "Epoch 47/100, Loss: 264.5606, Validation Accuracy: 0.6550\n",
            "Epoch 48/100, Loss: 220.3801, Validation Accuracy: 0.6899\n",
            "Epoch 49/100, Loss: 96.3886, Validation Accuracy: 0.6740\n",
            "Epoch 50/100, Loss: 67.2815, Validation Accuracy: 0.6341\n",
            "Epoch 51/100, Loss: 52.9282, Validation Accuracy: 0.6810\n",
            "Epoch 52/100, Loss: 29.1084, Validation Accuracy: 0.6830\n",
            "Epoch 53/100, Loss: 27.5562, Validation Accuracy: 0.6371\n",
            "Epoch 54/100, Loss: 42.6340, Validation Accuracy: 0.6381\n",
            "Epoch 55/100, Loss: 28.0777, Validation Accuracy: 0.6800\n",
            "Epoch 56/100, Loss: 15.8967, Validation Accuracy: 0.6451\n",
            "Epoch 57/100, Loss: 3.3526, Validation Accuracy: 0.6092\n",
            "Epoch 58/100, Loss: 12.8265, Validation Accuracy: 0.6062\n",
            "Epoch 59/100, Loss: 81.9436, Validation Accuracy: 0.5454\n",
            "Epoch 60/100, Loss: 10.8650, Validation Accuracy: 0.5942\n",
            "Epoch 61/100, Loss: 171.7434, Validation Accuracy: 0.6162\n",
            "Epoch 62/100, Loss: 10.3963, Validation Accuracy: 0.6221\n",
            "Epoch 63/100, Loss: 21.0624, Validation Accuracy: 0.6740\n",
            "Epoch 64/100, Loss: 12.6852, Validation Accuracy: 0.6411\n",
            "Epoch 65/100, Loss: 22.0728, Validation Accuracy: 0.6142\n",
            "Epoch 66/100, Loss: 8.2067, Validation Accuracy: 0.6491\n",
            "Epoch 67/100, Loss: 12.3639, Validation Accuracy: 0.5045\n",
            "Epoch 68/100, Loss: 456.3256, Validation Accuracy: 0.6142\n",
            "Epoch 69/100, Loss: 84.2991, Validation Accuracy: 0.3559\n",
            "Epoch 70/100, Loss: 38.7137, Validation Accuracy: 0.6032\n",
            "Epoch 71/100, Loss: 13.9719, Validation Accuracy: 0.6481\n",
            "Epoch 72/100, Loss: 8.4622, Validation Accuracy: 0.6261\n",
            "Epoch 73/100, Loss: 68.8058, Validation Accuracy: 0.5264\n",
            "Epoch 74/100, Loss: 43.7221, Validation Accuracy: 0.3170\n",
            "Epoch 75/100, Loss: 9.4877, Validation Accuracy: 0.5753\n",
            "Epoch 76/100, Loss: 24.6621, Validation Accuracy: 0.4975\n",
            "Epoch 77/100, Loss: 29.7121, Validation Accuracy: 0.6421\n",
            "Epoch 78/100, Loss: 38.5932, Validation Accuracy: 0.5972\n",
            "Epoch 79/100, Loss: 32.5260, Validation Accuracy: 0.6590\n",
            "Epoch 80/100, Loss: 68.6562, Validation Accuracy: 0.2522\n",
            "Epoch 81/100, Loss: 51.9600, Validation Accuracy: 0.6092\n",
            "Epoch 82/100, Loss: 45.0465, Validation Accuracy: 0.5942\n",
            "Epoch 83/100, Loss: 30.2344, Validation Accuracy: 0.4885\n",
            "Epoch 84/100, Loss: 15.2545, Validation Accuracy: 0.5723\n",
            "Epoch 85/100, Loss: 72.4112, Validation Accuracy: 0.2652\n",
            "Epoch 86/100, Loss: 27.4595, Validation Accuracy: 0.5992\n",
            "Epoch 87/100, Loss: 18.9335, Validation Accuracy: 0.5623\n",
            "Epoch 88/100, Loss: 31.7926, Validation Accuracy: 0.6191\n",
            "Epoch 89/100, Loss: 103.9166, Validation Accuracy: 0.5683\n",
            "Epoch 90/100, Loss: 49.2660, Validation Accuracy: 0.6770\n",
            "Epoch 91/100, Loss: 21.2273, Validation Accuracy: 0.5733\n",
            "Epoch 92/100, Loss: 44.7539, Validation Accuracy: 0.6281\n",
            "Epoch 93/100, Loss: 65.9886, Validation Accuracy: 0.5862\n",
            "Epoch 94/100, Loss: 170.6078, Validation Accuracy: 0.5633\n",
            "Epoch 95/100, Loss: 13.9259, Validation Accuracy: 0.6441\n",
            "Epoch 96/100, Loss: 79.2088, Validation Accuracy: 0.5613\n",
            "Epoch 97/100, Loss: 17.9198, Validation Accuracy: 0.6321\n",
            "Epoch 98/100, Loss: 34.3170, Validation Accuracy: 0.5962\n",
            "Epoch 99/100, Loss: 17.4004, Validation Accuracy: 0.6152\n",
            "Epoch 100/100, Loss: 17.8496, Validation Accuracy: 0.6550\n",
            "Epoch 101/100, Loss: 31.7043, Validation Accuracy: 0.5972\n",
            "Epoch 102/100, Loss: 91.1035, Validation Accuracy: 0.4078\n",
            "Epoch 103/100, Loss: 106.6820, Validation Accuracy: 0.6600\n",
            "Epoch 104/100, Loss: 48.3451, Validation Accuracy: 0.6411\n",
            "Epoch 105/100, Loss: 44.7190, Validation Accuracy: 0.6510\n",
            "Epoch 106/100, Loss: 29.8843, Validation Accuracy: 0.4297\n",
            "Epoch 107/100, Loss: 76.3790, Validation Accuracy: 0.4686\n",
            "Epoch 108/100, Loss: 57.1663, Validation Accuracy: 0.5304\n",
            "Epoch 109/100, Loss: 46.2298, Validation Accuracy: 0.1107\n",
            "Epoch 110/100, Loss: 40.6405, Validation Accuracy: 0.6421\n",
            "Epoch 111/100, Loss: 841.5488, Validation Accuracy: 0.1326\n",
            "Epoch 112/100, Loss: 35.4177, Validation Accuracy: 0.5085\n",
            "Epoch 113/100, Loss: 23.3721, Validation Accuracy: 0.6181\n",
            "Epoch 114/100, Loss: 28.3966, Validation Accuracy: 0.6261\n",
            "Epoch 115/100, Loss: 6.7952, Validation Accuracy: 0.6311\n",
            "Epoch 116/100, Loss: 9.7226, Validation Accuracy: 0.6132\n",
            "Epoch 117/100, Loss: 61.9843, Validation Accuracy: 0.6441\n",
            "Epoch 118/100, Loss: 57.8253, Validation Accuracy: 0.4945\n",
            "Epoch 119/100, Loss: 21.3197, Validation Accuracy: 0.5135\n",
            "Epoch 120/100, Loss: 19.5067, Validation Accuracy: 0.5115\n",
            "Epoch 121/100, Loss: 313.2778, Validation Accuracy: 0.5533\n",
            "Epoch 122/100, Loss: 42.9257, Validation Accuracy: 0.5354\n",
            "Epoch 123/100, Loss: 169.5119, Validation Accuracy: 0.6411\n",
            "Epoch 124/100, Loss: 70.8987, Validation Accuracy: 0.6092\n",
            "Epoch 125/100, Loss: 21.0099, Validation Accuracy: 0.5503\n",
            "Epoch 126/100, Loss: 14.0276, Validation Accuracy: 0.4726\n",
            "Epoch 127/100, Loss: 56.7944, Validation Accuracy: 0.5693\n",
            "Epoch 128/100, Loss: 12.5222, Validation Accuracy: 0.5324\n",
            "Epoch 129/100, Loss: 42.8203, Validation Accuracy: 0.6441\n",
            "Epoch 130/100, Loss: 175.8030, Validation Accuracy: 0.6441\n",
            "Epoch 131/100, Loss: 78.7398, Validation Accuracy: 0.5404\n",
            "Epoch 132/100, Loss: 39.1540, Validation Accuracy: 0.5952\n",
            "Epoch 133/100, Loss: 16.7448, Validation Accuracy: 0.4138\n",
            "Epoch 134/100, Loss: 18.2291, Validation Accuracy: 0.5065\n",
            "Epoch 135/100, Loss: 19.4181, Validation Accuracy: 0.6122\n",
            "Epoch 136/100, Loss: 10.1465, Validation Accuracy: 0.6062\n",
            "Epoch 137/100, Loss: 6.9969, Validation Accuracy: 0.5942\n",
            "Epoch 138/100, Loss: 59.8632, Validation Accuracy: 0.5703\n",
            "Epoch 139/100, Loss: 22.9053, Validation Accuracy: 0.5165\n",
            "Epoch 140/100, Loss: 28.8315, Validation Accuracy: 0.6391\n",
            "Epoch 141/100, Loss: 10.4982, Validation Accuracy: 0.6660\n",
            "Epoch 142/100, Loss: 17.9588, Validation Accuracy: 0.5982\n",
            "Epoch 143/100, Loss: 53.5447, Validation Accuracy: 0.4227\n",
            "Epoch 144/100, Loss: 8.2459, Validation Accuracy: 0.5434\n",
            "Epoch 145/100, Loss: 27.7381, Validation Accuracy: 0.6650\n",
            "Epoch 146/100, Loss: 73.7220, Validation Accuracy: 0.4596\n",
            "Epoch 147/100, Loss: 26.7424, Validation Accuracy: 0.4477\n",
            "Epoch 148/100, Loss: 102.7326, Validation Accuracy: 0.5693\n",
            "Epoch 149/100, Loss: 103.2248, Validation Accuracy: 0.6032\n",
            "Epoch 150/100, Loss: 26.8078, Validation Accuracy: 0.5713\n",
            "Epoch 151/100, Loss: 19.3236, Validation Accuracy: 0.6281\n",
            "Epoch 152/100, Loss: 17.1449, Validation Accuracy: 0.5902\n",
            "Epoch 153/100, Loss: 323.2680, Validation Accuracy: 0.6341\n",
            "Epoch 154/100, Loss: 66.6485, Validation Accuracy: 0.1107\n",
            "Epoch 155/100, Loss: 35.9806, Validation Accuracy: 0.6580\n",
            "Epoch 156/100, Loss: 21.8411, Validation Accuracy: 0.5603\n",
            "Epoch 157/100, Loss: 17.2131, Validation Accuracy: 0.6760\n",
            "Epoch 158/100, Loss: 15.8610, Validation Accuracy: 0.6221\n",
            "Epoch 159/100, Loss: 1530.1692, Validation Accuracy: 0.4616\n",
            "Epoch 160/100, Loss: 21.1137, Validation Accuracy: 0.5454\n",
            "Epoch 161/100, Loss: 177.8528, Validation Accuracy: 0.0140\n",
            "Epoch 162/100, Loss: 423.6980, Validation Accuracy: 0.5703\n",
            "Epoch 163/100, Loss: 65.3913, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 32.7163, Validation Accuracy: 0.4995\n",
            "Epoch 165/100, Loss: 15.5876, Validation Accuracy: 0.5703\n",
            "Epoch 166/100, Loss: 8.2472, Validation Accuracy: 0.5753\n",
            "Epoch 167/100, Loss: 1821.9907, Validation Accuracy: 0.6720\n",
            "Epoch 168/100, Loss: 36.1094, Validation Accuracy: 0.6102\n",
            "Epoch 169/100, Loss: 12.3650, Validation Accuracy: 0.5264\n",
            "Epoch 170/100, Loss: 118.4742, Validation Accuracy: 0.6481\n",
            "Epoch 171/100, Loss: 55.7387, Validation Accuracy: 0.5653\n",
            "Epoch 172/100, Loss: 262.8515, Validation Accuracy: 0.6291\n",
            "Epoch 173/100, Loss: 32.9097, Validation Accuracy: 0.6331\n",
            "Epoch 174/100, Loss: 60.0448, Validation Accuracy: 0.5733\n",
            "Epoch 175/100, Loss: 100.3016, Validation Accuracy: 0.6560\n",
            "Epoch 176/100, Loss: 15.9181, Validation Accuracy: 0.5703\n",
            "Epoch 177/100, Loss: 11.4039, Validation Accuracy: 0.5583\n",
            "Epoch 178/100, Loss: 16.8773, Validation Accuracy: 0.6112\n",
            "Epoch 179/100, Loss: 19.3355, Validation Accuracy: 0.5593\n",
            "Epoch 180/100, Loss: 15.1170, Validation Accuracy: 0.6530\n",
            "Epoch 181/100, Loss: 3.8913, Validation Accuracy: 0.6311\n",
            "Epoch 182/100, Loss: 10.9771, Validation Accuracy: 0.6122\n",
            "Epoch 183/100, Loss: 15.8771, Validation Accuracy: 0.6411\n",
            "Epoch 184/100, Loss: 42.4560, Validation Accuracy: 0.6730\n",
            "Epoch 185/100, Loss: 56.0702, Validation Accuracy: 0.6082\n",
            "Epoch 186/100, Loss: 56.7401, Validation Accuracy: 0.5005\n",
            "Epoch 187/100, Loss: 25.3784, Validation Accuracy: 0.5872\n",
            "Epoch 188/100, Loss: 13.4370, Validation Accuracy: 0.6022\n",
            "Epoch 189/100, Loss: 32.7410, Validation Accuracy: 0.6650\n",
            "Epoch 190/100, Loss: 30.3682, Validation Accuracy: 0.4736\n",
            "Epoch 191/100, Loss: 24.1155, Validation Accuracy: 0.6560\n",
            "Epoch 192/100, Loss: 345.2861, Validation Accuracy: 0.6002\n",
            "Epoch 193/100, Loss: 54.4213, Validation Accuracy: 0.6201\n",
            "Epoch 194/100, Loss: 33.9474, Validation Accuracy: 0.6331\n",
            "Epoch 195/100, Loss: 11.8897, Validation Accuracy: 0.5683\n",
            "Epoch 196/100, Loss: 4.1249, Validation Accuracy: 0.6341\n",
            "Epoch 197/100, Loss: 52.0207, Validation Accuracy: 0.6152\n",
            "Epoch 198/100, Loss: 17.0325, Validation Accuracy: 0.5823\n",
            "Epoch 199/100, Loss: 9.9840, Validation Accuracy: 0.6371\n",
            "Epoch 200/100, Loss: 9.4733, Validation Accuracy: 0.5703\n",
            "Reward for Child Model: 0.258582884321492\n",
            "Child_51:  {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, [3, 1, 0, 2, 1, 3, 3, 3, 3, 0, 0, 3, 0, 0, 1], 0.258582884321492\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 36, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(100, 36, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(36, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(84, 36, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=28512, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 22, 28]           1,408\n",
            "       BatchNorm2d-2           [-1, 64, 22, 28]             128\n",
            "            Conv2d-3           [-1, 36, 16, 24]          80,676\n",
            "       BatchNorm2d-4           [-1, 36, 16, 24]              72\n",
            "              ReLU-5           [-1, 36, 16, 24]               0\n",
            "            Conv2d-6           [-1, 36, 18, 22]         126,036\n",
            "       BatchNorm2d-7           [-1, 36, 18, 22]              72\n",
            "              ReLU-8           [-1, 36, 18, 22]               0\n",
            "            Conv2d-9           [-1, 48, 18, 18]           8,688\n",
            "      BatchNorm2d-10           [-1, 48, 18, 18]              96\n",
            "             ReLU-11           [-1, 48, 18, 18]               0\n",
            "           Conv2d-12           [-1, 36, 16, 20]          27,252\n",
            "      BatchNorm2d-13           [-1, 36, 16, 20]              72\n",
            "             ReLU-14           [-1, 36, 16, 20]               0\n",
            "           Linear-15                    [-1, 7]         199,591\n",
            "================================================================\n",
            "Total params: 444,091\n",
            "Trainable params: 444,091\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.86\n",
            "Params size (MB): 1.69\n",
            "Estimated Total Size (MB): 3.57\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 1.2047, Validation Accuracy: 0.6690\n",
            "Epoch 2/100, Loss: 1.0497, Validation Accuracy: 0.6690\n",
            "Epoch 3/100, Loss: 1.0262, Validation Accuracy: 0.6690\n",
            "Epoch 4/100, Loss: 1.1333, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 0.7316, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 1.2405, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 1.3484, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 0.9459, Validation Accuracy: 0.6690\n",
            "Epoch 9/100, Loss: 1.4814, Validation Accuracy: 0.6690\n",
            "Epoch 10/100, Loss: 0.9838, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 0.7820, Validation Accuracy: 0.1097\n",
            "Epoch 12/100, Loss: 0.8468, Validation Accuracy: 0.6690\n",
            "Epoch 13/100, Loss: 1.4142, Validation Accuracy: 0.6690\n",
            "Epoch 14/100, Loss: 1.1046, Validation Accuracy: 0.6690\n",
            "Epoch 15/100, Loss: 1.1550, Validation Accuracy: 0.6690\n",
            "Epoch 16/100, Loss: 1.1513, Validation Accuracy: 0.6690\n",
            "Epoch 17/100, Loss: 1.0656, Validation Accuracy: 0.6690\n",
            "Epoch 18/100, Loss: 1.1951, Validation Accuracy: 0.6690\n",
            "Epoch 19/100, Loss: 1.0489, Validation Accuracy: 0.6690\n",
            "Epoch 20/100, Loss: 1.1383, Validation Accuracy: 0.6690\n",
            "Epoch 21/100, Loss: 0.7310, Validation Accuracy: 0.6690\n",
            "Epoch 22/100, Loss: 0.9643, Validation Accuracy: 0.6690\n",
            "Epoch 23/100, Loss: 1.0742, Validation Accuracy: 0.1097\n",
            "Epoch 24/100, Loss: 1.1129, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 1.1994, Validation Accuracy: 0.6690\n",
            "Epoch 26/100, Loss: 1.1528, Validation Accuracy: 0.6690\n",
            "Epoch 27/100, Loss: 0.9166, Validation Accuracy: 0.6690\n",
            "Epoch 28/100, Loss: 1.3976, Validation Accuracy: 0.6690\n",
            "Epoch 29/100, Loss: 1.1161, Validation Accuracy: 0.6690\n",
            "Epoch 30/100, Loss: 1.3561, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 0.8210, Validation Accuracy: 0.6690\n",
            "Epoch 32/100, Loss: 1.2911, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 0.8839, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 1.0446, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 1.0358, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 1.0654, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 1.4543, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 0.8774, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 1.2018, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 1.2168, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 1.2116, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 1.1939, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 1.0609, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 1.4687, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 1.4089, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 0.9716, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 1.1788, Validation Accuracy: 0.6690\n",
            "Epoch 48/100, Loss: 1.2386, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 1.1118, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 1.5165, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 0.9212, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 1.1757, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 1.3063, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 1.6442, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 1.0581, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 1.4866, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 1.2476, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 1.0811, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 1.2494, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 1.0597, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 1.0031, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 0.9225, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 1.1455, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 0.8609, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 1.0032, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 1.3169, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 1.3985, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 1.1619, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 1.0051, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 0.8241, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 0.7670, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 0.7971, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 1.2034, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 0.7282, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 1.7268, Validation Accuracy: 0.6690\n",
            "Epoch 76/100, Loss: 1.1021, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 1.1273, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 1.1075, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 0.9988, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 0.9070, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 1.0957, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 1.1215, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 1.4442, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 1.4283, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 1.2124, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 1.6582, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 0.9603, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 1.3977, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 0.8703, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 0.9598, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 1.2293, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 1.4323, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 0.9190, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 1.0114, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 1.2489, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 1.0674, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 0.9468, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 0.9939, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 1.0802, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 1.0796, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 1.0924, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 1.0694, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 0.5430, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 1.2381, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 1.2220, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 1.0409, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 1.3388, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 0.9174, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 1.3072, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 1.4493, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.2703, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 1.3633, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 1.3931, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 1.1937, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 1.3523, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 1.4662, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 0.9527, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 0.8880, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 0.9063, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 0.8442, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 1.1360, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.0973, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 1.3165, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 1.0591, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 1.2172, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 1.3427, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 1.1591, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 0.8340, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 1.4897, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 1.0442, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 0.7250, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 1.1489, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 1.0806, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 0.9431, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 0.7707, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 1.2578, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 1.2152, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 1.3675, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 1.0826, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 0.9650, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 1.1932, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 1.2666, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 1.1293, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 1.2558, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 1.1312, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 1.3871, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 1.4744, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 1.1020, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 1.0255, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 1.3555, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 1.5605, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 1.4547, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 1.5376, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 1.2922, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 1.4745, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 1.1385, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 0.7575, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 1.0615, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 1.3875, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 1.4622, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 1.2986, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 1.4903, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 1.0502, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 1.1006, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 1.1362, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 1.1422, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 1.0273, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 1.2023, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 1.1314, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 1.1339, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 0.9569, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 1.5626, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 1.0217, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 1.0607, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 1.1672, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 1.1127, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 0.9217, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 1.2190, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 1.1986, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 0.8920, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 1.3292, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 1.6472, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 1.3223, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 1.2333, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 0.8862, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 0.8862, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 1.0312, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 0.7293, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 0.9905, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 0.8100, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 1.4002, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 0.9456, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 1.0804, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 1.2260, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 1.2019, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 1.1600, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 1.3022, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 1.1185, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 1.0729, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 1.4904, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_52:  {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, [3, 0, 3, 3, 2, 1, 2, 3, 1, 0, 2, 2, 1, 1, 1], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 36, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(164, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(164, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=99456, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 24, 28]           1,024\n",
            "       BatchNorm2d-2           [-1, 64, 24, 28]             128\n",
            "            Conv2d-3           [-1, 36, 22, 24]          34,596\n",
            "       BatchNorm2d-4           [-1, 36, 22, 24]              72\n",
            "              ReLU-5           [-1, 36, 22, 24]               0\n",
            "            Conv2d-6           [-1, 64, 16, 18]         112,960\n",
            "       BatchNorm2d-7           [-1, 64, 16, 18]             128\n",
            "              ReLU-8           [-1, 64, 16, 18]               0\n",
            "            Conv2d-9           [-1, 64, 24, 28]          10,560\n",
            "      BatchNorm2d-10           [-1, 64, 24, 28]             128\n",
            "             ReLU-11           [-1, 64, 24, 28]               0\n",
            "           Conv2d-12           [-1, 48, 24, 28]           7,920\n",
            "      BatchNorm2d-13           [-1, 48, 24, 28]              96\n",
            "             ReLU-14           [-1, 48, 24, 28]               0\n",
            "           Linear-15                    [-1, 7]         696,199\n",
            "================================================================\n",
            "Total params: 863,811\n",
            "Trainable params: 863,811\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.24\n",
            "Params size (MB): 3.30\n",
            "Estimated Total Size (MB): 6.54\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 9.6636, Validation Accuracy: 0.3161\n",
            "Epoch 2/100, Loss: 32.6645, Validation Accuracy: 0.6331\n",
            "Epoch 3/100, Loss: 24.9862, Validation Accuracy: 0.3679\n",
            "Epoch 4/100, Loss: 30.6059, Validation Accuracy: 0.5573\n",
            "Epoch 5/100, Loss: 30.8280, Validation Accuracy: 0.5464\n",
            "Epoch 6/100, Loss: 113.4876, Validation Accuracy: 0.2881\n",
            "Epoch 7/100, Loss: 26.8012, Validation Accuracy: 0.6650\n",
            "Epoch 8/100, Loss: 32.3137, Validation Accuracy: 0.6351\n",
            "Epoch 9/100, Loss: 32.3145, Validation Accuracy: 0.5105\n",
            "Epoch 10/100, Loss: 71.7059, Validation Accuracy: 0.3928\n",
            "Epoch 11/100, Loss: 47.6370, Validation Accuracy: 0.3091\n",
            "Epoch 12/100, Loss: 38.9600, Validation Accuracy: 0.5613\n",
            "Epoch 13/100, Loss: 16.9940, Validation Accuracy: 0.6002\n",
            "Epoch 14/100, Loss: 83.4885, Validation Accuracy: 0.6181\n",
            "Epoch 15/100, Loss: 87.3676, Validation Accuracy: 0.5703\n",
            "Epoch 16/100, Loss: 46.4938, Validation Accuracy: 0.6810\n",
            "Epoch 17/100, Loss: 70.6968, Validation Accuracy: 0.6770\n",
            "Epoch 18/100, Loss: 73.9887, Validation Accuracy: 0.4905\n",
            "Epoch 19/100, Loss: 78.5944, Validation Accuracy: 0.5882\n",
            "Epoch 20/100, Loss: 56.1832, Validation Accuracy: 0.6142\n",
            "Epoch 21/100, Loss: 63.1068, Validation Accuracy: 0.2263\n",
            "Epoch 22/100, Loss: 21.3864, Validation Accuracy: 0.5294\n",
            "Epoch 23/100, Loss: 46.0406, Validation Accuracy: 0.4596\n",
            "Epoch 24/100, Loss: 89.3162, Validation Accuracy: 0.6062\n",
            "Epoch 25/100, Loss: 91.6496, Validation Accuracy: 0.6720\n",
            "Epoch 26/100, Loss: 25.7449, Validation Accuracy: 0.4467\n",
            "Epoch 27/100, Loss: 42.8307, Validation Accuracy: 0.6820\n",
            "Epoch 28/100, Loss: 67.2904, Validation Accuracy: 0.6012\n",
            "Epoch 29/100, Loss: 38.7936, Validation Accuracy: 0.6500\n",
            "Epoch 30/100, Loss: 37.9220, Validation Accuracy: 0.6451\n",
            "Epoch 31/100, Loss: 87.8891, Validation Accuracy: 0.6670\n",
            "Epoch 32/100, Loss: 82.1219, Validation Accuracy: 0.4965\n",
            "Epoch 33/100, Loss: 46.8907, Validation Accuracy: 0.5474\n",
            "Epoch 34/100, Loss: 101.0350, Validation Accuracy: 0.6002\n",
            "Epoch 35/100, Loss: 41.8359, Validation Accuracy: 0.6072\n",
            "Epoch 36/100, Loss: 75.6205, Validation Accuracy: 0.6720\n",
            "Epoch 37/100, Loss: 92.1283, Validation Accuracy: 0.5314\n",
            "Epoch 38/100, Loss: 77.9312, Validation Accuracy: 0.5494\n",
            "Epoch 39/100, Loss: 122.3280, Validation Accuracy: 0.6680\n",
            "Epoch 40/100, Loss: 28.7647, Validation Accuracy: 0.6241\n",
            "Epoch 41/100, Loss: 85.5880, Validation Accuracy: 0.5892\n",
            "Epoch 42/100, Loss: 163.6311, Validation Accuracy: 0.6660\n",
            "Epoch 43/100, Loss: 39.2713, Validation Accuracy: 0.5254\n",
            "Epoch 44/100, Loss: 72.1124, Validation Accuracy: 0.6510\n",
            "Epoch 45/100, Loss: 54.6712, Validation Accuracy: 0.5364\n",
            "Epoch 46/100, Loss: 44.2682, Validation Accuracy: 0.6291\n",
            "Epoch 47/100, Loss: 46.0951, Validation Accuracy: 0.6191\n",
            "Epoch 48/100, Loss: 82.9270, Validation Accuracy: 0.6660\n",
            "Epoch 49/100, Loss: 22.9630, Validation Accuracy: 0.3579\n",
            "Epoch 50/100, Loss: 49.4249, Validation Accuracy: 0.6740\n",
            "Epoch 51/100, Loss: 65.6788, Validation Accuracy: 0.4516\n",
            "Epoch 52/100, Loss: 56.0554, Validation Accuracy: 0.5284\n",
            "Epoch 53/100, Loss: 26.9889, Validation Accuracy: 0.6530\n",
            "Epoch 54/100, Loss: 37.9432, Validation Accuracy: 0.6371\n",
            "Epoch 55/100, Loss: 40.0996, Validation Accuracy: 0.6650\n",
            "Epoch 56/100, Loss: 92.2689, Validation Accuracy: 0.6730\n",
            "Epoch 57/100, Loss: 19.5183, Validation Accuracy: 0.4497\n",
            "Epoch 58/100, Loss: 83.1012, Validation Accuracy: 0.6949\n",
            "Epoch 59/100, Loss: 77.4824, Validation Accuracy: 0.6820\n",
            "Epoch 60/100, Loss: 25.8961, Validation Accuracy: 0.4327\n",
            "Epoch 61/100, Loss: 21.7611, Validation Accuracy: 0.4985\n",
            "Epoch 62/100, Loss: 105.8676, Validation Accuracy: 0.5105\n",
            "Epoch 63/100, Loss: 57.5213, Validation Accuracy: 0.6600\n",
            "Epoch 64/100, Loss: 76.1809, Validation Accuracy: 0.6720\n",
            "Epoch 65/100, Loss: 68.8108, Validation Accuracy: 0.5723\n",
            "Epoch 66/100, Loss: 38.1199, Validation Accuracy: 0.5135\n",
            "Epoch 67/100, Loss: 98.8463, Validation Accuracy: 0.6201\n",
            "Epoch 68/100, Loss: 74.2098, Validation Accuracy: 0.6520\n",
            "Epoch 69/100, Loss: 74.9092, Validation Accuracy: 0.5852\n",
            "Epoch 70/100, Loss: 48.5839, Validation Accuracy: 0.6600\n",
            "Epoch 71/100, Loss: 205.6459, Validation Accuracy: 0.6411\n",
            "Epoch 72/100, Loss: 93.4947, Validation Accuracy: 0.5523\n",
            "Epoch 73/100, Loss: 15.2080, Validation Accuracy: 0.6640\n",
            "Epoch 74/100, Loss: 85.9811, Validation Accuracy: 0.5593\n",
            "Epoch 75/100, Loss: 89.0955, Validation Accuracy: 0.4965\n",
            "Epoch 76/100, Loss: 65.1525, Validation Accuracy: 0.6211\n",
            "Epoch 77/100, Loss: 85.9472, Validation Accuracy: 0.6122\n",
            "Epoch 78/100, Loss: 59.3261, Validation Accuracy: 0.6481\n",
            "Epoch 79/100, Loss: 64.3171, Validation Accuracy: 0.5174\n",
            "Epoch 80/100, Loss: 60.4913, Validation Accuracy: 0.5932\n",
            "Epoch 81/100, Loss: 41.7689, Validation Accuracy: 0.4297\n",
            "Epoch 82/100, Loss: 53.4584, Validation Accuracy: 0.6102\n",
            "Epoch 83/100, Loss: 112.7965, Validation Accuracy: 0.6072\n",
            "Epoch 84/100, Loss: 46.4600, Validation Accuracy: 0.5653\n",
            "Epoch 85/100, Loss: 36.3221, Validation Accuracy: 0.6411\n",
            "Epoch 86/100, Loss: 24.4665, Validation Accuracy: 0.6859\n",
            "Epoch 87/100, Loss: 65.0766, Validation Accuracy: 0.5922\n",
            "Epoch 88/100, Loss: 70.5626, Validation Accuracy: 0.6082\n",
            "Epoch 89/100, Loss: 71.9809, Validation Accuracy: 0.6411\n",
            "Epoch 90/100, Loss: 85.9802, Validation Accuracy: 0.5344\n",
            "Epoch 91/100, Loss: 63.0646, Validation Accuracy: 0.5633\n",
            "Epoch 92/100, Loss: 87.3217, Validation Accuracy: 0.5055\n",
            "Epoch 93/100, Loss: 36.1693, Validation Accuracy: 0.4905\n",
            "Epoch 94/100, Loss: 81.8158, Validation Accuracy: 0.6052\n",
            "Epoch 95/100, Loss: 20.7332, Validation Accuracy: 0.6600\n",
            "Epoch 96/100, Loss: 51.0686, Validation Accuracy: 0.4905\n",
            "Epoch 97/100, Loss: 61.5864, Validation Accuracy: 0.5773\n",
            "Epoch 98/100, Loss: 101.6707, Validation Accuracy: 0.6032\n",
            "Epoch 99/100, Loss: 88.9439, Validation Accuracy: 0.5952\n",
            "Epoch 100/100, Loss: 119.3221, Validation Accuracy: 0.5244\n",
            "Epoch 101/100, Loss: 61.3009, Validation Accuracy: 0.5484\n",
            "Epoch 102/100, Loss: 100.2716, Validation Accuracy: 0.6211\n",
            "Epoch 103/100, Loss: 17.6722, Validation Accuracy: 0.6082\n",
            "Epoch 104/100, Loss: 155.4397, Validation Accuracy: 0.5474\n",
            "Epoch 105/100, Loss: 82.2966, Validation Accuracy: 0.5703\n",
            "Epoch 106/100, Loss: 77.5840, Validation Accuracy: 0.4516\n",
            "Epoch 107/100, Loss: 48.6932, Validation Accuracy: 0.5992\n",
            "Epoch 108/100, Loss: 104.5878, Validation Accuracy: 0.6810\n",
            "Epoch 109/100, Loss: 69.1849, Validation Accuracy: 0.5862\n",
            "Epoch 110/100, Loss: 74.2955, Validation Accuracy: 0.6500\n",
            "Epoch 111/100, Loss: 23.9831, Validation Accuracy: 0.5174\n",
            "Epoch 112/100, Loss: 62.0579, Validation Accuracy: 0.5823\n",
            "Epoch 113/100, Loss: 21.7285, Validation Accuracy: 0.5982\n",
            "Epoch 114/100, Loss: 25.4167, Validation Accuracy: 0.6471\n",
            "Epoch 115/100, Loss: 58.9895, Validation Accuracy: 0.5952\n",
            "Epoch 116/100, Loss: 150.0860, Validation Accuracy: 0.4626\n",
            "Epoch 117/100, Loss: 77.0411, Validation Accuracy: 0.6152\n",
            "Epoch 118/100, Loss: 40.0089, Validation Accuracy: 0.6720\n",
            "Epoch 119/100, Loss: 99.0452, Validation Accuracy: 0.6680\n",
            "Epoch 120/100, Loss: 92.8609, Validation Accuracy: 0.5324\n",
            "Epoch 121/100, Loss: 68.5554, Validation Accuracy: 0.4915\n",
            "Epoch 122/100, Loss: 62.4818, Validation Accuracy: 0.6421\n",
            "Epoch 123/100, Loss: 126.5618, Validation Accuracy: 0.6710\n",
            "Epoch 124/100, Loss: 60.9037, Validation Accuracy: 0.6381\n",
            "Epoch 125/100, Loss: 48.5391, Validation Accuracy: 0.5045\n",
            "Epoch 126/100, Loss: 39.5512, Validation Accuracy: 0.6351\n",
            "Epoch 127/100, Loss: 136.9306, Validation Accuracy: 0.5842\n",
            "Epoch 128/100, Loss: 27.7050, Validation Accuracy: 0.6500\n",
            "Epoch 129/100, Loss: 73.6913, Validation Accuracy: 0.5912\n",
            "Epoch 130/100, Loss: 39.6104, Validation Accuracy: 0.5354\n",
            "Epoch 131/100, Loss: 63.1132, Validation Accuracy: 0.5254\n",
            "Epoch 132/100, Loss: 53.9131, Validation Accuracy: 0.6580\n",
            "Epoch 133/100, Loss: 49.5425, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 51.6167, Validation Accuracy: 0.5553\n",
            "Epoch 135/100, Loss: 61.7271, Validation Accuracy: 0.6471\n",
            "Epoch 136/100, Loss: 51.3143, Validation Accuracy: 0.6271\n",
            "Epoch 137/100, Loss: 65.4513, Validation Accuracy: 0.6211\n",
            "Epoch 138/100, Loss: 91.6405, Validation Accuracy: 0.5603\n",
            "Epoch 139/100, Loss: 71.6521, Validation Accuracy: 0.6451\n",
            "Epoch 140/100, Loss: 56.8441, Validation Accuracy: 0.4646\n",
            "Epoch 141/100, Loss: 94.4963, Validation Accuracy: 0.6211\n",
            "Epoch 142/100, Loss: 49.8784, Validation Accuracy: 0.6540\n",
            "Epoch 143/100, Loss: 31.2888, Validation Accuracy: 0.5294\n",
            "Epoch 144/100, Loss: 48.8690, Validation Accuracy: 0.6760\n",
            "Epoch 145/100, Loss: 47.4407, Validation Accuracy: 0.6341\n",
            "Epoch 146/100, Loss: 62.4292, Validation Accuracy: 0.4975\n",
            "Epoch 147/100, Loss: 31.5699, Validation Accuracy: 0.5573\n",
            "Epoch 148/100, Loss: 52.6729, Validation Accuracy: 0.4387\n",
            "Epoch 149/100, Loss: 95.0505, Validation Accuracy: 0.6102\n",
            "Epoch 150/100, Loss: 54.7744, Validation Accuracy: 0.4905\n",
            "Epoch 151/100, Loss: 61.2615, Validation Accuracy: 0.5125\n",
            "Epoch 152/100, Loss: 53.2089, Validation Accuracy: 0.6710\n",
            "Epoch 153/100, Loss: 43.7307, Validation Accuracy: 0.6241\n",
            "Epoch 154/100, Loss: 70.0194, Validation Accuracy: 0.6530\n",
            "Epoch 155/100, Loss: 109.0020, Validation Accuracy: 0.6261\n",
            "Epoch 156/100, Loss: 103.8052, Validation Accuracy: 0.6231\n",
            "Epoch 157/100, Loss: 47.2190, Validation Accuracy: 0.6251\n",
            "Epoch 158/100, Loss: 36.8327, Validation Accuracy: 0.5823\n",
            "Epoch 159/100, Loss: 78.3200, Validation Accuracy: 0.5922\n",
            "Epoch 160/100, Loss: 97.8716, Validation Accuracy: 0.5862\n",
            "Epoch 161/100, Loss: 24.9671, Validation Accuracy: 0.6271\n",
            "Epoch 162/100, Loss: 39.9989, Validation Accuracy: 0.6580\n",
            "Epoch 163/100, Loss: 79.3583, Validation Accuracy: 0.5603\n",
            "Epoch 164/100, Loss: 44.0386, Validation Accuracy: 0.5444\n",
            "Epoch 165/100, Loss: 68.4196, Validation Accuracy: 0.6461\n",
            "Epoch 166/100, Loss: 45.3369, Validation Accuracy: 0.5444\n",
            "Epoch 167/100, Loss: 107.8909, Validation Accuracy: 0.5673\n",
            "Epoch 168/100, Loss: 72.9509, Validation Accuracy: 0.6211\n",
            "Epoch 169/100, Loss: 95.1870, Validation Accuracy: 0.5653\n",
            "Epoch 170/100, Loss: 81.9695, Validation Accuracy: 0.6760\n",
            "Epoch 171/100, Loss: 18.7108, Validation Accuracy: 0.5623\n",
            "Epoch 172/100, Loss: 58.6595, Validation Accuracy: 0.6082\n",
            "Epoch 173/100, Loss: 22.1068, Validation Accuracy: 0.5852\n",
            "Epoch 174/100, Loss: 86.4678, Validation Accuracy: 0.6002\n",
            "Epoch 175/100, Loss: 59.9664, Validation Accuracy: 0.5723\n",
            "Epoch 176/100, Loss: 103.3724, Validation Accuracy: 0.6610\n",
            "Epoch 177/100, Loss: 167.2231, Validation Accuracy: 0.6820\n",
            "Epoch 178/100, Loss: 25.9443, Validation Accuracy: 0.6191\n",
            "Epoch 179/100, Loss: 2.0246, Validation Accuracy: 0.5932\n",
            "Epoch 180/100, Loss: 72.2242, Validation Accuracy: 0.6072\n",
            "Epoch 181/100, Loss: 110.8523, Validation Accuracy: 0.5942\n",
            "Epoch 182/100, Loss: 75.4815, Validation Accuracy: 0.5763\n",
            "Epoch 183/100, Loss: 60.9401, Validation Accuracy: 0.5952\n",
            "Epoch 184/100, Loss: 56.3213, Validation Accuracy: 0.6221\n",
            "Epoch 185/100, Loss: 140.6098, Validation Accuracy: 0.6500\n",
            "Epoch 186/100, Loss: 68.7708, Validation Accuracy: 0.6750\n",
            "Epoch 187/100, Loss: 42.8260, Validation Accuracy: 0.6590\n",
            "Epoch 188/100, Loss: 54.2191, Validation Accuracy: 0.6231\n",
            "Epoch 189/100, Loss: 59.0700, Validation Accuracy: 0.5932\n",
            "Epoch 190/100, Loss: 76.4295, Validation Accuracy: 0.6022\n",
            "Epoch 191/100, Loss: 79.3287, Validation Accuracy: 0.6062\n",
            "Epoch 192/100, Loss: 17.7199, Validation Accuracy: 0.5543\n",
            "Epoch 193/100, Loss: 63.2599, Validation Accuracy: 0.6590\n",
            "Epoch 194/100, Loss: 42.4978, Validation Accuracy: 0.5972\n",
            "Epoch 195/100, Loss: 105.5028, Validation Accuracy: 0.5992\n",
            "Epoch 196/100, Loss: 40.2342, Validation Accuracy: 0.6291\n",
            "Epoch 197/100, Loss: 226.1137, Validation Accuracy: 0.6201\n",
            "Epoch 198/100, Loss: 212.4909, Validation Accuracy: 0.6042\n",
            "Epoch 199/100, Loss: 96.8081, Validation Accuracy: 0.6421\n",
            "Epoch 200/100, Loss: 108.1863, Validation Accuracy: 0.5484\n",
            "Reward for Child Model: 0.2647005252119971\n",
            "Child_53:  {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, [2, 0, 3, 1, 2, 1, 3, 3, 3, 0, 0, 3, 0, 0, 2], 0.2647005252119971\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 36, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(72, 48, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(156, 48, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=117504, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 24, 24]           2,736\n",
            "       BatchNorm2d-2           [-1, 36, 24, 24]              72\n",
            "            Conv2d-3           [-1, 36, 24, 18]           9,108\n",
            "       BatchNorm2d-4           [-1, 36, 24, 18]              72\n",
            "              ReLU-5           [-1, 36, 24, 18]               0\n",
            "            Conv2d-6           [-1, 36, 24, 16]           3,924\n",
            "       BatchNorm2d-7           [-1, 36, 24, 16]              72\n",
            "              ReLU-8           [-1, 36, 24, 16]               0\n",
            "            Conv2d-9           [-1, 48, 22, 22]          31,152\n",
            "      BatchNorm2d-10           [-1, 48, 22, 22]              96\n",
            "             ReLU-11           [-1, 48, 22, 22]               0\n",
            "           Conv2d-12           [-1, 48, 24, 22]          22,512\n",
            "      BatchNorm2d-13           [-1, 48, 24, 22]              96\n",
            "             ReLU-14           [-1, 48, 24, 22]               0\n",
            "           Linear-15                    [-1, 7]         822,535\n",
            "================================================================\n",
            "Total params: 892,375\n",
            "Trainable params: 892,375\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.10\n",
            "Params size (MB): 3.40\n",
            "Estimated Total Size (MB): 5.51\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 17.6319, Validation Accuracy: 0.6540\n",
            "Epoch 2/100, Loss: 48.3763, Validation Accuracy: 0.1545\n",
            "Epoch 3/100, Loss: 21.9054, Validation Accuracy: 0.6032\n",
            "Epoch 4/100, Loss: 4.6282, Validation Accuracy: 0.6540\n",
            "Epoch 5/100, Loss: 17.7373, Validation Accuracy: 0.4895\n",
            "Epoch 6/100, Loss: 493.0602, Validation Accuracy: 0.0788\n",
            "Epoch 7/100, Loss: 92.0670, Validation Accuracy: 0.3958\n",
            "Epoch 8/100, Loss: 9.0466, Validation Accuracy: 0.6431\n",
            "Epoch 9/100, Loss: 11.2344, Validation Accuracy: 0.6052\n",
            "Epoch 10/100, Loss: 4.3546, Validation Accuracy: 0.6371\n",
            "Epoch 11/100, Loss: 8.6715, Validation Accuracy: 0.6211\n",
            "Epoch 12/100, Loss: 17.5291, Validation Accuracy: 0.6281\n",
            "Epoch 13/100, Loss: 208.5951, Validation Accuracy: 0.5793\n",
            "Epoch 14/100, Loss: 34.4426, Validation Accuracy: 0.6072\n",
            "Epoch 15/100, Loss: 14.3283, Validation Accuracy: 0.6082\n",
            "Epoch 16/100, Loss: 8.8917, Validation Accuracy: 0.6391\n",
            "Epoch 17/100, Loss: 16.9406, Validation Accuracy: 0.5324\n",
            "Epoch 18/100, Loss: 20.3361, Validation Accuracy: 0.6510\n",
            "Epoch 19/100, Loss: 123.2104, Validation Accuracy: 0.5055\n",
            "Epoch 20/100, Loss: 69.6208, Validation Accuracy: 0.3819\n",
            "Epoch 21/100, Loss: 31.0987, Validation Accuracy: 0.3450\n",
            "Epoch 22/100, Loss: 34.8270, Validation Accuracy: 0.6750\n",
            "Epoch 23/100, Loss: 23.6934, Validation Accuracy: 0.6221\n",
            "Epoch 24/100, Loss: 11.8715, Validation Accuracy: 0.6321\n",
            "Epoch 25/100, Loss: 16.5624, Validation Accuracy: 0.5005\n",
            "Epoch 26/100, Loss: 36.7876, Validation Accuracy: 0.4546\n",
            "Epoch 27/100, Loss: 120.7586, Validation Accuracy: 0.3789\n",
            "Epoch 28/100, Loss: 60.5807, Validation Accuracy: 0.5314\n",
            "Epoch 29/100, Loss: 38.8750, Validation Accuracy: 0.4985\n",
            "Epoch 30/100, Loss: 56.9837, Validation Accuracy: 0.6481\n",
            "Epoch 31/100, Loss: 22.1131, Validation Accuracy: 0.5833\n",
            "Epoch 32/100, Loss: 51.1436, Validation Accuracy: 0.3699\n",
            "Epoch 33/100, Loss: 53.8750, Validation Accuracy: 0.5932\n",
            "Epoch 34/100, Loss: 32.6635, Validation Accuracy: 0.5304\n",
            "Epoch 35/100, Loss: 105.5663, Validation Accuracy: 0.6500\n",
            "Epoch 36/100, Loss: 61.1251, Validation Accuracy: 0.6560\n",
            "Epoch 37/100, Loss: 51.2030, Validation Accuracy: 0.6740\n",
            "Epoch 38/100, Loss: 63.4188, Validation Accuracy: 0.5324\n",
            "Epoch 39/100, Loss: 29.1422, Validation Accuracy: 0.5184\n",
            "Epoch 40/100, Loss: 25.6431, Validation Accuracy: 0.6331\n",
            "Epoch 41/100, Loss: 58.6241, Validation Accuracy: 0.5982\n",
            "Epoch 42/100, Loss: 46.1242, Validation Accuracy: 0.4447\n",
            "Epoch 43/100, Loss: 80.6161, Validation Accuracy: 0.4138\n",
            "Epoch 44/100, Loss: 217.2883, Validation Accuracy: 0.4626\n",
            "Epoch 45/100, Loss: 77.6658, Validation Accuracy: 0.5294\n",
            "Epoch 46/100, Loss: 72.1198, Validation Accuracy: 0.6411\n",
            "Epoch 47/100, Loss: 49.1872, Validation Accuracy: 0.5803\n",
            "Epoch 48/100, Loss: 24.6598, Validation Accuracy: 0.6191\n",
            "Epoch 49/100, Loss: 36.8295, Validation Accuracy: 0.5055\n",
            "Epoch 50/100, Loss: 50.5150, Validation Accuracy: 0.6630\n",
            "Epoch 51/100, Loss: 120.4965, Validation Accuracy: 0.4556\n",
            "Epoch 52/100, Loss: 28.6935, Validation Accuracy: 0.4945\n",
            "Epoch 53/100, Loss: 74.8229, Validation Accuracy: 0.5763\n",
            "Epoch 54/100, Loss: 23.1453, Validation Accuracy: 0.5025\n",
            "Epoch 55/100, Loss: 24.8527, Validation Accuracy: 0.6540\n",
            "Epoch 56/100, Loss: 32.3497, Validation Accuracy: 0.4167\n",
            "Epoch 57/100, Loss: 67.1916, Validation Accuracy: 0.5254\n",
            "Epoch 58/100, Loss: 40.7894, Validation Accuracy: 0.6650\n",
            "Epoch 59/100, Loss: 55.8230, Validation Accuracy: 0.5912\n",
            "Epoch 60/100, Loss: 26.0772, Validation Accuracy: 0.6500\n",
            "Epoch 61/100, Loss: 40.0931, Validation Accuracy: 0.4985\n",
            "Epoch 62/100, Loss: 33.0471, Validation Accuracy: 0.5653\n",
            "Epoch 63/100, Loss: 12.2195, Validation Accuracy: 0.6580\n",
            "Epoch 64/100, Loss: 106.0498, Validation Accuracy: 0.4347\n",
            "Epoch 65/100, Loss: 49.9826, Validation Accuracy: 0.5862\n",
            "Epoch 66/100, Loss: 21.8906, Validation Accuracy: 0.5613\n",
            "Epoch 67/100, Loss: 27.2117, Validation Accuracy: 0.6052\n",
            "Epoch 68/100, Loss: 46.1751, Validation Accuracy: 0.6291\n",
            "Epoch 69/100, Loss: 48.4961, Validation Accuracy: 0.5543\n",
            "Epoch 70/100, Loss: 160.5502, Validation Accuracy: 0.5892\n",
            "Epoch 71/100, Loss: 29.2882, Validation Accuracy: 0.5882\n",
            "Epoch 72/100, Loss: 13.9435, Validation Accuracy: 0.6301\n",
            "Epoch 73/100, Loss: 58.1987, Validation Accuracy: 0.4726\n",
            "Epoch 74/100, Loss: 10.9255, Validation Accuracy: 0.6261\n",
            "Epoch 75/100, Loss: 46.8251, Validation Accuracy: 0.4576\n",
            "Epoch 76/100, Loss: 11.5215, Validation Accuracy: 0.5344\n",
            "Epoch 77/100, Loss: 21.7779, Validation Accuracy: 0.5603\n",
            "Epoch 78/100, Loss: 90.2536, Validation Accuracy: 0.6401\n",
            "Epoch 79/100, Loss: 69.2274, Validation Accuracy: 0.5833\n",
            "Epoch 80/100, Loss: 39.6715, Validation Accuracy: 0.5793\n",
            "Epoch 81/100, Loss: 39.3627, Validation Accuracy: 0.6271\n",
            "Epoch 82/100, Loss: 22.8907, Validation Accuracy: 0.6630\n",
            "Epoch 83/100, Loss: 271.7887, Validation Accuracy: 0.5793\n",
            "Epoch 84/100, Loss: 48.8918, Validation Accuracy: 0.4596\n",
            "Epoch 85/100, Loss: 71.1491, Validation Accuracy: 0.6032\n",
            "Epoch 86/100, Loss: 101.5634, Validation Accuracy: 0.4826\n",
            "Epoch 87/100, Loss: 96.1651, Validation Accuracy: 0.6401\n",
            "Epoch 88/100, Loss: 30.5349, Validation Accuracy: 0.5224\n",
            "Epoch 89/100, Loss: 19.5679, Validation Accuracy: 0.5005\n",
            "Epoch 90/100, Loss: 111.2011, Validation Accuracy: 0.5842\n",
            "Epoch 91/100, Loss: 336.1136, Validation Accuracy: 0.6560\n",
            "Epoch 92/100, Loss: 17.5425, Validation Accuracy: 0.6012\n",
            "Epoch 93/100, Loss: 49.5194, Validation Accuracy: 0.6740\n",
            "Epoch 94/100, Loss: 20.1778, Validation Accuracy: 0.4158\n",
            "Epoch 95/100, Loss: 31.1173, Validation Accuracy: 0.4776\n",
            "Epoch 96/100, Loss: 13.2899, Validation Accuracy: 0.3549\n",
            "Epoch 97/100, Loss: 39.6394, Validation Accuracy: 0.4287\n",
            "Epoch 98/100, Loss: 22.8413, Validation Accuracy: 0.6620\n",
            "Epoch 99/100, Loss: 63.7173, Validation Accuracy: 0.5733\n",
            "Epoch 100/100, Loss: 68.0714, Validation Accuracy: 0.6640\n",
            "Epoch 101/100, Loss: 84.8538, Validation Accuracy: 0.6211\n",
            "Epoch 102/100, Loss: 60.2504, Validation Accuracy: 0.3739\n",
            "Epoch 103/100, Loss: 45.7880, Validation Accuracy: 0.3021\n",
            "Epoch 104/100, Loss: 48.7055, Validation Accuracy: 0.5892\n",
            "Epoch 105/100, Loss: 73.2681, Validation Accuracy: 0.6491\n",
            "Epoch 106/100, Loss: 123.3138, Validation Accuracy: 0.6082\n",
            "Epoch 107/100, Loss: 36.2726, Validation Accuracy: 0.6311\n",
            "Epoch 108/100, Loss: 80.5552, Validation Accuracy: 0.6560\n",
            "Epoch 109/100, Loss: 29.6302, Validation Accuracy: 0.6660\n",
            "Epoch 110/100, Loss: 48.4307, Validation Accuracy: 0.5174\n",
            "Epoch 111/100, Loss: 29.8072, Validation Accuracy: 0.5324\n",
            "Epoch 112/100, Loss: 68.1956, Validation Accuracy: 0.5095\n",
            "Epoch 113/100, Loss: 6.8395, Validation Accuracy: 0.6291\n",
            "Epoch 114/100, Loss: 5.9091, Validation Accuracy: 0.6301\n",
            "Epoch 115/100, Loss: 23.9209, Validation Accuracy: 0.6241\n",
            "Epoch 116/100, Loss: 32.2688, Validation Accuracy: 0.6790\n",
            "Epoch 117/100, Loss: 46.6097, Validation Accuracy: 0.5563\n",
            "Epoch 118/100, Loss: 64.1156, Validation Accuracy: 0.5892\n",
            "Epoch 119/100, Loss: 58.1188, Validation Accuracy: 0.4865\n",
            "Epoch 120/100, Loss: 53.0528, Validation Accuracy: 0.6301\n",
            "Epoch 121/100, Loss: 48.1026, Validation Accuracy: 0.6371\n",
            "Epoch 122/100, Loss: 31.7325, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 46.5989, Validation Accuracy: 0.6371\n",
            "Epoch 124/100, Loss: 23.8309, Validation Accuracy: 0.6730\n",
            "Epoch 125/100, Loss: 23.3352, Validation Accuracy: 0.6481\n",
            "Epoch 126/100, Loss: 100.2421, Validation Accuracy: 0.5623\n",
            "Epoch 127/100, Loss: 72.2434, Validation Accuracy: 0.5184\n",
            "Epoch 128/100, Loss: 34.0251, Validation Accuracy: 0.6231\n",
            "Epoch 129/100, Loss: 58.3901, Validation Accuracy: 0.5813\n",
            "Epoch 130/100, Loss: 36.2072, Validation Accuracy: 0.6441\n",
            "Epoch 131/100, Loss: 34.8649, Validation Accuracy: 0.6740\n",
            "Epoch 132/100, Loss: 71.9170, Validation Accuracy: 0.5833\n",
            "Epoch 133/100, Loss: 31.8462, Validation Accuracy: 0.5753\n",
            "Epoch 134/100, Loss: 46.6058, Validation Accuracy: 0.6770\n",
            "Epoch 135/100, Loss: 83.3616, Validation Accuracy: 0.6590\n",
            "Epoch 136/100, Loss: 50.7415, Validation Accuracy: 0.6660\n",
            "Epoch 137/100, Loss: 231.7113, Validation Accuracy: 0.6162\n",
            "Epoch 138/100, Loss: 36.9527, Validation Accuracy: 0.6800\n",
            "Epoch 139/100, Loss: 31.1283, Validation Accuracy: 0.6052\n",
            "Epoch 140/100, Loss: 44.5932, Validation Accuracy: 0.4796\n",
            "Epoch 141/100, Loss: 69.4332, Validation Accuracy: 0.5334\n",
            "Epoch 142/100, Loss: 69.5754, Validation Accuracy: 0.5992\n",
            "Epoch 143/100, Loss: 35.7941, Validation Accuracy: 0.6720\n",
            "Epoch 144/100, Loss: 65.1988, Validation Accuracy: 0.4995\n",
            "Epoch 145/100, Loss: 35.2297, Validation Accuracy: 0.6191\n",
            "Epoch 146/100, Loss: 48.3860, Validation Accuracy: 0.4078\n",
            "Epoch 147/100, Loss: 171.4220, Validation Accuracy: 0.6610\n",
            "Epoch 148/100, Loss: 41.9053, Validation Accuracy: 0.6750\n",
            "Epoch 149/100, Loss: 32.8877, Validation Accuracy: 0.5454\n",
            "Epoch 150/100, Loss: 17.5580, Validation Accuracy: 0.5952\n",
            "Epoch 151/100, Loss: 106.0711, Validation Accuracy: 0.5384\n",
            "Epoch 152/100, Loss: 59.6751, Validation Accuracy: 0.6640\n",
            "Epoch 153/100, Loss: 21.8878, Validation Accuracy: 0.6321\n",
            "Epoch 154/100, Loss: 16.1419, Validation Accuracy: 0.6022\n",
            "Epoch 155/100, Loss: 43.6883, Validation Accuracy: 0.4955\n",
            "Epoch 156/100, Loss: 18.6330, Validation Accuracy: 0.5314\n",
            "Epoch 157/100, Loss: 47.8421, Validation Accuracy: 0.4945\n",
            "Epoch 158/100, Loss: 131.7708, Validation Accuracy: 0.4407\n",
            "Epoch 159/100, Loss: 127.1914, Validation Accuracy: 0.5902\n",
            "Epoch 160/100, Loss: 36.3721, Validation Accuracy: 0.6032\n",
            "Epoch 161/100, Loss: 45.0137, Validation Accuracy: 0.6670\n",
            "Epoch 162/100, Loss: 68.4917, Validation Accuracy: 0.6481\n",
            "Epoch 163/100, Loss: 15.6380, Validation Accuracy: 0.6201\n",
            "Epoch 164/100, Loss: 56.0888, Validation Accuracy: 0.5952\n",
            "Epoch 165/100, Loss: 41.8170, Validation Accuracy: 0.6660\n",
            "Epoch 166/100, Loss: 47.9272, Validation Accuracy: 0.5494\n",
            "Epoch 167/100, Loss: 31.3979, Validation Accuracy: 0.5583\n",
            "Epoch 168/100, Loss: 21.9609, Validation Accuracy: 0.5753\n",
            "Epoch 169/100, Loss: 34.2571, Validation Accuracy: 0.5294\n",
            "Epoch 170/100, Loss: 72.0846, Validation Accuracy: 0.6042\n",
            "Epoch 171/100, Loss: 119.5908, Validation Accuracy: 0.5773\n",
            "Epoch 172/100, Loss: 55.5890, Validation Accuracy: 0.6760\n",
            "Epoch 173/100, Loss: 44.3730, Validation Accuracy: 0.5892\n",
            "Epoch 174/100, Loss: 54.3765, Validation Accuracy: 0.5264\n",
            "Epoch 175/100, Loss: 44.9221, Validation Accuracy: 0.5105\n",
            "Epoch 176/100, Loss: 26.7848, Validation Accuracy: 0.5105\n",
            "Epoch 177/100, Loss: 110.6980, Validation Accuracy: 0.6750\n",
            "Epoch 178/100, Loss: 76.7352, Validation Accuracy: 0.5244\n",
            "Epoch 179/100, Loss: 74.4277, Validation Accuracy: 0.4945\n",
            "Epoch 180/100, Loss: 63.1095, Validation Accuracy: 0.6560\n",
            "Epoch 181/100, Loss: 63.3097, Validation Accuracy: 0.6371\n",
            "Epoch 182/100, Loss: 38.3043, Validation Accuracy: 0.5683\n",
            "Epoch 183/100, Loss: 77.7709, Validation Accuracy: 0.3220\n",
            "Epoch 184/100, Loss: 61.3252, Validation Accuracy: 0.6142\n",
            "Epoch 185/100, Loss: 28.0915, Validation Accuracy: 0.6351\n",
            "Epoch 186/100, Loss: 69.7993, Validation Accuracy: 0.5125\n",
            "Epoch 187/100, Loss: 26.8284, Validation Accuracy: 0.5593\n",
            "Epoch 188/100, Loss: 71.9797, Validation Accuracy: 0.4317\n",
            "Epoch 189/100, Loss: 74.2933, Validation Accuracy: 0.5982\n",
            "Epoch 190/100, Loss: 115.5889, Validation Accuracy: 0.5972\n",
            "Epoch 191/100, Loss: 35.4790, Validation Accuracy: 0.6311\n",
            "Epoch 192/100, Loss: 38.2163, Validation Accuracy: 0.4865\n",
            "Epoch 193/100, Loss: 50.0454, Validation Accuracy: 0.5713\n",
            "Epoch 194/100, Loss: 93.6816, Validation Accuracy: 0.5972\n",
            "Epoch 195/100, Loss: 50.3122, Validation Accuracy: 0.6530\n",
            "Epoch 196/100, Loss: 73.4154, Validation Accuracy: 0.6072\n",
            "Epoch 197/100, Loss: 44.9849, Validation Accuracy: 0.6002\n",
            "Epoch 198/100, Loss: 39.0954, Validation Accuracy: 0.5583\n",
            "Epoch 199/100, Loss: 89.7050, Validation Accuracy: 0.6590\n",
            "Epoch 200/100, Loss: 84.0118, Validation Accuracy: 0.6112\n",
            "Reward for Child Model: 0.2862210558013131\n",
            "Child_54:  {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, [2, 2, 1, 0, 3, 1, 0, 1, 1, 1, 1, 2, 0, 1, 2], 0.2862210558013131\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(88, 24, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(112, 48, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(48, 36, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=189280, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 28, 26]             240\n",
            "       BatchNorm2d-2           [-1, 24, 28, 26]              48\n",
            "            Conv2d-3           [-1, 64, 26, 24]          13,888\n",
            "       BatchNorm2d-4           [-1, 64, 26, 24]             128\n",
            "              ReLU-5           [-1, 64, 26, 24]               0\n",
            "            Conv2d-6           [-1, 24, 28, 22]          10,584\n",
            "       BatchNorm2d-7           [-1, 24, 28, 22]              48\n",
            "              ReLU-8           [-1, 24, 28, 22]               0\n",
            "            Conv2d-9           [-1, 48, 24, 20]         188,208\n",
            "      BatchNorm2d-10           [-1, 48, 24, 20]              96\n",
            "             ReLU-11           [-1, 48, 24, 20]               0\n",
            "           Conv2d-12           [-1, 36, 24, 20]           1,764\n",
            "      BatchNorm2d-13           [-1, 36, 24, 20]              72\n",
            "             ReLU-14           [-1, 36, 24, 20]               0\n",
            "           Linear-15                    [-1, 7]       1,324,967\n",
            "================================================================\n",
            "Total params: 1,540,043\n",
            "Trainable params: 1,540,043\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.44\n",
            "Params size (MB): 5.87\n",
            "Estimated Total Size (MB): 8.33\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 41.6406, Validation Accuracy: 0.1446\n",
            "Epoch 2/100, Loss: 64.7508, Validation Accuracy: 0.6520\n",
            "Epoch 3/100, Loss: 26.8746, Validation Accuracy: 0.6391\n",
            "Epoch 4/100, Loss: 91.5816, Validation Accuracy: 0.5474\n",
            "Epoch 5/100, Loss: 48.0600, Validation Accuracy: 0.3400\n",
            "Epoch 6/100, Loss: 220.6858, Validation Accuracy: 0.5952\n",
            "Epoch 7/100, Loss: 30.3172, Validation Accuracy: 0.3519\n",
            "Epoch 8/100, Loss: 14.7433, Validation Accuracy: 0.5075\n",
            "Epoch 9/100, Loss: 39.5855, Validation Accuracy: 0.3918\n",
            "Epoch 10/100, Loss: 64.9816, Validation Accuracy: 0.5254\n",
            "Epoch 11/100, Loss: 21.5566, Validation Accuracy: 0.4756\n",
            "Epoch 12/100, Loss: 24.6988, Validation Accuracy: 0.5224\n",
            "Epoch 13/100, Loss: 26.6829, Validation Accuracy: 0.5533\n",
            "Epoch 14/100, Loss: 7.2327, Validation Accuracy: 0.6341\n",
            "Epoch 15/100, Loss: 115.3474, Validation Accuracy: 0.6650\n",
            "Epoch 16/100, Loss: 158.7723, Validation Accuracy: 0.6730\n",
            "Epoch 17/100, Loss: 64.0070, Validation Accuracy: 0.5214\n",
            "Epoch 18/100, Loss: 13.3888, Validation Accuracy: 0.6122\n",
            "Epoch 19/100, Loss: 22.3639, Validation Accuracy: 0.5214\n",
            "Epoch 20/100, Loss: 9.8809, Validation Accuracy: 0.6102\n",
            "Epoch 21/100, Loss: 18.8498, Validation Accuracy: 0.6660\n",
            "Epoch 22/100, Loss: 21.9730, Validation Accuracy: 0.4058\n",
            "Epoch 23/100, Loss: 1602.7789, Validation Accuracy: 0.6132\n",
            "Epoch 24/100, Loss: 35.9550, Validation Accuracy: 0.5842\n",
            "Epoch 25/100, Loss: 32.2133, Validation Accuracy: 0.4447\n",
            "Epoch 26/100, Loss: 18.5650, Validation Accuracy: 0.3360\n",
            "Epoch 27/100, Loss: 10.9386, Validation Accuracy: 0.6570\n",
            "Epoch 28/100, Loss: 3.8891, Validation Accuracy: 0.6291\n",
            "Epoch 29/100, Loss: 34.7322, Validation Accuracy: 0.4367\n",
            "Epoch 30/100, Loss: 22.7739, Validation Accuracy: 0.3121\n",
            "Epoch 31/100, Loss: 33.6790, Validation Accuracy: 0.5474\n",
            "Epoch 32/100, Loss: 192.4348, Validation Accuracy: 0.6012\n",
            "Epoch 33/100, Loss: 65.1061, Validation Accuracy: 0.6321\n",
            "Epoch 34/100, Loss: 33.3297, Validation Accuracy: 0.4865\n",
            "Epoch 35/100, Loss: 37.9145, Validation Accuracy: 0.5244\n",
            "Epoch 36/100, Loss: 96.0498, Validation Accuracy: 0.6012\n",
            "Epoch 37/100, Loss: 29.9315, Validation Accuracy: 0.6241\n",
            "Epoch 38/100, Loss: 76.6668, Validation Accuracy: 0.2223\n",
            "Epoch 39/100, Loss: 69.1102, Validation Accuracy: 0.4397\n",
            "Epoch 40/100, Loss: 114.6414, Validation Accuracy: 0.6032\n",
            "Epoch 41/100, Loss: 205.8530, Validation Accuracy: 0.4706\n",
            "Epoch 42/100, Loss: 39.0322, Validation Accuracy: 0.6720\n",
            "Epoch 43/100, Loss: 11.0934, Validation Accuracy: 0.6560\n",
            "Epoch 44/100, Loss: 18.8335, Validation Accuracy: 0.5484\n",
            "Epoch 45/100, Loss: 18.4253, Validation Accuracy: 0.4885\n",
            "Epoch 46/100, Loss: 65.6907, Validation Accuracy: 0.6670\n",
            "Epoch 47/100, Loss: 112.6159, Validation Accuracy: 0.4995\n",
            "Epoch 48/100, Loss: 157.6044, Validation Accuracy: 0.5992\n",
            "Epoch 49/100, Loss: 21.9666, Validation Accuracy: 0.6451\n",
            "Epoch 50/100, Loss: 28.3810, Validation Accuracy: 0.5025\n",
            "Epoch 51/100, Loss: 56.5361, Validation Accuracy: 0.5484\n",
            "Epoch 52/100, Loss: 19.7754, Validation Accuracy: 0.6700\n",
            "Epoch 53/100, Loss: 23.5604, Validation Accuracy: 0.6500\n",
            "Epoch 54/100, Loss: 187.4040, Validation Accuracy: 0.5862\n",
            "Epoch 55/100, Loss: 26.2255, Validation Accuracy: 0.4716\n",
            "Epoch 56/100, Loss: 24.2834, Validation Accuracy: 0.5454\n",
            "Epoch 57/100, Loss: 22.8503, Validation Accuracy: 0.5085\n",
            "Epoch 58/100, Loss: 34.6807, Validation Accuracy: 0.5444\n",
            "Epoch 59/100, Loss: 18.6702, Validation Accuracy: 0.6122\n",
            "Epoch 60/100, Loss: 117.8386, Validation Accuracy: 0.4865\n",
            "Epoch 61/100, Loss: 150.1509, Validation Accuracy: 0.4935\n",
            "Epoch 62/100, Loss: 50.2073, Validation Accuracy: 0.6361\n",
            "Epoch 63/100, Loss: 35.7132, Validation Accuracy: 0.5793\n",
            "Epoch 64/100, Loss: 34.4879, Validation Accuracy: 0.6311\n",
            "Epoch 65/100, Loss: 39.7537, Validation Accuracy: 0.5723\n",
            "Epoch 66/100, Loss: 48.4953, Validation Accuracy: 0.4776\n",
            "Epoch 67/100, Loss: 123.9961, Validation Accuracy: 0.5703\n",
            "Epoch 68/100, Loss: 8.2612, Validation Accuracy: 0.6560\n",
            "Epoch 69/100, Loss: 19.1658, Validation Accuracy: 0.5603\n",
            "Epoch 70/100, Loss: 20.7471, Validation Accuracy: 0.4776\n",
            "Epoch 71/100, Loss: 40.6708, Validation Accuracy: 0.5733\n",
            "Epoch 72/100, Loss: 71.9606, Validation Accuracy: 0.6600\n",
            "Epoch 73/100, Loss: 146.1126, Validation Accuracy: 0.5833\n",
            "Epoch 74/100, Loss: 54.8885, Validation Accuracy: 0.6441\n",
            "Epoch 75/100, Loss: 59.0435, Validation Accuracy: 0.6481\n",
            "Epoch 76/100, Loss: 30.5338, Validation Accuracy: 0.5882\n",
            "Epoch 77/100, Loss: 31.9484, Validation Accuracy: 0.6500\n",
            "Epoch 78/100, Loss: 46.6431, Validation Accuracy: 0.6301\n",
            "Epoch 79/100, Loss: 132.3439, Validation Accuracy: 0.5633\n",
            "Epoch 80/100, Loss: 53.1099, Validation Accuracy: 0.6421\n",
            "Epoch 81/100, Loss: 53.8389, Validation Accuracy: 0.4656\n",
            "Epoch 82/100, Loss: 45.4407, Validation Accuracy: 0.6291\n",
            "Epoch 83/100, Loss: 49.5836, Validation Accuracy: 0.3230\n",
            "Epoch 84/100, Loss: 95.6687, Validation Accuracy: 0.5513\n",
            "Epoch 85/100, Loss: 31.0382, Validation Accuracy: 0.6700\n",
            "Epoch 86/100, Loss: 33.2427, Validation Accuracy: 0.5842\n",
            "Epoch 87/100, Loss: 113.8001, Validation Accuracy: 0.6620\n",
            "Epoch 88/100, Loss: 113.3485, Validation Accuracy: 0.5912\n",
            "Epoch 89/100, Loss: 13.3619, Validation Accuracy: 0.6510\n",
            "Epoch 90/100, Loss: 37.2499, Validation Accuracy: 0.5942\n",
            "Epoch 91/100, Loss: 63.4676, Validation Accuracy: 0.5862\n",
            "Epoch 92/100, Loss: 73.9983, Validation Accuracy: 0.5115\n",
            "Epoch 93/100, Loss: 60.8489, Validation Accuracy: 0.6431\n",
            "Epoch 94/100, Loss: 63.1920, Validation Accuracy: 0.5424\n",
            "Epoch 95/100, Loss: 78.5958, Validation Accuracy: 0.4138\n",
            "Epoch 96/100, Loss: 74.9217, Validation Accuracy: 0.6082\n",
            "Epoch 97/100, Loss: 34.7071, Validation Accuracy: 0.5553\n",
            "Epoch 98/100, Loss: 75.5998, Validation Accuracy: 0.6600\n",
            "Epoch 99/100, Loss: 78.4479, Validation Accuracy: 0.6241\n",
            "Epoch 100/100, Loss: 56.0352, Validation Accuracy: 0.5673\n",
            "Epoch 101/100, Loss: 95.2842, Validation Accuracy: 0.5434\n",
            "Epoch 102/100, Loss: 46.5011, Validation Accuracy: 0.6022\n",
            "Epoch 103/100, Loss: 132.6254, Validation Accuracy: 0.6411\n",
            "Epoch 104/100, Loss: 46.0413, Validation Accuracy: 0.5982\n",
            "Epoch 105/100, Loss: 27.1345, Validation Accuracy: 0.6201\n",
            "Epoch 106/100, Loss: 69.7597, Validation Accuracy: 0.6012\n",
            "Epoch 107/100, Loss: 44.6636, Validation Accuracy: 0.5603\n",
            "Epoch 108/100, Loss: 113.0298, Validation Accuracy: 0.5982\n",
            "Epoch 109/100, Loss: 115.1487, Validation Accuracy: 0.5713\n",
            "Epoch 110/100, Loss: 46.8524, Validation Accuracy: 0.6670\n",
            "Epoch 111/100, Loss: 43.6319, Validation Accuracy: 0.6750\n",
            "Epoch 112/100, Loss: 32.0207, Validation Accuracy: 0.6630\n",
            "Epoch 113/100, Loss: 65.1496, Validation Accuracy: 0.5803\n",
            "Epoch 114/100, Loss: 56.6552, Validation Accuracy: 0.5115\n",
            "Epoch 115/100, Loss: 52.8101, Validation Accuracy: 0.5872\n",
            "Epoch 116/100, Loss: 28.0150, Validation Accuracy: 0.6102\n",
            "Epoch 117/100, Loss: 34.7745, Validation Accuracy: 0.6500\n",
            "Epoch 118/100, Loss: 32.4144, Validation Accuracy: 0.6481\n",
            "Epoch 119/100, Loss: 99.8883, Validation Accuracy: 0.6321\n",
            "Epoch 120/100, Loss: 173.2625, Validation Accuracy: 0.5165\n",
            "Epoch 121/100, Loss: 162.3320, Validation Accuracy: 0.6670\n",
            "Epoch 122/100, Loss: 43.4274, Validation Accuracy: 0.5793\n",
            "Epoch 123/100, Loss: 78.2461, Validation Accuracy: 0.5773\n",
            "Epoch 124/100, Loss: 13.7798, Validation Accuracy: 0.5274\n",
            "Epoch 125/100, Loss: 16.1999, Validation Accuracy: 0.6241\n",
            "Epoch 126/100, Loss: 326.7747, Validation Accuracy: 0.5842\n",
            "Epoch 127/100, Loss: 63.3454, Validation Accuracy: 0.5882\n",
            "Epoch 128/100, Loss: 29.9055, Validation Accuracy: 0.5892\n",
            "Epoch 129/100, Loss: 23.8696, Validation Accuracy: 0.6600\n",
            "Epoch 130/100, Loss: 118.7328, Validation Accuracy: 0.6191\n",
            "Epoch 131/100, Loss: 46.8157, Validation Accuracy: 0.6062\n",
            "Epoch 132/100, Loss: 28.2899, Validation Accuracy: 0.5862\n",
            "Epoch 133/100, Loss: 47.5128, Validation Accuracy: 0.5643\n",
            "Epoch 134/100, Loss: 16.0856, Validation Accuracy: 0.6820\n",
            "Epoch 135/100, Loss: 63.8261, Validation Accuracy: 0.6201\n",
            "Epoch 136/100, Loss: 144.8428, Validation Accuracy: 0.6500\n",
            "Epoch 137/100, Loss: 75.8847, Validation Accuracy: 0.6381\n",
            "Epoch 138/100, Loss: 60.9910, Validation Accuracy: 0.6112\n",
            "Epoch 139/100, Loss: 70.4556, Validation Accuracy: 0.3838\n",
            "Epoch 140/100, Loss: 74.7542, Validation Accuracy: 0.5783\n",
            "Epoch 141/100, Loss: 340.8540, Validation Accuracy: 0.4816\n",
            "Epoch 142/100, Loss: 87.6453, Validation Accuracy: 0.6321\n",
            "Epoch 143/100, Loss: 29.3067, Validation Accuracy: 0.6431\n",
            "Epoch 144/100, Loss: 67.1903, Validation Accuracy: 0.6391\n",
            "Epoch 145/100, Loss: 27.5292, Validation Accuracy: 0.5862\n",
            "Epoch 146/100, Loss: 43.0676, Validation Accuracy: 0.6211\n",
            "Epoch 147/100, Loss: 31.0365, Validation Accuracy: 0.5354\n",
            "Epoch 148/100, Loss: 33.7131, Validation Accuracy: 0.5633\n",
            "Epoch 149/100, Loss: 58.1172, Validation Accuracy: 0.6092\n",
            "Epoch 150/100, Loss: 97.2291, Validation Accuracy: 0.6241\n",
            "Epoch 151/100, Loss: 52.8608, Validation Accuracy: 0.6580\n",
            "Epoch 152/100, Loss: 54.4297, Validation Accuracy: 0.5862\n",
            "Epoch 153/100, Loss: 35.2108, Validation Accuracy: 0.6072\n",
            "Epoch 154/100, Loss: 18.2167, Validation Accuracy: 0.6231\n",
            "Epoch 155/100, Loss: 57.5751, Validation Accuracy: 0.5404\n",
            "Epoch 156/100, Loss: 49.2660, Validation Accuracy: 0.6570\n",
            "Epoch 157/100, Loss: 75.3828, Validation Accuracy: 0.6600\n",
            "Epoch 158/100, Loss: 57.6971, Validation Accuracy: 0.6231\n",
            "Epoch 159/100, Loss: 81.8554, Validation Accuracy: 0.6261\n",
            "Epoch 160/100, Loss: 57.2777, Validation Accuracy: 0.6610\n",
            "Epoch 161/100, Loss: 44.0103, Validation Accuracy: 0.4895\n",
            "Epoch 162/100, Loss: 33.7693, Validation Accuracy: 0.5125\n",
            "Epoch 163/100, Loss: 9.1465, Validation Accuracy: 0.6381\n",
            "Epoch 164/100, Loss: 160.9957, Validation Accuracy: 0.5803\n",
            "Epoch 165/100, Loss: 236.1187, Validation Accuracy: 0.5912\n",
            "Epoch 166/100, Loss: 68.9613, Validation Accuracy: 0.5872\n",
            "Epoch 167/100, Loss: 101.1323, Validation Accuracy: 0.5803\n",
            "Epoch 168/100, Loss: 27.1067, Validation Accuracy: 0.5424\n",
            "Epoch 169/100, Loss: 22.7311, Validation Accuracy: 0.5932\n",
            "Epoch 170/100, Loss: 27.6816, Validation Accuracy: 0.6441\n",
            "Epoch 171/100, Loss: 87.1773, Validation Accuracy: 0.6171\n",
            "Epoch 172/100, Loss: 71.8167, Validation Accuracy: 0.5593\n",
            "Epoch 173/100, Loss: 109.2733, Validation Accuracy: 0.5862\n",
            "Epoch 174/100, Loss: 174.8920, Validation Accuracy: 0.4895\n",
            "Epoch 175/100, Loss: 77.3486, Validation Accuracy: 0.5713\n",
            "Epoch 176/100, Loss: 37.8497, Validation Accuracy: 0.5763\n",
            "Epoch 177/100, Loss: 106.0737, Validation Accuracy: 0.4816\n",
            "Epoch 178/100, Loss: 27.7305, Validation Accuracy: 0.6471\n",
            "Epoch 179/100, Loss: 22.7241, Validation Accuracy: 0.5852\n",
            "Epoch 180/100, Loss: 91.5091, Validation Accuracy: 0.6241\n",
            "Epoch 181/100, Loss: 80.4707, Validation Accuracy: 0.6491\n",
            "Epoch 182/100, Loss: 31.8479, Validation Accuracy: 0.6481\n",
            "Epoch 183/100, Loss: 72.4489, Validation Accuracy: 0.5075\n",
            "Epoch 184/100, Loss: 53.2492, Validation Accuracy: 0.6670\n",
            "Epoch 185/100, Loss: 90.2379, Validation Accuracy: 0.6730\n",
            "Epoch 186/100, Loss: 37.0416, Validation Accuracy: 0.6401\n",
            "Epoch 187/100, Loss: 149.1290, Validation Accuracy: 0.6341\n",
            "Epoch 188/100, Loss: 51.8452, Validation Accuracy: 0.6201\n",
            "Epoch 189/100, Loss: 96.4613, Validation Accuracy: 0.5743\n",
            "Epoch 190/100, Loss: 103.3889, Validation Accuracy: 0.5135\n",
            "Epoch 191/100, Loss: 14.0307, Validation Accuracy: 0.6471\n",
            "Epoch 192/100, Loss: 58.9494, Validation Accuracy: 0.6401\n",
            "Epoch 193/100, Loss: 105.4931, Validation Accuracy: 0.6012\n",
            "Epoch 194/100, Loss: 57.1775, Validation Accuracy: 0.5533\n",
            "Epoch 195/100, Loss: 15.3758, Validation Accuracy: 0.6152\n",
            "Epoch 196/100, Loss: 105.2404, Validation Accuracy: 0.4895\n",
            "Epoch 197/100, Loss: 79.4909, Validation Accuracy: 0.6371\n",
            "Epoch 198/100, Loss: 70.6701, Validation Accuracy: 0.4975\n",
            "Epoch 199/100, Loss: 98.3286, Validation Accuracy: 0.6231\n",
            "Epoch 200/100, Loss: 165.7487, Validation Accuracy: 0.6401\n",
            "Reward for Child Model: 0.2622420221851996\n",
            "Child_55:  {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, [0, 1, 0, 1, 1, 3, 0, 2, 0, 2, 3, 2, 0, 0, 1], 0.2622420221851996\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 36, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 36, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(72, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(172, 64, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=160160, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 28, 26]             480\n",
            "       BatchNorm2d-2           [-1, 48, 28, 26]              96\n",
            "            Conv2d-3           [-1, 36, 24, 20]          60,516\n",
            "       BatchNorm2d-4           [-1, 36, 24, 20]              72\n",
            "              ReLU-5           [-1, 36, 24, 20]               0\n",
            "            Conv2d-6           [-1, 36, 20, 18]          19,476\n",
            "       BatchNorm2d-7           [-1, 36, 20, 18]              72\n",
            "              ReLU-8           [-1, 36, 20, 18]               0\n",
            "            Conv2d-9           [-1, 64, 20, 20]          23,104\n",
            "      BatchNorm2d-10           [-1, 64, 20, 20]             128\n",
            "             ReLU-11           [-1, 64, 20, 20]               0\n",
            "           Conv2d-12           [-1, 64, 24, 16]          55,104\n",
            "      BatchNorm2d-13           [-1, 64, 24, 16]             128\n",
            "             ReLU-14           [-1, 64, 24, 16]               0\n",
            "           Linear-15                    [-1, 7]       1,121,127\n",
            "================================================================\n",
            "Total params: 1,280,303\n",
            "Trainable params: 1,280,303\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.37\n",
            "Params size (MB): 4.88\n",
            "Estimated Total Size (MB): 7.27\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 11.1447, Validation Accuracy: 0.6630\n",
            "Epoch 2/100, Loss: 18.4593, Validation Accuracy: 0.5095\n",
            "Epoch 3/100, Loss: 21.6143, Validation Accuracy: 0.6241\n",
            "Epoch 4/100, Loss: 8.8881, Validation Accuracy: 0.1496\n",
            "Epoch 5/100, Loss: 73.5925, Validation Accuracy: 0.5842\n",
            "Epoch 6/100, Loss: 18.6517, Validation Accuracy: 0.6012\n",
            "Epoch 7/100, Loss: 30.6250, Validation Accuracy: 0.6500\n",
            "Epoch 8/100, Loss: 62.0256, Validation Accuracy: 0.5464\n",
            "Epoch 9/100, Loss: 11.0621, Validation Accuracy: 0.5224\n",
            "Epoch 10/100, Loss: 183.5629, Validation Accuracy: 0.5364\n",
            "Epoch 11/100, Loss: 79.4451, Validation Accuracy: 0.5583\n",
            "Epoch 12/100, Loss: 27.2793, Validation Accuracy: 0.6241\n",
            "Epoch 13/100, Loss: 19.4649, Validation Accuracy: 0.6381\n",
            "Epoch 14/100, Loss: 9.8845, Validation Accuracy: 0.5982\n",
            "Epoch 15/100, Loss: 20.4097, Validation Accuracy: 0.5713\n",
            "Epoch 16/100, Loss: 4.9843, Validation Accuracy: 0.6142\n",
            "Epoch 17/100, Loss: 107.1867, Validation Accuracy: 0.3071\n",
            "Epoch 18/100, Loss: 36.5064, Validation Accuracy: 0.4945\n",
            "Epoch 19/100, Loss: 4.8376, Validation Accuracy: 0.6680\n",
            "Epoch 20/100, Loss: 167.5822, Validation Accuracy: 0.3519\n",
            "Epoch 21/100, Loss: 17.4089, Validation Accuracy: 0.6610\n",
            "Epoch 22/100, Loss: 721.4331, Validation Accuracy: 0.5135\n",
            "Epoch 23/100, Loss: 39.4307, Validation Accuracy: 0.5753\n",
            "Epoch 24/100, Loss: 11.6836, Validation Accuracy: 0.6680\n",
            "Epoch 25/100, Loss: 8.8885, Validation Accuracy: 0.6171\n",
            "Epoch 26/100, Loss: 11.7608, Validation Accuracy: 0.5922\n",
            "Epoch 27/100, Loss: 15.3687, Validation Accuracy: 0.6311\n",
            "Epoch 28/100, Loss: 54.3770, Validation Accuracy: 0.5852\n",
            "Epoch 29/100, Loss: 29.7886, Validation Accuracy: 0.6730\n",
            "Epoch 30/100, Loss: 18.4674, Validation Accuracy: 0.5464\n",
            "Epoch 31/100, Loss: 8.4902, Validation Accuracy: 0.6281\n",
            "Epoch 32/100, Loss: 5.8808, Validation Accuracy: 0.4855\n",
            "Epoch 33/100, Loss: 6.3889, Validation Accuracy: 0.5364\n",
            "Epoch 34/100, Loss: 9.4683, Validation Accuracy: 0.5643\n",
            "Epoch 35/100, Loss: 50.1044, Validation Accuracy: 0.4975\n",
            "Epoch 36/100, Loss: 37.6917, Validation Accuracy: 0.6092\n",
            "Epoch 37/100, Loss: 86.9404, Validation Accuracy: 0.5663\n",
            "Epoch 38/100, Loss: 13.0474, Validation Accuracy: 0.6760\n",
            "Epoch 39/100, Loss: 137.6687, Validation Accuracy: 0.6401\n",
            "Epoch 40/100, Loss: 242.8033, Validation Accuracy: 0.5454\n",
            "Epoch 41/100, Loss: 24.1617, Validation Accuracy: 0.6560\n",
            "Epoch 42/100, Loss: 1182.0992, Validation Accuracy: 0.5872\n",
            "Epoch 43/100, Loss: 77.5454, Validation Accuracy: 0.5773\n",
            "Epoch 44/100, Loss: 44.4844, Validation Accuracy: 0.5165\n",
            "Epoch 45/100, Loss: 20.9652, Validation Accuracy: 0.6401\n",
            "Epoch 46/100, Loss: 6.8132, Validation Accuracy: 0.6052\n",
            "Epoch 47/100, Loss: 5.9852, Validation Accuracy: 0.5693\n",
            "Epoch 48/100, Loss: 8.9975, Validation Accuracy: 0.5862\n",
            "Epoch 49/100, Loss: 25.2162, Validation Accuracy: 0.6082\n",
            "Epoch 50/100, Loss: 10.3385, Validation Accuracy: 0.6261\n",
            "Epoch 51/100, Loss: 14.4445, Validation Accuracy: 0.5444\n",
            "Epoch 52/100, Loss: 31.3609, Validation Accuracy: 0.6481\n",
            "Epoch 53/100, Loss: 38.9491, Validation Accuracy: 0.6879\n",
            "Epoch 54/100, Loss: 12.7625, Validation Accuracy: 0.6700\n",
            "Epoch 55/100, Loss: 5.3747, Validation Accuracy: 0.6251\n",
            "Epoch 56/100, Loss: 12.6553, Validation Accuracy: 0.5773\n",
            "Epoch 57/100, Loss: 13.5593, Validation Accuracy: 0.6411\n",
            "Epoch 58/100, Loss: 11.3972, Validation Accuracy: 0.6431\n",
            "Epoch 59/100, Loss: 19.4592, Validation Accuracy: 0.6221\n",
            "Epoch 60/100, Loss: 30.1340, Validation Accuracy: 0.6461\n",
            "Epoch 61/100, Loss: 8.0772, Validation Accuracy: 0.6022\n",
            "Epoch 62/100, Loss: 33.3383, Validation Accuracy: 0.5912\n",
            "Epoch 63/100, Loss: 27.9620, Validation Accuracy: 0.6201\n",
            "Epoch 64/100, Loss: 210.3668, Validation Accuracy: 0.6022\n",
            "Epoch 65/100, Loss: 26.1430, Validation Accuracy: 0.6660\n",
            "Epoch 66/100, Loss: 32.6091, Validation Accuracy: 0.6630\n",
            "Epoch 67/100, Loss: 11.2679, Validation Accuracy: 0.6949\n",
            "Epoch 68/100, Loss: 21.7800, Validation Accuracy: 0.5523\n",
            "Epoch 69/100, Loss: 10.3432, Validation Accuracy: 0.5513\n",
            "Epoch 70/100, Loss: 4.8991, Validation Accuracy: 0.6800\n",
            "Epoch 71/100, Loss: 30.8939, Validation Accuracy: 0.6351\n",
            "Epoch 72/100, Loss: 45.1736, Validation Accuracy: 0.5842\n",
            "Epoch 73/100, Loss: 51.1241, Validation Accuracy: 0.6351\n",
            "Epoch 74/100, Loss: 54.4936, Validation Accuracy: 0.4467\n",
            "Epoch 75/100, Loss: 35.5043, Validation Accuracy: 0.6520\n",
            "Epoch 76/100, Loss: 77.9599, Validation Accuracy: 0.5304\n",
            "Epoch 77/100, Loss: 56.0429, Validation Accuracy: 0.6670\n",
            "Epoch 78/100, Loss: 33.9924, Validation Accuracy: 0.6072\n",
            "Epoch 79/100, Loss: 15.5670, Validation Accuracy: 0.6540\n",
            "Epoch 80/100, Loss: 48.6302, Validation Accuracy: 0.6281\n",
            "Epoch 81/100, Loss: 41.8713, Validation Accuracy: 0.5085\n",
            "Epoch 82/100, Loss: 53.0497, Validation Accuracy: 0.6152\n",
            "Epoch 83/100, Loss: 25.2070, Validation Accuracy: 0.5992\n",
            "Epoch 84/100, Loss: 40.1364, Validation Accuracy: 0.6152\n",
            "Epoch 85/100, Loss: 30.4036, Validation Accuracy: 0.5264\n",
            "Epoch 86/100, Loss: 91.5259, Validation Accuracy: 0.5833\n",
            "Epoch 87/100, Loss: 23.1646, Validation Accuracy: 0.6022\n",
            "Epoch 88/100, Loss: 8.0127, Validation Accuracy: 0.5992\n",
            "Epoch 89/100, Loss: 13.2978, Validation Accuracy: 0.6221\n",
            "Epoch 90/100, Loss: 26.6119, Validation Accuracy: 0.5952\n",
            "Epoch 91/100, Loss: 21.2230, Validation Accuracy: 0.6540\n",
            "Epoch 92/100, Loss: 8.5468, Validation Accuracy: 0.6301\n",
            "Epoch 93/100, Loss: 71.4051, Validation Accuracy: 0.6181\n",
            "Epoch 94/100, Loss: 46.7454, Validation Accuracy: 0.6461\n",
            "Epoch 95/100, Loss: 22.3829, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 40.5158, Validation Accuracy: 0.6491\n",
            "Epoch 97/100, Loss: 29.8491, Validation Accuracy: 0.6241\n",
            "Epoch 98/100, Loss: 637.2190, Validation Accuracy: 0.4716\n",
            "Epoch 99/100, Loss: 81.1876, Validation Accuracy: 0.6002\n",
            "Epoch 100/100, Loss: 81.8718, Validation Accuracy: 0.6191\n",
            "Epoch 101/100, Loss: 27.7564, Validation Accuracy: 0.6421\n",
            "Epoch 102/100, Loss: 29.6021, Validation Accuracy: 0.5414\n",
            "Epoch 103/100, Loss: 20.3601, Validation Accuracy: 0.6171\n",
            "Epoch 104/100, Loss: 41.8476, Validation Accuracy: 0.4885\n",
            "Epoch 105/100, Loss: 32.2052, Validation Accuracy: 0.4546\n",
            "Epoch 106/100, Loss: 69.1273, Validation Accuracy: 0.5942\n",
            "Epoch 107/100, Loss: 61.0470, Validation Accuracy: 0.5902\n",
            "Epoch 108/100, Loss: 29.5836, Validation Accuracy: 0.6002\n",
            "Epoch 109/100, Loss: 28.7510, Validation Accuracy: 0.4875\n",
            "Epoch 110/100, Loss: 175.2870, Validation Accuracy: 0.6112\n",
            "Epoch 111/100, Loss: 217.6973, Validation Accuracy: 0.5503\n",
            "Epoch 112/100, Loss: 34.7184, Validation Accuracy: 0.6441\n",
            "Epoch 113/100, Loss: 41.2466, Validation Accuracy: 0.5733\n",
            "Epoch 114/100, Loss: 63.8138, Validation Accuracy: 0.5035\n",
            "Epoch 115/100, Loss: 20.7102, Validation Accuracy: 0.6411\n",
            "Epoch 116/100, Loss: 14.3645, Validation Accuracy: 0.6530\n",
            "Epoch 117/100, Loss: 42.5144, Validation Accuracy: 0.6381\n",
            "Epoch 118/100, Loss: 19.0345, Validation Accuracy: 0.5942\n",
            "Epoch 119/100, Loss: 18.7609, Validation Accuracy: 0.6750\n",
            "Epoch 120/100, Loss: 66.6985, Validation Accuracy: 0.6670\n",
            "Epoch 121/100, Loss: 38.3278, Validation Accuracy: 0.5922\n",
            "Epoch 122/100, Loss: 23.8578, Validation Accuracy: 0.6441\n",
            "Epoch 123/100, Loss: 12.4056, Validation Accuracy: 0.6710\n",
            "Epoch 124/100, Loss: 18.4040, Validation Accuracy: 0.5703\n",
            "Epoch 125/100, Loss: 16.7913, Validation Accuracy: 0.6152\n",
            "Epoch 126/100, Loss: 32.0977, Validation Accuracy: 0.5633\n",
            "Epoch 127/100, Loss: 15.3690, Validation Accuracy: 0.6381\n",
            "Epoch 128/100, Loss: 12.4737, Validation Accuracy: 0.6421\n",
            "Epoch 129/100, Loss: 11.9299, Validation Accuracy: 0.4925\n",
            "Epoch 130/100, Loss: 35.3130, Validation Accuracy: 0.5484\n",
            "Epoch 131/100, Loss: 29.9936, Validation Accuracy: 0.6241\n",
            "Epoch 132/100, Loss: 79.5850, Validation Accuracy: 0.5992\n",
            "Epoch 133/100, Loss: 37.7039, Validation Accuracy: 0.6351\n",
            "Epoch 134/100, Loss: 40.7653, Validation Accuracy: 0.6630\n",
            "Epoch 135/100, Loss: 38.4837, Validation Accuracy: 0.6132\n",
            "Epoch 136/100, Loss: 29.4728, Validation Accuracy: 0.6670\n",
            "Epoch 137/100, Loss: 45.0206, Validation Accuracy: 0.6471\n",
            "Epoch 138/100, Loss: 23.4965, Validation Accuracy: 0.4646\n",
            "Epoch 139/100, Loss: 49.3295, Validation Accuracy: 0.6032\n",
            "Epoch 140/100, Loss: 75.7603, Validation Accuracy: 0.4158\n",
            "Epoch 141/100, Loss: 39.5884, Validation Accuracy: 0.5294\n",
            "Epoch 142/100, Loss: 42.1553, Validation Accuracy: 0.6700\n",
            "Epoch 143/100, Loss: 26.2042, Validation Accuracy: 0.5912\n",
            "Epoch 144/100, Loss: 88.5265, Validation Accuracy: 0.6550\n",
            "Epoch 145/100, Loss: 61.2706, Validation Accuracy: 0.6002\n",
            "Epoch 146/100, Loss: 50.4469, Validation Accuracy: 0.5683\n",
            "Epoch 147/100, Loss: 85.5264, Validation Accuracy: 0.4746\n",
            "Epoch 148/100, Loss: 105.4938, Validation Accuracy: 0.5055\n",
            "Epoch 149/100, Loss: 66.7151, Validation Accuracy: 0.5852\n",
            "Epoch 150/100, Loss: 66.5216, Validation Accuracy: 0.6730\n",
            "Epoch 151/100, Loss: 34.1442, Validation Accuracy: 0.6560\n",
            "Epoch 152/100, Loss: 57.2597, Validation Accuracy: 0.6790\n",
            "Epoch 153/100, Loss: 28.7839, Validation Accuracy: 0.5174\n",
            "Epoch 154/100, Loss: 44.5870, Validation Accuracy: 0.6570\n",
            "Epoch 155/100, Loss: 46.3995, Validation Accuracy: 0.6510\n",
            "Epoch 156/100, Loss: 13.2791, Validation Accuracy: 0.5902\n",
            "Epoch 157/100, Loss: 36.6058, Validation Accuracy: 0.6461\n",
            "Epoch 158/100, Loss: 33.9380, Validation Accuracy: 0.6780\n",
            "Epoch 159/100, Loss: 47.3666, Validation Accuracy: 0.6261\n",
            "Epoch 160/100, Loss: 87.2758, Validation Accuracy: 0.5823\n",
            "Epoch 161/100, Loss: 36.5410, Validation Accuracy: 0.6510\n",
            "Epoch 162/100, Loss: 93.1425, Validation Accuracy: 0.5573\n",
            "Epoch 163/100, Loss: 49.2749, Validation Accuracy: 0.5982\n",
            "Epoch 164/100, Loss: 36.7746, Validation Accuracy: 0.6710\n",
            "Epoch 165/100, Loss: 42.3492, Validation Accuracy: 0.5932\n",
            "Epoch 166/100, Loss: 35.7710, Validation Accuracy: 0.6331\n",
            "Epoch 167/100, Loss: 20.8445, Validation Accuracy: 0.6301\n",
            "Epoch 168/100, Loss: 35.2046, Validation Accuracy: 0.6281\n",
            "Epoch 169/100, Loss: 149.7130, Validation Accuracy: 0.4875\n",
            "Epoch 170/100, Loss: 78.8945, Validation Accuracy: 0.5244\n",
            "Epoch 171/100, Loss: 45.9866, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 72.4810, Validation Accuracy: 0.6132\n",
            "Epoch 173/100, Loss: 73.5654, Validation Accuracy: 0.5852\n",
            "Epoch 174/100, Loss: 24.3696, Validation Accuracy: 0.6301\n",
            "Epoch 175/100, Loss: 32.1316, Validation Accuracy: 0.6471\n",
            "Epoch 176/100, Loss: 32.7570, Validation Accuracy: 0.6201\n",
            "Epoch 177/100, Loss: 114.0966, Validation Accuracy: 0.5224\n",
            "Epoch 178/100, Loss: 43.4161, Validation Accuracy: 0.6411\n",
            "Epoch 179/100, Loss: 23.6934, Validation Accuracy: 0.5244\n",
            "Epoch 180/100, Loss: 38.6166, Validation Accuracy: 0.6520\n",
            "Epoch 181/100, Loss: 12.8702, Validation Accuracy: 0.5992\n",
            "Epoch 182/100, Loss: 42.1641, Validation Accuracy: 0.5942\n",
            "Epoch 183/100, Loss: 47.1582, Validation Accuracy: 0.5743\n",
            "Epoch 184/100, Loss: 64.0949, Validation Accuracy: 0.6540\n",
            "Epoch 185/100, Loss: 67.1928, Validation Accuracy: 0.5633\n",
            "Epoch 186/100, Loss: 90.9539, Validation Accuracy: 0.6730\n",
            "Epoch 187/100, Loss: 28.3208, Validation Accuracy: 0.5244\n",
            "Epoch 188/100, Loss: 41.4300, Validation Accuracy: 0.5902\n",
            "Epoch 189/100, Loss: 32.4670, Validation Accuracy: 0.5942\n",
            "Epoch 190/100, Loss: 79.0595, Validation Accuracy: 0.4646\n",
            "Epoch 191/100, Loss: 128.2357, Validation Accuracy: 0.4307\n",
            "Epoch 192/100, Loss: 48.6693, Validation Accuracy: 0.5713\n",
            "Epoch 193/100, Loss: 31.0815, Validation Accuracy: 0.6500\n",
            "Epoch 194/100, Loss: 37.6568, Validation Accuracy: 0.5454\n",
            "Epoch 195/100, Loss: 60.6047, Validation Accuracy: 0.5494\n",
            "Epoch 196/100, Loss: 22.9688, Validation Accuracy: 0.6112\n",
            "Epoch 197/100, Loss: 21.0050, Validation Accuracy: 0.6640\n",
            "Epoch 198/100, Loss: 111.5944, Validation Accuracy: 0.6700\n",
            "Epoch 199/100, Loss: 33.0299, Validation Accuracy: 0.6590\n",
            "Epoch 200/100, Loss: 6.9652, Validation Accuracy: 0.5204\n",
            "Reward for Child Model: 0.300749573479958\n",
            "Child_56:  {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, [0, 1, 2, 2, 3, 1, 2, 1, 1, 2, 0, 3, 0, 2, 3], 0.300749573479958\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 48, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 48, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(72, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(72, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=15840, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 24, 26]           1,104\n",
            "       BatchNorm2d-2           [-1, 24, 24, 26]              48\n",
            "            Conv2d-3           [-1, 48, 20, 26]           5,808\n",
            "       BatchNorm2d-4           [-1, 48, 20, 26]              96\n",
            "              ReLU-5           [-1, 48, 20, 26]               0\n",
            "            Conv2d-6           [-1, 48, 14, 26]          16,176\n",
            "       BatchNorm2d-7           [-1, 48, 14, 26]              96\n",
            "              ReLU-8           [-1, 48, 14, 26]               0\n",
            "            Conv2d-9           [-1, 48, 18, 24]          72,624\n",
            "      BatchNorm2d-10           [-1, 48, 18, 24]              96\n",
            "             ReLU-11           [-1, 48, 18, 24]               0\n",
            "           Conv2d-12           [-1, 36, 20, 22]          64,836\n",
            "      BatchNorm2d-13           [-1, 36, 20, 22]              72\n",
            "             ReLU-14           [-1, 36, 20, 22]               0\n",
            "           Linear-15                    [-1, 7]         110,887\n",
            "================================================================\n",
            "Total params: 271,843\n",
            "Trainable params: 271,843\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.04\n",
            "Params size (MB): 1.04\n",
            "Estimated Total Size (MB): 3.08\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 1.2224, Validation Accuracy: 0.6690\n",
            "Epoch 2/100, Loss: 1.1414, Validation Accuracy: 0.6690\n",
            "Epoch 3/100, Loss: 0.9323, Validation Accuracy: 0.6690\n",
            "Epoch 4/100, Loss: 1.0463, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 1.1999, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 0.9984, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 1.3302, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 1.2140, Validation Accuracy: 0.6690\n",
            "Epoch 9/100, Loss: 1.1547, Validation Accuracy: 0.6690\n",
            "Epoch 10/100, Loss: 1.4271, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 1.2366, Validation Accuracy: 0.6690\n",
            "Epoch 12/100, Loss: 1.0570, Validation Accuracy: 0.6690\n",
            "Epoch 13/100, Loss: 1.1711, Validation Accuracy: 0.6690\n",
            "Epoch 14/100, Loss: 1.3255, Validation Accuracy: 0.6690\n",
            "Epoch 15/100, Loss: 1.3939, Validation Accuracy: 0.6690\n",
            "Epoch 16/100, Loss: 1.0398, Validation Accuracy: 0.6690\n",
            "Epoch 17/100, Loss: 1.1250, Validation Accuracy: 0.6690\n",
            "Epoch 18/100, Loss: 0.6208, Validation Accuracy: 0.6690\n",
            "Epoch 19/100, Loss: 1.1697, Validation Accuracy: 0.6690\n",
            "Epoch 20/100, Loss: 1.0220, Validation Accuracy: 0.6690\n",
            "Epoch 21/100, Loss: 1.0065, Validation Accuracy: 0.6690\n",
            "Epoch 22/100, Loss: 0.8614, Validation Accuracy: 0.6690\n",
            "Epoch 23/100, Loss: 1.5366, Validation Accuracy: 0.6690\n",
            "Epoch 24/100, Loss: 1.1490, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 0.9282, Validation Accuracy: 0.6690\n",
            "Epoch 26/100, Loss: 0.8650, Validation Accuracy: 0.6690\n",
            "Epoch 27/100, Loss: 1.2519, Validation Accuracy: 0.6690\n",
            "Epoch 28/100, Loss: 1.2843, Validation Accuracy: 0.6690\n",
            "Epoch 29/100, Loss: 1.1826, Validation Accuracy: 0.6690\n",
            "Epoch 30/100, Loss: 1.2033, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 1.2131, Validation Accuracy: 0.6690\n",
            "Epoch 32/100, Loss: 0.9032, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 1.2024, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 0.9883, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 1.0866, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 1.5459, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 0.9707, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 0.9278, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 1.1575, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 1.0675, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 1.1045, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 1.2597, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 0.8655, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 1.0253, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 0.7832, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 0.9130, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 1.3145, Validation Accuracy: 0.6690\n",
            "Epoch 48/100, Loss: 1.0689, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 1.0416, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 0.9737, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 0.9569, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 0.8334, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 0.9101, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 0.9412, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 1.1543, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 0.8288, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 0.9468, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 1.2113, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 0.9759, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 1.2483, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 1.0082, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 1.2146, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 0.7318, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 0.9124, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 1.2898, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 1.0189, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 1.3974, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 0.9744, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 1.1817, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 0.9228, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 1.0395, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 1.1272, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 1.0757, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 1.0288, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 0.8866, Validation Accuracy: 0.6620\n",
            "Epoch 76/100, Loss: 1.4943, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 1.0782, Validation Accuracy: 0.6680\n",
            "Epoch 78/100, Loss: 1.1145, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 1.3231, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 0.7949, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 0.8636, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 1.3401, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 1.3046, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 1.2535, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 0.9755, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 0.9254, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 1.2601, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 0.9304, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 1.2311, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 1.1675, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 1.1355, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 1.1904, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 1.2488, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 1.3565, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 1.1769, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 1.0330, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 1.3755, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 0.9058, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 1.1370, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 1.2329, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 1.4439, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 1.1560, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 1.1295, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 1.0271, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 1.3094, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 0.9721, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 1.1183, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 1.1297, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 1.1150, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 1.3725, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.0786, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 0.7786, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 1.3531, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 1.0141, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 1.3627, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 1.3317, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 0.8808, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 1.1986, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 1.2280, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 1.4711, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 0.9308, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.0909, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 1.2708, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 1.3587, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 1.0148, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 1.1196, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 1.2823, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 1.1179, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 1.1165, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 1.3007, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 1.0973, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 1.2282, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 0.8240, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 0.9086, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 1.3572, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 0.8142, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 1.3603, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 1.4561, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 1.2569, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 0.9185, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 0.9398, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 1.0800, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 1.1084, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 1.4247, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 1.3432, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 1.1616, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 1.2052, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 1.2662, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 0.9424, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 1.3341, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 1.1068, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 1.0824, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 1.0897, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 0.8201, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 1.2181, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 1.1888, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 1.0294, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 1.6216, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 1.3827, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 0.9143, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 0.9579, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 1.3243, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 1.1720, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 1.2009, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 1.5410, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 0.9602, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 1.1430, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 0.9843, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 1.0368, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 1.2163, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 1.1153, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 1.0262, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 0.9098, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 1.4036, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 1.1765, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 1.1854, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 1.1188, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 1.1850, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 0.9904, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 1.3354, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 1.1796, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 1.2163, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 1.2635, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 0.8622, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 1.0480, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 1.2979, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 1.1441, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 1.4560, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 1.5626, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 1.0845, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 1.1734, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 1.2927, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 0.8066, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 1.1188, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 0.8923, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 1.1486, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 1.1841, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 1.3169, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 0.8089, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 1.0947, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_57:  {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, [2, 1, 0, 2, 0, 2, 3, 0, 2, 3, 1, 2, 2, 2, 1], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 24, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 24, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(72, 36, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(36, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=68640, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 26, 22]           3,072\n",
            "       BatchNorm2d-2           [-1, 48, 26, 22]              96\n",
            "            Conv2d-3           [-1, 24, 20, 20]          24,216\n",
            "       BatchNorm2d-4           [-1, 24, 20, 20]              48\n",
            "              ReLU-5           [-1, 24, 20, 20]               0\n",
            "            Conv2d-6           [-1, 24, 16, 18]           8,664\n",
            "       BatchNorm2d-7           [-1, 24, 16, 18]              48\n",
            "              ReLU-8           [-1, 24, 16, 18]               0\n",
            "            Conv2d-9           [-1, 36, 22, 22]          12,996\n",
            "      BatchNorm2d-10           [-1, 36, 22, 22]              72\n",
            "             ReLU-11           [-1, 36, 22, 22]               0\n",
            "           Conv2d-12           [-1, 36, 18, 18]          32,436\n",
            "      BatchNorm2d-13           [-1, 36, 18, 18]              72\n",
            "             ReLU-14           [-1, 36, 18, 18]               0\n",
            "           Linear-15                    [-1, 7]         480,487\n",
            "================================================================\n",
            "Total params: 562,207\n",
            "Trainable params: 562,207\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.46\n",
            "Params size (MB): 2.14\n",
            "Estimated Total Size (MB): 3.62\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 6.0090, Validation Accuracy: 0.4118\n",
            "Epoch 2/100, Loss: 23.2546, Validation Accuracy: 0.6341\n",
            "Epoch 3/100, Loss: 12.9534, Validation Accuracy: 0.6431\n",
            "Epoch 4/100, Loss: 10.9719, Validation Accuracy: 0.5643\n",
            "Epoch 5/100, Loss: 21.4870, Validation Accuracy: 0.5165\n",
            "Epoch 6/100, Loss: 50.7863, Validation Accuracy: 0.6211\n",
            "Epoch 7/100, Loss: 16.2567, Validation Accuracy: 0.5603\n",
            "Epoch 8/100, Loss: 114.0305, Validation Accuracy: 0.6142\n",
            "Epoch 9/100, Loss: 170.8327, Validation Accuracy: 0.5155\n",
            "Epoch 10/100, Loss: 73.4334, Validation Accuracy: 0.6062\n",
            "Epoch 11/100, Loss: 6.5608, Validation Accuracy: 0.6600\n",
            "Epoch 12/100, Loss: 55.6157, Validation Accuracy: 0.3290\n",
            "Epoch 13/100, Loss: 32.5051, Validation Accuracy: 0.5055\n",
            "Epoch 14/100, Loss: 9.3853, Validation Accuracy: 0.5194\n",
            "Epoch 15/100, Loss: 5.0833, Validation Accuracy: 0.6062\n",
            "Epoch 16/100, Loss: 6.2208, Validation Accuracy: 0.5434\n",
            "Epoch 17/100, Loss: 11.5270, Validation Accuracy: 0.5653\n",
            "Epoch 18/100, Loss: 13.5290, Validation Accuracy: 0.5224\n",
            "Epoch 19/100, Loss: 80.6277, Validation Accuracy: 0.6381\n",
            "Epoch 20/100, Loss: 38.4193, Validation Accuracy: 0.6341\n",
            "Epoch 21/100, Loss: 4.3101, Validation Accuracy: 0.4387\n",
            "Epoch 22/100, Loss: 11.5553, Validation Accuracy: 0.5563\n",
            "Epoch 23/100, Loss: 21.7072, Validation Accuracy: 0.6002\n",
            "Epoch 24/100, Loss: 27.7647, Validation Accuracy: 0.4287\n",
            "Epoch 25/100, Loss: 117.0918, Validation Accuracy: 0.4108\n",
            "Epoch 26/100, Loss: 103.5690, Validation Accuracy: 0.6650\n",
            "Epoch 27/100, Loss: 23.5738, Validation Accuracy: 0.6261\n",
            "Epoch 28/100, Loss: 12.4581, Validation Accuracy: 0.6142\n",
            "Epoch 29/100, Loss: 95.8831, Validation Accuracy: 0.4646\n",
            "Epoch 30/100, Loss: 23.2291, Validation Accuracy: 0.5952\n",
            "Epoch 31/100, Loss: 28.7472, Validation Accuracy: 0.6361\n",
            "Epoch 32/100, Loss: 20.6336, Validation Accuracy: 0.6371\n",
            "Epoch 33/100, Loss: 7.0218, Validation Accuracy: 0.4636\n",
            "Epoch 34/100, Loss: 23.4547, Validation Accuracy: 0.5404\n",
            "Epoch 35/100, Loss: 19.3054, Validation Accuracy: 0.4556\n",
            "Epoch 36/100, Loss: 180.7261, Validation Accuracy: 0.5464\n",
            "Epoch 37/100, Loss: 14.4921, Validation Accuracy: 0.4985\n",
            "Epoch 38/100, Loss: 20.1537, Validation Accuracy: 0.6580\n",
            "Epoch 39/100, Loss: 28.4018, Validation Accuracy: 0.5424\n",
            "Epoch 40/100, Loss: 17.9641, Validation Accuracy: 0.5643\n",
            "Epoch 41/100, Loss: 59.5861, Validation Accuracy: 0.3848\n",
            "Epoch 42/100, Loss: 5.9122, Validation Accuracy: 0.6710\n",
            "Epoch 43/100, Loss: 33.6415, Validation Accuracy: 0.5803\n",
            "Epoch 44/100, Loss: 12.8698, Validation Accuracy: 0.6391\n",
            "Epoch 45/100, Loss: 18.8085, Validation Accuracy: 0.5992\n",
            "Epoch 46/100, Loss: 8.3750, Validation Accuracy: 0.5942\n",
            "Epoch 47/100, Loss: 45.1243, Validation Accuracy: 0.6351\n",
            "Epoch 48/100, Loss: 55.7297, Validation Accuracy: 0.5922\n",
            "Epoch 49/100, Loss: 24.3664, Validation Accuracy: 0.5892\n",
            "Epoch 50/100, Loss: 18.2484, Validation Accuracy: 0.6421\n",
            "Epoch 51/100, Loss: 145.6107, Validation Accuracy: 0.5494\n",
            "Epoch 52/100, Loss: 25.2394, Validation Accuracy: 0.6461\n",
            "Epoch 53/100, Loss: 25.2578, Validation Accuracy: 0.6082\n",
            "Epoch 54/100, Loss: 13.1500, Validation Accuracy: 0.5902\n",
            "Epoch 55/100, Loss: 11.1689, Validation Accuracy: 0.6062\n",
            "Epoch 56/100, Loss: 17.1858, Validation Accuracy: 0.4706\n",
            "Epoch 57/100, Loss: 31.9133, Validation Accuracy: 0.6162\n",
            "Epoch 58/100, Loss: 63.0986, Validation Accuracy: 0.4327\n",
            "Epoch 59/100, Loss: 54.9390, Validation Accuracy: 0.6620\n",
            "Epoch 60/100, Loss: 12.3348, Validation Accuracy: 0.6451\n",
            "Epoch 61/100, Loss: 40.2301, Validation Accuracy: 0.5932\n",
            "Epoch 62/100, Loss: 20.9627, Validation Accuracy: 0.3938\n",
            "Epoch 63/100, Loss: 97.8271, Validation Accuracy: 0.2901\n",
            "Epoch 64/100, Loss: 52.0979, Validation Accuracy: 0.5503\n",
            "Epoch 65/100, Loss: 23.2344, Validation Accuracy: 0.6271\n",
            "Epoch 66/100, Loss: 24.8272, Validation Accuracy: 0.5464\n",
            "Epoch 67/100, Loss: 94.6436, Validation Accuracy: 0.4676\n",
            "Epoch 68/100, Loss: 56.0465, Validation Accuracy: 0.5135\n",
            "Epoch 69/100, Loss: 28.8930, Validation Accuracy: 0.3121\n",
            "Epoch 70/100, Loss: 18.1225, Validation Accuracy: 0.6291\n",
            "Epoch 71/100, Loss: 40.0550, Validation Accuracy: 0.5613\n",
            "Epoch 72/100, Loss: 89.0845, Validation Accuracy: 0.5892\n",
            "Epoch 73/100, Loss: 49.4182, Validation Accuracy: 0.6162\n",
            "Epoch 74/100, Loss: 60.7522, Validation Accuracy: 0.6510\n",
            "Epoch 75/100, Loss: 14.5501, Validation Accuracy: 0.6481\n",
            "Epoch 76/100, Loss: 12.8646, Validation Accuracy: 0.4167\n",
            "Epoch 77/100, Loss: 31.4022, Validation Accuracy: 0.5743\n",
            "Epoch 78/100, Loss: 15.8973, Validation Accuracy: 0.5932\n",
            "Epoch 79/100, Loss: 68.6055, Validation Accuracy: 0.6092\n",
            "Epoch 80/100, Loss: 31.5371, Validation Accuracy: 0.4536\n",
            "Epoch 81/100, Loss: 71.8355, Validation Accuracy: 0.6241\n",
            "Epoch 82/100, Loss: 26.7508, Validation Accuracy: 0.5364\n",
            "Epoch 83/100, Loss: 44.3333, Validation Accuracy: 0.4875\n",
            "Epoch 84/100, Loss: 133.0524, Validation Accuracy: 0.6451\n",
            "Epoch 85/100, Loss: 10.6559, Validation Accuracy: 0.6530\n",
            "Epoch 86/100, Loss: 38.8839, Validation Accuracy: 0.5434\n",
            "Epoch 87/100, Loss: 26.7202, Validation Accuracy: 0.6062\n",
            "Epoch 88/100, Loss: 87.8996, Validation Accuracy: 0.5852\n",
            "Epoch 89/100, Loss: 34.3788, Validation Accuracy: 0.6530\n",
            "Epoch 90/100, Loss: 12.4386, Validation Accuracy: 0.6630\n",
            "Epoch 91/100, Loss: 58.1297, Validation Accuracy: 0.5613\n",
            "Epoch 92/100, Loss: 16.8504, Validation Accuracy: 0.6750\n",
            "Epoch 93/100, Loss: 40.1830, Validation Accuracy: 0.4307\n",
            "Epoch 94/100, Loss: 35.1675, Validation Accuracy: 0.5244\n",
            "Epoch 95/100, Loss: 75.0660, Validation Accuracy: 0.5613\n",
            "Epoch 96/100, Loss: 45.1129, Validation Accuracy: 0.6431\n",
            "Epoch 97/100, Loss: 39.2392, Validation Accuracy: 0.6780\n",
            "Epoch 98/100, Loss: 22.1118, Validation Accuracy: 0.5952\n",
            "Epoch 99/100, Loss: 49.1877, Validation Accuracy: 0.5244\n",
            "Epoch 100/100, Loss: 21.9825, Validation Accuracy: 0.6540\n",
            "Epoch 101/100, Loss: 33.8592, Validation Accuracy: 0.6022\n",
            "Epoch 102/100, Loss: 39.7451, Validation Accuracy: 0.6381\n",
            "Epoch 103/100, Loss: 23.9080, Validation Accuracy: 0.6590\n",
            "Epoch 104/100, Loss: 22.5981, Validation Accuracy: 0.6471\n",
            "Epoch 105/100, Loss: 79.8540, Validation Accuracy: 0.3549\n",
            "Epoch 106/100, Loss: 11.4950, Validation Accuracy: 0.6301\n",
            "Epoch 107/100, Loss: 15.2081, Validation Accuracy: 0.6261\n",
            "Epoch 108/100, Loss: 13.0331, Validation Accuracy: 0.6530\n",
            "Epoch 109/100, Loss: 28.7932, Validation Accuracy: 0.6062\n",
            "Epoch 110/100, Loss: 35.7498, Validation Accuracy: 0.5454\n",
            "Epoch 111/100, Loss: 51.0949, Validation Accuracy: 0.6171\n",
            "Epoch 112/100, Loss: 33.5500, Validation Accuracy: 0.5424\n",
            "Epoch 113/100, Loss: 22.2017, Validation Accuracy: 0.6630\n",
            "Epoch 114/100, Loss: 27.7574, Validation Accuracy: 0.5823\n",
            "Epoch 115/100, Loss: 22.9112, Validation Accuracy: 0.5743\n",
            "Epoch 116/100, Loss: 21.0169, Validation Accuracy: 0.4197\n",
            "Epoch 117/100, Loss: 11.8102, Validation Accuracy: 0.6600\n",
            "Epoch 118/100, Loss: 48.5898, Validation Accuracy: 0.6820\n",
            "Epoch 119/100, Loss: 50.0924, Validation Accuracy: 0.5065\n",
            "Epoch 120/100, Loss: 25.5370, Validation Accuracy: 0.6092\n",
            "Epoch 121/100, Loss: 22.1160, Validation Accuracy: 0.5145\n",
            "Epoch 122/100, Loss: 13.8074, Validation Accuracy: 0.5693\n",
            "Epoch 123/100, Loss: 27.1619, Validation Accuracy: 0.6510\n",
            "Epoch 124/100, Loss: 35.6270, Validation Accuracy: 0.2931\n",
            "Epoch 125/100, Loss: 39.9133, Validation Accuracy: 0.6321\n",
            "Epoch 126/100, Loss: 49.8873, Validation Accuracy: 0.5753\n",
            "Epoch 127/100, Loss: 28.6000, Validation Accuracy: 0.6491\n",
            "Epoch 128/100, Loss: 35.7672, Validation Accuracy: 0.5553\n",
            "Epoch 129/100, Loss: 23.0370, Validation Accuracy: 0.6092\n",
            "Epoch 130/100, Loss: 16.7594, Validation Accuracy: 0.5862\n",
            "Epoch 131/100, Loss: 28.4438, Validation Accuracy: 0.6670\n",
            "Epoch 132/100, Loss: 26.3513, Validation Accuracy: 0.5833\n",
            "Epoch 133/100, Loss: 26.6261, Validation Accuracy: 0.5753\n",
            "Epoch 134/100, Loss: 24.7855, Validation Accuracy: 0.6660\n",
            "Epoch 135/100, Loss: 33.4917, Validation Accuracy: 0.5613\n",
            "Epoch 136/100, Loss: 65.3138, Validation Accuracy: 0.6550\n",
            "Epoch 137/100, Loss: 22.0729, Validation Accuracy: 0.5484\n",
            "Epoch 138/100, Loss: 17.1423, Validation Accuracy: 0.3968\n",
            "Epoch 139/100, Loss: 40.5991, Validation Accuracy: 0.5653\n",
            "Epoch 140/100, Loss: 40.2116, Validation Accuracy: 0.5922\n",
            "Epoch 141/100, Loss: 21.2880, Validation Accuracy: 0.4945\n",
            "Epoch 142/100, Loss: 14.7164, Validation Accuracy: 0.5872\n",
            "Epoch 143/100, Loss: 16.4337, Validation Accuracy: 0.5862\n",
            "Epoch 144/100, Loss: 56.7268, Validation Accuracy: 0.6790\n",
            "Epoch 145/100, Loss: 83.0356, Validation Accuracy: 0.5623\n",
            "Epoch 146/100, Loss: 60.6010, Validation Accuracy: 0.6162\n",
            "Epoch 147/100, Loss: 48.2161, Validation Accuracy: 0.6132\n",
            "Epoch 148/100, Loss: 71.9193, Validation Accuracy: 0.6431\n",
            "Epoch 149/100, Loss: 67.9161, Validation Accuracy: 0.6491\n",
            "Epoch 150/100, Loss: 27.0851, Validation Accuracy: 0.6640\n",
            "Epoch 151/100, Loss: 61.9281, Validation Accuracy: 0.5533\n",
            "Epoch 152/100, Loss: 13.4994, Validation Accuracy: 0.4845\n",
            "Epoch 153/100, Loss: 61.0936, Validation Accuracy: 0.5852\n",
            "Epoch 154/100, Loss: 28.6572, Validation Accuracy: 0.3888\n",
            "Epoch 155/100, Loss: 56.1956, Validation Accuracy: 0.6002\n",
            "Epoch 156/100, Loss: 69.2913, Validation Accuracy: 0.6441\n",
            "Epoch 157/100, Loss: 19.6412, Validation Accuracy: 0.6580\n",
            "Epoch 158/100, Loss: 24.4344, Validation Accuracy: 0.6251\n",
            "Epoch 159/100, Loss: 68.4781, Validation Accuracy: 0.6102\n",
            "Epoch 160/100, Loss: 68.0986, Validation Accuracy: 0.6112\n",
            "Epoch 161/100, Loss: 47.7208, Validation Accuracy: 0.5683\n",
            "Epoch 162/100, Loss: 10.5789, Validation Accuracy: 0.5513\n",
            "Epoch 163/100, Loss: 10.5503, Validation Accuracy: 0.6112\n",
            "Epoch 164/100, Loss: 31.5803, Validation Accuracy: 0.6102\n",
            "Epoch 165/100, Loss: 50.5626, Validation Accuracy: 0.5753\n",
            "Epoch 166/100, Loss: 56.4858, Validation Accuracy: 0.6461\n",
            "Epoch 167/100, Loss: 33.1031, Validation Accuracy: 0.6261\n",
            "Epoch 168/100, Loss: 19.6687, Validation Accuracy: 0.6311\n",
            "Epoch 169/100, Loss: 44.4610, Validation Accuracy: 0.6241\n",
            "Epoch 170/100, Loss: 18.5834, Validation Accuracy: 0.5025\n",
            "Epoch 171/100, Loss: 56.7638, Validation Accuracy: 0.6361\n",
            "Epoch 172/100, Loss: 69.9954, Validation Accuracy: 0.4447\n",
            "Epoch 173/100, Loss: 134.5378, Validation Accuracy: 0.5274\n",
            "Epoch 174/100, Loss: 19.5711, Validation Accuracy: 0.4686\n",
            "Epoch 175/100, Loss: 33.5548, Validation Accuracy: 0.6181\n",
            "Epoch 176/100, Loss: 35.6519, Validation Accuracy: 0.5823\n",
            "Epoch 177/100, Loss: 28.4215, Validation Accuracy: 0.6600\n",
            "Epoch 178/100, Loss: 21.4202, Validation Accuracy: 0.6162\n",
            "Epoch 179/100, Loss: 93.8617, Validation Accuracy: 0.5633\n",
            "Epoch 180/100, Loss: 29.5917, Validation Accuracy: 0.6800\n",
            "Epoch 181/100, Loss: 35.6905, Validation Accuracy: 0.6421\n",
            "Epoch 182/100, Loss: 31.3208, Validation Accuracy: 0.5713\n",
            "Epoch 183/100, Loss: 13.3356, Validation Accuracy: 0.5972\n",
            "Epoch 184/100, Loss: 62.2829, Validation Accuracy: 0.5314\n",
            "Epoch 185/100, Loss: 21.6742, Validation Accuracy: 0.6171\n",
            "Epoch 186/100, Loss: 16.0841, Validation Accuracy: 0.5753\n",
            "Epoch 187/100, Loss: 57.4263, Validation Accuracy: 0.5912\n",
            "Epoch 188/100, Loss: 10.2654, Validation Accuracy: 0.5484\n",
            "Epoch 189/100, Loss: 42.3667, Validation Accuracy: 0.5224\n",
            "Epoch 190/100, Loss: 17.5875, Validation Accuracy: 0.6510\n",
            "Epoch 191/100, Loss: 30.1945, Validation Accuracy: 0.5842\n",
            "Epoch 192/100, Loss: 35.4192, Validation Accuracy: 0.5872\n",
            "Epoch 193/100, Loss: 92.1371, Validation Accuracy: 0.6221\n",
            "Epoch 194/100, Loss: 46.2569, Validation Accuracy: 0.5563\n",
            "Epoch 195/100, Loss: 56.5070, Validation Accuracy: 0.6600\n",
            "Epoch 196/100, Loss: 33.1664, Validation Accuracy: 0.6520\n",
            "Epoch 197/100, Loss: 39.3263, Validation Accuracy: 0.5174\n",
            "Epoch 198/100, Loss: 33.1191, Validation Accuracy: 0.5723\n",
            "Epoch 199/100, Loss: 35.3193, Validation Accuracy: 0.5823\n",
            "Epoch 200/100, Loss: 15.3727, Validation Accuracy: 0.6760\n",
            "Reward for Child Model: 0.3088775064099447\n",
            "Child_58:  {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, [1, 3, 2, 3, 1, 0, 2, 1, 0, 2, 0, 1, 2, 2, 1], 0.3088775064099447\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 64, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(152, 36, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(276, 24, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=317856, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 22, 28]             528\n",
            "       BatchNorm2d-2           [-1, 24, 22, 28]              48\n",
            "            Conv2d-3           [-1, 64, 22, 24]           7,744\n",
            "       BatchNorm2d-4           [-1, 64, 22, 24]             128\n",
            "              ReLU-5           [-1, 64, 22, 24]               0\n",
            "            Conv2d-6           [-1, 64, 22, 20]          20,544\n",
            "       BatchNorm2d-7           [-1, 64, 22, 20]             128\n",
            "              ReLU-8           [-1, 64, 22, 20]               0\n",
            "            Conv2d-9           [-1, 36, 16, 22]         268,164\n",
            "      BatchNorm2d-10           [-1, 36, 16, 22]              72\n",
            "             ReLU-11           [-1, 36, 16, 22]               0\n",
            "           Conv2d-12           [-1, 24, 16, 24]         231,864\n",
            "      BatchNorm2d-13           [-1, 24, 16, 24]              48\n",
            "             ReLU-14           [-1, 24, 16, 24]               0\n",
            "           Linear-15                    [-1, 7]       2,224,999\n",
            "================================================================\n",
            "Total params: 2,754,267\n",
            "Trainable params: 2,754,267\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.14\n",
            "Params size (MB): 10.51\n",
            "Estimated Total Size (MB): 12.66\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 8.8198, Validation Accuracy: 0.3619\n",
            "Epoch 2/100, Loss: 37.0817, Validation Accuracy: 0.5075\n",
            "Epoch 3/100, Loss: 11.7885, Validation Accuracy: 0.2762\n",
            "Epoch 4/100, Loss: 78.9677, Validation Accuracy: 0.6221\n",
            "Epoch 5/100, Loss: 236.4370, Validation Accuracy: 0.4865\n",
            "Epoch 6/100, Loss: 547.1564, Validation Accuracy: 0.1097\n",
            "Epoch 7/100, Loss: 20.5432, Validation Accuracy: 0.6142\n",
            "Epoch 8/100, Loss: 39.9365, Validation Accuracy: 0.6491\n",
            "Epoch 9/100, Loss: 16.7281, Validation Accuracy: 0.4317\n",
            "Epoch 10/100, Loss: 3646.4578, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 379.3070, Validation Accuracy: 0.5852\n",
            "Epoch 12/100, Loss: 201.3990, Validation Accuracy: 0.4467\n",
            "Epoch 13/100, Loss: 200.9501, Validation Accuracy: 0.5833\n",
            "Epoch 14/100, Loss: 90.5282, Validation Accuracy: 0.6231\n",
            "Epoch 15/100, Loss: 30.8094, Validation Accuracy: 0.5982\n",
            "Epoch 16/100, Loss: 13.1407, Validation Accuracy: 0.5703\n",
            "Epoch 17/100, Loss: 8.1790, Validation Accuracy: 0.6351\n",
            "Epoch 18/100, Loss: 5919.7720, Validation Accuracy: 0.4816\n",
            "Epoch 19/100, Loss: 205.6980, Validation Accuracy: 0.6231\n",
            "Epoch 20/100, Loss: 22.0869, Validation Accuracy: 0.5663\n",
            "Epoch 21/100, Loss: 13.5183, Validation Accuracy: 0.6510\n",
            "Epoch 22/100, Loss: 6.5748, Validation Accuracy: 0.6590\n",
            "Epoch 23/100, Loss: 14.9318, Validation Accuracy: 0.5823\n",
            "Epoch 24/100, Loss: 11.0438, Validation Accuracy: 0.5254\n",
            "Epoch 25/100, Loss: 13.5709, Validation Accuracy: 0.5613\n",
            "Epoch 26/100, Loss: 56.8310, Validation Accuracy: 0.5174\n",
            "Epoch 27/100, Loss: 11.6995, Validation Accuracy: 0.6211\n",
            "Epoch 28/100, Loss: 9.3149, Validation Accuracy: 0.6471\n",
            "Epoch 29/100, Loss: 387.5665, Validation Accuracy: 0.5972\n",
            "Epoch 30/100, Loss: 64.7589, Validation Accuracy: 0.5683\n",
            "Epoch 31/100, Loss: 94.0239, Validation Accuracy: 0.5823\n",
            "Epoch 32/100, Loss: 15.4732, Validation Accuracy: 0.4387\n",
            "Epoch 33/100, Loss: 319.0851, Validation Accuracy: 0.6122\n",
            "Epoch 34/100, Loss: 63.0468, Validation Accuracy: 0.6162\n",
            "Epoch 35/100, Loss: 75.9081, Validation Accuracy: 0.6092\n",
            "Epoch 36/100, Loss: 43.2525, Validation Accuracy: 0.5972\n",
            "Epoch 37/100, Loss: 13.6417, Validation Accuracy: 0.6112\n",
            "Epoch 38/100, Loss: 12.9838, Validation Accuracy: 0.6281\n",
            "Epoch 39/100, Loss: 33.1333, Validation Accuracy: 0.5105\n",
            "Epoch 40/100, Loss: 7.9805, Validation Accuracy: 0.2343\n",
            "Epoch 41/100, Loss: 160.8982, Validation Accuracy: 0.5633\n",
            "Epoch 42/100, Loss: 2488.4319, Validation Accuracy: 0.1805\n",
            "Epoch 43/100, Loss: 80.1560, Validation Accuracy: 0.5852\n",
            "Epoch 44/100, Loss: 16.6744, Validation Accuracy: 0.5563\n",
            "Epoch 45/100, Loss: 7.3327, Validation Accuracy: 0.5833\n",
            "Epoch 46/100, Loss: 278.9654, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 21.0382, Validation Accuracy: 0.3958\n",
            "Epoch 48/100, Loss: 32.3256, Validation Accuracy: 0.6112\n",
            "Epoch 49/100, Loss: 6.7848, Validation Accuracy: 0.6630\n",
            "Epoch 50/100, Loss: 5.1023, Validation Accuracy: 0.5962\n",
            "Epoch 51/100, Loss: 8.1204, Validation Accuracy: 0.5623\n",
            "Epoch 52/100, Loss: 18.5785, Validation Accuracy: 0.3519\n",
            "Epoch 53/100, Loss: 31.3165, Validation Accuracy: 0.6261\n",
            "Epoch 54/100, Loss: 9.4537, Validation Accuracy: 0.5952\n",
            "Epoch 55/100, Loss: 11.0910, Validation Accuracy: 0.6331\n",
            "Epoch 56/100, Loss: 1068.2130, Validation Accuracy: 0.6590\n",
            "Epoch 57/100, Loss: 67.3275, Validation Accuracy: 0.4885\n",
            "Epoch 58/100, Loss: 50.6343, Validation Accuracy: 0.5095\n",
            "Epoch 59/100, Loss: 21.8535, Validation Accuracy: 0.4317\n",
            "Epoch 60/100, Loss: 14.6721, Validation Accuracy: 0.5194\n",
            "Epoch 61/100, Loss: 13.8032, Validation Accuracy: 0.6311\n",
            "Epoch 62/100, Loss: 36.8465, Validation Accuracy: 0.6261\n",
            "Epoch 63/100, Loss: 167.2788, Validation Accuracy: 0.1097\n",
            "Epoch 64/100, Loss: 57.4807, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 114.2664, Validation Accuracy: 0.6112\n",
            "Epoch 66/100, Loss: 25.3992, Validation Accuracy: 0.6022\n",
            "Epoch 67/100, Loss: 3819.4053, Validation Accuracy: 0.4167\n",
            "Epoch 68/100, Loss: 435.1414, Validation Accuracy: 0.4935\n",
            "Epoch 69/100, Loss: 152.3548, Validation Accuracy: 0.5703\n",
            "Epoch 70/100, Loss: 45.8487, Validation Accuracy: 0.5513\n",
            "Epoch 71/100, Loss: 25.7274, Validation Accuracy: 0.6321\n",
            "Epoch 72/100, Loss: 27.6581, Validation Accuracy: 0.5813\n",
            "Epoch 73/100, Loss: 16.0503, Validation Accuracy: 0.4895\n",
            "Epoch 74/100, Loss: 8.3405, Validation Accuracy: 0.6431\n",
            "Epoch 75/100, Loss: 14.6214, Validation Accuracy: 0.6211\n",
            "Epoch 76/100, Loss: 5.4808, Validation Accuracy: 0.6919\n",
            "Epoch 77/100, Loss: 5.4419, Validation Accuracy: 0.6401\n",
            "Epoch 78/100, Loss: 24.1683, Validation Accuracy: 0.2183\n",
            "Epoch 79/100, Loss: 154.9344, Validation Accuracy: 0.5643\n",
            "Epoch 80/100, Loss: 24.2063, Validation Accuracy: 0.6560\n",
            "Epoch 81/100, Loss: 339.2922, Validation Accuracy: 0.6241\n",
            "Epoch 82/100, Loss: 205.1812, Validation Accuracy: 0.6092\n",
            "Epoch 83/100, Loss: 54.4578, Validation Accuracy: 0.5932\n",
            "Epoch 84/100, Loss: 3513.8325, Validation Accuracy: 0.5942\n",
            "Epoch 85/100, Loss: 389.7567, Validation Accuracy: 0.5224\n",
            "Epoch 86/100, Loss: 293.5888, Validation Accuracy: 0.6700\n",
            "Epoch 87/100, Loss: 161.9449, Validation Accuracy: 0.6152\n",
            "Epoch 88/100, Loss: 133.6957, Validation Accuracy: 0.5603\n",
            "Epoch 89/100, Loss: 39.8135, Validation Accuracy: 0.6291\n",
            "Epoch 90/100, Loss: 37.1014, Validation Accuracy: 0.6620\n",
            "Epoch 91/100, Loss: 21.0009, Validation Accuracy: 0.6321\n",
            "Epoch 92/100, Loss: 14.1157, Validation Accuracy: 0.5523\n",
            "Epoch 93/100, Loss: 12.3921, Validation Accuracy: 0.5583\n",
            "Epoch 94/100, Loss: 164.4982, Validation Accuracy: 0.6271\n",
            "Epoch 95/100, Loss: 14.8424, Validation Accuracy: 0.5773\n",
            "Epoch 96/100, Loss: 10.1474, Validation Accuracy: 0.5454\n",
            "Epoch 97/100, Loss: 13.6998, Validation Accuracy: 0.6371\n",
            "Epoch 98/100, Loss: 13.7532, Validation Accuracy: 0.5912\n",
            "Epoch 99/100, Loss: 116.5906, Validation Accuracy: 0.5214\n",
            "Epoch 100/100, Loss: 6.9071, Validation Accuracy: 0.4855\n",
            "Epoch 101/100, Loss: 17.2944, Validation Accuracy: 0.6680\n",
            "Epoch 102/100, Loss: 16.3015, Validation Accuracy: 0.5125\n",
            "Epoch 103/100, Loss: 14.2267, Validation Accuracy: 0.4855\n",
            "Epoch 104/100, Loss: 43.5634, Validation Accuracy: 0.4965\n",
            "Epoch 105/100, Loss: 35.3326, Validation Accuracy: 0.5992\n",
            "Epoch 106/100, Loss: 13.7921, Validation Accuracy: 0.6540\n",
            "Epoch 107/100, Loss: 11.7897, Validation Accuracy: 0.5145\n",
            "Epoch 108/100, Loss: 10.6509, Validation Accuracy: 0.6411\n",
            "Epoch 109/100, Loss: 40.3204, Validation Accuracy: 0.4835\n",
            "Epoch 110/100, Loss: 143.8790, Validation Accuracy: 0.6082\n",
            "Epoch 111/100, Loss: 5006.2036, Validation Accuracy: 0.3848\n",
            "Epoch 112/100, Loss: 1056.9880, Validation Accuracy: 0.4915\n",
            "Epoch 113/100, Loss: 196.8368, Validation Accuracy: 0.5653\n",
            "Epoch 114/100, Loss: 235.8692, Validation Accuracy: 0.5982\n",
            "Epoch 115/100, Loss: 137.4151, Validation Accuracy: 0.6012\n",
            "Epoch 116/100, Loss: 104.0974, Validation Accuracy: 0.6451\n",
            "Epoch 117/100, Loss: 157.5105, Validation Accuracy: 0.6481\n",
            "Epoch 118/100, Loss: 1472.2872, Validation Accuracy: 0.1266\n",
            "Epoch 119/100, Loss: 50.1324, Validation Accuracy: 0.4955\n",
            "Epoch 120/100, Loss: 49.0630, Validation Accuracy: 0.6152\n",
            "Epoch 121/100, Loss: 36.1980, Validation Accuracy: 0.5474\n",
            "Epoch 122/100, Loss: 20.9186, Validation Accuracy: 0.5613\n",
            "Epoch 123/100, Loss: 27.6414, Validation Accuracy: 0.6231\n",
            "Epoch 124/100, Loss: 6.7815, Validation Accuracy: 0.5633\n",
            "Epoch 125/100, Loss: 7.4293, Validation Accuracy: 0.5254\n",
            "Epoch 126/100, Loss: 169.4253, Validation Accuracy: 0.6341\n",
            "Epoch 127/100, Loss: 19.9018, Validation Accuracy: 0.5962\n",
            "Epoch 128/100, Loss: 9.6421, Validation Accuracy: 0.6849\n",
            "Epoch 129/100, Loss: 5.3187, Validation Accuracy: 0.4935\n",
            "Epoch 130/100, Loss: 23.5014, Validation Accuracy: 0.6132\n",
            "Epoch 131/100, Loss: 9.7165, Validation Accuracy: 0.6740\n",
            "Epoch 132/100, Loss: 9.0687, Validation Accuracy: 0.5892\n",
            "Epoch 133/100, Loss: 25.8159, Validation Accuracy: 0.6391\n",
            "Epoch 134/100, Loss: 3.5213, Validation Accuracy: 0.6162\n",
            "Epoch 135/100, Loss: 30.8036, Validation Accuracy: 0.5693\n",
            "Epoch 136/100, Loss: 184.3434, Validation Accuracy: 0.5803\n",
            "Epoch 137/100, Loss: 20.6619, Validation Accuracy: 0.6790\n",
            "Epoch 138/100, Loss: 41.3093, Validation Accuracy: 0.6770\n",
            "Epoch 139/100, Loss: 3472.6763, Validation Accuracy: 0.4088\n",
            "Epoch 140/100, Loss: 18.1981, Validation Accuracy: 0.6381\n",
            "Epoch 141/100, Loss: 2629.0129, Validation Accuracy: 0.6211\n",
            "Epoch 142/100, Loss: 915.5597, Validation Accuracy: 0.6590\n",
            "Epoch 143/100, Loss: 1139.3636, Validation Accuracy: 0.6361\n",
            "Epoch 144/100, Loss: 519.2664, Validation Accuracy: 0.6271\n",
            "Epoch 145/100, Loss: 267.9690, Validation Accuracy: 0.6191\n",
            "Epoch 146/100, Loss: 134.9219, Validation Accuracy: 0.6580\n",
            "Epoch 147/100, Loss: 53.3021, Validation Accuracy: 0.6002\n",
            "Epoch 148/100, Loss: 21.2208, Validation Accuracy: 0.6301\n",
            "Epoch 149/100, Loss: 14.6285, Validation Accuracy: 0.6461\n",
            "Epoch 150/100, Loss: 27.4631, Validation Accuracy: 0.5533\n",
            "Epoch 151/100, Loss: 20.8944, Validation Accuracy: 0.5803\n",
            "Epoch 152/100, Loss: 22.3164, Validation Accuracy: 0.6052\n",
            "Epoch 153/100, Loss: 10.5471, Validation Accuracy: 0.4596\n",
            "Epoch 154/100, Loss: 19.4762, Validation Accuracy: 0.5474\n",
            "Epoch 155/100, Loss: 12.3188, Validation Accuracy: 0.5583\n",
            "Epoch 156/100, Loss: 24.9669, Validation Accuracy: 0.5155\n",
            "Epoch 157/100, Loss: 22.0852, Validation Accuracy: 0.6171\n",
            "Epoch 158/100, Loss: 54.7381, Validation Accuracy: 0.5484\n",
            "Epoch 159/100, Loss: 7.8378, Validation Accuracy: 0.6461\n",
            "Epoch 160/100, Loss: 38.7610, Validation Accuracy: 0.6590\n",
            "Epoch 161/100, Loss: 167.6001, Validation Accuracy: 0.6520\n",
            "Epoch 162/100, Loss: 19.1584, Validation Accuracy: 0.5982\n",
            "Epoch 163/100, Loss: 235.2453, Validation Accuracy: 0.6122\n",
            "Epoch 164/100, Loss: 15.9822, Validation Accuracy: 0.6321\n",
            "Epoch 165/100, Loss: 34.2385, Validation Accuracy: 0.4068\n",
            "Epoch 166/100, Loss: 17.7952, Validation Accuracy: 0.5753\n",
            "Epoch 167/100, Loss: 11.2671, Validation Accuracy: 0.6391\n",
            "Epoch 168/100, Loss: 37.8459, Validation Accuracy: 0.3659\n",
            "Epoch 169/100, Loss: 43.5226, Validation Accuracy: 0.6221\n",
            "Epoch 170/100, Loss: 113.5350, Validation Accuracy: 0.6670\n",
            "Epoch 171/100, Loss: 36.1121, Validation Accuracy: 0.5204\n",
            "Epoch 172/100, Loss: 23.8845, Validation Accuracy: 0.5224\n",
            "Epoch 173/100, Loss: 269.4610, Validation Accuracy: 0.5035\n",
            "Epoch 174/100, Loss: 26.2151, Validation Accuracy: 0.6281\n",
            "Epoch 175/100, Loss: 47.8946, Validation Accuracy: 0.3619\n",
            "Epoch 176/100, Loss: 15.8203, Validation Accuracy: 0.6441\n",
            "Epoch 177/100, Loss: 32.6364, Validation Accuracy: 0.6710\n",
            "Epoch 178/100, Loss: 21.4165, Validation Accuracy: 0.5165\n",
            "Epoch 179/100, Loss: 15.9576, Validation Accuracy: 0.5813\n",
            "Epoch 180/100, Loss: 171.3660, Validation Accuracy: 0.6102\n",
            "Epoch 181/100, Loss: 26.2183, Validation Accuracy: 0.5244\n",
            "Epoch 182/100, Loss: 14.8475, Validation Accuracy: 0.5793\n",
            "Epoch 183/100, Loss: 24.0905, Validation Accuracy: 0.6042\n",
            "Epoch 184/100, Loss: 14.7143, Validation Accuracy: 0.5563\n",
            "Epoch 185/100, Loss: 8.5425, Validation Accuracy: 0.6510\n",
            "Epoch 186/100, Loss: 4.8756, Validation Accuracy: 0.6211\n",
            "Epoch 187/100, Loss: 66.0802, Validation Accuracy: 0.5274\n",
            "Epoch 188/100, Loss: 29.7944, Validation Accuracy: 0.6171\n",
            "Epoch 189/100, Loss: 19.5899, Validation Accuracy: 0.5184\n",
            "Epoch 190/100, Loss: 10.1225, Validation Accuracy: 0.5244\n",
            "Epoch 191/100, Loss: 17.3877, Validation Accuracy: 0.5952\n",
            "Epoch 192/100, Loss: 10.8989, Validation Accuracy: 0.5503\n",
            "Epoch 193/100, Loss: 27.0399, Validation Accuracy: 0.6271\n",
            "Epoch 194/100, Loss: 208.2515, Validation Accuracy: 0.6471\n",
            "Epoch 195/100, Loss: 21.9020, Validation Accuracy: 0.5763\n",
            "Epoch 196/100, Loss: 41.6792, Validation Accuracy: 0.6680\n",
            "Epoch 197/100, Loss: 34.6549, Validation Accuracy: 0.5454\n",
            "Epoch 198/100, Loss: 25.0431, Validation Accuracy: 0.6082\n",
            "Epoch 199/100, Loss: 61.7618, Validation Accuracy: 0.6331\n",
            "Epoch 200/100, Loss: 167.1274, Validation Accuracy: 0.5842\n",
            "Reward for Child Model: 0.2980722933598883\n",
            "Child_59:  {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, [3, 0, 0, 0, 2, 3, 0, 2, 3, 3, 3, 1, 3, 2, 0], 0.2980722933598883\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 64, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(128, 64, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(128, 36, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(164, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=129792, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 26, 26]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 26, 26]             128\n",
            "            Conv2d-3           [-1, 64, 24, 22]          61,504\n",
            "       BatchNorm2d-4           [-1, 64, 24, 22]             128\n",
            "              ReLU-5           [-1, 64, 24, 22]               0\n",
            "            Conv2d-6           [-1, 64, 26, 24]          24,640\n",
            "       BatchNorm2d-7           [-1, 64, 26, 24]             128\n",
            "              ReLU-8           [-1, 64, 26, 24]               0\n",
            "            Conv2d-9           [-1, 36, 22, 20]         161,316\n",
            "      BatchNorm2d-10           [-1, 36, 22, 20]              72\n",
            "             ReLU-11           [-1, 36, 22, 20]               0\n",
            "           Conv2d-12           [-1, 64, 22, 26]          52,544\n",
            "      BatchNorm2d-13           [-1, 64, 22, 26]             128\n",
            "             ReLU-14           [-1, 64, 22, 26]               0\n",
            "           Linear-15                    [-1, 7]         908,551\n",
            "================================================================\n",
            "Total params: 1,210,931\n",
            "Trainable params: 1,210,931\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.55\n",
            "Params size (MB): 4.62\n",
            "Estimated Total Size (MB): 8.18\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 28.0766, Validation Accuracy: 0.5135\n",
            "Epoch 2/100, Loss: 334.9589, Validation Accuracy: 0.5872\n",
            "Epoch 3/100, Loss: 18.4904, Validation Accuracy: 0.6171\n",
            "Epoch 4/100, Loss: 7.8441, Validation Accuracy: 0.2762\n",
            "Epoch 5/100, Loss: 17.9564, Validation Accuracy: 0.4397\n",
            "Epoch 6/100, Loss: 73.9942, Validation Accuracy: 0.5015\n",
            "Epoch 7/100, Loss: 88.0615, Validation Accuracy: 0.6351\n",
            "Epoch 8/100, Loss: 41.2623, Validation Accuracy: 0.4985\n",
            "Epoch 9/100, Loss: 10.7242, Validation Accuracy: 0.4965\n",
            "Epoch 10/100, Loss: 27.3302, Validation Accuracy: 0.6670\n",
            "Epoch 11/100, Loss: 9.7814, Validation Accuracy: 0.6381\n",
            "Epoch 12/100, Loss: 57.1192, Validation Accuracy: 0.5633\n",
            "Epoch 13/100, Loss: 80.5594, Validation Accuracy: 0.5932\n",
            "Epoch 14/100, Loss: 22.4561, Validation Accuracy: 0.6321\n",
            "Epoch 15/100, Loss: 58.7098, Validation Accuracy: 0.6500\n",
            "Epoch 16/100, Loss: 132.3205, Validation Accuracy: 0.5653\n",
            "Epoch 17/100, Loss: 56.4644, Validation Accuracy: 0.6590\n",
            "Epoch 18/100, Loss: 33.5377, Validation Accuracy: 0.5723\n",
            "Epoch 19/100, Loss: 28.7582, Validation Accuracy: 0.6630\n",
            "Epoch 20/100, Loss: 160.8515, Validation Accuracy: 0.6491\n",
            "Epoch 21/100, Loss: 42.8701, Validation Accuracy: 0.4875\n",
            "Epoch 22/100, Loss: 24.1223, Validation Accuracy: 0.5882\n",
            "Epoch 23/100, Loss: 86.8325, Validation Accuracy: 0.5404\n",
            "Epoch 24/100, Loss: 48.8097, Validation Accuracy: 0.6530\n",
            "Epoch 25/100, Loss: 6.2914, Validation Accuracy: 0.6899\n",
            "Epoch 26/100, Loss: 41.1474, Validation Accuracy: 0.5174\n",
            "Epoch 27/100, Loss: 39.3730, Validation Accuracy: 0.6630\n",
            "Epoch 28/100, Loss: 25.8688, Validation Accuracy: 0.6401\n",
            "Epoch 29/100, Loss: 48.0696, Validation Accuracy: 0.6301\n",
            "Epoch 30/100, Loss: 56.0101, Validation Accuracy: 0.4138\n",
            "Epoch 31/100, Loss: 42.0327, Validation Accuracy: 0.5174\n",
            "Epoch 32/100, Loss: 63.7977, Validation Accuracy: 0.4756\n",
            "Epoch 33/100, Loss: 92.5290, Validation Accuracy: 0.4546\n",
            "Epoch 34/100, Loss: 98.0621, Validation Accuracy: 0.5683\n",
            "Epoch 35/100, Loss: 58.9674, Validation Accuracy: 0.6580\n",
            "Epoch 36/100, Loss: 67.1787, Validation Accuracy: 0.5284\n",
            "Epoch 37/100, Loss: 49.3635, Validation Accuracy: 0.5573\n",
            "Epoch 38/100, Loss: 45.4284, Validation Accuracy: 0.5593\n",
            "Epoch 39/100, Loss: 83.2906, Validation Accuracy: 0.5424\n",
            "Epoch 40/100, Loss: 87.8706, Validation Accuracy: 0.5763\n",
            "Epoch 41/100, Loss: 26.5220, Validation Accuracy: 0.5833\n",
            "Epoch 42/100, Loss: 47.5705, Validation Accuracy: 0.5184\n",
            "Epoch 43/100, Loss: 104.0912, Validation Accuracy: 0.6600\n",
            "Epoch 44/100, Loss: 73.1286, Validation Accuracy: 0.5085\n",
            "Epoch 45/100, Loss: 30.4519, Validation Accuracy: 0.6839\n",
            "Epoch 46/100, Loss: 132.6337, Validation Accuracy: 0.5494\n",
            "Epoch 47/100, Loss: 70.7074, Validation Accuracy: 0.6431\n",
            "Epoch 48/100, Loss: 21.0399, Validation Accuracy: 0.6162\n",
            "Epoch 49/100, Loss: 118.8288, Validation Accuracy: 0.4387\n",
            "Epoch 50/100, Loss: 80.5795, Validation Accuracy: 0.5603\n",
            "Epoch 51/100, Loss: 133.0587, Validation Accuracy: 0.3749\n",
            "Epoch 52/100, Loss: 64.5983, Validation Accuracy: 0.6162\n",
            "Epoch 53/100, Loss: 51.5081, Validation Accuracy: 0.6520\n",
            "Epoch 54/100, Loss: 47.5821, Validation Accuracy: 0.5693\n",
            "Epoch 55/100, Loss: 64.7635, Validation Accuracy: 0.4337\n",
            "Epoch 56/100, Loss: 57.6972, Validation Accuracy: 0.5783\n",
            "Epoch 57/100, Loss: 93.7196, Validation Accuracy: 0.6760\n",
            "Epoch 58/100, Loss: 63.0353, Validation Accuracy: 0.4786\n",
            "Epoch 59/100, Loss: 44.7801, Validation Accuracy: 0.6341\n",
            "Epoch 60/100, Loss: 58.0115, Validation Accuracy: 0.4606\n",
            "Epoch 61/100, Loss: 98.4733, Validation Accuracy: 0.4816\n",
            "Epoch 62/100, Loss: 55.4348, Validation Accuracy: 0.5902\n",
            "Epoch 63/100, Loss: 32.3965, Validation Accuracy: 0.5823\n",
            "Epoch 64/100, Loss: 46.4459, Validation Accuracy: 0.5513\n",
            "Epoch 65/100, Loss: 43.1785, Validation Accuracy: 0.6540\n",
            "Epoch 66/100, Loss: 75.4889, Validation Accuracy: 0.6052\n",
            "Epoch 67/100, Loss: 43.8914, Validation Accuracy: 0.4865\n",
            "Epoch 68/100, Loss: 33.2044, Validation Accuracy: 0.6142\n",
            "Epoch 69/100, Loss: 188.3487, Validation Accuracy: 0.3679\n",
            "Epoch 70/100, Loss: 70.0795, Validation Accuracy: 0.4337\n",
            "Epoch 71/100, Loss: 15.7498, Validation Accuracy: 0.4606\n",
            "Epoch 72/100, Loss: 45.8747, Validation Accuracy: 0.6301\n",
            "Epoch 73/100, Loss: 29.6099, Validation Accuracy: 0.5723\n",
            "Epoch 74/100, Loss: 70.0481, Validation Accuracy: 0.5922\n",
            "Epoch 75/100, Loss: 27.3955, Validation Accuracy: 0.5673\n",
            "Epoch 76/100, Loss: 145.4392, Validation Accuracy: 0.4616\n",
            "Epoch 77/100, Loss: 47.8735, Validation Accuracy: 0.6660\n",
            "Epoch 78/100, Loss: 83.2818, Validation Accuracy: 0.6301\n",
            "Epoch 79/100, Loss: 37.5048, Validation Accuracy: 0.5503\n",
            "Epoch 80/100, Loss: 20.5339, Validation Accuracy: 0.5743\n",
            "Epoch 81/100, Loss: 79.8146, Validation Accuracy: 0.5852\n",
            "Epoch 82/100, Loss: 44.9384, Validation Accuracy: 0.4467\n",
            "Epoch 83/100, Loss: 124.1335, Validation Accuracy: 0.5174\n",
            "Epoch 84/100, Loss: 18.9775, Validation Accuracy: 0.6092\n",
            "Epoch 85/100, Loss: 115.6857, Validation Accuracy: 0.6660\n",
            "Epoch 86/100, Loss: 56.6052, Validation Accuracy: 0.6281\n",
            "Epoch 87/100, Loss: 32.6976, Validation Accuracy: 0.6082\n",
            "Epoch 88/100, Loss: 61.5496, Validation Accuracy: 0.6171\n",
            "Epoch 89/100, Loss: 34.3620, Validation Accuracy: 0.5962\n",
            "Epoch 90/100, Loss: 63.6368, Validation Accuracy: 0.5184\n",
            "Epoch 91/100, Loss: 56.0777, Validation Accuracy: 0.6500\n",
            "Epoch 92/100, Loss: 20.6867, Validation Accuracy: 0.5334\n",
            "Epoch 93/100, Loss: 19.4020, Validation Accuracy: 0.5344\n",
            "Epoch 94/100, Loss: 84.8966, Validation Accuracy: 0.6311\n",
            "Epoch 95/100, Loss: 59.3782, Validation Accuracy: 0.5244\n",
            "Epoch 96/100, Loss: 87.9282, Validation Accuracy: 0.5892\n",
            "Epoch 97/100, Loss: 89.9906, Validation Accuracy: 0.6481\n",
            "Epoch 98/100, Loss: 41.8582, Validation Accuracy: 0.6550\n",
            "Epoch 99/100, Loss: 129.1048, Validation Accuracy: 0.6002\n",
            "Epoch 100/100, Loss: 109.0141, Validation Accuracy: 0.5753\n",
            "Epoch 101/100, Loss: 19.9486, Validation Accuracy: 0.6710\n",
            "Epoch 102/100, Loss: 31.6687, Validation Accuracy: 0.6361\n",
            "Epoch 103/100, Loss: 38.7851, Validation Accuracy: 0.6261\n",
            "Epoch 104/100, Loss: 63.7218, Validation Accuracy: 0.6670\n",
            "Epoch 105/100, Loss: 139.8481, Validation Accuracy: 0.5424\n",
            "Epoch 106/100, Loss: 109.2148, Validation Accuracy: 0.4108\n",
            "Epoch 107/100, Loss: 33.4730, Validation Accuracy: 0.6341\n",
            "Epoch 108/100, Loss: 79.7686, Validation Accuracy: 0.5813\n",
            "Epoch 109/100, Loss: 31.1744, Validation Accuracy: 0.5364\n",
            "Epoch 110/100, Loss: 117.6604, Validation Accuracy: 0.5793\n",
            "Epoch 111/100, Loss: 93.3525, Validation Accuracy: 0.5434\n",
            "Epoch 112/100, Loss: 63.8003, Validation Accuracy: 0.5663\n",
            "Epoch 113/100, Loss: 48.3673, Validation Accuracy: 0.6102\n",
            "Epoch 114/100, Loss: 59.8372, Validation Accuracy: 0.5912\n",
            "Epoch 115/100, Loss: 191.0843, Validation Accuracy: 0.6191\n",
            "Epoch 116/100, Loss: 125.8359, Validation Accuracy: 0.5932\n",
            "Epoch 117/100, Loss: 42.6222, Validation Accuracy: 0.6152\n",
            "Epoch 118/100, Loss: 29.8144, Validation Accuracy: 0.5643\n",
            "Epoch 119/100, Loss: 70.6741, Validation Accuracy: 0.5902\n",
            "Epoch 120/100, Loss: 33.7062, Validation Accuracy: 0.6341\n",
            "Epoch 121/100, Loss: 122.3270, Validation Accuracy: 0.5793\n",
            "Epoch 122/100, Loss: 44.1897, Validation Accuracy: 0.6191\n",
            "Epoch 123/100, Loss: 43.8803, Validation Accuracy: 0.6610\n",
            "Epoch 124/100, Loss: 42.5164, Validation Accuracy: 0.6371\n",
            "Epoch 125/100, Loss: 56.1398, Validation Accuracy: 0.6610\n",
            "Epoch 126/100, Loss: 42.5327, Validation Accuracy: 0.5543\n",
            "Epoch 127/100, Loss: 91.3645, Validation Accuracy: 0.6381\n",
            "Epoch 128/100, Loss: 59.6855, Validation Accuracy: 0.5424\n",
            "Epoch 129/100, Loss: 62.7735, Validation Accuracy: 0.6381\n",
            "Epoch 130/100, Loss: 79.0273, Validation Accuracy: 0.4865\n",
            "Epoch 131/100, Loss: 30.3289, Validation Accuracy: 0.6012\n",
            "Epoch 132/100, Loss: 54.9674, Validation Accuracy: 0.6102\n",
            "Epoch 133/100, Loss: 34.1833, Validation Accuracy: 0.6371\n",
            "Epoch 134/100, Loss: 63.0943, Validation Accuracy: 0.5244\n",
            "Epoch 135/100, Loss: 51.7668, Validation Accuracy: 0.5932\n",
            "Epoch 136/100, Loss: 78.3034, Validation Accuracy: 0.6251\n",
            "Epoch 137/100, Loss: 47.0158, Validation Accuracy: 0.4676\n",
            "Epoch 138/100, Loss: 57.4522, Validation Accuracy: 0.6022\n",
            "Epoch 139/100, Loss: 51.6053, Validation Accuracy: 0.5354\n",
            "Epoch 140/100, Loss: 55.0671, Validation Accuracy: 0.6291\n",
            "Epoch 141/100, Loss: 49.0547, Validation Accuracy: 0.5324\n",
            "Epoch 142/100, Loss: 79.0858, Validation Accuracy: 0.4786\n",
            "Epoch 143/100, Loss: 85.9231, Validation Accuracy: 0.5065\n",
            "Epoch 144/100, Loss: 59.1390, Validation Accuracy: 0.5852\n",
            "Epoch 145/100, Loss: 61.4451, Validation Accuracy: 0.5414\n",
            "Epoch 146/100, Loss: 35.3664, Validation Accuracy: 0.5414\n",
            "Epoch 147/100, Loss: 35.3288, Validation Accuracy: 0.5693\n",
            "Epoch 148/100, Loss: 114.4522, Validation Accuracy: 0.5613\n",
            "Epoch 149/100, Loss: 37.7070, Validation Accuracy: 0.5932\n",
            "Epoch 150/100, Loss: 58.5178, Validation Accuracy: 0.6411\n",
            "Epoch 151/100, Loss: 45.8422, Validation Accuracy: 0.5125\n",
            "Epoch 152/100, Loss: 57.0047, Validation Accuracy: 0.6650\n",
            "Epoch 153/100, Loss: 53.8974, Validation Accuracy: 0.5374\n",
            "Epoch 154/100, Loss: 63.7103, Validation Accuracy: 0.6162\n",
            "Epoch 155/100, Loss: 28.0291, Validation Accuracy: 0.5234\n",
            "Epoch 156/100, Loss: 56.0050, Validation Accuracy: 0.5753\n",
            "Epoch 157/100, Loss: 76.7870, Validation Accuracy: 0.6670\n",
            "Epoch 158/100, Loss: 99.3240, Validation Accuracy: 0.6540\n",
            "Epoch 159/100, Loss: 53.7874, Validation Accuracy: 0.6201\n",
            "Epoch 160/100, Loss: 39.7847, Validation Accuracy: 0.5962\n",
            "Epoch 161/100, Loss: 85.2082, Validation Accuracy: 0.6730\n",
            "Epoch 162/100, Loss: 38.1785, Validation Accuracy: 0.6610\n",
            "Epoch 163/100, Loss: 59.7691, Validation Accuracy: 0.5404\n",
            "Epoch 164/100, Loss: 42.8606, Validation Accuracy: 0.5105\n",
            "Epoch 165/100, Loss: 72.0810, Validation Accuracy: 0.6082\n",
            "Epoch 166/100, Loss: 49.6201, Validation Accuracy: 0.5783\n",
            "Epoch 167/100, Loss: 45.3350, Validation Accuracy: 0.6590\n",
            "Epoch 168/100, Loss: 49.1321, Validation Accuracy: 0.6321\n",
            "Epoch 169/100, Loss: 95.3342, Validation Accuracy: 0.5204\n",
            "Epoch 170/100, Loss: 51.0978, Validation Accuracy: 0.5314\n",
            "Epoch 171/100, Loss: 32.9896, Validation Accuracy: 0.5823\n",
            "Epoch 172/100, Loss: 95.1430, Validation Accuracy: 0.5464\n",
            "Epoch 173/100, Loss: 72.8313, Validation Accuracy: 0.6441\n",
            "Epoch 174/100, Loss: 22.2504, Validation Accuracy: 0.6162\n",
            "Epoch 175/100, Loss: 70.2365, Validation Accuracy: 0.6560\n",
            "Epoch 176/100, Loss: 37.8244, Validation Accuracy: 0.5444\n",
            "Epoch 177/100, Loss: 242.5599, Validation Accuracy: 0.4955\n",
            "Epoch 178/100, Loss: 51.4487, Validation Accuracy: 0.5434\n",
            "Epoch 179/100, Loss: 47.8958, Validation Accuracy: 0.6092\n",
            "Epoch 180/100, Loss: 49.0305, Validation Accuracy: 0.6321\n",
            "Epoch 181/100, Loss: 144.9685, Validation Accuracy: 0.5593\n",
            "Epoch 182/100, Loss: 67.5660, Validation Accuracy: 0.5823\n",
            "Epoch 183/100, Loss: 55.7465, Validation Accuracy: 0.6770\n",
            "Epoch 184/100, Loss: 26.4312, Validation Accuracy: 0.6510\n",
            "Epoch 185/100, Loss: 68.6308, Validation Accuracy: 0.5603\n",
            "Epoch 186/100, Loss: 100.0933, Validation Accuracy: 0.5703\n",
            "Epoch 187/100, Loss: 107.4817, Validation Accuracy: 0.5304\n",
            "Epoch 188/100, Loss: 34.6775, Validation Accuracy: 0.6401\n",
            "Epoch 189/100, Loss: 40.5557, Validation Accuracy: 0.6241\n",
            "Epoch 190/100, Loss: 38.8168, Validation Accuracy: 0.6072\n",
            "Epoch 191/100, Loss: 42.7245, Validation Accuracy: 0.5065\n",
            "Epoch 192/100, Loss: 46.0961, Validation Accuracy: 0.6122\n",
            "Epoch 193/100, Loss: 278.7390, Validation Accuracy: 0.6351\n",
            "Epoch 194/100, Loss: 46.1054, Validation Accuracy: 0.5414\n",
            "Epoch 195/100, Loss: 72.0310, Validation Accuracy: 0.6500\n",
            "Epoch 196/100, Loss: 69.8633, Validation Accuracy: 0.4736\n",
            "Epoch 197/100, Loss: 69.0502, Validation Accuracy: 0.6231\n",
            "Epoch 198/100, Loss: 33.9289, Validation Accuracy: 0.5105\n",
            "Epoch 199/100, Loss: 56.8915, Validation Accuracy: 0.6810\n",
            "Epoch 200/100, Loss: 173.4158, Validation Accuracy: 0.5583\n",
            "Reward for Child Model: 0.31576159852455576\n",
            "Child_60:  {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, [1, 1, 3, 1, 2, 3, 0, 1, 3, 2, 3, 1, 2, 0, 3], 0.31576159852455576\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 24, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 48, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(96, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(156, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=101376, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 22, 24]           2,544\n",
            "       BatchNorm2d-2           [-1, 24, 22, 24]              48\n",
            "            Conv2d-3           [-1, 24, 16, 22]          12,120\n",
            "       BatchNorm2d-4           [-1, 24, 16, 22]              48\n",
            "              ReLU-5           [-1, 24, 16, 22]               0\n",
            "            Conv2d-6           [-1, 48, 16, 20]           3,504\n",
            "       BatchNorm2d-7           [-1, 48, 16, 20]              96\n",
            "              ReLU-8           [-1, 48, 16, 20]               0\n",
            "            Conv2d-9           [-1, 36, 18, 20]          86,436\n",
            "      BatchNorm2d-10           [-1, 36, 18, 20]              72\n",
            "             ReLU-11           [-1, 36, 18, 20]               0\n",
            "           Conv2d-12           [-1, 48, 20, 24]          22,512\n",
            "      BatchNorm2d-13           [-1, 48, 20, 24]              96\n",
            "             ReLU-14           [-1, 48, 20, 24]               0\n",
            "           Linear-15                    [-1, 7]         709,639\n",
            "================================================================\n",
            "Total params: 837,115\n",
            "Trainable params: 837,115\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.56\n",
            "Params size (MB): 3.19\n",
            "Estimated Total Size (MB): 4.76\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 154.9131, Validation Accuracy: 0.6491\n",
            "Epoch 2/100, Loss: 4.2840, Validation Accuracy: 0.6371\n",
            "Epoch 3/100, Loss: 129.7743, Validation Accuracy: 0.4038\n",
            "Epoch 4/100, Loss: 12.7753, Validation Accuracy: 0.6351\n",
            "Epoch 5/100, Loss: 6.2401, Validation Accuracy: 0.1216\n",
            "Epoch 6/100, Loss: 333.3932, Validation Accuracy: 0.6540\n",
            "Epoch 7/100, Loss: 48.3574, Validation Accuracy: 0.5404\n",
            "Epoch 8/100, Loss: 7.9908, Validation Accuracy: 0.4915\n",
            "Epoch 9/100, Loss: 4.4752, Validation Accuracy: 0.5474\n",
            "Epoch 10/100, Loss: 2.4323, Validation Accuracy: 0.6481\n",
            "Epoch 11/100, Loss: 2.4317, Validation Accuracy: 0.6032\n",
            "Epoch 12/100, Loss: 27.9402, Validation Accuracy: 0.5434\n",
            "Epoch 13/100, Loss: 12.2080, Validation Accuracy: 0.6271\n",
            "Epoch 14/100, Loss: 985.0819, Validation Accuracy: 0.5673\n",
            "Epoch 15/100, Loss: 46.7539, Validation Accuracy: 0.5583\n",
            "Epoch 16/100, Loss: 9.4188, Validation Accuracy: 0.6680\n",
            "Epoch 17/100, Loss: 176.5688, Validation Accuracy: 0.6092\n",
            "Epoch 18/100, Loss: 42.2410, Validation Accuracy: 0.6132\n",
            "Epoch 19/100, Loss: 12.0948, Validation Accuracy: 0.6590\n",
            "Epoch 20/100, Loss: 5.3761, Validation Accuracy: 0.5234\n",
            "Epoch 21/100, Loss: 4.8209, Validation Accuracy: 0.4915\n",
            "Epoch 22/100, Loss: 4.7566, Validation Accuracy: 0.6580\n",
            "Epoch 23/100, Loss: 5.8197, Validation Accuracy: 0.6590\n",
            "Epoch 24/100, Loss: 4.7261, Validation Accuracy: 0.6062\n",
            "Epoch 25/100, Loss: 7.8008, Validation Accuracy: 0.5803\n",
            "Epoch 26/100, Loss: 6.0819, Validation Accuracy: 0.6820\n",
            "Epoch 27/100, Loss: 20.5619, Validation Accuracy: 0.4915\n",
            "Epoch 28/100, Loss: 3.0834, Validation Accuracy: 0.6660\n",
            "Epoch 29/100, Loss: 6.0138, Validation Accuracy: 0.5404\n",
            "Epoch 30/100, Loss: 6.1873, Validation Accuracy: 0.6201\n",
            "Epoch 31/100, Loss: 72.7093, Validation Accuracy: 0.4995\n",
            "Epoch 32/100, Loss: 8.2636, Validation Accuracy: 0.6640\n",
            "Epoch 33/100, Loss: 3.7269, Validation Accuracy: 0.6052\n",
            "Epoch 34/100, Loss: 2.2016, Validation Accuracy: 0.6481\n",
            "Epoch 35/100, Loss: 25.1376, Validation Accuracy: 0.6052\n",
            "Epoch 36/100, Loss: 5.6117, Validation Accuracy: 0.5035\n",
            "Epoch 37/100, Loss: 2.0026, Validation Accuracy: 0.6680\n",
            "Epoch 38/100, Loss: 8.8069, Validation Accuracy: 0.6660\n",
            "Epoch 39/100, Loss: 253.2853, Validation Accuracy: 0.6580\n",
            "Epoch 40/100, Loss: 17.0221, Validation Accuracy: 0.5105\n",
            "Epoch 41/100, Loss: 6.2699, Validation Accuracy: 0.6510\n",
            "Epoch 42/100, Loss: 4.5038, Validation Accuracy: 0.6211\n",
            "Epoch 43/100, Loss: 5.3099, Validation Accuracy: 0.6072\n",
            "Epoch 44/100, Loss: 25.5785, Validation Accuracy: 0.6341\n",
            "Epoch 45/100, Loss: 124.4101, Validation Accuracy: 0.0518\n",
            "Epoch 46/100, Loss: 48.8693, Validation Accuracy: 0.6371\n",
            "Epoch 47/100, Loss: 30.0725, Validation Accuracy: 0.5314\n",
            "Epoch 48/100, Loss: 17.7414, Validation Accuracy: 0.5872\n",
            "Epoch 49/100, Loss: 7.5301, Validation Accuracy: 0.6291\n",
            "Epoch 50/100, Loss: 5.6271, Validation Accuracy: 0.5364\n",
            "Epoch 51/100, Loss: 1119.9247, Validation Accuracy: 0.0518\n",
            "Epoch 52/100, Loss: 41.7529, Validation Accuracy: 0.6730\n",
            "Epoch 53/100, Loss: 7.3305, Validation Accuracy: 0.4975\n",
            "Epoch 54/100, Loss: 5.4040, Validation Accuracy: 0.6281\n",
            "Epoch 55/100, Loss: 5.4563, Validation Accuracy: 0.6391\n",
            "Epoch 56/100, Loss: 13.1858, Validation Accuracy: 0.4845\n",
            "Epoch 57/100, Loss: 11.6909, Validation Accuracy: 0.6421\n",
            "Epoch 58/100, Loss: 7.1473, Validation Accuracy: 0.5842\n",
            "Epoch 59/100, Loss: 118.4187, Validation Accuracy: 0.5902\n",
            "Epoch 60/100, Loss: 15.6767, Validation Accuracy: 0.5354\n",
            "Epoch 61/100, Loss: 8.5460, Validation Accuracy: 0.6132\n",
            "Epoch 62/100, Loss: 4.7254, Validation Accuracy: 0.6331\n",
            "Epoch 63/100, Loss: 14.0297, Validation Accuracy: 0.5394\n",
            "Epoch 64/100, Loss: 30.0318, Validation Accuracy: 0.5922\n",
            "Epoch 65/100, Loss: 168.0851, Validation Accuracy: 0.6600\n",
            "Epoch 66/100, Loss: 17.2052, Validation Accuracy: 0.6550\n",
            "Epoch 67/100, Loss: 1.6217, Validation Accuracy: 0.6820\n",
            "Epoch 68/100, Loss: 9.5759, Validation Accuracy: 0.6231\n",
            "Epoch 69/100, Loss: 7.7496, Validation Accuracy: 0.6191\n",
            "Epoch 70/100, Loss: 24.0343, Validation Accuracy: 0.4975\n",
            "Epoch 71/100, Loss: 78.7483, Validation Accuracy: 0.4098\n",
            "Epoch 72/100, Loss: 60.9986, Validation Accuracy: 0.6281\n",
            "Epoch 73/100, Loss: 15.6595, Validation Accuracy: 0.5823\n",
            "Epoch 74/100, Loss: 7.6101, Validation Accuracy: 0.6361\n",
            "Epoch 75/100, Loss: 8.4508, Validation Accuracy: 0.6311\n",
            "Epoch 76/100, Loss: 17.2142, Validation Accuracy: 0.3878\n",
            "Epoch 77/100, Loss: 20.6970, Validation Accuracy: 0.6530\n",
            "Epoch 78/100, Loss: 7.8957, Validation Accuracy: 0.6142\n",
            "Epoch 79/100, Loss: 35.1484, Validation Accuracy: 0.4845\n",
            "Epoch 80/100, Loss: 60.1784, Validation Accuracy: 0.5533\n",
            "Epoch 81/100, Loss: 14.8254, Validation Accuracy: 0.6191\n",
            "Epoch 82/100, Loss: 21.2049, Validation Accuracy: 0.6331\n",
            "Epoch 83/100, Loss: 26.4330, Validation Accuracy: 0.5803\n",
            "Epoch 84/100, Loss: 11.7516, Validation Accuracy: 0.6271\n",
            "Epoch 85/100, Loss: 22.1327, Validation Accuracy: 0.6162\n",
            "Epoch 86/100, Loss: 69.7015, Validation Accuracy: 0.6560\n",
            "Epoch 87/100, Loss: 129.5475, Validation Accuracy: 0.6550\n",
            "Epoch 88/100, Loss: 40.8801, Validation Accuracy: 0.5194\n",
            "Epoch 89/100, Loss: 10.3067, Validation Accuracy: 0.5763\n",
            "Epoch 90/100, Loss: 273.8341, Validation Accuracy: 0.6520\n",
            "Epoch 91/100, Loss: 18.2414, Validation Accuracy: 0.6132\n",
            "Epoch 92/100, Loss: 8.3313, Validation Accuracy: 0.5753\n",
            "Epoch 93/100, Loss: 4.5904, Validation Accuracy: 0.6481\n",
            "Epoch 94/100, Loss: 6.4557, Validation Accuracy: 0.4457\n",
            "Epoch 95/100, Loss: 5.8327, Validation Accuracy: 0.4915\n",
            "Epoch 96/100, Loss: 12.1912, Validation Accuracy: 0.3639\n",
            "Epoch 97/100, Loss: 6.7539, Validation Accuracy: 0.5683\n",
            "Epoch 98/100, Loss: 13.8654, Validation Accuracy: 0.5982\n",
            "Epoch 99/100, Loss: 8.5280, Validation Accuracy: 0.2802\n",
            "Epoch 100/100, Loss: 9.6016, Validation Accuracy: 0.6191\n",
            "Epoch 101/100, Loss: 9.4522, Validation Accuracy: 0.5454\n",
            "Epoch 102/100, Loss: 11.0467, Validation Accuracy: 0.6411\n",
            "Epoch 103/100, Loss: 6.9103, Validation Accuracy: 0.5484\n",
            "Epoch 104/100, Loss: 26.0476, Validation Accuracy: 0.4397\n",
            "Epoch 105/100, Loss: 21.5183, Validation Accuracy: 0.5872\n",
            "Epoch 106/100, Loss: 9.6431, Validation Accuracy: 0.6869\n",
            "Epoch 107/100, Loss: 2.3255, Validation Accuracy: 0.5763\n",
            "Epoch 108/100, Loss: 14.6938, Validation Accuracy: 0.6630\n",
            "Epoch 109/100, Loss: 44.3697, Validation Accuracy: 0.4167\n",
            "Epoch 110/100, Loss: 62.0688, Validation Accuracy: 0.5992\n",
            "Epoch 111/100, Loss: 19.9466, Validation Accuracy: 0.4975\n",
            "Epoch 112/100, Loss: 13.9529, Validation Accuracy: 0.6411\n",
            "Epoch 113/100, Loss: 40.6676, Validation Accuracy: 0.5165\n",
            "Epoch 114/100, Loss: 61.8905, Validation Accuracy: 0.3958\n",
            "Epoch 115/100, Loss: 7.5072, Validation Accuracy: 0.6760\n",
            "Epoch 116/100, Loss: 13.8648, Validation Accuracy: 0.5065\n",
            "Epoch 117/100, Loss: 4.5651, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 16.3493, Validation Accuracy: 0.6750\n",
            "Epoch 119/100, Loss: 14.1542, Validation Accuracy: 0.5872\n",
            "Epoch 120/100, Loss: 38.9626, Validation Accuracy: 0.5324\n",
            "Epoch 121/100, Loss: 105.3530, Validation Accuracy: 0.5404\n",
            "Epoch 122/100, Loss: 11.9838, Validation Accuracy: 0.5324\n",
            "Epoch 123/100, Loss: 21.5116, Validation Accuracy: 0.5533\n",
            "Epoch 124/100, Loss: 24.4481, Validation Accuracy: 0.5613\n",
            "Epoch 125/100, Loss: 104.7536, Validation Accuracy: 0.6321\n",
            "Epoch 126/100, Loss: 67.0853, Validation Accuracy: 0.5623\n",
            "Epoch 127/100, Loss: 252.1984, Validation Accuracy: 0.6082\n",
            "Epoch 128/100, Loss: 19.6257, Validation Accuracy: 0.4995\n",
            "Epoch 129/100, Loss: 18.7516, Validation Accuracy: 0.5304\n",
            "Epoch 130/100, Loss: 7.1987, Validation Accuracy: 0.6072\n",
            "Epoch 131/100, Loss: 7.0360, Validation Accuracy: 0.6540\n",
            "Epoch 132/100, Loss: 11.6479, Validation Accuracy: 0.4526\n",
            "Epoch 133/100, Loss: 7.5970, Validation Accuracy: 0.4467\n",
            "Epoch 134/100, Loss: 13.2753, Validation Accuracy: 0.6451\n",
            "Epoch 135/100, Loss: 119.2770, Validation Accuracy: 0.1456\n",
            "Epoch 136/100, Loss: 35.0281, Validation Accuracy: 0.6590\n",
            "Epoch 137/100, Loss: 46.0402, Validation Accuracy: 0.6201\n",
            "Epoch 138/100, Loss: 18.3280, Validation Accuracy: 0.6500\n",
            "Epoch 139/100, Loss: 8.0608, Validation Accuracy: 0.5643\n",
            "Epoch 140/100, Loss: 10.4521, Validation Accuracy: 0.5862\n",
            "Epoch 141/100, Loss: 8.3101, Validation Accuracy: 0.4935\n",
            "Epoch 142/100, Loss: 15.5967, Validation Accuracy: 0.5653\n",
            "Epoch 143/100, Loss: 7.7631, Validation Accuracy: 0.6042\n",
            "Epoch 144/100, Loss: 10.1182, Validation Accuracy: 0.4337\n",
            "Epoch 145/100, Loss: 3.4145, Validation Accuracy: 0.6530\n",
            "Epoch 146/100, Loss: 74.5994, Validation Accuracy: 0.5105\n",
            "Epoch 147/100, Loss: 12.7396, Validation Accuracy: 0.6032\n",
            "Epoch 148/100, Loss: 6.8595, Validation Accuracy: 0.5503\n",
            "Epoch 149/100, Loss: 11.4873, Validation Accuracy: 0.6331\n",
            "Epoch 150/100, Loss: 32.3161, Validation Accuracy: 0.4257\n",
            "Epoch 151/100, Loss: 8.0147, Validation Accuracy: 0.6441\n",
            "Epoch 152/100, Loss: 8.0693, Validation Accuracy: 0.6052\n",
            "Epoch 153/100, Loss: 12.5723, Validation Accuracy: 0.6481\n",
            "Epoch 154/100, Loss: 146.6275, Validation Accuracy: 0.5563\n",
            "Epoch 155/100, Loss: 5.0714, Validation Accuracy: 0.6321\n",
            "Epoch 156/100, Loss: 7.3276, Validation Accuracy: 0.6132\n",
            "Epoch 157/100, Loss: 22.4808, Validation Accuracy: 0.5763\n",
            "Epoch 158/100, Loss: 5.0823, Validation Accuracy: 0.5653\n",
            "Epoch 159/100, Loss: 7.3130, Validation Accuracy: 0.5823\n",
            "Epoch 160/100, Loss: 11.7774, Validation Accuracy: 0.6321\n",
            "Epoch 161/100, Loss: 111.9710, Validation Accuracy: 0.6162\n",
            "Epoch 162/100, Loss: 30.9914, Validation Accuracy: 0.6640\n",
            "Epoch 163/100, Loss: 11.9801, Validation Accuracy: 0.6211\n",
            "Epoch 164/100, Loss: 7.3641, Validation Accuracy: 0.3619\n",
            "Epoch 165/100, Loss: 24.6341, Validation Accuracy: 0.5085\n",
            "Epoch 166/100, Loss: 17.1662, Validation Accuracy: 0.6600\n",
            "Epoch 167/100, Loss: 22.9618, Validation Accuracy: 0.5444\n",
            "Epoch 168/100, Loss: 13.6088, Validation Accuracy: 0.6441\n",
            "Epoch 169/100, Loss: 12.1933, Validation Accuracy: 0.5214\n",
            "Epoch 170/100, Loss: 9.6713, Validation Accuracy: 0.5932\n",
            "Epoch 171/100, Loss: 20.3006, Validation Accuracy: 0.5733\n",
            "Epoch 172/100, Loss: 20.0251, Validation Accuracy: 0.6391\n",
            "Epoch 173/100, Loss: 16.8421, Validation Accuracy: 0.6301\n",
            "Epoch 174/100, Loss: 25.1453, Validation Accuracy: 0.6510\n",
            "Epoch 175/100, Loss: 41.5633, Validation Accuracy: 0.6371\n",
            "Epoch 176/100, Loss: 26.3440, Validation Accuracy: 0.5194\n",
            "Epoch 177/100, Loss: 25.1088, Validation Accuracy: 0.6261\n",
            "Epoch 178/100, Loss: 75.6702, Validation Accuracy: 0.5125\n",
            "Epoch 179/100, Loss: 15.7870, Validation Accuracy: 0.6311\n",
            "Epoch 180/100, Loss: 22.2807, Validation Accuracy: 0.6550\n",
            "Epoch 181/100, Loss: 40.7791, Validation Accuracy: 0.5464\n",
            "Epoch 182/100, Loss: 25.0958, Validation Accuracy: 0.5513\n",
            "Epoch 183/100, Loss: 16.5558, Validation Accuracy: 0.5793\n",
            "Epoch 184/100, Loss: 28.4073, Validation Accuracy: 0.5334\n",
            "Epoch 185/100, Loss: 53.0568, Validation Accuracy: 0.5135\n",
            "Epoch 186/100, Loss: 23.2625, Validation Accuracy: 0.6580\n",
            "Epoch 187/100, Loss: 28.7695, Validation Accuracy: 0.5553\n",
            "Epoch 188/100, Loss: 66.6475, Validation Accuracy: 0.5284\n",
            "Epoch 189/100, Loss: 50.5206, Validation Accuracy: 0.5763\n",
            "Epoch 190/100, Loss: 34.6094, Validation Accuracy: 0.6191\n",
            "Epoch 191/100, Loss: 51.8055, Validation Accuracy: 0.6032\n",
            "Epoch 192/100, Loss: 21.9608, Validation Accuracy: 0.6510\n",
            "Epoch 193/100, Loss: 23.0634, Validation Accuracy: 0.6830\n",
            "Epoch 194/100, Loss: 12.9238, Validation Accuracy: 0.5384\n",
            "Epoch 195/100, Loss: 15.1855, Validation Accuracy: 0.6830\n",
            "Epoch 196/100, Loss: 5.8027, Validation Accuracy: 0.6720\n",
            "Epoch 197/100, Loss: 14.3297, Validation Accuracy: 0.6022\n",
            "Epoch 198/100, Loss: 36.0316, Validation Accuracy: 0.5513\n",
            "Epoch 199/100, Loss: 17.8310, Validation Accuracy: 0.6600\n",
            "Epoch 200/100, Loss: 47.8489, Validation Accuracy: 0.5174\n",
            "Reward for Child Model: 0.3034428373146045\n",
            "Child_61:  {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, [3, 2, 0, 3, 1, 0, 0, 1, 2, 2, 2, 1, 1, 0, 2], 0.3034428373146045\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 64, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(100, 36, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(196, 36, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=108160, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 26, 26]           1,008\n",
            "       BatchNorm2d-2           [-1, 36, 26, 26]              72\n",
            "            Conv2d-3           [-1, 24, 26, 20]           6,072\n",
            "       BatchNorm2d-4           [-1, 24, 26, 20]              48\n",
            "              ReLU-5           [-1, 24, 26, 20]               0\n",
            "            Conv2d-6           [-1, 64, 22, 18]          23,104\n",
            "       BatchNorm2d-7           [-1, 64, 22, 18]             128\n",
            "              ReLU-8           [-1, 64, 22, 18]               0\n",
            "            Conv2d-9           [-1, 36, 24, 20]          75,636\n",
            "      BatchNorm2d-10           [-1, 36, 24, 20]              72\n",
            "             ReLU-11           [-1, 36, 24, 20]               0\n",
            "           Conv2d-12           [-1, 36, 22, 26]          35,316\n",
            "      BatchNorm2d-13           [-1, 36, 22, 26]              72\n",
            "             ReLU-14           [-1, 36, 22, 26]               0\n",
            "           Linear-15                    [-1, 7]         757,127\n",
            "================================================================\n",
            "Total params: 898,655\n",
            "Trainable params: 898,655\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.10\n",
            "Params size (MB): 3.43\n",
            "Estimated Total Size (MB): 5.54\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 17.8108, Validation Accuracy: 0.3370\n",
            "Epoch 2/100, Loss: 12.8465, Validation Accuracy: 0.5902\n",
            "Epoch 3/100, Loss: 19.5847, Validation Accuracy: 0.5583\n",
            "Epoch 4/100, Loss: 67.5200, Validation Accuracy: 0.5344\n",
            "Epoch 5/100, Loss: 1324.0750, Validation Accuracy: 0.5563\n",
            "Epoch 6/100, Loss: 23.0564, Validation Accuracy: 0.5444\n",
            "Epoch 7/100, Loss: 9.4878, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 178.9855, Validation Accuracy: 0.5783\n",
            "Epoch 9/100, Loss: 2492.6047, Validation Accuracy: 0.5623\n",
            "Epoch 10/100, Loss: 410.9391, Validation Accuracy: 0.6281\n",
            "Epoch 11/100, Loss: 56.8151, Validation Accuracy: 0.5503\n",
            "Epoch 12/100, Loss: 33.9089, Validation Accuracy: 0.6640\n",
            "Epoch 13/100, Loss: 15.8116, Validation Accuracy: 0.6251\n",
            "Epoch 14/100, Loss: 10.0268, Validation Accuracy: 0.5075\n",
            "Epoch 15/100, Loss: 6.1160, Validation Accuracy: 0.6680\n",
            "Epoch 16/100, Loss: 4.6999, Validation Accuracy: 0.5613\n",
            "Epoch 17/100, Loss: 6.5259, Validation Accuracy: 0.5533\n",
            "Epoch 18/100, Loss: 3.4908, Validation Accuracy: 0.6869\n",
            "Epoch 19/100, Loss: 8.8688, Validation Accuracy: 0.6770\n",
            "Epoch 20/100, Loss: 10.3593, Validation Accuracy: 0.4337\n",
            "Epoch 21/100, Loss: 5.6872, Validation Accuracy: 0.6112\n",
            "Epoch 22/100, Loss: 7.3824, Validation Accuracy: 0.6082\n",
            "Epoch 23/100, Loss: 18.2816, Validation Accuracy: 0.6630\n",
            "Epoch 24/100, Loss: 63.2263, Validation Accuracy: 0.4237\n",
            "Epoch 25/100, Loss: 16.3959, Validation Accuracy: 0.6441\n",
            "Epoch 26/100, Loss: 96.2736, Validation Accuracy: 0.6640\n",
            "Epoch 27/100, Loss: 5.0749, Validation Accuracy: 0.6820\n",
            "Epoch 28/100, Loss: 1.6142, Validation Accuracy: 0.6500\n",
            "Epoch 29/100, Loss: 7.3502, Validation Accuracy: 0.1924\n",
            "Epoch 30/100, Loss: 8.3601, Validation Accuracy: 0.4925\n",
            "Epoch 31/100, Loss: 1640.9767, Validation Accuracy: 0.6461\n",
            "Epoch 32/100, Loss: 13.0401, Validation Accuracy: 0.6122\n",
            "Epoch 33/100, Loss: 9.4635, Validation Accuracy: 0.4895\n",
            "Epoch 34/100, Loss: 5.8434, Validation Accuracy: 0.6550\n",
            "Epoch 35/100, Loss: 8.2785, Validation Accuracy: 0.5174\n",
            "Epoch 36/100, Loss: 304.0614, Validation Accuracy: 0.5773\n",
            "Epoch 37/100, Loss: 27.1570, Validation Accuracy: 0.6052\n",
            "Epoch 38/100, Loss: 424.1630, Validation Accuracy: 0.5523\n",
            "Epoch 39/100, Loss: 30.0688, Validation Accuracy: 0.6102\n",
            "Epoch 40/100, Loss: 10.3274, Validation Accuracy: 0.6600\n",
            "Epoch 41/100, Loss: 20.5712, Validation Accuracy: 0.6451\n",
            "Epoch 42/100, Loss: 738.1430, Validation Accuracy: 0.3619\n",
            "Epoch 43/100, Loss: 94.2569, Validation Accuracy: 0.5653\n",
            "Epoch 44/100, Loss: 6.9194, Validation Accuracy: 0.5464\n",
            "Epoch 45/100, Loss: 6.8626, Validation Accuracy: 0.5025\n",
            "Epoch 46/100, Loss: 12.9922, Validation Accuracy: 0.5553\n",
            "Epoch 47/100, Loss: 14.2896, Validation Accuracy: 0.6650\n",
            "Epoch 48/100, Loss: 7.3280, Validation Accuracy: 0.6361\n",
            "Epoch 49/100, Loss: 7.8395, Validation Accuracy: 0.6261\n",
            "Epoch 50/100, Loss: 8.6151, Validation Accuracy: 0.6171\n",
            "Epoch 51/100, Loss: 8.3284, Validation Accuracy: 0.6062\n",
            "Epoch 52/100, Loss: 16.9332, Validation Accuracy: 0.5344\n",
            "Epoch 53/100, Loss: 23.8905, Validation Accuracy: 0.6879\n",
            "Epoch 54/100, Loss: 43.3357, Validation Accuracy: 0.6680\n",
            "Epoch 55/100, Loss: 24.5826, Validation Accuracy: 0.4417\n",
            "Epoch 56/100, Loss: 1770.8077, Validation Accuracy: 0.6002\n",
            "Epoch 57/100, Loss: 198.0575, Validation Accuracy: 0.5174\n",
            "Epoch 58/100, Loss: 42.3925, Validation Accuracy: 0.6191\n",
            "Epoch 59/100, Loss: 7.2148, Validation Accuracy: 0.6132\n",
            "Epoch 60/100, Loss: 15.0551, Validation Accuracy: 0.6162\n",
            "Epoch 61/100, Loss: 180.8457, Validation Accuracy: 0.5872\n",
            "Epoch 62/100, Loss: 22.9702, Validation Accuracy: 0.5015\n",
            "Epoch 63/100, Loss: 59.0351, Validation Accuracy: 0.6401\n",
            "Epoch 64/100, Loss: 60.6443, Validation Accuracy: 0.6092\n",
            "Epoch 65/100, Loss: 12.6447, Validation Accuracy: 0.6610\n",
            "Epoch 66/100, Loss: 7.8217, Validation Accuracy: 0.6760\n",
            "Epoch 67/100, Loss: 24.0041, Validation Accuracy: 0.5852\n",
            "Epoch 68/100, Loss: 6.1842, Validation Accuracy: 0.6520\n",
            "Epoch 69/100, Loss: 12.8869, Validation Accuracy: 0.6062\n",
            "Epoch 70/100, Loss: 17.9217, Validation Accuracy: 0.5733\n",
            "Epoch 71/100, Loss: 22.9524, Validation Accuracy: 0.5224\n",
            "Epoch 72/100, Loss: 28.2073, Validation Accuracy: 0.3111\n",
            "Epoch 73/100, Loss: 51.6351, Validation Accuracy: 0.2652\n",
            "Epoch 74/100, Loss: 73.6221, Validation Accuracy: 0.6510\n",
            "Epoch 75/100, Loss: 18.3963, Validation Accuracy: 0.6221\n",
            "Epoch 76/100, Loss: 17.3524, Validation Accuracy: 0.6012\n",
            "Epoch 77/100, Loss: 48.5281, Validation Accuracy: 0.6441\n",
            "Epoch 78/100, Loss: 23.7852, Validation Accuracy: 0.4786\n",
            "Epoch 79/100, Loss: 15.3162, Validation Accuracy: 0.6590\n",
            "Epoch 80/100, Loss: 155.3538, Validation Accuracy: 0.6361\n",
            "Epoch 81/100, Loss: 36.4777, Validation Accuracy: 0.4477\n",
            "Epoch 82/100, Loss: 29.8157, Validation Accuracy: 0.6630\n",
            "Epoch 83/100, Loss: 14.0292, Validation Accuracy: 0.6820\n",
            "Epoch 84/100, Loss: 11.1344, Validation Accuracy: 0.6251\n",
            "Epoch 85/100, Loss: 15.4308, Validation Accuracy: 0.6760\n",
            "Epoch 86/100, Loss: 10.1689, Validation Accuracy: 0.4437\n",
            "Epoch 87/100, Loss: 32.2940, Validation Accuracy: 0.6800\n",
            "Epoch 88/100, Loss: 119.8467, Validation Accuracy: 0.6670\n",
            "Epoch 89/100, Loss: 31.0606, Validation Accuracy: 0.3809\n",
            "Epoch 90/100, Loss: 9.6085, Validation Accuracy: 0.6630\n",
            "Epoch 91/100, Loss: 18.1283, Validation Accuracy: 0.5753\n",
            "Epoch 92/100, Loss: 19.4987, Validation Accuracy: 0.6311\n",
            "Epoch 93/100, Loss: 11.6621, Validation Accuracy: 0.6072\n",
            "Epoch 94/100, Loss: 39.5184, Validation Accuracy: 0.6491\n",
            "Epoch 95/100, Loss: 32.6540, Validation Accuracy: 0.5045\n",
            "Epoch 96/100, Loss: 22.0013, Validation Accuracy: 0.6431\n",
            "Epoch 97/100, Loss: 16.1558, Validation Accuracy: 0.5892\n",
            "Epoch 98/100, Loss: 28.8632, Validation Accuracy: 0.4447\n",
            "Epoch 99/100, Loss: 24.9961, Validation Accuracy: 0.6331\n",
            "Epoch 100/100, Loss: 6.4325, Validation Accuracy: 0.4945\n",
            "Epoch 101/100, Loss: 21.5400, Validation Accuracy: 0.6710\n",
            "Epoch 102/100, Loss: 98.3084, Validation Accuracy: 0.6231\n",
            "Epoch 103/100, Loss: 11.6214, Validation Accuracy: 0.6311\n",
            "Epoch 104/100, Loss: 32.5810, Validation Accuracy: 0.5573\n",
            "Epoch 105/100, Loss: 61.6698, Validation Accuracy: 0.4158\n",
            "Epoch 106/100, Loss: 20.9146, Validation Accuracy: 0.6012\n",
            "Epoch 107/100, Loss: 28.1358, Validation Accuracy: 0.6451\n",
            "Epoch 108/100, Loss: 30.7438, Validation Accuracy: 0.6620\n",
            "Epoch 109/100, Loss: 25.1845, Validation Accuracy: 0.4068\n",
            "Epoch 110/100, Loss: 17.6635, Validation Accuracy: 0.5563\n",
            "Epoch 111/100, Loss: 81.5774, Validation Accuracy: 0.6600\n",
            "Epoch 112/100, Loss: 89.7324, Validation Accuracy: 0.6351\n",
            "Epoch 113/100, Loss: 14.3937, Validation Accuracy: 0.5503\n",
            "Epoch 114/100, Loss: 34.2295, Validation Accuracy: 0.6321\n",
            "Epoch 115/100, Loss: 11.7816, Validation Accuracy: 0.6451\n",
            "Epoch 116/100, Loss: 15.6225, Validation Accuracy: 0.4586\n",
            "Epoch 117/100, Loss: 38.5795, Validation Accuracy: 0.5783\n",
            "Epoch 118/100, Loss: 16.0856, Validation Accuracy: 0.5932\n",
            "Epoch 119/100, Loss: 63.4582, Validation Accuracy: 0.5494\n",
            "Epoch 120/100, Loss: 19.6105, Validation Accuracy: 0.6780\n",
            "Epoch 121/100, Loss: 115.8947, Validation Accuracy: 0.6451\n",
            "Epoch 122/100, Loss: 81.5818, Validation Accuracy: 0.5543\n",
            "Epoch 123/100, Loss: 17.5301, Validation Accuracy: 0.5982\n",
            "Epoch 124/100, Loss: 32.2975, Validation Accuracy: 0.4865\n",
            "Epoch 125/100, Loss: 19.5051, Validation Accuracy: 0.6261\n",
            "Epoch 126/100, Loss: 19.5416, Validation Accuracy: 0.5882\n",
            "Epoch 127/100, Loss: 41.6829, Validation Accuracy: 0.5075\n",
            "Epoch 128/100, Loss: 46.8511, Validation Accuracy: 0.6500\n",
            "Epoch 129/100, Loss: 31.8702, Validation Accuracy: 0.6152\n",
            "Epoch 130/100, Loss: 41.1091, Validation Accuracy: 0.6660\n",
            "Epoch 131/100, Loss: 82.5344, Validation Accuracy: 0.4975\n",
            "Epoch 132/100, Loss: 22.8799, Validation Accuracy: 0.2183\n",
            "Epoch 133/100, Loss: 39.4760, Validation Accuracy: 0.6710\n",
            "Epoch 134/100, Loss: 51.7155, Validation Accuracy: 0.6421\n",
            "Epoch 135/100, Loss: 40.9213, Validation Accuracy: 0.4915\n",
            "Epoch 136/100, Loss: 21.7519, Validation Accuracy: 0.6171\n",
            "Epoch 137/100, Loss: 93.7078, Validation Accuracy: 0.5882\n",
            "Epoch 138/100, Loss: 22.6794, Validation Accuracy: 0.5334\n",
            "Epoch 139/100, Loss: 20.1747, Validation Accuracy: 0.6171\n",
            "Epoch 140/100, Loss: 18.6307, Validation Accuracy: 0.1755\n",
            "Epoch 141/100, Loss: 27.8169, Validation Accuracy: 0.6341\n",
            "Epoch 142/100, Loss: 19.9456, Validation Accuracy: 0.5484\n",
            "Epoch 143/100, Loss: 26.8857, Validation Accuracy: 0.6461\n",
            "Epoch 144/100, Loss: 41.5885, Validation Accuracy: 0.5862\n",
            "Epoch 145/100, Loss: 45.5462, Validation Accuracy: 0.5543\n",
            "Epoch 146/100, Loss: 19.0106, Validation Accuracy: 0.5733\n",
            "Epoch 147/100, Loss: 22.3729, Validation Accuracy: 0.4696\n",
            "Epoch 148/100, Loss: 24.0234, Validation Accuracy: 0.6520\n",
            "Epoch 149/100, Loss: 12.4334, Validation Accuracy: 0.5085\n",
            "Epoch 150/100, Loss: 56.2588, Validation Accuracy: 0.6072\n",
            "Epoch 151/100, Loss: 31.2541, Validation Accuracy: 0.5992\n",
            "Epoch 152/100, Loss: 54.2829, Validation Accuracy: 0.5523\n",
            "Epoch 153/100, Loss: 71.0427, Validation Accuracy: 0.5763\n",
            "Epoch 154/100, Loss: 23.8388, Validation Accuracy: 0.6481\n",
            "Epoch 155/100, Loss: 33.7556, Validation Accuracy: 0.6560\n",
            "Epoch 156/100, Loss: 31.7390, Validation Accuracy: 0.4726\n",
            "Epoch 157/100, Loss: 72.6283, Validation Accuracy: 0.6371\n",
            "Epoch 158/100, Loss: 13.6243, Validation Accuracy: 0.6620\n",
            "Epoch 159/100, Loss: 32.4883, Validation Accuracy: 0.4995\n",
            "Epoch 160/100, Loss: 29.2465, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 8.6904, Validation Accuracy: 0.6231\n",
            "Epoch 162/100, Loss: 39.9217, Validation Accuracy: 0.6052\n",
            "Epoch 163/100, Loss: 61.7214, Validation Accuracy: 0.5075\n",
            "Epoch 164/100, Loss: 14.7549, Validation Accuracy: 0.5623\n",
            "Epoch 165/100, Loss: 51.3939, Validation Accuracy: 0.6451\n",
            "Epoch 166/100, Loss: 48.7474, Validation Accuracy: 0.6201\n",
            "Epoch 167/100, Loss: 29.4932, Validation Accuracy: 0.5842\n",
            "Epoch 168/100, Loss: 15.1606, Validation Accuracy: 0.6919\n",
            "Epoch 169/100, Loss: 105.2370, Validation Accuracy: 0.6281\n",
            "Epoch 170/100, Loss: 65.0152, Validation Accuracy: 0.5653\n",
            "Epoch 171/100, Loss: 42.5410, Validation Accuracy: 0.6281\n",
            "Epoch 172/100, Loss: 53.0697, Validation Accuracy: 0.6181\n",
            "Epoch 173/100, Loss: 31.3938, Validation Accuracy: 0.5204\n",
            "Epoch 174/100, Loss: 15.6732, Validation Accuracy: 0.4746\n",
            "Epoch 175/100, Loss: 41.4535, Validation Accuracy: 0.6291\n",
            "Epoch 176/100, Loss: 72.3514, Validation Accuracy: 0.4985\n",
            "Epoch 177/100, Loss: 31.8691, Validation Accuracy: 0.5663\n",
            "Epoch 178/100, Loss: 35.8176, Validation Accuracy: 0.5194\n",
            "Epoch 179/100, Loss: 40.8474, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 72.0205, Validation Accuracy: 0.6610\n",
            "Epoch 181/100, Loss: 32.7253, Validation Accuracy: 0.6620\n",
            "Epoch 182/100, Loss: 34.8708, Validation Accuracy: 0.6331\n",
            "Epoch 183/100, Loss: 52.8600, Validation Accuracy: 0.6610\n",
            "Epoch 184/100, Loss: 61.7081, Validation Accuracy: 0.6421\n",
            "Epoch 185/100, Loss: 28.6956, Validation Accuracy: 0.3858\n",
            "Epoch 186/100, Loss: 45.7600, Validation Accuracy: 0.6710\n",
            "Epoch 187/100, Loss: 45.3014, Validation Accuracy: 0.6570\n",
            "Epoch 188/100, Loss: 43.7184, Validation Accuracy: 0.6471\n",
            "Epoch 189/100, Loss: 27.1802, Validation Accuracy: 0.5454\n",
            "Epoch 190/100, Loss: 42.7261, Validation Accuracy: 0.5962\n",
            "Epoch 191/100, Loss: 22.4456, Validation Accuracy: 0.6271\n",
            "Epoch 192/100, Loss: 25.2306, Validation Accuracy: 0.6421\n",
            "Epoch 193/100, Loss: 9.1159, Validation Accuracy: 0.5324\n",
            "Epoch 194/100, Loss: 34.5823, Validation Accuracy: 0.6291\n",
            "Epoch 195/100, Loss: 32.5495, Validation Accuracy: 0.5653\n",
            "Epoch 196/100, Loss: 27.3547, Validation Accuracy: 0.6411\n",
            "Epoch 197/100, Loss: 63.1361, Validation Accuracy: 0.5643\n",
            "Epoch 198/100, Loss: 44.4219, Validation Accuracy: 0.6650\n",
            "Epoch 199/100, Loss: 48.3093, Validation Accuracy: 0.6760\n",
            "Epoch 200/100, Loss: 36.6454, Validation Accuracy: 0.5095\n",
            "Reward for Child Model: 0.3088775064099447\n",
            "Child_62:  {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, [1, 1, 1, 0, 3, 0, 2, 1, 3, 1, 3, 1, 2, 0, 1], 0.3088775064099447\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(100, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(200, 64, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(164, 36, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=91936, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 26, 26]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 26, 26]             128\n",
            "            Conv2d-3           [-1, 36, 22, 22]          57,636\n",
            "       BatchNorm2d-4           [-1, 36, 22, 22]              72\n",
            "              ReLU-5           [-1, 36, 22, 22]               0\n",
            "            Conv2d-6           [-1, 36, 22, 22]          90,036\n",
            "       BatchNorm2d-7           [-1, 36, 22, 22]              72\n",
            "              ReLU-8           [-1, 36, 22, 22]               0\n",
            "            Conv2d-9           [-1, 64, 20, 26]          89,664\n",
            "      BatchNorm2d-10           [-1, 64, 20, 26]             128\n",
            "             ReLU-11           [-1, 64, 20, 26]               0\n",
            "           Conv2d-12           [-1, 36, 22, 24]          88,596\n",
            "      BatchNorm2d-13           [-1, 36, 22, 24]              72\n",
            "             ReLU-14           [-1, 36, 22, 24]               0\n",
            "           Linear-15                    [-1, 7]         643,559\n",
            "================================================================\n",
            "Total params: 971,755\n",
            "Trainable params: 971,755\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.65\n",
            "Params size (MB): 3.71\n",
            "Estimated Total Size (MB): 6.37\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 41.7973, Validation Accuracy: 0.6481\n",
            "Epoch 2/100, Loss: 22.9983, Validation Accuracy: 0.5145\n",
            "Epoch 3/100, Loss: 24.3526, Validation Accuracy: 0.5673\n",
            "Epoch 4/100, Loss: 51.8063, Validation Accuracy: 0.5703\n",
            "Epoch 5/100, Loss: 8.0500, Validation Accuracy: 0.6351\n",
            "Epoch 6/100, Loss: 14.9719, Validation Accuracy: 0.5464\n",
            "Epoch 7/100, Loss: 10.5501, Validation Accuracy: 0.5733\n",
            "Epoch 8/100, Loss: 39.9711, Validation Accuracy: 0.4277\n",
            "Epoch 9/100, Loss: 50.9866, Validation Accuracy: 0.6261\n",
            "Epoch 10/100, Loss: 71.8127, Validation Accuracy: 0.4158\n",
            "Epoch 11/100, Loss: 29.3807, Validation Accuracy: 0.6092\n",
            "Epoch 12/100, Loss: 31.7430, Validation Accuracy: 0.5055\n",
            "Epoch 13/100, Loss: 69.9140, Validation Accuracy: 0.4576\n",
            "Epoch 14/100, Loss: 57.0844, Validation Accuracy: 0.6201\n",
            "Epoch 15/100, Loss: 47.1078, Validation Accuracy: 0.5593\n",
            "Epoch 16/100, Loss: 46.6257, Validation Accuracy: 0.2702\n",
            "Epoch 17/100, Loss: 43.9197, Validation Accuracy: 0.6162\n",
            "Epoch 18/100, Loss: 38.1705, Validation Accuracy: 0.4975\n",
            "Epoch 19/100, Loss: 46.7732, Validation Accuracy: 0.6520\n",
            "Epoch 20/100, Loss: 575.4103, Validation Accuracy: 0.6381\n",
            "Epoch 21/100, Loss: 53.8376, Validation Accuracy: 0.5803\n",
            "Epoch 22/100, Loss: 29.4234, Validation Accuracy: 0.4726\n",
            "Epoch 23/100, Loss: 33.7669, Validation Accuracy: 0.5633\n",
            "Epoch 24/100, Loss: 50.7613, Validation Accuracy: 0.5862\n",
            "Epoch 25/100, Loss: 30.6663, Validation Accuracy: 0.3240\n",
            "Epoch 26/100, Loss: 51.0325, Validation Accuracy: 0.4437\n",
            "Epoch 27/100, Loss: 20.6656, Validation Accuracy: 0.6471\n",
            "Epoch 28/100, Loss: 37.8502, Validation Accuracy: 0.4546\n",
            "Epoch 29/100, Loss: 27.2719, Validation Accuracy: 0.6281\n",
            "Epoch 30/100, Loss: 51.5038, Validation Accuracy: 0.6331\n",
            "Epoch 31/100, Loss: 58.8148, Validation Accuracy: 0.6142\n",
            "Epoch 32/100, Loss: 68.4794, Validation Accuracy: 0.6381\n",
            "Epoch 33/100, Loss: 109.4876, Validation Accuracy: 0.6191\n",
            "Epoch 34/100, Loss: 56.5145, Validation Accuracy: 0.3529\n",
            "Epoch 35/100, Loss: 47.4059, Validation Accuracy: 0.5573\n",
            "Epoch 36/100, Loss: 32.9029, Validation Accuracy: 0.3579\n",
            "Epoch 37/100, Loss: 34.0634, Validation Accuracy: 0.6281\n",
            "Epoch 38/100, Loss: 30.0578, Validation Accuracy: 0.6421\n",
            "Epoch 39/100, Loss: 28.4602, Validation Accuracy: 0.2702\n",
            "Epoch 40/100, Loss: 99.2399, Validation Accuracy: 0.6510\n",
            "Epoch 41/100, Loss: 85.8345, Validation Accuracy: 0.5324\n",
            "Epoch 42/100, Loss: 29.6021, Validation Accuracy: 0.5693\n",
            "Epoch 43/100, Loss: 54.8071, Validation Accuracy: 0.6231\n",
            "Epoch 44/100, Loss: 39.1226, Validation Accuracy: 0.5364\n",
            "Epoch 45/100, Loss: 159.1594, Validation Accuracy: 0.5474\n",
            "Epoch 46/100, Loss: 128.4833, Validation Accuracy: 0.6491\n",
            "Epoch 47/100, Loss: 77.4755, Validation Accuracy: 0.6481\n",
            "Epoch 48/100, Loss: 139.5148, Validation Accuracy: 0.5513\n",
            "Epoch 49/100, Loss: 70.8588, Validation Accuracy: 0.6211\n",
            "Epoch 50/100, Loss: 35.7058, Validation Accuracy: 0.6042\n",
            "Epoch 51/100, Loss: 100.7351, Validation Accuracy: 0.6022\n",
            "Epoch 52/100, Loss: 54.3304, Validation Accuracy: 0.5653\n",
            "Epoch 53/100, Loss: 34.9064, Validation Accuracy: 0.5942\n",
            "Epoch 54/100, Loss: 38.5504, Validation Accuracy: 0.5643\n",
            "Epoch 55/100, Loss: 45.4440, Validation Accuracy: 0.6162\n",
            "Epoch 56/100, Loss: 42.6672, Validation Accuracy: 0.5254\n",
            "Epoch 57/100, Loss: 55.8282, Validation Accuracy: 0.5733\n",
            "Epoch 58/100, Loss: 30.6503, Validation Accuracy: 0.5384\n",
            "Epoch 59/100, Loss: 39.9646, Validation Accuracy: 0.6640\n",
            "Epoch 60/100, Loss: 71.5828, Validation Accuracy: 0.5982\n",
            "Epoch 61/100, Loss: 39.4219, Validation Accuracy: 0.5882\n",
            "Epoch 62/100, Loss: 105.0055, Validation Accuracy: 0.5962\n",
            "Epoch 63/100, Loss: 73.4918, Validation Accuracy: 0.5723\n",
            "Epoch 64/100, Loss: 51.5330, Validation Accuracy: 0.6441\n",
            "Epoch 65/100, Loss: 39.9503, Validation Accuracy: 0.6820\n",
            "Epoch 66/100, Loss: 53.8259, Validation Accuracy: 0.6570\n",
            "Epoch 67/100, Loss: 70.8480, Validation Accuracy: 0.4895\n",
            "Epoch 68/100, Loss: 145.7583, Validation Accuracy: 0.5484\n",
            "Epoch 69/100, Loss: 123.5880, Validation Accuracy: 0.6830\n",
            "Epoch 70/100, Loss: 41.0724, Validation Accuracy: 0.6152\n",
            "Epoch 71/100, Loss: 44.2112, Validation Accuracy: 0.6520\n",
            "Epoch 72/100, Loss: 50.2510, Validation Accuracy: 0.6391\n",
            "Epoch 73/100, Loss: 47.8330, Validation Accuracy: 0.5912\n",
            "Epoch 74/100, Loss: 34.9263, Validation Accuracy: 0.5214\n",
            "Epoch 75/100, Loss: 51.6746, Validation Accuracy: 0.6760\n",
            "Epoch 76/100, Loss: 137.3981, Validation Accuracy: 0.5314\n",
            "Epoch 77/100, Loss: 70.8096, Validation Accuracy: 0.5613\n",
            "Epoch 78/100, Loss: 86.3269, Validation Accuracy: 0.4656\n",
            "Epoch 79/100, Loss: 29.3836, Validation Accuracy: 0.6351\n",
            "Epoch 80/100, Loss: 48.9207, Validation Accuracy: 0.6291\n",
            "Epoch 81/100, Loss: 36.8257, Validation Accuracy: 0.6550\n",
            "Epoch 82/100, Loss: 149.9381, Validation Accuracy: 0.5633\n",
            "Epoch 83/100, Loss: 18.8477, Validation Accuracy: 0.6241\n",
            "Epoch 84/100, Loss: 47.6081, Validation Accuracy: 0.5204\n",
            "Epoch 85/100, Loss: 85.4317, Validation Accuracy: 0.5773\n",
            "Epoch 86/100, Loss: 66.3487, Validation Accuracy: 0.5852\n",
            "Epoch 87/100, Loss: 23.3133, Validation Accuracy: 0.3868\n",
            "Epoch 88/100, Loss: 80.1763, Validation Accuracy: 0.5055\n",
            "Epoch 89/100, Loss: 34.5676, Validation Accuracy: 0.6500\n",
            "Epoch 90/100, Loss: 56.0141, Validation Accuracy: 0.5872\n",
            "Epoch 91/100, Loss: 60.1373, Validation Accuracy: 0.5474\n",
            "Epoch 92/100, Loss: 33.7478, Validation Accuracy: 0.6291\n",
            "Epoch 93/100, Loss: 63.5234, Validation Accuracy: 0.6142\n",
            "Epoch 94/100, Loss: 91.9516, Validation Accuracy: 0.5234\n",
            "Epoch 95/100, Loss: 65.8760, Validation Accuracy: 0.4716\n",
            "Epoch 96/100, Loss: 45.6526, Validation Accuracy: 0.6401\n",
            "Epoch 97/100, Loss: 78.8970, Validation Accuracy: 0.6471\n",
            "Epoch 98/100, Loss: 51.4118, Validation Accuracy: 0.4526\n",
            "Epoch 99/100, Loss: 60.4479, Validation Accuracy: 0.5105\n",
            "Epoch 100/100, Loss: 122.7317, Validation Accuracy: 0.5902\n",
            "Epoch 101/100, Loss: 54.8551, Validation Accuracy: 0.6421\n",
            "Epoch 102/100, Loss: 39.1808, Validation Accuracy: 0.5813\n",
            "Epoch 103/100, Loss: 107.8650, Validation Accuracy: 0.5773\n",
            "Epoch 104/100, Loss: 50.7653, Validation Accuracy: 0.6590\n",
            "Epoch 105/100, Loss: 35.2555, Validation Accuracy: 0.5533\n",
            "Epoch 106/100, Loss: 33.5099, Validation Accuracy: 0.5862\n",
            "Epoch 107/100, Loss: 62.5035, Validation Accuracy: 0.6142\n",
            "Epoch 108/100, Loss: 52.4374, Validation Accuracy: 0.5902\n",
            "Epoch 109/100, Loss: 28.0266, Validation Accuracy: 0.4726\n",
            "Epoch 110/100, Loss: 42.8536, Validation Accuracy: 0.6720\n",
            "Epoch 111/100, Loss: 160.2571, Validation Accuracy: 0.6361\n",
            "Epoch 112/100, Loss: 52.9237, Validation Accuracy: 0.6032\n",
            "Epoch 113/100, Loss: 111.9898, Validation Accuracy: 0.6251\n",
            "Epoch 114/100, Loss: 48.1001, Validation Accuracy: 0.6421\n",
            "Epoch 115/100, Loss: 47.9413, Validation Accuracy: 0.5872\n",
            "Epoch 116/100, Loss: 41.4546, Validation Accuracy: 0.5234\n",
            "Epoch 117/100, Loss: 103.9857, Validation Accuracy: 0.6201\n",
            "Epoch 118/100, Loss: 80.0288, Validation Accuracy: 0.6790\n",
            "Epoch 119/100, Loss: 67.3841, Validation Accuracy: 0.5593\n",
            "Epoch 120/100, Loss: 62.1015, Validation Accuracy: 0.6152\n",
            "Epoch 121/100, Loss: 34.7553, Validation Accuracy: 0.6102\n",
            "Epoch 122/100, Loss: 34.6431, Validation Accuracy: 0.6321\n",
            "Epoch 123/100, Loss: 60.6433, Validation Accuracy: 0.6431\n",
            "Epoch 124/100, Loss: 73.0872, Validation Accuracy: 0.6500\n",
            "Epoch 125/100, Loss: 127.2781, Validation Accuracy: 0.5952\n",
            "Epoch 126/100, Loss: 91.9961, Validation Accuracy: 0.6181\n",
            "Epoch 127/100, Loss: 104.3824, Validation Accuracy: 0.6032\n",
            "Epoch 128/100, Loss: 54.5823, Validation Accuracy: 0.4826\n",
            "Epoch 129/100, Loss: 53.7024, Validation Accuracy: 0.6451\n",
            "Epoch 130/100, Loss: 31.5655, Validation Accuracy: 0.6261\n",
            "Epoch 131/100, Loss: 23.2232, Validation Accuracy: 0.6331\n",
            "Epoch 132/100, Loss: 164.7785, Validation Accuracy: 0.6610\n",
            "Epoch 133/100, Loss: 28.1542, Validation Accuracy: 0.6152\n",
            "Epoch 134/100, Loss: 44.0032, Validation Accuracy: 0.6660\n",
            "Epoch 135/100, Loss: 62.0369, Validation Accuracy: 0.6361\n",
            "Epoch 136/100, Loss: 72.9558, Validation Accuracy: 0.5474\n",
            "Epoch 137/100, Loss: 154.9896, Validation Accuracy: 0.6550\n",
            "Epoch 138/100, Loss: 26.7321, Validation Accuracy: 0.4287\n",
            "Epoch 139/100, Loss: 63.6837, Validation Accuracy: 0.5204\n",
            "Epoch 140/100, Loss: 62.0715, Validation Accuracy: 0.6381\n",
            "Epoch 141/100, Loss: 76.3582, Validation Accuracy: 0.6371\n",
            "Epoch 142/100, Loss: 139.1055, Validation Accuracy: 0.6331\n",
            "Epoch 143/100, Loss: 94.8643, Validation Accuracy: 0.6231\n",
            "Epoch 144/100, Loss: 116.0496, Validation Accuracy: 0.4965\n",
            "Epoch 145/100, Loss: 42.5427, Validation Accuracy: 0.5922\n",
            "Epoch 146/100, Loss: 39.3967, Validation Accuracy: 0.6510\n",
            "Epoch 147/100, Loss: 56.7512, Validation Accuracy: 0.6411\n",
            "Epoch 148/100, Loss: 92.8877, Validation Accuracy: 0.5454\n",
            "Epoch 149/100, Loss: 79.8730, Validation Accuracy: 0.6670\n",
            "Epoch 150/100, Loss: 108.4901, Validation Accuracy: 0.6132\n",
            "Epoch 151/100, Loss: 46.7046, Validation Accuracy: 0.6471\n",
            "Epoch 152/100, Loss: 49.7991, Validation Accuracy: 0.6700\n",
            "Epoch 153/100, Loss: 37.3353, Validation Accuracy: 0.6211\n",
            "Epoch 154/100, Loss: 53.7489, Validation Accuracy: 0.6022\n",
            "Epoch 155/100, Loss: 100.8410, Validation Accuracy: 0.6241\n",
            "Epoch 156/100, Loss: 63.8183, Validation Accuracy: 0.6042\n",
            "Epoch 157/100, Loss: 86.6344, Validation Accuracy: 0.5932\n",
            "Epoch 158/100, Loss: 51.0348, Validation Accuracy: 0.6491\n",
            "Epoch 159/100, Loss: 83.9617, Validation Accuracy: 0.5414\n",
            "Epoch 160/100, Loss: 128.2527, Validation Accuracy: 0.4895\n",
            "Epoch 161/100, Loss: 32.3576, Validation Accuracy: 0.5932\n",
            "Epoch 162/100, Loss: 33.6900, Validation Accuracy: 0.6122\n",
            "Epoch 163/100, Loss: 45.1433, Validation Accuracy: 0.5763\n",
            "Epoch 164/100, Loss: 25.1627, Validation Accuracy: 0.5603\n",
            "Epoch 165/100, Loss: 32.9574, Validation Accuracy: 0.6171\n",
            "Epoch 166/100, Loss: 8.4063, Validation Accuracy: 0.6351\n",
            "Epoch 167/100, Loss: 33.3517, Validation Accuracy: 0.5005\n",
            "Epoch 168/100, Loss: 96.8407, Validation Accuracy: 0.5713\n",
            "Epoch 169/100, Loss: 60.9652, Validation Accuracy: 0.6251\n",
            "Epoch 170/100, Loss: 80.0245, Validation Accuracy: 0.6570\n",
            "Epoch 171/100, Loss: 110.8443, Validation Accuracy: 0.6261\n",
            "Epoch 172/100, Loss: 59.5143, Validation Accuracy: 0.6002\n",
            "Epoch 173/100, Loss: 28.7688, Validation Accuracy: 0.6231\n",
            "Epoch 174/100, Loss: 15.4545, Validation Accuracy: 0.6012\n",
            "Epoch 175/100, Loss: 143.4587, Validation Accuracy: 0.6311\n",
            "Epoch 176/100, Loss: 25.4143, Validation Accuracy: 0.5902\n",
            "Epoch 177/100, Loss: 45.8936, Validation Accuracy: 0.5444\n",
            "Epoch 178/100, Loss: 36.0335, Validation Accuracy: 0.6012\n",
            "Epoch 179/100, Loss: 137.2393, Validation Accuracy: 0.5155\n",
            "Epoch 180/100, Loss: 54.1772, Validation Accuracy: 0.5454\n",
            "Epoch 181/100, Loss: 16.8741, Validation Accuracy: 0.6162\n",
            "Epoch 182/100, Loss: 48.4670, Validation Accuracy: 0.5523\n",
            "Epoch 183/100, Loss: 19.7638, Validation Accuracy: 0.6152\n",
            "Epoch 184/100, Loss: 68.7202, Validation Accuracy: 0.3460\n",
            "Epoch 185/100, Loss: 234.9506, Validation Accuracy: 0.4596\n",
            "Epoch 186/100, Loss: 31.8166, Validation Accuracy: 0.6500\n",
            "Epoch 187/100, Loss: 52.5503, Validation Accuracy: 0.6231\n",
            "Epoch 188/100, Loss: 65.6383, Validation Accuracy: 0.6520\n",
            "Epoch 189/100, Loss: 94.9128, Validation Accuracy: 0.6371\n",
            "Epoch 190/100, Loss: 85.3316, Validation Accuracy: 0.6800\n",
            "Epoch 191/100, Loss: 53.3820, Validation Accuracy: 0.6251\n",
            "Epoch 192/100, Loss: 78.9197, Validation Accuracy: 0.6381\n",
            "Epoch 193/100, Loss: 93.3569, Validation Accuracy: 0.6640\n",
            "Epoch 194/100, Loss: 133.8766, Validation Accuracy: 0.6201\n",
            "Epoch 195/100, Loss: 71.0403, Validation Accuracy: 0.5833\n",
            "Epoch 196/100, Loss: 58.8942, Validation Accuracy: 0.5872\n",
            "Epoch 197/100, Loss: 38.0016, Validation Accuracy: 0.6859\n",
            "Epoch 198/100, Loss: 88.3630, Validation Accuracy: 0.6122\n",
            "Epoch 199/100, Loss: 49.0927, Validation Accuracy: 0.5474\n",
            "Epoch 200/100, Loss: 131.3276, Validation Accuracy: 0.5833\n",
            "Reward for Child Model: 0.3227472240939291\n",
            "Child_63:  {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, [1, 1, 3, 2, 2, 1, 2, 2, 1, 3, 0, 3, 2, 1, 1], 0.3227472240939291\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 36, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 24, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(84, 48, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(84, 36, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=97344, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 26, 24]           1,104\n",
            "       BatchNorm2d-2           [-1, 24, 26, 24]              48\n",
            "            Conv2d-3           [-1, 36, 22, 18]          30,276\n",
            "       BatchNorm2d-4           [-1, 36, 22, 18]              72\n",
            "              ReLU-5           [-1, 36, 22, 18]               0\n",
            "            Conv2d-6           [-1, 24, 16, 12]          42,360\n",
            "       BatchNorm2d-7           [-1, 24, 16, 12]              48\n",
            "              ReLU-8           [-1, 24, 16, 12]               0\n",
            "            Conv2d-9           [-1, 48, 26, 22]          12,144\n",
            "      BatchNorm2d-10           [-1, 48, 26, 22]              96\n",
            "             ReLU-11           [-1, 48, 26, 22]               0\n",
            "           Conv2d-12           [-1, 36, 24, 22]           9,108\n",
            "      BatchNorm2d-13           [-1, 36, 24, 22]              72\n",
            "             ReLU-14           [-1, 36, 24, 22]               0\n",
            "           Linear-15                    [-1, 7]         681,415\n",
            "================================================================\n",
            "Total params: 776,743\n",
            "Trainable params: 776,743\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.72\n",
            "Params size (MB): 2.96\n",
            "Estimated Total Size (MB): 4.70\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 13.1873, Validation Accuracy: 0.6191\n",
            "Epoch 2/100, Loss: 3.7367, Validation Accuracy: 0.5623\n",
            "Epoch 3/100, Loss: 0.9304, Validation Accuracy: 0.6381\n",
            "Epoch 4/100, Loss: 2.3206, Validation Accuracy: 0.6241\n",
            "Epoch 5/100, Loss: 71.2203, Validation Accuracy: 0.4875\n",
            "Epoch 6/100, Loss: 18.3460, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 8.3328, Validation Accuracy: 0.6002\n",
            "Epoch 8/100, Loss: 7.0296, Validation Accuracy: 0.5025\n",
            "Epoch 9/100, Loss: 1.2237, Validation Accuracy: 0.6441\n",
            "Epoch 10/100, Loss: 3.2124, Validation Accuracy: 0.5623\n",
            "Epoch 11/100, Loss: 45.7248, Validation Accuracy: 0.5344\n",
            "Epoch 12/100, Loss: 36.6076, Validation Accuracy: 0.6291\n",
            "Epoch 13/100, Loss: 349.8372, Validation Accuracy: 0.6500\n",
            "Epoch 14/100, Loss: 28.7503, Validation Accuracy: 0.6102\n",
            "Epoch 15/100, Loss: 16.1750, Validation Accuracy: 0.5803\n",
            "Epoch 16/100, Loss: 4.1471, Validation Accuracy: 0.6142\n",
            "Epoch 17/100, Loss: 1.8634, Validation Accuracy: 0.6181\n",
            "Epoch 18/100, Loss: 71.2144, Validation Accuracy: 0.6421\n",
            "Epoch 19/100, Loss: 2.7871, Validation Accuracy: 0.6540\n",
            "Epoch 20/100, Loss: 15.7134, Validation Accuracy: 0.5284\n",
            "Epoch 21/100, Loss: 16.5743, Validation Accuracy: 0.6331\n",
            "Epoch 22/100, Loss: 2.8910, Validation Accuracy: 0.4237\n",
            "Epoch 23/100, Loss: 2.9575, Validation Accuracy: 0.6371\n",
            "Epoch 24/100, Loss: 8.7897, Validation Accuracy: 0.6411\n",
            "Epoch 25/100, Loss: 2.7017, Validation Accuracy: 0.5334\n",
            "Epoch 26/100, Loss: 6.8165, Validation Accuracy: 0.6351\n",
            "Epoch 27/100, Loss: 5.5166, Validation Accuracy: 0.5085\n",
            "Epoch 28/100, Loss: 11.0173, Validation Accuracy: 0.5852\n",
            "Epoch 29/100, Loss: 4.2524, Validation Accuracy: 0.5942\n",
            "Epoch 30/100, Loss: 1.3077, Validation Accuracy: 0.6461\n",
            "Epoch 31/100, Loss: 1.3011, Validation Accuracy: 0.6491\n",
            "Epoch 32/100, Loss: 4.3975, Validation Accuracy: 0.3559\n",
            "Epoch 33/100, Loss: 186.0798, Validation Accuracy: 0.6520\n",
            "Epoch 34/100, Loss: 6.7526, Validation Accuracy: 0.5942\n",
            "Epoch 35/100, Loss: 4.8884, Validation Accuracy: 0.6231\n",
            "Epoch 36/100, Loss: 4.7599, Validation Accuracy: 0.2582\n",
            "Epoch 37/100, Loss: 36.5571, Validation Accuracy: 0.6102\n",
            "Epoch 38/100, Loss: 4.3406, Validation Accuracy: 0.5842\n",
            "Epoch 39/100, Loss: 6.2579, Validation Accuracy: 0.5902\n",
            "Epoch 40/100, Loss: 2.8416, Validation Accuracy: 0.6321\n",
            "Epoch 41/100, Loss: 3.8077, Validation Accuracy: 0.5324\n",
            "Epoch 42/100, Loss: 29.1039, Validation Accuracy: 0.6082\n",
            "Epoch 43/100, Loss: 81.3662, Validation Accuracy: 0.5892\n",
            "Epoch 44/100, Loss: 5.4509, Validation Accuracy: 0.6500\n",
            "Epoch 45/100, Loss: 4.0954, Validation Accuracy: 0.6411\n",
            "Epoch 46/100, Loss: 3.3936, Validation Accuracy: 0.6481\n",
            "Epoch 47/100, Loss: 2.0554, Validation Accuracy: 0.5952\n",
            "Epoch 48/100, Loss: 10.4936, Validation Accuracy: 0.4237\n",
            "Epoch 49/100, Loss: 2.9556, Validation Accuracy: 0.4447\n",
            "Epoch 50/100, Loss: 8.1222, Validation Accuracy: 0.4965\n",
            "Epoch 51/100, Loss: 65.0183, Validation Accuracy: 0.5972\n",
            "Epoch 52/100, Loss: 15.1195, Validation Accuracy: 0.5663\n",
            "Epoch 53/100, Loss: 7.4797, Validation Accuracy: 0.6600\n",
            "Epoch 54/100, Loss: 7.0530, Validation Accuracy: 0.5813\n",
            "Epoch 55/100, Loss: 225.8144, Validation Accuracy: 0.2652\n",
            "Epoch 56/100, Loss: 12.7470, Validation Accuracy: 0.6351\n",
            "Epoch 57/100, Loss: 3.4645, Validation Accuracy: 0.5912\n",
            "Epoch 58/100, Loss: 52.0391, Validation Accuracy: 0.5633\n",
            "Epoch 59/100, Loss: 10.3938, Validation Accuracy: 0.6680\n",
            "Epoch 60/100, Loss: 12.3598, Validation Accuracy: 0.5155\n",
            "Epoch 61/100, Loss: 7.5522, Validation Accuracy: 0.6560\n",
            "Epoch 62/100, Loss: 9.1793, Validation Accuracy: 0.5384\n",
            "Epoch 63/100, Loss: 63.1473, Validation Accuracy: 0.6162\n",
            "Epoch 64/100, Loss: 43.2100, Validation Accuracy: 0.5613\n",
            "Epoch 65/100, Loss: 8.7713, Validation Accuracy: 0.6431\n",
            "Epoch 66/100, Loss: 5.6213, Validation Accuracy: 0.6301\n",
            "Epoch 67/100, Loss: 3.2800, Validation Accuracy: 0.3968\n",
            "Epoch 68/100, Loss: 4.2819, Validation Accuracy: 0.5962\n",
            "Epoch 69/100, Loss: 9.9303, Validation Accuracy: 0.5543\n",
            "Epoch 70/100, Loss: 40.9890, Validation Accuracy: 0.6162\n",
            "Epoch 71/100, Loss: 12.7250, Validation Accuracy: 0.4447\n",
            "Epoch 72/100, Loss: 10.8500, Validation Accuracy: 0.5035\n",
            "Epoch 73/100, Loss: 12.2375, Validation Accuracy: 0.6491\n",
            "Epoch 74/100, Loss: 21.6425, Validation Accuracy: 0.6600\n",
            "Epoch 75/100, Loss: 31.8871, Validation Accuracy: 0.6082\n",
            "Epoch 76/100, Loss: 19.1038, Validation Accuracy: 0.6231\n",
            "Epoch 77/100, Loss: 7.3910, Validation Accuracy: 0.5125\n",
            "Epoch 78/100, Loss: 20.8742, Validation Accuracy: 0.5922\n",
            "Epoch 79/100, Loss: 25.0917, Validation Accuracy: 0.3460\n",
            "Epoch 80/100, Loss: 17.4908, Validation Accuracy: 0.6650\n",
            "Epoch 81/100, Loss: 8.1989, Validation Accuracy: 0.6211\n",
            "Epoch 82/100, Loss: 4.8802, Validation Accuracy: 0.6630\n",
            "Epoch 83/100, Loss: 6.7161, Validation Accuracy: 0.6740\n",
            "Epoch 84/100, Loss: 54.0328, Validation Accuracy: 0.6570\n",
            "Epoch 85/100, Loss: 21.5482, Validation Accuracy: 0.5902\n",
            "Epoch 86/100, Loss: 7.2236, Validation Accuracy: 0.6122\n",
            "Epoch 87/100, Loss: 15.3843, Validation Accuracy: 0.5942\n",
            "Epoch 88/100, Loss: 5.1469, Validation Accuracy: 0.6361\n",
            "Epoch 89/100, Loss: 12.2166, Validation Accuracy: 0.5523\n",
            "Epoch 90/100, Loss: 16.5108, Validation Accuracy: 0.5503\n",
            "Epoch 91/100, Loss: 19.0446, Validation Accuracy: 0.5135\n",
            "Epoch 92/100, Loss: 9.5156, Validation Accuracy: 0.6391\n",
            "Epoch 93/100, Loss: 5.1638, Validation Accuracy: 0.3549\n",
            "Epoch 94/100, Loss: 9.7331, Validation Accuracy: 0.6790\n",
            "Epoch 95/100, Loss: 24.1529, Validation Accuracy: 0.6082\n",
            "Epoch 96/100, Loss: 10.4209, Validation Accuracy: 0.6411\n",
            "Epoch 97/100, Loss: 8.4900, Validation Accuracy: 0.5553\n",
            "Epoch 98/100, Loss: 7.9587, Validation Accuracy: 0.6710\n",
            "Epoch 99/100, Loss: 24.0857, Validation Accuracy: 0.6142\n",
            "Epoch 100/100, Loss: 19.0834, Validation Accuracy: 0.6750\n",
            "Epoch 101/100, Loss: 10.7183, Validation Accuracy: 0.5852\n",
            "Epoch 102/100, Loss: 19.9687, Validation Accuracy: 0.5663\n",
            "Epoch 103/100, Loss: 10.0742, Validation Accuracy: 0.5523\n",
            "Epoch 104/100, Loss: 15.8077, Validation Accuracy: 0.5982\n",
            "Epoch 105/100, Loss: 15.7115, Validation Accuracy: 0.6510\n",
            "Epoch 106/100, Loss: 10.5918, Validation Accuracy: 0.5653\n",
            "Epoch 107/100, Loss: 17.1437, Validation Accuracy: 0.6530\n",
            "Epoch 108/100, Loss: 13.2326, Validation Accuracy: 0.3928\n",
            "Epoch 109/100, Loss: 25.2323, Validation Accuracy: 0.5374\n",
            "Epoch 110/100, Loss: 18.7382, Validation Accuracy: 0.5434\n",
            "Epoch 111/100, Loss: 47.0707, Validation Accuracy: 0.5513\n",
            "Epoch 112/100, Loss: 22.2789, Validation Accuracy: 0.6251\n",
            "Epoch 113/100, Loss: 7.4598, Validation Accuracy: 0.6909\n",
            "Epoch 114/100, Loss: 15.8062, Validation Accuracy: 0.6451\n",
            "Epoch 115/100, Loss: 20.7686, Validation Accuracy: 0.5723\n",
            "Epoch 116/100, Loss: 32.8816, Validation Accuracy: 0.4566\n",
            "Epoch 117/100, Loss: 9.3864, Validation Accuracy: 0.5723\n",
            "Epoch 118/100, Loss: 10.1557, Validation Accuracy: 0.6550\n",
            "Epoch 119/100, Loss: 30.6021, Validation Accuracy: 0.6620\n",
            "Epoch 120/100, Loss: 52.4086, Validation Accuracy: 0.6381\n",
            "Epoch 121/100, Loss: 16.0617, Validation Accuracy: 0.5703\n",
            "Epoch 122/100, Loss: 37.4973, Validation Accuracy: 0.5643\n",
            "Epoch 123/100, Loss: 21.7490, Validation Accuracy: 0.4437\n",
            "Epoch 124/100, Loss: 6.0199, Validation Accuracy: 0.5992\n",
            "Epoch 125/100, Loss: 41.1278, Validation Accuracy: 0.6700\n",
            "Epoch 126/100, Loss: 16.2836, Validation Accuracy: 0.6082\n",
            "Epoch 127/100, Loss: 13.2784, Validation Accuracy: 0.5274\n",
            "Epoch 128/100, Loss: 12.9531, Validation Accuracy: 0.6191\n",
            "Epoch 129/100, Loss: 17.5864, Validation Accuracy: 0.4167\n",
            "Epoch 130/100, Loss: 56.0770, Validation Accuracy: 0.5942\n",
            "Epoch 131/100, Loss: 20.2704, Validation Accuracy: 0.6720\n",
            "Epoch 132/100, Loss: 31.0446, Validation Accuracy: 0.5264\n",
            "Epoch 133/100, Loss: 9.6400, Validation Accuracy: 0.6012\n",
            "Epoch 134/100, Loss: 7.0750, Validation Accuracy: 0.5872\n",
            "Epoch 135/100, Loss: 25.9965, Validation Accuracy: 0.5494\n",
            "Epoch 136/100, Loss: 28.3023, Validation Accuracy: 0.6660\n",
            "Epoch 137/100, Loss: 9.9433, Validation Accuracy: 0.6371\n",
            "Epoch 138/100, Loss: 20.1523, Validation Accuracy: 0.6331\n",
            "Epoch 139/100, Loss: 55.2796, Validation Accuracy: 0.5663\n",
            "Epoch 140/100, Loss: 34.0774, Validation Accuracy: 0.5643\n",
            "Epoch 141/100, Loss: 19.4682, Validation Accuracy: 0.6132\n",
            "Epoch 142/100, Loss: 9.3062, Validation Accuracy: 0.6321\n",
            "Epoch 143/100, Loss: 22.1273, Validation Accuracy: 0.6680\n",
            "Epoch 144/100, Loss: 17.2050, Validation Accuracy: 0.5174\n",
            "Epoch 145/100, Loss: 62.4488, Validation Accuracy: 0.6281\n",
            "Epoch 146/100, Loss: 14.1336, Validation Accuracy: 0.6929\n",
            "Epoch 147/100, Loss: 19.9914, Validation Accuracy: 0.6102\n",
            "Epoch 148/100, Loss: 7.5373, Validation Accuracy: 0.6201\n",
            "Epoch 149/100, Loss: 22.6352, Validation Accuracy: 0.4487\n",
            "Epoch 150/100, Loss: 15.1098, Validation Accuracy: 0.5404\n",
            "Epoch 151/100, Loss: 8.6874, Validation Accuracy: 0.5773\n",
            "Epoch 152/100, Loss: 6.5671, Validation Accuracy: 0.5573\n",
            "Epoch 153/100, Loss: 15.0385, Validation Accuracy: 0.5813\n",
            "Epoch 154/100, Loss: 20.9638, Validation Accuracy: 0.5952\n",
            "Epoch 155/100, Loss: 24.7807, Validation Accuracy: 0.6620\n",
            "Epoch 156/100, Loss: 16.6457, Validation Accuracy: 0.4835\n",
            "Epoch 157/100, Loss: 21.1521, Validation Accuracy: 0.6321\n",
            "Epoch 158/100, Loss: 5.9497, Validation Accuracy: 0.5653\n",
            "Epoch 159/100, Loss: 15.1701, Validation Accuracy: 0.6082\n",
            "Epoch 160/100, Loss: 34.7393, Validation Accuracy: 0.5613\n",
            "Epoch 161/100, Loss: 13.6885, Validation Accuracy: 0.5653\n",
            "Epoch 162/100, Loss: 20.1516, Validation Accuracy: 0.5543\n",
            "Epoch 163/100, Loss: 16.1500, Validation Accuracy: 0.5583\n",
            "Epoch 164/100, Loss: 12.9431, Validation Accuracy: 0.6251\n",
            "Epoch 165/100, Loss: 25.2980, Validation Accuracy: 0.6301\n",
            "Epoch 166/100, Loss: 14.1659, Validation Accuracy: 0.5224\n",
            "Epoch 167/100, Loss: 5.6500, Validation Accuracy: 0.4776\n",
            "Epoch 168/100, Loss: 18.3991, Validation Accuracy: 0.6112\n",
            "Epoch 169/100, Loss: 46.8021, Validation Accuracy: 0.6770\n",
            "Epoch 170/100, Loss: 6.8667, Validation Accuracy: 0.5314\n",
            "Epoch 171/100, Loss: 11.4507, Validation Accuracy: 0.5912\n",
            "Epoch 172/100, Loss: 18.3187, Validation Accuracy: 0.6710\n",
            "Epoch 173/100, Loss: 14.9391, Validation Accuracy: 0.5573\n",
            "Epoch 174/100, Loss: 16.5937, Validation Accuracy: 0.5553\n",
            "Epoch 175/100, Loss: 14.5235, Validation Accuracy: 0.6301\n",
            "Epoch 176/100, Loss: 44.5658, Validation Accuracy: 0.6471\n",
            "Epoch 177/100, Loss: 13.1703, Validation Accuracy: 0.6461\n",
            "Epoch 178/100, Loss: 7.3687, Validation Accuracy: 0.6570\n",
            "Epoch 179/100, Loss: 16.8651, Validation Accuracy: 0.6550\n",
            "Epoch 180/100, Loss: 9.9942, Validation Accuracy: 0.5374\n",
            "Epoch 181/100, Loss: 34.9863, Validation Accuracy: 0.6670\n",
            "Epoch 182/100, Loss: 12.5871, Validation Accuracy: 0.5464\n",
            "Epoch 183/100, Loss: 16.5899, Validation Accuracy: 0.5424\n",
            "Epoch 184/100, Loss: 21.7718, Validation Accuracy: 0.5434\n",
            "Epoch 185/100, Loss: 10.3988, Validation Accuracy: 0.6441\n",
            "Epoch 186/100, Loss: 20.8239, Validation Accuracy: 0.5623\n",
            "Epoch 187/100, Loss: 4.9539, Validation Accuracy: 0.5753\n",
            "Epoch 188/100, Loss: 17.2649, Validation Accuracy: 0.5613\n",
            "Epoch 189/100, Loss: 13.0726, Validation Accuracy: 0.6540\n",
            "Epoch 190/100, Loss: 27.1139, Validation Accuracy: 0.3729\n",
            "Epoch 191/100, Loss: 31.0785, Validation Accuracy: 0.6500\n",
            "Epoch 192/100, Loss: 14.4146, Validation Accuracy: 0.6371\n",
            "Epoch 193/100, Loss: 8.7472, Validation Accuracy: 0.6451\n",
            "Epoch 194/100, Loss: 13.9620, Validation Accuracy: 0.6550\n",
            "Epoch 195/100, Loss: 8.2158, Validation Accuracy: 0.5254\n",
            "Epoch 196/100, Loss: 130.5900, Validation Accuracy: 0.6012\n",
            "Epoch 197/100, Loss: 13.3770, Validation Accuracy: 0.6211\n",
            "Epoch 198/100, Loss: 4.0145, Validation Accuracy: 0.6670\n",
            "Epoch 199/100, Loss: 8.2575, Validation Accuracy: 0.5803\n",
            "Epoch 200/100, Loss: 1130.6512, Validation Accuracy: 0.0150\n",
            "Reward for Child Model: 0.2967396323270139\n",
            "Child_64:  {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, [1, 2, 0, 2, 3, 1, 3, 3, 0, 0, 1, 2, 1, 0, 1], 0.2967396323270139\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(64, 24, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(112, 36, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=65472, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 24, 22]           2,544\n",
            "       BatchNorm2d-2           [-1, 24, 24, 22]              48\n",
            "            Conv2d-3           [-1, 24, 24, 22]             600\n",
            "       BatchNorm2d-4           [-1, 24, 24, 22]              48\n",
            "              ReLU-5           [-1, 24, 24, 22]               0\n",
            "            Conv2d-6           [-1, 64, 20, 22]           7,744\n",
            "       BatchNorm2d-7           [-1, 64, 20, 22]             128\n",
            "              ReLU-8           [-1, 64, 20, 22]               0\n",
            "            Conv2d-9           [-1, 24, 18, 18]          23,064\n",
            "      BatchNorm2d-10           [-1, 24, 18, 18]              48\n",
            "             ReLU-11           [-1, 24, 18, 18]               0\n",
            "           Conv2d-12           [-1, 36, 18, 18]         141,156\n",
            "      BatchNorm2d-13           [-1, 36, 18, 18]              72\n",
            "             ReLU-14           [-1, 36, 18, 18]               0\n",
            "           Linear-15                    [-1, 7]         458,311\n",
            "================================================================\n",
            "Total params: 633,763\n",
            "Trainable params: 633,763\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.57\n",
            "Params size (MB): 2.42\n",
            "Estimated Total Size (MB): 4.00\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 7.4595, Validation Accuracy: 0.5105\n",
            "Epoch 2/100, Loss: 8.2272, Validation Accuracy: 0.5553\n",
            "Epoch 3/100, Loss: 26.2127, Validation Accuracy: 0.5982\n",
            "Epoch 4/100, Loss: 3.6248, Validation Accuracy: 0.5494\n",
            "Epoch 5/100, Loss: 1.5494, Validation Accuracy: 0.5484\n",
            "Epoch 6/100, Loss: 2.7122, Validation Accuracy: 0.5354\n",
            "Epoch 7/100, Loss: 10.0287, Validation Accuracy: 0.5314\n",
            "Epoch 8/100, Loss: 59.2357, Validation Accuracy: 0.2991\n",
            "Epoch 9/100, Loss: 3.9458, Validation Accuracy: 0.3948\n",
            "Epoch 10/100, Loss: 1.8891, Validation Accuracy: 0.6391\n",
            "Epoch 11/100, Loss: 3.6901, Validation Accuracy: 0.5982\n",
            "Epoch 12/100, Loss: 1.0156, Validation Accuracy: 0.6331\n",
            "Epoch 13/100, Loss: 3.3269, Validation Accuracy: 0.6550\n",
            "Epoch 14/100, Loss: 125.4932, Validation Accuracy: 0.6361\n",
            "Epoch 15/100, Loss: 18.3452, Validation Accuracy: 0.6640\n",
            "Epoch 16/100, Loss: 3.0536, Validation Accuracy: 0.4297\n",
            "Epoch 17/100, Loss: 3.5196, Validation Accuracy: 0.5234\n",
            "Epoch 18/100, Loss: 3.4648, Validation Accuracy: 0.6401\n",
            "Epoch 19/100, Loss: 1.8371, Validation Accuracy: 0.6171\n",
            "Epoch 20/100, Loss: 3.0347, Validation Accuracy: 0.6181\n",
            "Epoch 21/100, Loss: 4.0811, Validation Accuracy: 0.4995\n",
            "Epoch 22/100, Loss: 211.8358, Validation Accuracy: 0.6590\n",
            "Epoch 23/100, Loss: 9.5746, Validation Accuracy: 0.4796\n",
            "Epoch 24/100, Loss: 15.4282, Validation Accuracy: 0.5683\n",
            "Epoch 25/100, Loss: 4.2695, Validation Accuracy: 0.3699\n",
            "Epoch 26/100, Loss: 4.3430, Validation Accuracy: 0.3838\n",
            "Epoch 27/100, Loss: 2.4051, Validation Accuracy: 0.6640\n",
            "Epoch 28/100, Loss: 3.2638, Validation Accuracy: 0.5783\n",
            "Epoch 29/100, Loss: 5.8884, Validation Accuracy: 0.5673\n",
            "Epoch 30/100, Loss: 71.5046, Validation Accuracy: 0.6600\n",
            "Epoch 31/100, Loss: 4.7360, Validation Accuracy: 0.6650\n",
            "Epoch 32/100, Loss: 22.6523, Validation Accuracy: 0.6331\n",
            "Epoch 33/100, Loss: 9.0937, Validation Accuracy: 0.5952\n",
            "Epoch 34/100, Loss: 4.0156, Validation Accuracy: 0.6680\n",
            "Epoch 35/100, Loss: 2.4076, Validation Accuracy: 0.6590\n",
            "Epoch 36/100, Loss: 28.6124, Validation Accuracy: 0.4108\n",
            "Epoch 37/100, Loss: 47.2673, Validation Accuracy: 0.5803\n",
            "Epoch 38/100, Loss: 18.7030, Validation Accuracy: 0.5902\n",
            "Epoch 39/100, Loss: 3.8548, Validation Accuracy: 0.5892\n",
            "Epoch 40/100, Loss: 4.1089, Validation Accuracy: 0.6590\n",
            "Epoch 41/100, Loss: 6.3161, Validation Accuracy: 0.6022\n",
            "Epoch 42/100, Loss: 3.6479, Validation Accuracy: 0.4776\n",
            "Epoch 43/100, Loss: 7.7562, Validation Accuracy: 0.5603\n",
            "Epoch 44/100, Loss: 49.9914, Validation Accuracy: 0.6660\n",
            "Epoch 45/100, Loss: 12.2514, Validation Accuracy: 0.6550\n",
            "Epoch 46/100, Loss: 9.1518, Validation Accuracy: 0.6381\n",
            "Epoch 47/100, Loss: 2.7923, Validation Accuracy: 0.6381\n",
            "Epoch 48/100, Loss: 13.5608, Validation Accuracy: 0.5454\n",
            "Epoch 49/100, Loss: 17.8019, Validation Accuracy: 0.6361\n",
            "Epoch 50/100, Loss: 7.1191, Validation Accuracy: 0.6321\n",
            "Epoch 51/100, Loss: 13.3478, Validation Accuracy: 0.4816\n",
            "Epoch 52/100, Loss: 5.7469, Validation Accuracy: 0.4646\n",
            "Epoch 53/100, Loss: 12.4708, Validation Accuracy: 0.5095\n",
            "Epoch 54/100, Loss: 23.3768, Validation Accuracy: 0.6371\n",
            "Epoch 55/100, Loss: 27.0199, Validation Accuracy: 0.5803\n",
            "Epoch 56/100, Loss: 11.0536, Validation Accuracy: 0.4736\n",
            "Epoch 57/100, Loss: 3.5289, Validation Accuracy: 0.5992\n",
            "Epoch 58/100, Loss: 19.3267, Validation Accuracy: 0.6431\n",
            "Epoch 59/100, Loss: 27.9615, Validation Accuracy: 0.6132\n",
            "Epoch 60/100, Loss: 36.7707, Validation Accuracy: 0.6510\n",
            "Epoch 61/100, Loss: 14.0513, Validation Accuracy: 0.5523\n",
            "Epoch 62/100, Loss: 8.5707, Validation Accuracy: 0.5593\n",
            "Epoch 63/100, Loss: 3.5238, Validation Accuracy: 0.5763\n",
            "Epoch 64/100, Loss: 3.3260, Validation Accuracy: 0.6221\n",
            "Epoch 65/100, Loss: 13.7214, Validation Accuracy: 0.6162\n",
            "Epoch 66/100, Loss: 11.0333, Validation Accuracy: 0.3978\n",
            "Epoch 67/100, Loss: 5.1199, Validation Accuracy: 0.5942\n",
            "Epoch 68/100, Loss: 8.3766, Validation Accuracy: 0.4885\n",
            "Epoch 69/100, Loss: 10.2900, Validation Accuracy: 0.4068\n",
            "Epoch 70/100, Loss: 22.0961, Validation Accuracy: 0.5354\n",
            "Epoch 71/100, Loss: 47.6827, Validation Accuracy: 0.5793\n",
            "Epoch 72/100, Loss: 2.7944, Validation Accuracy: 0.5753\n",
            "Epoch 73/100, Loss: 3.5323, Validation Accuracy: 0.6640\n",
            "Epoch 74/100, Loss: 28.6504, Validation Accuracy: 0.5952\n",
            "Epoch 75/100, Loss: 19.5528, Validation Accuracy: 0.6830\n",
            "Epoch 76/100, Loss: 7.2434, Validation Accuracy: 0.5095\n",
            "Epoch 77/100, Loss: 6.0619, Validation Accuracy: 0.6082\n",
            "Epoch 78/100, Loss: 16.5478, Validation Accuracy: 0.5394\n",
            "Epoch 79/100, Loss: 4.7982, Validation Accuracy: 0.6092\n",
            "Epoch 80/100, Loss: 13.8011, Validation Accuracy: 0.4716\n",
            "Epoch 81/100, Loss: 9.0999, Validation Accuracy: 0.5613\n",
            "Epoch 82/100, Loss: 9.3856, Validation Accuracy: 0.6102\n",
            "Epoch 83/100, Loss: 8.9053, Validation Accuracy: 0.6092\n",
            "Epoch 84/100, Loss: 37.6333, Validation Accuracy: 0.6142\n",
            "Epoch 85/100, Loss: 37.5934, Validation Accuracy: 0.6530\n",
            "Epoch 86/100, Loss: 12.8359, Validation Accuracy: 0.6341\n",
            "Epoch 87/100, Loss: 6.0322, Validation Accuracy: 0.6112\n",
            "Epoch 88/100, Loss: 9.1710, Validation Accuracy: 0.6570\n",
            "Epoch 89/100, Loss: 3.8758, Validation Accuracy: 0.5803\n",
            "Epoch 90/100, Loss: 1.8490, Validation Accuracy: 0.6750\n",
            "Epoch 91/100, Loss: 13.6371, Validation Accuracy: 0.4307\n",
            "Epoch 92/100, Loss: 20.2331, Validation Accuracy: 0.4975\n",
            "Epoch 93/100, Loss: 38.6587, Validation Accuracy: 0.6321\n",
            "Epoch 94/100, Loss: 84.5802, Validation Accuracy: 0.6072\n",
            "Epoch 95/100, Loss: 17.5938, Validation Accuracy: 0.6311\n",
            "Epoch 96/100, Loss: 8.8575, Validation Accuracy: 0.6112\n",
            "Epoch 97/100, Loss: 4.1914, Validation Accuracy: 0.5364\n",
            "Epoch 98/100, Loss: 11.0044, Validation Accuracy: 0.5862\n",
            "Epoch 99/100, Loss: 14.9991, Validation Accuracy: 0.5992\n",
            "Epoch 100/100, Loss: 11.3328, Validation Accuracy: 0.5244\n",
            "Epoch 101/100, Loss: 44.5367, Validation Accuracy: 0.6520\n",
            "Epoch 102/100, Loss: 22.0514, Validation Accuracy: 0.6750\n",
            "Epoch 103/100, Loss: 7.9632, Validation Accuracy: 0.5763\n",
            "Epoch 104/100, Loss: 6.3268, Validation Accuracy: 0.5194\n",
            "Epoch 105/100, Loss: 7.2945, Validation Accuracy: 0.5244\n",
            "Epoch 106/100, Loss: 34.3758, Validation Accuracy: 0.6640\n",
            "Epoch 107/100, Loss: 18.6868, Validation Accuracy: 0.6211\n",
            "Epoch 108/100, Loss: 6.2366, Validation Accuracy: 0.6351\n",
            "Epoch 109/100, Loss: 8.1783, Validation Accuracy: 0.6361\n",
            "Epoch 110/100, Loss: 2.9828, Validation Accuracy: 0.6540\n",
            "Epoch 111/100, Loss: 5.1179, Validation Accuracy: 0.5693\n",
            "Epoch 112/100, Loss: 6.9335, Validation Accuracy: 0.6321\n",
            "Epoch 113/100, Loss: 9.0884, Validation Accuracy: 0.6132\n",
            "Epoch 114/100, Loss: 26.2886, Validation Accuracy: 0.6401\n",
            "Epoch 115/100, Loss: 30.0119, Validation Accuracy: 0.6042\n",
            "Epoch 116/100, Loss: 17.2347, Validation Accuracy: 0.5932\n",
            "Epoch 117/100, Loss: 9.8674, Validation Accuracy: 0.5842\n",
            "Epoch 118/100, Loss: 10.6919, Validation Accuracy: 0.5773\n",
            "Epoch 119/100, Loss: 3.5551, Validation Accuracy: 0.5573\n",
            "Epoch 120/100, Loss: 58.7444, Validation Accuracy: 0.6700\n",
            "Epoch 121/100, Loss: 18.6951, Validation Accuracy: 0.5573\n",
            "Epoch 122/100, Loss: 42.2094, Validation Accuracy: 0.6142\n",
            "Epoch 123/100, Loss: 7.5546, Validation Accuracy: 0.6102\n",
            "Epoch 124/100, Loss: 7.4450, Validation Accuracy: 0.4925\n",
            "Epoch 125/100, Loss: 51.6033, Validation Accuracy: 0.3769\n",
            "Epoch 126/100, Loss: 56.0287, Validation Accuracy: 0.5982\n",
            "Epoch 127/100, Loss: 5.8001, Validation Accuracy: 0.6152\n",
            "Epoch 128/100, Loss: 2.3189, Validation Accuracy: 0.5862\n",
            "Epoch 129/100, Loss: 6.1629, Validation Accuracy: 0.6431\n",
            "Epoch 130/100, Loss: 6.6374, Validation Accuracy: 0.5035\n",
            "Epoch 131/100, Loss: 7.5341, Validation Accuracy: 0.4277\n",
            "Epoch 132/100, Loss: 4.0418, Validation Accuracy: 0.6321\n",
            "Epoch 133/100, Loss: 9.9740, Validation Accuracy: 0.6740\n",
            "Epoch 134/100, Loss: 182.9988, Validation Accuracy: 0.5394\n",
            "Epoch 135/100, Loss: 11.6393, Validation Accuracy: 0.5852\n",
            "Epoch 136/100, Loss: 6.9897, Validation Accuracy: 0.6132\n",
            "Epoch 137/100, Loss: 2.6070, Validation Accuracy: 0.6221\n",
            "Epoch 138/100, Loss: 9.4862, Validation Accuracy: 0.4716\n",
            "Epoch 139/100, Loss: 8.9304, Validation Accuracy: 0.6411\n",
            "Epoch 140/100, Loss: 14.8886, Validation Accuracy: 0.6391\n",
            "Epoch 141/100, Loss: 15.1821, Validation Accuracy: 0.6530\n",
            "Epoch 142/100, Loss: 17.2230, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 23.7670, Validation Accuracy: 0.4915\n",
            "Epoch 144/100, Loss: 23.3641, Validation Accuracy: 0.5673\n",
            "Epoch 145/100, Loss: 15.4144, Validation Accuracy: 0.5474\n",
            "Epoch 146/100, Loss: 9.7335, Validation Accuracy: 0.6600\n",
            "Epoch 147/100, Loss: 30.7301, Validation Accuracy: 0.2124\n",
            "Epoch 148/100, Loss: 62.5624, Validation Accuracy: 0.6401\n",
            "Epoch 149/100, Loss: 7.7357, Validation Accuracy: 0.6251\n",
            "Epoch 150/100, Loss: 3.2350, Validation Accuracy: 0.4965\n",
            "Epoch 151/100, Loss: 5.8852, Validation Accuracy: 0.6311\n",
            "Epoch 152/100, Loss: 11.7935, Validation Accuracy: 0.5992\n",
            "Epoch 153/100, Loss: 14.0858, Validation Accuracy: 0.5613\n",
            "Epoch 154/100, Loss: 86.5578, Validation Accuracy: 0.4177\n",
            "Epoch 155/100, Loss: 4.2378, Validation Accuracy: 0.4118\n",
            "Epoch 156/100, Loss: 7.4774, Validation Accuracy: 0.6401\n",
            "Epoch 157/100, Loss: 4.1530, Validation Accuracy: 0.6251\n",
            "Epoch 158/100, Loss: 8.2074, Validation Accuracy: 0.6191\n",
            "Epoch 159/100, Loss: 3.6572, Validation Accuracy: 0.5852\n",
            "Epoch 160/100, Loss: 121.5031, Validation Accuracy: 0.5125\n",
            "Epoch 161/100, Loss: 8.7745, Validation Accuracy: 0.6032\n",
            "Epoch 162/100, Loss: 8.4228, Validation Accuracy: 0.6271\n",
            "Epoch 163/100, Loss: 5.8558, Validation Accuracy: 0.5962\n",
            "Epoch 164/100, Loss: 8.8419, Validation Accuracy: 0.5105\n",
            "Epoch 165/100, Loss: 12.9464, Validation Accuracy: 0.6062\n",
            "Epoch 166/100, Loss: 4.4761, Validation Accuracy: 0.6152\n",
            "Epoch 167/100, Loss: 30.1598, Validation Accuracy: 0.6351\n",
            "Epoch 168/100, Loss: 18.2916, Validation Accuracy: 0.5573\n",
            "Epoch 169/100, Loss: 28.3439, Validation Accuracy: 0.5394\n",
            "Epoch 170/100, Loss: 7.5256, Validation Accuracy: 0.5573\n",
            "Epoch 171/100, Loss: 14.7055, Validation Accuracy: 0.6720\n",
            "Epoch 172/100, Loss: 9.3679, Validation Accuracy: 0.6072\n",
            "Epoch 173/100, Loss: 10.3491, Validation Accuracy: 0.6221\n",
            "Epoch 174/100, Loss: 6.6092, Validation Accuracy: 0.4586\n",
            "Epoch 175/100, Loss: 15.4677, Validation Accuracy: 0.6241\n",
            "Epoch 176/100, Loss: 5.2786, Validation Accuracy: 0.3270\n",
            "Epoch 177/100, Loss: 6.7773, Validation Accuracy: 0.5723\n",
            "Epoch 178/100, Loss: 14.1058, Validation Accuracy: 0.5075\n",
            "Epoch 179/100, Loss: 18.1192, Validation Accuracy: 0.5663\n",
            "Epoch 180/100, Loss: 6.1436, Validation Accuracy: 0.6132\n",
            "Epoch 181/100, Loss: 1.3083, Validation Accuracy: 0.4716\n",
            "Epoch 182/100, Loss: 22.7454, Validation Accuracy: 0.5723\n",
            "Epoch 183/100, Loss: 31.7708, Validation Accuracy: 0.6171\n",
            "Epoch 184/100, Loss: 10.5129, Validation Accuracy: 0.6869\n",
            "Epoch 185/100, Loss: 8.8657, Validation Accuracy: 0.6032\n",
            "Epoch 186/100, Loss: 13.5933, Validation Accuracy: 0.6291\n",
            "Epoch 187/100, Loss: 35.7339, Validation Accuracy: 0.6540\n",
            "Epoch 188/100, Loss: 30.5469, Validation Accuracy: 0.4626\n",
            "Epoch 189/100, Loss: 4.2685, Validation Accuracy: 0.5613\n",
            "Epoch 190/100, Loss: 5.7324, Validation Accuracy: 0.6510\n",
            "Epoch 191/100, Loss: 29.3253, Validation Accuracy: 0.6181\n",
            "Epoch 192/100, Loss: 16.6585, Validation Accuracy: 0.6301\n",
            "Epoch 193/100, Loss: 13.2012, Validation Accuracy: 0.6500\n",
            "Epoch 194/100, Loss: 5.1755, Validation Accuracy: 0.5733\n",
            "Epoch 195/100, Loss: 3.5363, Validation Accuracy: 0.5902\n",
            "Epoch 196/100, Loss: 6.1661, Validation Accuracy: 0.5803\n",
            "Epoch 197/100, Loss: 67.9339, Validation Accuracy: 0.5304\n",
            "Epoch 198/100, Loss: 14.0565, Validation Accuracy: 0.4646\n",
            "Epoch 199/100, Loss: 9.8052, Validation Accuracy: 0.6361\n",
            "Epoch 200/100, Loss: 7.8004, Validation Accuracy: 0.5912\n",
            "Reward for Child Model: 0.2573707790286969\n",
            "Child_65:  {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, [2, 3, 0, 0, 0, 0, 2, 0, 3, 1, 2, 0, 3, 2, 1], 0.2573707790286969\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(60, 24, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(120, 24, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(180, 36, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=14256, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 26, 24]           1,656\n",
            "       BatchNorm2d-2           [-1, 36, 26, 24]              72\n",
            "            Conv2d-3           [-1, 24, 26, 18]           6,072\n",
            "       BatchNorm2d-4           [-1, 24, 26, 18]              48\n",
            "              ReLU-5           [-1, 24, 26, 18]               0\n",
            "            Conv2d-6           [-1, 24, 22, 20]          36,024\n",
            "       BatchNorm2d-7           [-1, 24, 22, 20]              48\n",
            "              ReLU-8           [-1, 24, 22, 20]               0\n",
            "            Conv2d-9           [-1, 24, 24, 20]          43,224\n",
            "      BatchNorm2d-10           [-1, 24, 24, 20]              48\n",
            "             ReLU-11           [-1, 24, 24, 20]               0\n",
            "           Conv2d-12           [-1, 36, 22, 18]         226,836\n",
            "      BatchNorm2d-13           [-1, 36, 22, 18]              72\n",
            "             ReLU-14           [-1, 36, 22, 18]               0\n",
            "           Linear-15                    [-1, 7]          99,799\n",
            "================================================================\n",
            "Total params: 413,899\n",
            "Trainable params: 413,899\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.43\n",
            "Params size (MB): 1.58\n",
            "Estimated Total Size (MB): 3.02\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 1.4268, Validation Accuracy: 0.6680\n",
            "Epoch 2/100, Loss: 1.0292, Validation Accuracy: 0.6690\n",
            "Epoch 3/100, Loss: 0.9660, Validation Accuracy: 0.6690\n",
            "Epoch 4/100, Loss: 0.6731, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 1.1783, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 1.0331, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 0.9511, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 0.8386, Validation Accuracy: 0.6690\n",
            "Epoch 9/100, Loss: 1.1299, Validation Accuracy: 0.6690\n",
            "Epoch 10/100, Loss: 0.9462, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 1.1498, Validation Accuracy: 0.6690\n",
            "Epoch 12/100, Loss: 1.0695, Validation Accuracy: 0.6690\n",
            "Epoch 13/100, Loss: 1.1668, Validation Accuracy: 0.6690\n",
            "Epoch 14/100, Loss: 1.0179, Validation Accuracy: 0.6690\n",
            "Epoch 15/100, Loss: 1.0595, Validation Accuracy: 0.6690\n",
            "Epoch 16/100, Loss: 0.9895, Validation Accuracy: 0.6690\n",
            "Epoch 17/100, Loss: 0.7256, Validation Accuracy: 0.6690\n",
            "Epoch 18/100, Loss: 1.1989, Validation Accuracy: 0.6690\n",
            "Epoch 19/100, Loss: 1.1541, Validation Accuracy: 0.6690\n",
            "Epoch 20/100, Loss: 1.1403, Validation Accuracy: 0.6690\n",
            "Epoch 21/100, Loss: 1.2567, Validation Accuracy: 0.6690\n",
            "Epoch 22/100, Loss: 1.2846, Validation Accuracy: 0.6690\n",
            "Epoch 23/100, Loss: 1.0920, Validation Accuracy: 0.6690\n",
            "Epoch 24/100, Loss: 1.0123, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 0.8399, Validation Accuracy: 0.6690\n",
            "Epoch 26/100, Loss: 1.0468, Validation Accuracy: 0.6690\n",
            "Epoch 27/100, Loss: 1.1877, Validation Accuracy: 0.6690\n",
            "Epoch 28/100, Loss: 1.1118, Validation Accuracy: 0.6690\n",
            "Epoch 29/100, Loss: 0.8694, Validation Accuracy: 0.6690\n",
            "Epoch 30/100, Loss: 1.1099, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 0.6686, Validation Accuracy: 0.6690\n",
            "Epoch 32/100, Loss: 1.1410, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 0.9617, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 1.0836, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 0.9246, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 1.1813, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 1.1814, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 1.1227, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 1.0448, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 1.0010, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 1.1164, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 2.0212, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 1.3386, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 1.4637, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 0.9144, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 1.2924, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 1.1599, Validation Accuracy: 0.6690\n",
            "Epoch 48/100, Loss: 1.2474, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 0.8434, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 1.2387, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 1.2994, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 1.1649, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 1.3632, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 0.9400, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 1.0479, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 1.3972, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 1.2840, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 1.0185, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 1.1071, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 0.9261, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 1.0398, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 1.0593, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 1.0924, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 0.9862, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 1.1455, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 1.0990, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 1.2442, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 0.7631, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 1.0532, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 1.1197, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 1.3674, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 0.8809, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 0.9452, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 1.0815, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 1.1629, Validation Accuracy: 0.6690\n",
            "Epoch 76/100, Loss: 1.3967, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 0.8613, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 1.0538, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 0.8658, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 1.2415, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 1.4183, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 1.1561, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 1.0773, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 0.6449, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 0.8377, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 1.1949, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 1.4225, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 0.9225, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 1.3818, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 1.0182, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 0.9899, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 1.1397, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 1.1223, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 1.0645, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 0.9285, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 1.0496, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 0.8826, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 1.0591, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 1.1544, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 1.3720, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 0.8027, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 1.2826, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 1.0930, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 1.2885, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 0.9675, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 1.2443, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 1.1275, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 0.9025, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 0.9277, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 1.0282, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.3187, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 1.1417, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 1.2894, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 1.0059, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 0.9945, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 0.8745, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 0.9828, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 1.1419, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 1.1785, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 1.2444, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 1.1258, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.3927, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 1.0695, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 1.0833, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 1.0145, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 1.5616, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 0.9326, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 1.1845, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 1.1123, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 1.1115, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 0.8989, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 1.3413, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 0.8227, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 1.1613, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 1.1220, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 1.3758, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 0.7997, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 0.8380, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 1.1763, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 1.8216, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 1.2843, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 1.0852, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 0.9717, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 1.0050, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 1.1272, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 0.8856, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 1.1848, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 1.1454, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 1.1913, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 1.1955, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 1.0599, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 1.3132, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 0.8905, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 0.9413, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 1.0041, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 1.1455, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 1.1950, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 1.2022, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 0.9299, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 1.0465, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 0.9365, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 1.1077, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 1.4724, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 0.9663, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 1.0832, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 1.2816, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 1.1728, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 0.9255, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 1.3511, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 1.4370, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 1.4704, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 1.2312, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 1.1149, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 1.0442, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 1.1914, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 1.2709, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 1.0248, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 0.6798, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 1.1779, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 1.4363, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 1.1586, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 0.9876, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 1.4007, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 1.3369, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 1.2841, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 1.0536, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 1.1678, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 0.8084, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 0.5693, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 1.0281, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 1.2839, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 1.2618, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 0.8667, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 1.1414, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 1.2032, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 1.0858, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 1.1375, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 1.0383, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 1.1679, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 1.0369, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_66:  {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, [1, 2, 1, 0, 3, 0, 2, 2, 0, 1, 2, 0, 2, 3, 1], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 36, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(60, 24, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(24, 64, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(88, 48, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=44928, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 28, 26]             240\n",
            "       BatchNorm2d-2           [-1, 24, 28, 26]              48\n",
            "            Conv2d-3           [-1, 36, 22, 22]          30,276\n",
            "       BatchNorm2d-4           [-1, 36, 22, 22]              72\n",
            "              ReLU-5           [-1, 36, 22, 22]               0\n",
            "            Conv2d-6           [-1, 24, 24, 22]          36,024\n",
            "       BatchNorm2d-7           [-1, 24, 24, 22]              48\n",
            "              ReLU-8           [-1, 24, 24, 22]               0\n",
            "            Conv2d-9           [-1, 64, 24, 18]           7,744\n",
            "      BatchNorm2d-10           [-1, 64, 24, 18]             128\n",
            "             ReLU-11           [-1, 64, 24, 18]               0\n",
            "           Conv2d-12           [-1, 48, 26, 24]          38,064\n",
            "      BatchNorm2d-13           [-1, 48, 26, 24]              96\n",
            "             ReLU-14           [-1, 48, 26, 24]               0\n",
            "           Linear-15                    [-1, 7]         314,503\n",
            "================================================================\n",
            "Total params: 427,243\n",
            "Trainable params: 427,243\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.27\n",
            "Params size (MB): 1.63\n",
            "Estimated Total Size (MB): 3.91\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 1.2520, Validation Accuracy: 0.6690\n",
            "Epoch 2/100, Loss: 1.3811, Validation Accuracy: 0.6690\n",
            "Epoch 3/100, Loss: 1.2717, Validation Accuracy: 0.6690\n",
            "Epoch 4/100, Loss: 1.1323, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 1.3246, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 1.5005, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 1.2145, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 1.0536, Validation Accuracy: 0.6690\n",
            "Epoch 9/100, Loss: 1.0754, Validation Accuracy: 0.6690\n",
            "Epoch 10/100, Loss: 1.1794, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 1.2859, Validation Accuracy: 0.6690\n",
            "Epoch 12/100, Loss: 1.3220, Validation Accuracy: 0.6690\n",
            "Epoch 13/100, Loss: 1.5111, Validation Accuracy: 0.6690\n",
            "Epoch 14/100, Loss: 1.2065, Validation Accuracy: 0.6690\n",
            "Epoch 15/100, Loss: 0.7970, Validation Accuracy: 0.6690\n",
            "Epoch 16/100, Loss: 0.8827, Validation Accuracy: 0.6690\n",
            "Epoch 17/100, Loss: 1.0811, Validation Accuracy: 0.6690\n",
            "Epoch 18/100, Loss: 1.3523, Validation Accuracy: 0.6690\n",
            "Epoch 19/100, Loss: 1.1542, Validation Accuracy: 0.6690\n",
            "Epoch 20/100, Loss: 1.4739, Validation Accuracy: 0.6690\n",
            "Epoch 21/100, Loss: 1.0937, Validation Accuracy: 0.6690\n",
            "Epoch 22/100, Loss: 1.2092, Validation Accuracy: 0.6690\n",
            "Epoch 23/100, Loss: 1.1819, Validation Accuracy: 0.6690\n",
            "Epoch 24/100, Loss: 1.3760, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 1.0021, Validation Accuracy: 0.6690\n",
            "Epoch 26/100, Loss: 0.9708, Validation Accuracy: 0.6690\n",
            "Epoch 27/100, Loss: 0.9289, Validation Accuracy: 0.6690\n",
            "Epoch 28/100, Loss: 1.2970, Validation Accuracy: 0.6690\n",
            "Epoch 29/100, Loss: 1.4732, Validation Accuracy: 0.6690\n",
            "Epoch 30/100, Loss: 1.1814, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 1.2161, Validation Accuracy: 0.6690\n",
            "Epoch 32/100, Loss: 1.1700, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 1.3074, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 0.6583, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 1.1494, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 1.0875, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 1.0646, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 1.2532, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 0.9457, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 1.6114, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 1.1009, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 0.9820, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 1.5860, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 1.5799, Validation Accuracy: 0.6640\n",
            "Epoch 45/100, Loss: 1.0271, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 1.0349, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 1.1239, Validation Accuracy: 0.6690\n",
            "Epoch 48/100, Loss: 1.1163, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 0.9094, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 1.1003, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 1.0302, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 0.8915, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 0.7229, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 0.7175, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 1.1371, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 1.2411, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 0.9454, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 1.2284, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 0.8943, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 1.3989, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 1.0232, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 1.1128, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 1.1030, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 1.1741, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 1.8539, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 1.0168, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 1.2844, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 1.1276, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 1.2369, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 0.8928, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 1.0732, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 0.8488, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 1.1603, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 0.9257, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 1.0455, Validation Accuracy: 0.6690\n",
            "Epoch 76/100, Loss: 1.0525, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 1.1439, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 1.2733, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 0.7814, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 1.1635, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 1.0287, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 0.6822, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 0.9922, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 1.1324, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 1.2629, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 1.0587, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 0.9401, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 1.0957, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 0.8917, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 1.2222, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 1.2906, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 1.1979, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 0.6447, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 1.4801, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 1.1086, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 0.8170, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 0.9461, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 1.1539, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 1.2824, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 1.0102, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 1.3532, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 1.6379, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 1.1286, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 1.2269, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 0.9539, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 1.2688, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 1.0377, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 1.1587, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 1.3402, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 1.3117, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.1891, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 1.1211, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 1.4788, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 1.3001, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 0.8600, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 1.1867, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 1.1611, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 0.8203, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 1.2027, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 1.0762, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 1.0456, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.1716, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 1.2395, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 0.9131, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 1.3024, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 0.8189, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 1.2773, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 1.1870, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 1.1706, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 1.1591, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 1.1485, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 1.4306, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 1.2954, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 1.3223, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 1.1639, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 0.9572, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 1.2534, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 1.0930, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 0.9672, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 1.0322, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 1.2502, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 0.9970, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 1.5848, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 1.0870, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 1.1618, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 0.7083, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 0.8763, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 0.8045, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 1.1219, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 1.4180, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 1.3300, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 1.1613, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 1.0739, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 1.0234, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 1.0460, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 1.1158, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 1.0625, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 1.2471, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 1.1617, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 0.8460, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 1.4192, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 1.2460, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 0.8488, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 1.4210, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 1.0997, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 1.0833, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 1.1101, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 1.4311, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 1.2485, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 1.3304, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 1.1132, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 1.3434, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 1.0481, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 1.2622, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 0.9128, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 0.8364, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 1.0304, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 1.4497, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 1.2065, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 1.0714, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 0.8889, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 0.8623, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 1.0680, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 1.0106, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 1.2473, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 0.9736, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 1.2965, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 1.1674, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 1.0143, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 1.1666, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 1.1758, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 1.4896, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 1.0365, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 1.5097, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 1.4133, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 1.6261, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 1.1385, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 1.0521, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 1.4412, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 1.0860, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_67:  {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, [0, 1, 0, 3, 2, 1, 2, 2, 0, 0, 2, 3, 1, 1, 2], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 64, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(64, 36, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(100, 24, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(148, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=142464, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 24, 28]             384\n",
            "       BatchNorm2d-2           [-1, 24, 24, 28]              48\n",
            "            Conv2d-3           [-1, 64, 22, 24]          23,104\n",
            "       BatchNorm2d-4           [-1, 64, 22, 24]             128\n",
            "              ReLU-5           [-1, 64, 22, 24]               0\n",
            "            Conv2d-6           [-1, 36, 22, 22]           6,948\n",
            "       BatchNorm2d-7           [-1, 36, 22, 22]              72\n",
            "              ReLU-8           [-1, 36, 22, 22]               0\n",
            "            Conv2d-9           [-1, 24, 18, 20]          60,024\n",
            "      BatchNorm2d-10           [-1, 24, 18, 20]              48\n",
            "             ReLU-11           [-1, 24, 18, 20]               0\n",
            "           Conv2d-12           [-1, 64, 20, 28]          47,424\n",
            "      BatchNorm2d-13           [-1, 64, 20, 28]             128\n",
            "             ReLU-14           [-1, 64, 20, 28]               0\n",
            "           Linear-15                    [-1, 7]         997,255\n",
            "================================================================\n",
            "Total params: 1,135,563\n",
            "Trainable params: 1,135,563\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.44\n",
            "Params size (MB): 4.33\n",
            "Estimated Total Size (MB): 6.78\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 3.1725, Validation Accuracy: 0.3430\n",
            "Epoch 2/100, Loss: 37.6972, Validation Accuracy: 0.6281\n",
            "Epoch 3/100, Loss: 23.5929, Validation Accuracy: 0.4158\n",
            "Epoch 4/100, Loss: 17.0412, Validation Accuracy: 0.4177\n",
            "Epoch 5/100, Loss: 30.0842, Validation Accuracy: 0.6750\n",
            "Epoch 6/100, Loss: 9.6917, Validation Accuracy: 0.3529\n",
            "Epoch 7/100, Loss: 11.3356, Validation Accuracy: 0.4387\n",
            "Epoch 8/100, Loss: 51.8381, Validation Accuracy: 0.4756\n",
            "Epoch 9/100, Loss: 174.0807, Validation Accuracy: 0.5224\n",
            "Epoch 10/100, Loss: 20.8212, Validation Accuracy: 0.6281\n",
            "Epoch 11/100, Loss: 433.3455, Validation Accuracy: 0.5434\n",
            "Epoch 12/100, Loss: 10.2728, Validation Accuracy: 0.3769\n",
            "Epoch 13/100, Loss: 15.3288, Validation Accuracy: 0.5563\n",
            "Epoch 14/100, Loss: 8.5662, Validation Accuracy: 0.5753\n",
            "Epoch 15/100, Loss: 62.7659, Validation Accuracy: 0.5234\n",
            "Epoch 16/100, Loss: 5.4748, Validation Accuracy: 0.5773\n",
            "Epoch 17/100, Loss: 2.8450, Validation Accuracy: 0.5942\n",
            "Epoch 18/100, Loss: 4.5260, Validation Accuracy: 0.6002\n",
            "Epoch 19/100, Loss: 3.9329, Validation Accuracy: 0.5862\n",
            "Epoch 20/100, Loss: 4.6766, Validation Accuracy: 0.6600\n",
            "Epoch 21/100, Loss: 187.9037, Validation Accuracy: 0.5852\n",
            "Epoch 22/100, Loss: 35.1688, Validation Accuracy: 0.5793\n",
            "Epoch 23/100, Loss: 3.8036, Validation Accuracy: 0.6341\n",
            "Epoch 24/100, Loss: 21.1619, Validation Accuracy: 0.5414\n",
            "Epoch 25/100, Loss: 1253.0380, Validation Accuracy: 0.3779\n",
            "Epoch 26/100, Loss: 66.1862, Validation Accuracy: 0.5663\n",
            "Epoch 27/100, Loss: 112.8567, Validation Accuracy: 0.5374\n",
            "Epoch 28/100, Loss: 23.6855, Validation Accuracy: 0.4806\n",
            "Epoch 29/100, Loss: 5.5948, Validation Accuracy: 0.6431\n",
            "Epoch 30/100, Loss: 4.6270, Validation Accuracy: 0.6590\n",
            "Epoch 31/100, Loss: 2.4729, Validation Accuracy: 0.4646\n",
            "Epoch 32/100, Loss: 4.9630, Validation Accuracy: 0.6281\n",
            "Epoch 33/100, Loss: 1.4843, Validation Accuracy: 0.5165\n",
            "Epoch 34/100, Loss: 5.6395, Validation Accuracy: 0.6132\n",
            "Epoch 35/100, Loss: 72.0655, Validation Accuracy: 0.5204\n",
            "Epoch 36/100, Loss: 7.6602, Validation Accuracy: 0.6491\n",
            "Epoch 37/100, Loss: 9.6635, Validation Accuracy: 0.6650\n",
            "Epoch 38/100, Loss: 7.6698, Validation Accuracy: 0.6401\n",
            "Epoch 39/100, Loss: 3.8174, Validation Accuracy: 0.5912\n",
            "Epoch 40/100, Loss: 4.1400, Validation Accuracy: 0.6002\n",
            "Epoch 41/100, Loss: 8.8103, Validation Accuracy: 0.6002\n",
            "Epoch 42/100, Loss: 18.8099, Validation Accuracy: 0.5474\n",
            "Epoch 43/100, Loss: 2.6631, Validation Accuracy: 0.6461\n",
            "Epoch 44/100, Loss: 3.1013, Validation Accuracy: 0.6092\n",
            "Epoch 45/100, Loss: 4.2812, Validation Accuracy: 0.6770\n",
            "Epoch 46/100, Loss: 2.3963, Validation Accuracy: 0.5842\n",
            "Epoch 47/100, Loss: 40.4191, Validation Accuracy: 0.5344\n",
            "Epoch 48/100, Loss: 18.3407, Validation Accuracy: 0.5464\n",
            "Epoch 49/100, Loss: 3.5312, Validation Accuracy: 0.4586\n",
            "Epoch 50/100, Loss: 5.4460, Validation Accuracy: 0.4786\n",
            "Epoch 51/100, Loss: 14.2476, Validation Accuracy: 0.5763\n",
            "Epoch 52/100, Loss: 7.1696, Validation Accuracy: 0.5304\n",
            "Epoch 53/100, Loss: 7.9034, Validation Accuracy: 0.6331\n",
            "Epoch 54/100, Loss: 20.3702, Validation Accuracy: 0.6660\n",
            "Epoch 55/100, Loss: 11.7587, Validation Accuracy: 0.6331\n",
            "Epoch 56/100, Loss: 10.5242, Validation Accuracy: 0.6082\n",
            "Epoch 57/100, Loss: 8.0807, Validation Accuracy: 0.3769\n",
            "Epoch 58/100, Loss: 11.4754, Validation Accuracy: 0.6610\n",
            "Epoch 59/100, Loss: 96.6765, Validation Accuracy: 0.5643\n",
            "Epoch 60/100, Loss: 13.0970, Validation Accuracy: 0.5793\n",
            "Epoch 61/100, Loss: 12.0331, Validation Accuracy: 0.5015\n",
            "Epoch 62/100, Loss: 6.1550, Validation Accuracy: 0.4008\n",
            "Epoch 63/100, Loss: 7.3137, Validation Accuracy: 0.6610\n",
            "Epoch 64/100, Loss: 14.3708, Validation Accuracy: 0.5364\n",
            "Epoch 65/100, Loss: 7.4395, Validation Accuracy: 0.5922\n",
            "Epoch 66/100, Loss: 11.5134, Validation Accuracy: 0.5214\n",
            "Epoch 67/100, Loss: 6.4172, Validation Accuracy: 0.5962\n",
            "Epoch 68/100, Loss: 2814.3213, Validation Accuracy: 0.6441\n",
            "Epoch 69/100, Loss: 405.4198, Validation Accuracy: 0.5603\n",
            "Epoch 70/100, Loss: 79.0897, Validation Accuracy: 0.6680\n",
            "Epoch 71/100, Loss: 9.5649, Validation Accuracy: 0.6431\n",
            "Epoch 72/100, Loss: 18.3135, Validation Accuracy: 0.5892\n",
            "Epoch 73/100, Loss: 14.6795, Validation Accuracy: 0.5833\n",
            "Epoch 74/100, Loss: 8.7800, Validation Accuracy: 0.5643\n",
            "Epoch 75/100, Loss: 5.8102, Validation Accuracy: 0.5553\n",
            "Epoch 76/100, Loss: 14.8462, Validation Accuracy: 0.4975\n",
            "Epoch 77/100, Loss: 14.7400, Validation Accuracy: 0.5952\n",
            "Epoch 78/100, Loss: 226.3025, Validation Accuracy: 0.5523\n",
            "Epoch 79/100, Loss: 13.6936, Validation Accuracy: 0.2762\n",
            "Epoch 80/100, Loss: 10.5357, Validation Accuracy: 0.6780\n",
            "Epoch 81/100, Loss: 306.6103, Validation Accuracy: 0.6331\n",
            "Epoch 82/100, Loss: 13.4582, Validation Accuracy: 0.5075\n",
            "Epoch 83/100, Loss: 15.8716, Validation Accuracy: 0.6471\n",
            "Epoch 84/100, Loss: 5.7085, Validation Accuracy: 0.4556\n",
            "Epoch 85/100, Loss: 12.7426, Validation Accuracy: 0.3061\n",
            "Epoch 86/100, Loss: 1.9899, Validation Accuracy: 0.5683\n",
            "Epoch 87/100, Loss: 3.1707, Validation Accuracy: 0.4726\n",
            "Epoch 88/100, Loss: 16.1005, Validation Accuracy: 0.6122\n",
            "Epoch 89/100, Loss: 2.8556, Validation Accuracy: 0.6630\n",
            "Epoch 90/100, Loss: 5.0029, Validation Accuracy: 0.5005\n",
            "Epoch 91/100, Loss: 3.8793, Validation Accuracy: 0.6251\n",
            "Epoch 92/100, Loss: 8.4911, Validation Accuracy: 0.6590\n",
            "Epoch 93/100, Loss: 6.4355, Validation Accuracy: 0.6540\n",
            "Epoch 94/100, Loss: 435.7094, Validation Accuracy: 0.6012\n",
            "Epoch 95/100, Loss: 50.4008, Validation Accuracy: 0.6221\n",
            "Epoch 96/100, Loss: 39.0985, Validation Accuracy: 0.6640\n",
            "Epoch 97/100, Loss: 4.6282, Validation Accuracy: 0.4666\n",
            "Epoch 98/100, Loss: 12.6584, Validation Accuracy: 0.5703\n",
            "Epoch 99/100, Loss: 15.1541, Validation Accuracy: 0.5095\n",
            "Epoch 100/100, Loss: 1.7774, Validation Accuracy: 0.5005\n",
            "Epoch 101/100, Loss: 6.7459, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 462.2556, Validation Accuracy: 0.5165\n",
            "Epoch 103/100, Loss: 11.7423, Validation Accuracy: 0.5593\n",
            "Epoch 104/100, Loss: 304.9572, Validation Accuracy: 0.5424\n",
            "Epoch 105/100, Loss: 18.2752, Validation Accuracy: 0.5882\n",
            "Epoch 106/100, Loss: 20.9209, Validation Accuracy: 0.5424\n",
            "Epoch 107/100, Loss: 6.9797, Validation Accuracy: 0.6142\n",
            "Epoch 108/100, Loss: 19.8991, Validation Accuracy: 0.6122\n",
            "Epoch 109/100, Loss: 7.0436, Validation Accuracy: 0.6630\n",
            "Epoch 110/100, Loss: 12.1274, Validation Accuracy: 0.4726\n",
            "Epoch 111/100, Loss: 5.3113, Validation Accuracy: 0.6441\n",
            "Epoch 112/100, Loss: 3.1616, Validation Accuracy: 0.6530\n",
            "Epoch 113/100, Loss: 3.0426, Validation Accuracy: 0.5533\n",
            "Epoch 114/100, Loss: 29.9442, Validation Accuracy: 0.4128\n",
            "Epoch 115/100, Loss: 6.0807, Validation Accuracy: 0.5573\n",
            "Epoch 116/100, Loss: 15.3351, Validation Accuracy: 0.5314\n",
            "Epoch 117/100, Loss: 26.8434, Validation Accuracy: 0.6610\n",
            "Epoch 118/100, Loss: 197.2465, Validation Accuracy: 0.6540\n",
            "Epoch 119/100, Loss: 9.7616, Validation Accuracy: 0.5284\n",
            "Epoch 120/100, Loss: 13.2799, Validation Accuracy: 0.6122\n",
            "Epoch 121/100, Loss: 52.0029, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 10.8404, Validation Accuracy: 0.5813\n",
            "Epoch 123/100, Loss: 15.2373, Validation Accuracy: 0.4437\n",
            "Epoch 124/100, Loss: 8.4693, Validation Accuracy: 0.5374\n",
            "Epoch 125/100, Loss: 17.3647, Validation Accuracy: 0.6590\n",
            "Epoch 126/100, Loss: 39.6059, Validation Accuracy: 0.5593\n",
            "Epoch 127/100, Loss: 16.6414, Validation Accuracy: 0.5962\n",
            "Epoch 128/100, Loss: 13.5618, Validation Accuracy: 0.5842\n",
            "Epoch 129/100, Loss: 10.5978, Validation Accuracy: 0.5533\n",
            "Epoch 130/100, Loss: 8.0557, Validation Accuracy: 0.5583\n",
            "Epoch 131/100, Loss: 9.1625, Validation Accuracy: 0.5962\n",
            "Epoch 132/100, Loss: 11.7750, Validation Accuracy: 0.6042\n",
            "Epoch 133/100, Loss: 36.5889, Validation Accuracy: 0.4806\n",
            "Epoch 134/100, Loss: 8.0568, Validation Accuracy: 0.6441\n",
            "Epoch 135/100, Loss: 9.9899, Validation Accuracy: 0.5992\n",
            "Epoch 136/100, Loss: 14.0545, Validation Accuracy: 0.3888\n",
            "Epoch 137/100, Loss: 24.2692, Validation Accuracy: 0.6710\n",
            "Epoch 138/100, Loss: 10.9480, Validation Accuracy: 0.6361\n",
            "Epoch 139/100, Loss: 23.8983, Validation Accuracy: 0.6800\n",
            "Epoch 140/100, Loss: 36.6749, Validation Accuracy: 0.4177\n",
            "Epoch 141/100, Loss: 37.0572, Validation Accuracy: 0.6162\n",
            "Epoch 142/100, Loss: 19.3275, Validation Accuracy: 0.5882\n",
            "Epoch 143/100, Loss: 20.3505, Validation Accuracy: 0.6142\n",
            "Epoch 144/100, Loss: 378.7981, Validation Accuracy: 0.5583\n",
            "Epoch 145/100, Loss: 88.3697, Validation Accuracy: 0.4616\n",
            "Epoch 146/100, Loss: 27.1464, Validation Accuracy: 0.6401\n",
            "Epoch 147/100, Loss: 5.7370, Validation Accuracy: 0.6610\n",
            "Epoch 148/100, Loss: 17.8469, Validation Accuracy: 0.6421\n",
            "Epoch 149/100, Loss: 6.2584, Validation Accuracy: 0.6291\n",
            "Epoch 150/100, Loss: 7.6277, Validation Accuracy: 0.6062\n",
            "Epoch 151/100, Loss: 3.6294, Validation Accuracy: 0.5244\n",
            "Epoch 152/100, Loss: 13.9499, Validation Accuracy: 0.5204\n",
            "Epoch 153/100, Loss: 5.1150, Validation Accuracy: 0.5882\n",
            "Epoch 154/100, Loss: 4.8985, Validation Accuracy: 0.3609\n",
            "Epoch 155/100, Loss: 22.0925, Validation Accuracy: 0.4556\n",
            "Epoch 156/100, Loss: 19.8961, Validation Accuracy: 0.6451\n",
            "Epoch 157/100, Loss: 31.2945, Validation Accuracy: 0.5773\n",
            "Epoch 158/100, Loss: 16.5996, Validation Accuracy: 0.5763\n",
            "Epoch 159/100, Loss: 10.5243, Validation Accuracy: 0.5334\n",
            "Epoch 160/100, Loss: 4.9953, Validation Accuracy: 0.5414\n",
            "Epoch 161/100, Loss: 15.2228, Validation Accuracy: 0.5763\n",
            "Epoch 162/100, Loss: 31.5857, Validation Accuracy: 0.5174\n",
            "Epoch 163/100, Loss: 24.2308, Validation Accuracy: 0.5912\n",
            "Epoch 164/100, Loss: 22.5857, Validation Accuracy: 0.5872\n",
            "Epoch 165/100, Loss: 21.9678, Validation Accuracy: 0.6142\n",
            "Epoch 166/100, Loss: 8.5976, Validation Accuracy: 0.6351\n",
            "Epoch 167/100, Loss: 17.4799, Validation Accuracy: 0.6481\n",
            "Epoch 168/100, Loss: 8.6300, Validation Accuracy: 0.5962\n",
            "Epoch 169/100, Loss: 21.6469, Validation Accuracy: 0.6082\n",
            "Epoch 170/100, Loss: 6.4978, Validation Accuracy: 0.5454\n",
            "Epoch 171/100, Loss: 11.8671, Validation Accuracy: 0.6600\n",
            "Epoch 172/100, Loss: 62.2886, Validation Accuracy: 0.6181\n",
            "Epoch 173/100, Loss: 15.5869, Validation Accuracy: 0.4995\n",
            "Epoch 174/100, Loss: 17.6821, Validation Accuracy: 0.5394\n",
            "Epoch 175/100, Loss: 10.2260, Validation Accuracy: 0.6461\n",
            "Epoch 176/100, Loss: 11.8466, Validation Accuracy: 0.5683\n",
            "Epoch 177/100, Loss: 14.3937, Validation Accuracy: 0.5543\n",
            "Epoch 178/100, Loss: 24.1928, Validation Accuracy: 0.6590\n",
            "Epoch 179/100, Loss: 22.6170, Validation Accuracy: 0.3838\n",
            "Epoch 180/100, Loss: 26.8815, Validation Accuracy: 0.5434\n",
            "Epoch 181/100, Loss: 11.3123, Validation Accuracy: 0.6361\n",
            "Epoch 182/100, Loss: 37.2669, Validation Accuracy: 0.6052\n",
            "Epoch 183/100, Loss: 31.9388, Validation Accuracy: 0.5484\n",
            "Epoch 184/100, Loss: 11.1584, Validation Accuracy: 0.6580\n",
            "Epoch 185/100, Loss: 14.3493, Validation Accuracy: 0.6401\n",
            "Epoch 186/100, Loss: 26.6864, Validation Accuracy: 0.6002\n",
            "Epoch 187/100, Loss: 10.8205, Validation Accuracy: 0.5992\n",
            "Epoch 188/100, Loss: 14.7477, Validation Accuracy: 0.6281\n",
            "Epoch 189/100, Loss: 9.4485, Validation Accuracy: 0.5962\n",
            "Epoch 190/100, Loss: 15.2223, Validation Accuracy: 0.6152\n",
            "Epoch 191/100, Loss: 31.6810, Validation Accuracy: 0.5892\n",
            "Epoch 192/100, Loss: 11.7866, Validation Accuracy: 0.6261\n",
            "Epoch 193/100, Loss: 9.5336, Validation Accuracy: 0.5683\n",
            "Epoch 194/100, Loss: 12.9202, Validation Accuracy: 0.5643\n",
            "Epoch 195/100, Loss: 15.5299, Validation Accuracy: 0.5912\n",
            "Epoch 196/100, Loss: 46.9400, Validation Accuracy: 0.5234\n",
            "Epoch 197/100, Loss: 250.7094, Validation Accuracy: 0.4766\n",
            "Epoch 198/100, Loss: 42.2714, Validation Accuracy: 0.5434\n",
            "Epoch 199/100, Loss: 3.8412, Validation Accuracy: 0.6510\n",
            "Epoch 200/100, Loss: 18.7121, Validation Accuracy: 0.4596\n",
            "Reward for Child Model: 0.27595403249788275\n",
            "Child_68:  {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, [2, 0, 0, 1, 2, 3, 0, 1, 1, 2, 2, 0, 2, 0, 3], 0.27595403249788275\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(60, 36, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(96, 36, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(120, 36, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=12960, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 26, 24]           1,104\n",
            "       BatchNorm2d-2           [-1, 24, 26, 24]              48\n",
            "            Conv2d-3           [-1, 36, 22, 20]          21,636\n",
            "       BatchNorm2d-4           [-1, 36, 22, 20]              72\n",
            "              ReLU-5           [-1, 36, 22, 20]               0\n",
            "            Conv2d-6           [-1, 36, 24, 22]          19,476\n",
            "       BatchNorm2d-7           [-1, 36, 24, 22]              72\n",
            "              ReLU-8           [-1, 36, 24, 22]               0\n",
            "            Conv2d-9           [-1, 36, 20, 20]         120,996\n",
            "      BatchNorm2d-10           [-1, 36, 20, 20]              72\n",
            "             ReLU-11           [-1, 36, 20, 20]               0\n",
            "           Conv2d-12           [-1, 36, 20, 18]         211,716\n",
            "      BatchNorm2d-13           [-1, 36, 20, 18]              72\n",
            "             ReLU-14           [-1, 36, 20, 18]               0\n",
            "           Linear-15                    [-1, 7]          90,727\n",
            "================================================================\n",
            "Total params: 465,991\n",
            "Trainable params: 465,991\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.65\n",
            "Params size (MB): 1.78\n",
            "Estimated Total Size (MB): 3.44\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 0.9999, Validation Accuracy: 0.6690\n",
            "Epoch 2/100, Loss: 1.2218, Validation Accuracy: 0.6690\n",
            "Epoch 3/100, Loss: 1.2758, Validation Accuracy: 0.6690\n",
            "Epoch 4/100, Loss: 0.9361, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 1.0324, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 1.3080, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 1.4767, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 1.0140, Validation Accuracy: 0.6690\n",
            "Epoch 9/100, Loss: 1.4551, Validation Accuracy: 0.6690\n",
            "Epoch 10/100, Loss: 1.1365, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 0.9937, Validation Accuracy: 0.6690\n",
            "Epoch 12/100, Loss: 1.1355, Validation Accuracy: 0.6690\n",
            "Epoch 13/100, Loss: 1.1831, Validation Accuracy: 0.6690\n",
            "Epoch 14/100, Loss: 1.3179, Validation Accuracy: 0.6690\n",
            "Epoch 15/100, Loss: 1.1537, Validation Accuracy: 0.6690\n",
            "Epoch 16/100, Loss: 1.0875, Validation Accuracy: 0.6690\n",
            "Epoch 17/100, Loss: 0.9576, Validation Accuracy: 0.6690\n",
            "Epoch 18/100, Loss: 1.0934, Validation Accuracy: 0.6690\n",
            "Epoch 19/100, Loss: 1.0260, Validation Accuracy: 0.6690\n",
            "Epoch 20/100, Loss: 1.2969, Validation Accuracy: 0.6690\n",
            "Epoch 21/100, Loss: 0.9974, Validation Accuracy: 0.6690\n",
            "Epoch 22/100, Loss: 1.0993, Validation Accuracy: 0.6690\n",
            "Epoch 23/100, Loss: 1.2851, Validation Accuracy: 0.6690\n",
            "Epoch 24/100, Loss: 1.2227, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 1.1888, Validation Accuracy: 0.6690\n",
            "Epoch 26/100, Loss: 1.2111, Validation Accuracy: 0.6690\n",
            "Epoch 27/100, Loss: 1.0972, Validation Accuracy: 0.6690\n",
            "Epoch 28/100, Loss: 1.1893, Validation Accuracy: 0.6690\n",
            "Epoch 29/100, Loss: 0.8581, Validation Accuracy: 0.6690\n",
            "Epoch 30/100, Loss: 0.8355, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 1.1744, Validation Accuracy: 0.4556\n",
            "Epoch 32/100, Loss: 0.8603, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 1.0147, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 1.2950, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 1.7477, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 1.2470, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 1.1928, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 1.2354, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 1.2474, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 1.1982, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 1.1001, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 1.2773, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 1.2239, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 0.9854, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 1.2678, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 1.1084, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 1.2854, Validation Accuracy: 0.6690\n",
            "Epoch 48/100, Loss: 1.4937, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 0.6896, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 1.0322, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 0.6888, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 0.9979, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 1.2291, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 1.3107, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 1.1374, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 1.2388, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 1.2675, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 0.9166, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 1.5083, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 0.9336, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 1.1357, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 0.9368, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 0.8755, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 1.4422, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 1.0511, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 1.0239, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 1.1191, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 0.9762, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 1.2889, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 1.1028, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 1.1251, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 1.1743, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 1.1542, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 1.0975, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 1.2151, Validation Accuracy: 0.6690\n",
            "Epoch 76/100, Loss: 0.7654, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 1.0056, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 0.8218, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 1.1295, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 0.8434, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 1.0394, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 0.9594, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 1.3596, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 0.9866, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 0.9736, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 0.9621, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 0.8831, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 1.2032, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 1.2450, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 1.1145, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 1.0951, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 0.9123, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 0.9347, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 1.0586, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 1.4071, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 1.0793, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 0.9151, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 1.4229, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 1.0454, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 1.3425, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 0.9698, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 1.3701, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 1.0217, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 1.2477, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 0.9152, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 1.0400, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 1.0449, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 1.0751, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 0.9323, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 1.2004, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.0226, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 0.8960, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 1.3194, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 1.0542, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 1.1476, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 1.1195, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 1.3261, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 1.2240, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 1.2535, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 0.7879, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 1.0264, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.1057, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 0.9245, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 1.1978, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 0.9949, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 1.3582, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 1.0774, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 1.1699, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 1.9110, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 0.5296, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 0.8910, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 1.1542, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 1.2168, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 1.0465, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 1.1891, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 1.2364, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 1.6251, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 1.4043, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 1.0046, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 1.0510, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 1.3688, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 1.2491, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 0.8475, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 0.9235, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 1.2437, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 0.9445, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 1.0771, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 1.5197, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 1.1269, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 1.2704, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 1.3758, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 1.1425, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 1.1709, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 1.2996, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 1.1220, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 0.9396, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 1.0336, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 1.3262, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 1.0119, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 1.0920, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 1.1453, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 0.9840, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 1.1292, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 1.2673, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 0.9544, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 1.2352, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 0.9249, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 1.1282, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 1.1970, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 1.2714, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 1.1367, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 1.1570, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 1.0401, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 1.3901, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 0.8757, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 0.6563, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 1.4912, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 1.1546, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 2.0442, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 1.3196, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 1.1127, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 1.2901, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 1.3242, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 1.0680, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 1.1292, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 1.2792, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 1.6851, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 1.4100, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 0.8529, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 1.2703, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 1.5979, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 0.8525, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 0.8828, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 1.2200, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 1.1345, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 1.2898, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 1.2990, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 1.1392, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 0.9063, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 1.0974, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_69:  {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, [1, 2, 0, 2, 2, 1, 1, 1, 1, 3, 2, 1, 3, 3, 1], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(64, 24, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(24, 48, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(48, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=161280, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 24, 28]           1,024\n",
            "       BatchNorm2d-2           [-1, 64, 24, 28]             128\n",
            "            Conv2d-3           [-1, 64, 18, 22]         200,768\n",
            "       BatchNorm2d-4           [-1, 64, 18, 22]             128\n",
            "              ReLU-5           [-1, 64, 18, 22]               0\n",
            "            Conv2d-6           [-1, 24, 16, 16]          32,280\n",
            "       BatchNorm2d-7           [-1, 24, 16, 16]              48\n",
            "              ReLU-8           [-1, 24, 16, 16]               0\n",
            "            Conv2d-9           [-1, 48, 14, 10]          24,240\n",
            "      BatchNorm2d-10           [-1, 48, 14, 10]              96\n",
            "             ReLU-11           [-1, 48, 14, 10]               0\n",
            "           Conv2d-12             [-1, 64, 8, 4]         150,592\n",
            "      BatchNorm2d-13             [-1, 64, 8, 4]             128\n",
            "             ReLU-14             [-1, 64, 8, 4]               0\n",
            "           Linear-15                    [-1, 7]       1,128,967\n",
            "================================================================\n",
            "Total params: 1,538,399\n",
            "Trainable params: 1,538,399\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.58\n",
            "Params size (MB): 5.87\n",
            "Estimated Total Size (MB): 7.46\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 12.0519, Validation Accuracy: 0.4177\n",
            "Epoch 2/100, Loss: 31.4149, Validation Accuracy: 0.0708\n",
            "Epoch 3/100, Loss: 38.7821, Validation Accuracy: 0.6610\n",
            "Epoch 4/100, Loss: 6.5080, Validation Accuracy: 0.6670\n",
            "Epoch 5/100, Loss: 215.9124, Validation Accuracy: 0.5673\n",
            "Epoch 6/100, Loss: 43.2444, Validation Accuracy: 0.4865\n",
            "Epoch 7/100, Loss: 7.6062, Validation Accuracy: 0.4975\n",
            "Epoch 8/100, Loss: 20.1253, Validation Accuracy: 0.6481\n",
            "Epoch 9/100, Loss: 30.8081, Validation Accuracy: 0.5713\n",
            "Epoch 10/100, Loss: 56.3372, Validation Accuracy: 0.6291\n",
            "Epoch 11/100, Loss: 89.2068, Validation Accuracy: 0.4397\n",
            "Epoch 12/100, Loss: 83.2796, Validation Accuracy: 0.6491\n",
            "Epoch 13/100, Loss: 30.0518, Validation Accuracy: 0.5234\n",
            "Epoch 14/100, Loss: 17.3076, Validation Accuracy: 0.6331\n",
            "Epoch 15/100, Loss: 67.5965, Validation Accuracy: 0.5194\n",
            "Epoch 16/100, Loss: 69.5194, Validation Accuracy: 0.5723\n",
            "Epoch 17/100, Loss: 51.0895, Validation Accuracy: 0.6560\n",
            "Epoch 18/100, Loss: 41.8717, Validation Accuracy: 0.5274\n",
            "Epoch 19/100, Loss: 50.9453, Validation Accuracy: 0.6630\n",
            "Epoch 20/100, Loss: 64.1219, Validation Accuracy: 0.6221\n",
            "Epoch 21/100, Loss: 69.2637, Validation Accuracy: 0.3848\n",
            "Epoch 22/100, Loss: 70.5794, Validation Accuracy: 0.5723\n",
            "Epoch 23/100, Loss: 68.6642, Validation Accuracy: 0.5184\n",
            "Epoch 24/100, Loss: 166.3485, Validation Accuracy: 0.4756\n",
            "Epoch 25/100, Loss: 98.8692, Validation Accuracy: 0.6471\n",
            "Epoch 26/100, Loss: 29.3997, Validation Accuracy: 0.5454\n",
            "Epoch 27/100, Loss: 77.8836, Validation Accuracy: 0.6520\n",
            "Epoch 28/100, Loss: 69.8523, Validation Accuracy: 0.6092\n",
            "Epoch 29/100, Loss: 41.8887, Validation Accuracy: 0.6371\n",
            "Epoch 30/100, Loss: 65.8636, Validation Accuracy: 0.5902\n",
            "Epoch 31/100, Loss: 72.7122, Validation Accuracy: 0.6839\n",
            "Epoch 32/100, Loss: 46.6771, Validation Accuracy: 0.2582\n",
            "Epoch 33/100, Loss: 42.7827, Validation Accuracy: 0.6391\n",
            "Epoch 34/100, Loss: 57.1326, Validation Accuracy: 0.3848\n",
            "Epoch 35/100, Loss: 129.7377, Validation Accuracy: 0.6351\n",
            "Epoch 36/100, Loss: 45.6845, Validation Accuracy: 0.6381\n",
            "Epoch 37/100, Loss: 103.6612, Validation Accuracy: 0.5703\n",
            "Epoch 38/100, Loss: 82.1680, Validation Accuracy: 0.6760\n",
            "Epoch 39/100, Loss: 46.7668, Validation Accuracy: 0.5364\n",
            "Epoch 40/100, Loss: 20.0017, Validation Accuracy: 0.6800\n",
            "Epoch 41/100, Loss: 49.6054, Validation Accuracy: 0.6271\n",
            "Epoch 42/100, Loss: 89.5815, Validation Accuracy: 0.5464\n",
            "Epoch 43/100, Loss: 19.2247, Validation Accuracy: 0.6341\n",
            "Epoch 44/100, Loss: 92.5452, Validation Accuracy: 0.6560\n",
            "Epoch 45/100, Loss: 52.4943, Validation Accuracy: 0.6331\n",
            "Epoch 46/100, Loss: 123.6667, Validation Accuracy: 0.6191\n",
            "Epoch 47/100, Loss: 92.3355, Validation Accuracy: 0.5932\n",
            "Epoch 48/100, Loss: 214.1975, Validation Accuracy: 0.4806\n",
            "Epoch 49/100, Loss: 46.3185, Validation Accuracy: 0.5763\n",
            "Epoch 50/100, Loss: 39.0812, Validation Accuracy: 0.5105\n",
            "Epoch 51/100, Loss: 22.0757, Validation Accuracy: 0.5972\n",
            "Epoch 52/100, Loss: 170.0796, Validation Accuracy: 0.5294\n",
            "Epoch 53/100, Loss: 56.6540, Validation Accuracy: 0.6849\n",
            "Epoch 54/100, Loss: 48.2116, Validation Accuracy: 0.6421\n",
            "Epoch 55/100, Loss: 32.2399, Validation Accuracy: 0.6839\n",
            "Epoch 56/100, Loss: 78.4081, Validation Accuracy: 0.6780\n",
            "Epoch 57/100, Loss: 45.3871, Validation Accuracy: 0.5892\n",
            "Epoch 58/100, Loss: 48.9681, Validation Accuracy: 0.5583\n",
            "Epoch 59/100, Loss: 40.9837, Validation Accuracy: 0.5494\n",
            "Epoch 60/100, Loss: 30.5144, Validation Accuracy: 0.5224\n",
            "Epoch 61/100, Loss: 52.4413, Validation Accuracy: 0.5872\n",
            "Epoch 62/100, Loss: 55.2581, Validation Accuracy: 0.6152\n",
            "Epoch 63/100, Loss: 82.2957, Validation Accuracy: 0.6810\n",
            "Epoch 64/100, Loss: 109.1480, Validation Accuracy: 0.5354\n",
            "Epoch 65/100, Loss: 115.8069, Validation Accuracy: 0.6600\n",
            "Epoch 66/100, Loss: 49.6949, Validation Accuracy: 0.4088\n",
            "Epoch 67/100, Loss: 51.9579, Validation Accuracy: 0.5773\n",
            "Epoch 68/100, Loss: 31.0066, Validation Accuracy: 0.6381\n",
            "Epoch 69/100, Loss: 371.8405, Validation Accuracy: 0.6750\n",
            "Epoch 70/100, Loss: 84.0640, Validation Accuracy: 0.5723\n",
            "Epoch 71/100, Loss: 63.8373, Validation Accuracy: 0.6231\n",
            "Epoch 72/100, Loss: 23.5689, Validation Accuracy: 0.5494\n",
            "Epoch 73/100, Loss: 75.1549, Validation Accuracy: 0.5823\n",
            "Epoch 74/100, Loss: 88.5612, Validation Accuracy: 0.6291\n",
            "Epoch 75/100, Loss: 77.8322, Validation Accuracy: 0.6162\n",
            "Epoch 76/100, Loss: 79.0438, Validation Accuracy: 0.6451\n",
            "Epoch 77/100, Loss: 111.6560, Validation Accuracy: 0.5972\n",
            "Epoch 78/100, Loss: 80.8788, Validation Accuracy: 0.6142\n",
            "Epoch 79/100, Loss: 36.2982, Validation Accuracy: 0.3948\n",
            "Epoch 80/100, Loss: 27.9184, Validation Accuracy: 0.6770\n",
            "Epoch 81/100, Loss: 76.9463, Validation Accuracy: 0.6431\n",
            "Epoch 82/100, Loss: 54.1674, Validation Accuracy: 0.6102\n",
            "Epoch 83/100, Loss: 112.7801, Validation Accuracy: 0.5922\n",
            "Epoch 84/100, Loss: 59.7022, Validation Accuracy: 0.6530\n",
            "Epoch 85/100, Loss: 29.0196, Validation Accuracy: 0.5454\n",
            "Epoch 86/100, Loss: 91.6059, Validation Accuracy: 0.6550\n",
            "Epoch 87/100, Loss: 54.8939, Validation Accuracy: 0.6650\n",
            "Epoch 88/100, Loss: 46.3161, Validation Accuracy: 0.5344\n",
            "Epoch 89/100, Loss: 42.6236, Validation Accuracy: 0.6650\n",
            "Epoch 90/100, Loss: 36.5875, Validation Accuracy: 0.5494\n",
            "Epoch 91/100, Loss: 55.6177, Validation Accuracy: 0.6500\n",
            "Epoch 92/100, Loss: 327.8267, Validation Accuracy: 0.5384\n",
            "Epoch 93/100, Loss: 66.0404, Validation Accuracy: 0.6491\n",
            "Epoch 94/100, Loss: 38.8427, Validation Accuracy: 0.6401\n",
            "Epoch 95/100, Loss: 38.6288, Validation Accuracy: 0.4596\n",
            "Epoch 96/100, Loss: 50.6445, Validation Accuracy: 0.6869\n",
            "Epoch 97/100, Loss: 64.8166, Validation Accuracy: 0.6909\n",
            "Epoch 98/100, Loss: 68.5091, Validation Accuracy: 0.6401\n",
            "Epoch 99/100, Loss: 21.5512, Validation Accuracy: 0.6760\n",
            "Epoch 100/100, Loss: 70.7340, Validation Accuracy: 0.4985\n",
            "Epoch 101/100, Loss: 21.2850, Validation Accuracy: 0.5274\n",
            "Epoch 102/100, Loss: 15.6544, Validation Accuracy: 0.6720\n",
            "Epoch 103/100, Loss: 41.8523, Validation Accuracy: 0.5713\n",
            "Epoch 104/100, Loss: 49.1133, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 62.7604, Validation Accuracy: 0.6780\n",
            "Epoch 106/100, Loss: 50.2015, Validation Accuracy: 0.6830\n",
            "Epoch 107/100, Loss: 50.4410, Validation Accuracy: 0.5862\n",
            "Epoch 108/100, Loss: 186.0845, Validation Accuracy: 0.6899\n",
            "Epoch 109/100, Loss: 42.4375, Validation Accuracy: 0.6132\n",
            "Epoch 110/100, Loss: 19.2281, Validation Accuracy: 0.5713\n",
            "Epoch 111/100, Loss: 18.4299, Validation Accuracy: 0.6650\n",
            "Epoch 112/100, Loss: 30.4783, Validation Accuracy: 0.5244\n",
            "Epoch 113/100, Loss: 34.3551, Validation Accuracy: 0.5424\n",
            "Epoch 114/100, Loss: 38.7831, Validation Accuracy: 0.6321\n",
            "Epoch 115/100, Loss: 18.5360, Validation Accuracy: 0.3121\n",
            "Epoch 116/100, Loss: 197.6901, Validation Accuracy: 0.5922\n",
            "Epoch 117/100, Loss: 55.3390, Validation Accuracy: 0.6630\n",
            "Epoch 118/100, Loss: 57.2810, Validation Accuracy: 0.6580\n",
            "Epoch 119/100, Loss: 51.3821, Validation Accuracy: 0.5503\n",
            "Epoch 120/100, Loss: 112.4325, Validation Accuracy: 0.6281\n",
            "Epoch 121/100, Loss: 68.3760, Validation Accuracy: 0.5055\n",
            "Epoch 122/100, Loss: 41.7930, Validation Accuracy: 0.4945\n",
            "Epoch 123/100, Loss: 62.9565, Validation Accuracy: 0.5773\n",
            "Epoch 124/100, Loss: 12.2537, Validation Accuracy: 0.6770\n",
            "Epoch 125/100, Loss: 110.1519, Validation Accuracy: 0.5155\n",
            "Epoch 126/100, Loss: 40.2190, Validation Accuracy: 0.6371\n",
            "Epoch 127/100, Loss: 9.4526, Validation Accuracy: 0.6830\n",
            "Epoch 128/100, Loss: 40.0481, Validation Accuracy: 0.5733\n",
            "Epoch 129/100, Loss: 69.8094, Validation Accuracy: 0.6560\n",
            "Epoch 130/100, Loss: 82.7874, Validation Accuracy: 0.4945\n",
            "Epoch 131/100, Loss: 94.6387, Validation Accuracy: 0.5803\n",
            "Epoch 132/100, Loss: 18.7227, Validation Accuracy: 0.5623\n",
            "Epoch 133/100, Loss: 44.7387, Validation Accuracy: 0.5733\n",
            "Epoch 134/100, Loss: 53.0276, Validation Accuracy: 0.5962\n",
            "Epoch 135/100, Loss: 121.8438, Validation Accuracy: 0.6361\n",
            "Epoch 136/100, Loss: 17.9906, Validation Accuracy: 0.5932\n",
            "Epoch 137/100, Loss: 21.0902, Validation Accuracy: 0.6630\n",
            "Epoch 138/100, Loss: 34.1805, Validation Accuracy: 0.5932\n",
            "Epoch 139/100, Loss: 116.1884, Validation Accuracy: 0.5553\n",
            "Epoch 140/100, Loss: 82.5810, Validation Accuracy: 0.6481\n",
            "Epoch 141/100, Loss: 39.8906, Validation Accuracy: 0.6122\n",
            "Epoch 142/100, Loss: 10.8381, Validation Accuracy: 0.5304\n",
            "Epoch 143/100, Loss: 58.7051, Validation Accuracy: 0.6500\n",
            "Epoch 144/100, Loss: 81.4654, Validation Accuracy: 0.5673\n",
            "Epoch 145/100, Loss: 24.1334, Validation Accuracy: 0.5912\n",
            "Epoch 146/100, Loss: 92.1625, Validation Accuracy: 0.6670\n",
            "Epoch 147/100, Loss: 14.4502, Validation Accuracy: 0.6311\n",
            "Epoch 148/100, Loss: 33.8904, Validation Accuracy: 0.5543\n",
            "Epoch 149/100, Loss: 49.2303, Validation Accuracy: 0.5254\n",
            "Epoch 150/100, Loss: 51.5371, Validation Accuracy: 0.6471\n",
            "Epoch 151/100, Loss: 49.0978, Validation Accuracy: 0.5613\n",
            "Epoch 152/100, Loss: 115.5834, Validation Accuracy: 0.6969\n",
            "Epoch 153/100, Loss: 41.5826, Validation Accuracy: 0.6012\n",
            "Epoch 154/100, Loss: 188.2324, Validation Accuracy: 0.6660\n",
            "Epoch 155/100, Loss: 15.7608, Validation Accuracy: 0.6610\n",
            "Epoch 156/100, Loss: 77.5064, Validation Accuracy: 0.6371\n",
            "Epoch 157/100, Loss: 11.3239, Validation Accuracy: 0.6361\n",
            "Epoch 158/100, Loss: 71.5571, Validation Accuracy: 0.6371\n",
            "Epoch 159/100, Loss: 208.6686, Validation Accuracy: 0.4945\n",
            "Epoch 160/100, Loss: 11.6496, Validation Accuracy: 0.5892\n",
            "Epoch 161/100, Loss: 50.6538, Validation Accuracy: 0.5035\n",
            "Epoch 162/100, Loss: 23.2332, Validation Accuracy: 0.6201\n",
            "Epoch 163/100, Loss: 72.0793, Validation Accuracy: 0.6241\n",
            "Epoch 164/100, Loss: 61.7160, Validation Accuracy: 0.6899\n",
            "Epoch 165/100, Loss: 96.8890, Validation Accuracy: 0.6580\n",
            "Epoch 166/100, Loss: 113.1219, Validation Accuracy: 0.5842\n",
            "Epoch 167/100, Loss: 59.3984, Validation Accuracy: 0.4437\n",
            "Epoch 168/100, Loss: 25.1721, Validation Accuracy: 0.5603\n",
            "Epoch 169/100, Loss: 17.0268, Validation Accuracy: 0.5942\n",
            "Epoch 170/100, Loss: 56.2061, Validation Accuracy: 0.5394\n",
            "Epoch 171/100, Loss: 19.9073, Validation Accuracy: 0.6441\n",
            "Epoch 172/100, Loss: 68.1177, Validation Accuracy: 0.5743\n",
            "Epoch 173/100, Loss: 105.0473, Validation Accuracy: 0.6221\n",
            "Epoch 174/100, Loss: 25.8457, Validation Accuracy: 0.5633\n",
            "Epoch 175/100, Loss: 52.4037, Validation Accuracy: 0.5823\n",
            "Epoch 176/100, Loss: 26.0051, Validation Accuracy: 0.6201\n",
            "Epoch 177/100, Loss: 101.9214, Validation Accuracy: 0.3898\n",
            "Epoch 178/100, Loss: 23.3472, Validation Accuracy: 0.6500\n",
            "Epoch 179/100, Loss: 74.6359, Validation Accuracy: 0.5733\n",
            "Epoch 180/100, Loss: 36.6708, Validation Accuracy: 0.5204\n",
            "Epoch 181/100, Loss: 123.7238, Validation Accuracy: 0.6431\n",
            "Epoch 182/100, Loss: 33.5364, Validation Accuracy: 0.6112\n",
            "Epoch 183/100, Loss: 181.5548, Validation Accuracy: 0.6750\n",
            "Epoch 184/100, Loss: 218.0815, Validation Accuracy: 0.6261\n",
            "Epoch 185/100, Loss: 80.2109, Validation Accuracy: 0.5942\n",
            "Epoch 186/100, Loss: 150.9244, Validation Accuracy: 0.6122\n",
            "Epoch 187/100, Loss: 74.6829, Validation Accuracy: 0.6740\n",
            "Epoch 188/100, Loss: 20.2443, Validation Accuracy: 0.6002\n",
            "Epoch 189/100, Loss: 136.1755, Validation Accuracy: 0.6261\n",
            "Epoch 190/100, Loss: 34.9050, Validation Accuracy: 0.5902\n",
            "Epoch 191/100, Loss: 33.3949, Validation Accuracy: 0.5842\n",
            "Epoch 192/100, Loss: 72.7786, Validation Accuracy: 0.6720\n",
            "Epoch 193/100, Loss: 106.4895, Validation Accuracy: 0.6859\n",
            "Epoch 194/100, Loss: 21.2365, Validation Accuracy: 0.5783\n",
            "Epoch 195/100, Loss: 48.4969, Validation Accuracy: 0.6271\n",
            "Epoch 196/100, Loss: 184.9465, Validation Accuracy: 0.6022\n",
            "Epoch 197/100, Loss: 33.6224, Validation Accuracy: 0.6520\n",
            "Epoch 198/100, Loss: 63.0836, Validation Accuracy: 0.5833\n",
            "Epoch 199/100, Loss: 128.6723, Validation Accuracy: 0.5454\n",
            "Epoch 200/100, Loss: 20.7029, Validation Accuracy: 0.6481\n",
            "Reward for Child Model: 0.2772237576546104\n",
            "Child_70:  {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, [2, 0, 3, 3, 3, 3, 1, 3, 0, 1, 3, 2, 3, 3, 3], 0.2772237576546104\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 24, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 64, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(124, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(224, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=282240, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 28, 24]             576\n",
            "       BatchNorm2d-2           [-1, 36, 28, 24]              72\n",
            "            Conv2d-3           [-1, 24, 22, 20]          30,264\n",
            "       BatchNorm2d-4           [-1, 24, 22, 20]              48\n",
            "              ReLU-5           [-1, 24, 22, 20]               0\n",
            "            Conv2d-6           [-1, 64, 20, 14]          32,320\n",
            "       BatchNorm2d-7           [-1, 64, 20, 14]             128\n",
            "              ReLU-8           [-1, 64, 20, 14]               0\n",
            "            Conv2d-9           [-1, 64, 24, 24]          39,744\n",
            "      BatchNorm2d-10           [-1, 64, 24, 24]             128\n",
            "             ReLU-11           [-1, 64, 24, 24]               0\n",
            "           Conv2d-12           [-1, 48, 26, 24]          32,304\n",
            "      BatchNorm2d-13           [-1, 48, 26, 24]              96\n",
            "             ReLU-14           [-1, 48, 26, 24]               0\n",
            "           Linear-15                    [-1, 7]       1,975,687\n",
            "================================================================\n",
            "Total params: 2,111,367\n",
            "Trainable params: 2,111,367\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.55\n",
            "Params size (MB): 8.05\n",
            "Estimated Total Size (MB): 10.61\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 19.0280, Validation Accuracy: 0.6800\n",
            "Epoch 2/100, Loss: 181.1757, Validation Accuracy: 0.6680\n",
            "Epoch 3/100, Loss: 42.4694, Validation Accuracy: 0.5404\n",
            "Epoch 4/100, Loss: 27.6810, Validation Accuracy: 0.6381\n",
            "Epoch 5/100, Loss: 11.3753, Validation Accuracy: 0.4835\n",
            "Epoch 6/100, Loss: 235.6093, Validation Accuracy: 0.3400\n",
            "Epoch 7/100, Loss: 26.4314, Validation Accuracy: 0.5394\n",
            "Epoch 8/100, Loss: 47.6353, Validation Accuracy: 0.6281\n",
            "Epoch 9/100, Loss: 44.2165, Validation Accuracy: 0.6082\n",
            "Epoch 10/100, Loss: 49.2495, Validation Accuracy: 0.6770\n",
            "Epoch 11/100, Loss: 46.8117, Validation Accuracy: 0.2712\n",
            "Epoch 12/100, Loss: 239.5845, Validation Accuracy: 0.6241\n",
            "Epoch 13/100, Loss: 81.2029, Validation Accuracy: 0.4845\n",
            "Epoch 14/100, Loss: 42.8018, Validation Accuracy: 0.4526\n",
            "Epoch 15/100, Loss: 103.3456, Validation Accuracy: 0.5394\n",
            "Epoch 16/100, Loss: 125.2072, Validation Accuracy: 0.6092\n",
            "Epoch 17/100, Loss: 50.1949, Validation Accuracy: 0.6520\n",
            "Epoch 18/100, Loss: 9032.1650, Validation Accuracy: 0.6540\n",
            "Epoch 19/100, Loss: 214.4682, Validation Accuracy: 0.6122\n",
            "Epoch 20/100, Loss: 88.8562, Validation Accuracy: 0.6132\n",
            "Epoch 21/100, Loss: 313.4865, Validation Accuracy: 0.6441\n",
            "Epoch 22/100, Loss: 1002.3616, Validation Accuracy: 0.4716\n",
            "Epoch 23/100, Loss: 217.9575, Validation Accuracy: 0.6481\n",
            "Epoch 24/100, Loss: 35.7541, Validation Accuracy: 0.5593\n",
            "Epoch 25/100, Loss: 19.8115, Validation Accuracy: 0.5932\n",
            "Epoch 26/100, Loss: 597.2803, Validation Accuracy: 0.6201\n",
            "Epoch 27/100, Loss: 28.2275, Validation Accuracy: 0.6331\n",
            "Epoch 28/100, Loss: 79.6347, Validation Accuracy: 0.6181\n",
            "Epoch 29/100, Loss: 147.2949, Validation Accuracy: 0.6371\n",
            "Epoch 30/100, Loss: 82.1204, Validation Accuracy: 0.6112\n",
            "Epoch 31/100, Loss: 42.8793, Validation Accuracy: 0.5942\n",
            "Epoch 32/100, Loss: 16.3203, Validation Accuracy: 0.6750\n",
            "Epoch 33/100, Loss: 16.7801, Validation Accuracy: 0.6351\n",
            "Epoch 34/100, Loss: 26.3836, Validation Accuracy: 0.4337\n",
            "Epoch 35/100, Loss: 349.3121, Validation Accuracy: 0.6381\n",
            "Epoch 36/100, Loss: 1460.9670, Validation Accuracy: 0.6261\n",
            "Epoch 37/100, Loss: 20.4871, Validation Accuracy: 0.5503\n",
            "Epoch 38/100, Loss: 71.5274, Validation Accuracy: 0.6530\n",
            "Epoch 39/100, Loss: 34.8036, Validation Accuracy: 0.5414\n",
            "Epoch 40/100, Loss: 1019.7898, Validation Accuracy: 0.5992\n",
            "Epoch 41/100, Loss: 74.8333, Validation Accuracy: 0.6331\n",
            "Epoch 42/100, Loss: 193.2498, Validation Accuracy: 0.5713\n",
            "Epoch 43/100, Loss: 86.6913, Validation Accuracy: 0.6331\n",
            "Epoch 44/100, Loss: 56.9101, Validation Accuracy: 0.5922\n",
            "Epoch 45/100, Loss: 44.1235, Validation Accuracy: 0.6341\n",
            "Epoch 46/100, Loss: 20.1401, Validation Accuracy: 0.6800\n",
            "Epoch 47/100, Loss: 99.1171, Validation Accuracy: 0.6590\n",
            "Epoch 48/100, Loss: 114.2321, Validation Accuracy: 0.6590\n",
            "Epoch 49/100, Loss: 592.5046, Validation Accuracy: 0.6361\n",
            "Epoch 50/100, Loss: 20.9076, Validation Accuracy: 0.6291\n",
            "Epoch 51/100, Loss: 24.8975, Validation Accuracy: 0.5324\n",
            "Epoch 52/100, Loss: 111.6379, Validation Accuracy: 0.5533\n",
            "Epoch 53/100, Loss: 16.2037, Validation Accuracy: 0.5424\n",
            "Epoch 54/100, Loss: 53.7610, Validation Accuracy: 0.6849\n",
            "Epoch 55/100, Loss: 42.7697, Validation Accuracy: 0.5424\n",
            "Epoch 56/100, Loss: 90.0526, Validation Accuracy: 0.6680\n",
            "Epoch 57/100, Loss: 96.0945, Validation Accuracy: 0.4895\n",
            "Epoch 58/100, Loss: 105.0330, Validation Accuracy: 0.6540\n",
            "Epoch 59/100, Loss: 67.8727, Validation Accuracy: 0.6211\n",
            "Epoch 60/100, Loss: 82.5723, Validation Accuracy: 0.6520\n",
            "Epoch 61/100, Loss: 41.0969, Validation Accuracy: 0.4716\n",
            "Epoch 62/100, Loss: 31.2617, Validation Accuracy: 0.6012\n",
            "Epoch 63/100, Loss: 98.6242, Validation Accuracy: 0.6181\n",
            "Epoch 64/100, Loss: 212.7267, Validation Accuracy: 0.5892\n",
            "Epoch 65/100, Loss: 93.8990, Validation Accuracy: 0.6301\n",
            "Epoch 66/100, Loss: 14.1515, Validation Accuracy: 0.6530\n",
            "Epoch 67/100, Loss: 38.9127, Validation Accuracy: 0.6730\n",
            "Epoch 68/100, Loss: 66.5661, Validation Accuracy: 0.5434\n",
            "Epoch 69/100, Loss: 97.2242, Validation Accuracy: 0.6321\n",
            "Epoch 70/100, Loss: 396.0867, Validation Accuracy: 0.5842\n",
            "Epoch 71/100, Loss: 22.0686, Validation Accuracy: 0.4925\n",
            "Epoch 72/100, Loss: 96.8384, Validation Accuracy: 0.4845\n",
            "Epoch 73/100, Loss: 20.9967, Validation Accuracy: 0.6211\n",
            "Epoch 74/100, Loss: 62.0619, Validation Accuracy: 0.5484\n",
            "Epoch 75/100, Loss: 45.0761, Validation Accuracy: 0.6052\n",
            "Epoch 76/100, Loss: 63.8327, Validation Accuracy: 0.6321\n",
            "Epoch 77/100, Loss: 165.1458, Validation Accuracy: 0.6381\n",
            "Epoch 78/100, Loss: 115.9594, Validation Accuracy: 0.6441\n",
            "Epoch 79/100, Loss: 544.5842, Validation Accuracy: 0.4377\n",
            "Epoch 80/100, Loss: 163.7368, Validation Accuracy: 0.6171\n",
            "Epoch 81/100, Loss: 23.0445, Validation Accuracy: 0.4636\n",
            "Epoch 82/100, Loss: 38.2927, Validation Accuracy: 0.6281\n",
            "Epoch 83/100, Loss: 36.6989, Validation Accuracy: 0.6560\n",
            "Epoch 84/100, Loss: 19.9791, Validation Accuracy: 0.5793\n",
            "Epoch 85/100, Loss: 39.1805, Validation Accuracy: 0.6162\n",
            "Epoch 86/100, Loss: 71.2357, Validation Accuracy: 0.6411\n",
            "Epoch 87/100, Loss: 26.0577, Validation Accuracy: 0.6570\n",
            "Epoch 88/100, Loss: 162.1974, Validation Accuracy: 0.5543\n",
            "Epoch 89/100, Loss: 175.8105, Validation Accuracy: 0.5962\n",
            "Epoch 90/100, Loss: 58.0649, Validation Accuracy: 0.6520\n",
            "Epoch 91/100, Loss: 102.0414, Validation Accuracy: 0.6610\n",
            "Epoch 92/100, Loss: 22.5701, Validation Accuracy: 0.6271\n",
            "Epoch 93/100, Loss: 72.9322, Validation Accuracy: 0.6062\n",
            "Epoch 94/100, Loss: 88.1854, Validation Accuracy: 0.6421\n",
            "Epoch 95/100, Loss: 65.1197, Validation Accuracy: 0.6251\n",
            "Epoch 96/100, Loss: 57.3658, Validation Accuracy: 0.5513\n",
            "Epoch 97/100, Loss: 33.0439, Validation Accuracy: 0.5892\n",
            "Epoch 98/100, Loss: 171.6958, Validation Accuracy: 0.4586\n",
            "Epoch 99/100, Loss: 107.7850, Validation Accuracy: 0.4078\n",
            "Epoch 100/100, Loss: 75.6453, Validation Accuracy: 0.5633\n",
            "Epoch 101/100, Loss: 107.0194, Validation Accuracy: 0.5872\n",
            "Epoch 102/100, Loss: 88.4866, Validation Accuracy: 0.6491\n",
            "Epoch 103/100, Loss: 314.0368, Validation Accuracy: 0.5842\n",
            "Epoch 104/100, Loss: 138.5214, Validation Accuracy: 0.4606\n",
            "Epoch 105/100, Loss: 40.4053, Validation Accuracy: 0.4756\n",
            "Epoch 106/100, Loss: 34.1274, Validation Accuracy: 0.6032\n",
            "Epoch 107/100, Loss: 44.3938, Validation Accuracy: 0.4945\n",
            "Epoch 108/100, Loss: 142.5026, Validation Accuracy: 0.6191\n",
            "Epoch 109/100, Loss: 78.3039, Validation Accuracy: 0.5793\n",
            "Epoch 110/100, Loss: 183.6013, Validation Accuracy: 0.5264\n",
            "Epoch 111/100, Loss: 461.7479, Validation Accuracy: 0.5274\n",
            "Epoch 112/100, Loss: 105.5393, Validation Accuracy: 0.6451\n",
            "Epoch 113/100, Loss: 70.2294, Validation Accuracy: 0.6062\n",
            "Epoch 114/100, Loss: 59.3499, Validation Accuracy: 0.5553\n",
            "Epoch 115/100, Loss: 56.1427, Validation Accuracy: 0.6291\n",
            "Epoch 116/100, Loss: 22.7030, Validation Accuracy: 0.6680\n",
            "Epoch 117/100, Loss: 33.0302, Validation Accuracy: 0.6281\n",
            "Epoch 118/100, Loss: 34.1555, Validation Accuracy: 0.6461\n",
            "Epoch 119/100, Loss: 22.5142, Validation Accuracy: 0.6530\n",
            "Epoch 120/100, Loss: 11.3640, Validation Accuracy: 0.5982\n",
            "Epoch 121/100, Loss: 153.8502, Validation Accuracy: 0.6191\n",
            "Epoch 122/100, Loss: 61.7884, Validation Accuracy: 0.5513\n",
            "Epoch 123/100, Loss: 42.5996, Validation Accuracy: 0.5603\n",
            "Epoch 124/100, Loss: 48.6221, Validation Accuracy: 0.6152\n",
            "Epoch 125/100, Loss: 147.4616, Validation Accuracy: 0.6520\n",
            "Epoch 126/100, Loss: 117.2363, Validation Accuracy: 0.4746\n",
            "Epoch 127/100, Loss: 49.6764, Validation Accuracy: 0.5783\n",
            "Epoch 128/100, Loss: 64.8576, Validation Accuracy: 0.6052\n",
            "Epoch 129/100, Loss: 23.2513, Validation Accuracy: 0.6271\n",
            "Epoch 130/100, Loss: 48.5300, Validation Accuracy: 0.4078\n",
            "Epoch 131/100, Loss: 143.0622, Validation Accuracy: 0.5992\n",
            "Epoch 132/100, Loss: 84.3207, Validation Accuracy: 0.5753\n",
            "Epoch 133/100, Loss: 51.5349, Validation Accuracy: 0.5833\n",
            "Epoch 134/100, Loss: 128.8864, Validation Accuracy: 0.6311\n",
            "Epoch 135/100, Loss: 100.4972, Validation Accuracy: 0.5155\n",
            "Epoch 136/100, Loss: 244.2891, Validation Accuracy: 0.6481\n",
            "Epoch 137/100, Loss: 53.9402, Validation Accuracy: 0.6610\n",
            "Epoch 138/100, Loss: 49.8681, Validation Accuracy: 0.5862\n",
            "Epoch 139/100, Loss: 68.0581, Validation Accuracy: 0.6570\n",
            "Epoch 140/100, Loss: 309.0849, Validation Accuracy: 0.5852\n",
            "Epoch 141/100, Loss: 118.6478, Validation Accuracy: 0.5454\n",
            "Epoch 142/100, Loss: 35.2851, Validation Accuracy: 0.5314\n",
            "Epoch 143/100, Loss: 93.4276, Validation Accuracy: 0.6451\n",
            "Epoch 144/100, Loss: 70.1795, Validation Accuracy: 0.5174\n",
            "Epoch 145/100, Loss: 102.2569, Validation Accuracy: 0.5803\n",
            "Epoch 146/100, Loss: 59.9614, Validation Accuracy: 0.4377\n",
            "Epoch 147/100, Loss: 33.7717, Validation Accuracy: 0.5763\n",
            "Epoch 148/100, Loss: 126.7423, Validation Accuracy: 0.3041\n",
            "Epoch 149/100, Loss: 53.8977, Validation Accuracy: 0.5942\n",
            "Epoch 150/100, Loss: 85.4089, Validation Accuracy: 0.5992\n",
            "Epoch 151/100, Loss: 110.5875, Validation Accuracy: 0.6152\n",
            "Epoch 152/100, Loss: 155.0073, Validation Accuracy: 0.6411\n",
            "Epoch 153/100, Loss: 77.5619, Validation Accuracy: 0.5105\n",
            "Epoch 154/100, Loss: 60.3209, Validation Accuracy: 0.5464\n",
            "Epoch 155/100, Loss: 261.9847, Validation Accuracy: 0.6640\n",
            "Epoch 156/100, Loss: 33.2007, Validation Accuracy: 0.6072\n",
            "Epoch 157/100, Loss: 90.6392, Validation Accuracy: 0.5773\n",
            "Epoch 158/100, Loss: 123.5110, Validation Accuracy: 0.5952\n",
            "Epoch 159/100, Loss: 103.6526, Validation Accuracy: 0.6790\n",
            "Epoch 160/100, Loss: 143.3823, Validation Accuracy: 0.6221\n",
            "Epoch 161/100, Loss: 77.3097, Validation Accuracy: 0.3470\n",
            "Epoch 162/100, Loss: 30.7785, Validation Accuracy: 0.5833\n",
            "Epoch 163/100, Loss: 80.3316, Validation Accuracy: 0.6570\n",
            "Epoch 164/100, Loss: 63.4786, Validation Accuracy: 0.6002\n",
            "Epoch 165/100, Loss: 78.3829, Validation Accuracy: 0.5623\n",
            "Epoch 166/100, Loss: 94.7787, Validation Accuracy: 0.6251\n",
            "Epoch 167/100, Loss: 76.0097, Validation Accuracy: 0.6660\n",
            "Epoch 168/100, Loss: 171.6111, Validation Accuracy: 0.6361\n",
            "Epoch 169/100, Loss: 158.6255, Validation Accuracy: 0.6162\n",
            "Epoch 170/100, Loss: 198.6819, Validation Accuracy: 0.4457\n",
            "Epoch 171/100, Loss: 70.9297, Validation Accuracy: 0.5324\n",
            "Epoch 172/100, Loss: 85.3687, Validation Accuracy: 0.6640\n",
            "Epoch 173/100, Loss: 186.3060, Validation Accuracy: 0.6281\n",
            "Epoch 174/100, Loss: 58.5737, Validation Accuracy: 0.5892\n",
            "Epoch 175/100, Loss: 129.7210, Validation Accuracy: 0.6281\n",
            "Epoch 176/100, Loss: 105.7246, Validation Accuracy: 0.6072\n",
            "Epoch 177/100, Loss: 62.7635, Validation Accuracy: 0.6012\n",
            "Epoch 178/100, Loss: 42.8788, Validation Accuracy: 0.6381\n",
            "Epoch 179/100, Loss: 58.6251, Validation Accuracy: 0.6461\n",
            "Epoch 180/100, Loss: 59.5368, Validation Accuracy: 0.6680\n",
            "Epoch 181/100, Loss: 197.7926, Validation Accuracy: 0.6800\n",
            "Epoch 182/100, Loss: 60.0182, Validation Accuracy: 0.5902\n",
            "Epoch 183/100, Loss: 142.3675, Validation Accuracy: 0.6650\n",
            "Epoch 184/100, Loss: 121.7812, Validation Accuracy: 0.5035\n",
            "Epoch 185/100, Loss: 134.4813, Validation Accuracy: 0.5982\n",
            "Epoch 186/100, Loss: 34.7230, Validation Accuracy: 0.5713\n",
            "Epoch 187/100, Loss: 78.2784, Validation Accuracy: 0.6401\n",
            "Epoch 188/100, Loss: 66.6885, Validation Accuracy: 0.6590\n",
            "Epoch 189/100, Loss: 29.5618, Validation Accuracy: 0.6132\n",
            "Epoch 190/100, Loss: 45.1915, Validation Accuracy: 0.6590\n",
            "Epoch 191/100, Loss: 40.0963, Validation Accuracy: 0.5593\n",
            "Epoch 192/100, Loss: 94.8390, Validation Accuracy: 0.5842\n",
            "Epoch 193/100, Loss: 167.7516, Validation Accuracy: 0.4746\n",
            "Epoch 194/100, Loss: 233.1278, Validation Accuracy: 0.6271\n",
            "Epoch 195/100, Loss: 42.5131, Validation Accuracy: 0.5314\n",
            "Epoch 196/100, Loss: 31.2241, Validation Accuracy: 0.5872\n",
            "Epoch 197/100, Loss: 12.8140, Validation Accuracy: 0.5803\n",
            "Epoch 198/100, Loss: 62.4244, Validation Accuracy: 0.6441\n",
            "Epoch 199/100, Loss: 203.8635, Validation Accuracy: 0.6790\n",
            "Epoch 200/100, Loss: 161.6004, Validation Accuracy: 0.5823\n",
            "Reward for Child Model: 0.3129958192883965\n",
            "Child_71:  {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, [0, 2, 1, 3, 2, 0, 1, 3, 3, 2, 0, 3, 1, 0, 2], 0.3129958192883965\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 48, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(100, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(172, 48, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=88704, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 24, 28]             576\n",
            "       BatchNorm2d-2           [-1, 36, 24, 28]              72\n",
            "            Conv2d-3           [-1, 48, 20, 28]           8,688\n",
            "       BatchNorm2d-4           [-1, 48, 20, 28]              96\n",
            "              ReLU-5           [-1, 48, 20, 28]               0\n",
            "            Conv2d-6           [-1, 64, 16, 28]          15,424\n",
            "       BatchNorm2d-7           [-1, 64, 16, 28]             128\n",
            "              ReLU-8           [-1, 64, 16, 28]               0\n",
            "            Conv2d-9           [-1, 24, 24, 22]          16,824\n",
            "      BatchNorm2d-10           [-1, 24, 24, 22]              48\n",
            "             ReLU-11           [-1, 24, 24, 22]               0\n",
            "           Conv2d-12           [-1, 48, 22, 22]         173,424\n",
            "      BatchNorm2d-13           [-1, 48, 22, 22]              96\n",
            "             ReLU-14           [-1, 48, 22, 22]               0\n",
            "           Linear-15                    [-1, 7]         620,935\n",
            "================================================================\n",
            "Total params: 836,311\n",
            "Trainable params: 836,311\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.46\n",
            "Params size (MB): 3.19\n",
            "Estimated Total Size (MB): 5.66\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 7.5082, Validation Accuracy: 0.4706\n",
            "Epoch 2/100, Loss: 38.4191, Validation Accuracy: 0.6351\n",
            "Epoch 3/100, Loss: 73.5318, Validation Accuracy: 0.6092\n",
            "Epoch 4/100, Loss: 4.6515, Validation Accuracy: 0.5553\n",
            "Epoch 5/100, Loss: 19.8093, Validation Accuracy: 0.6570\n",
            "Epoch 6/100, Loss: 13.4590, Validation Accuracy: 0.5324\n",
            "Epoch 7/100, Loss: 267.9008, Validation Accuracy: 0.5872\n",
            "Epoch 8/100, Loss: 39.4661, Validation Accuracy: 0.6381\n",
            "Epoch 9/100, Loss: 18.4083, Validation Accuracy: 0.5364\n",
            "Epoch 10/100, Loss: 4.7904, Validation Accuracy: 0.4437\n",
            "Epoch 11/100, Loss: 6.8035, Validation Accuracy: 0.5194\n",
            "Epoch 12/100, Loss: 4.8573, Validation Accuracy: 0.5982\n",
            "Epoch 13/100, Loss: 5.2471, Validation Accuracy: 0.5842\n",
            "Epoch 14/100, Loss: 9.6066, Validation Accuracy: 0.3799\n",
            "Epoch 15/100, Loss: 104.8181, Validation Accuracy: 0.6351\n",
            "Epoch 16/100, Loss: 8.8556, Validation Accuracy: 0.5244\n",
            "Epoch 17/100, Loss: 10.3204, Validation Accuracy: 0.5194\n",
            "Epoch 18/100, Loss: 2.7160, Validation Accuracy: 0.6580\n",
            "Epoch 19/100, Loss: 7.8318, Validation Accuracy: 0.6869\n",
            "Epoch 20/100, Loss: 7.0141, Validation Accuracy: 0.6321\n",
            "Epoch 21/100, Loss: 13.3550, Validation Accuracy: 0.5394\n",
            "Epoch 22/100, Loss: 132.6598, Validation Accuracy: 0.5823\n",
            "Epoch 23/100, Loss: 10.3934, Validation Accuracy: 0.5603\n",
            "Epoch 24/100, Loss: 13.9338, Validation Accuracy: 0.5364\n",
            "Epoch 25/100, Loss: 12.1619, Validation Accuracy: 0.4397\n",
            "Epoch 26/100, Loss: 13.5322, Validation Accuracy: 0.2981\n",
            "Epoch 27/100, Loss: 36.4069, Validation Accuracy: 0.5823\n",
            "Epoch 28/100, Loss: 33.6903, Validation Accuracy: 0.6899\n",
            "Epoch 29/100, Loss: 43.3617, Validation Accuracy: 0.5743\n",
            "Epoch 30/100, Loss: 10.9757, Validation Accuracy: 0.6142\n",
            "Epoch 31/100, Loss: 25.5860, Validation Accuracy: 0.4167\n",
            "Epoch 32/100, Loss: 48.2893, Validation Accuracy: 0.5773\n",
            "Epoch 33/100, Loss: 80.5327, Validation Accuracy: 0.6191\n",
            "Epoch 34/100, Loss: 14.3763, Validation Accuracy: 0.6072\n",
            "Epoch 35/100, Loss: 19.5467, Validation Accuracy: 0.6341\n",
            "Epoch 36/100, Loss: 19.1264, Validation Accuracy: 0.6471\n",
            "Epoch 37/100, Loss: 32.4126, Validation Accuracy: 0.4885\n",
            "Epoch 38/100, Loss: 14.3779, Validation Accuracy: 0.6451\n",
            "Epoch 39/100, Loss: 32.1935, Validation Accuracy: 0.4128\n",
            "Epoch 40/100, Loss: 41.0867, Validation Accuracy: 0.5623\n",
            "Epoch 41/100, Loss: 42.6403, Validation Accuracy: 0.5573\n",
            "Epoch 42/100, Loss: 12.6859, Validation Accuracy: 0.6441\n",
            "Epoch 43/100, Loss: 24.1613, Validation Accuracy: 0.4726\n",
            "Epoch 44/100, Loss: 217.8002, Validation Accuracy: 0.5174\n",
            "Epoch 45/100, Loss: 36.7070, Validation Accuracy: 0.6032\n",
            "Epoch 46/100, Loss: 17.0306, Validation Accuracy: 0.6670\n",
            "Epoch 47/100, Loss: 22.1841, Validation Accuracy: 0.4975\n",
            "Epoch 48/100, Loss: 12.4956, Validation Accuracy: 0.6211\n",
            "Epoch 49/100, Loss: 20.4590, Validation Accuracy: 0.6421\n",
            "Epoch 50/100, Loss: 30.7249, Validation Accuracy: 0.6700\n",
            "Epoch 51/100, Loss: 22.2207, Validation Accuracy: 0.6122\n",
            "Epoch 52/100, Loss: 19.8271, Validation Accuracy: 0.6171\n",
            "Epoch 53/100, Loss: 20.6103, Validation Accuracy: 0.6082\n",
            "Epoch 54/100, Loss: 29.4900, Validation Accuracy: 0.4796\n",
            "Epoch 55/100, Loss: 30.5907, Validation Accuracy: 0.6680\n",
            "Epoch 56/100, Loss: 24.9587, Validation Accuracy: 0.5633\n",
            "Epoch 57/100, Loss: 59.6010, Validation Accuracy: 0.6171\n",
            "Epoch 58/100, Loss: 102.7944, Validation Accuracy: 0.6301\n",
            "Epoch 59/100, Loss: 6.8343, Validation Accuracy: 0.6471\n",
            "Epoch 60/100, Loss: 15.0553, Validation Accuracy: 0.6301\n",
            "Epoch 61/100, Loss: 12.9355, Validation Accuracy: 0.6371\n",
            "Epoch 62/100, Loss: 19.7384, Validation Accuracy: 0.6670\n",
            "Epoch 63/100, Loss: 35.3195, Validation Accuracy: 0.5743\n",
            "Epoch 64/100, Loss: 29.3925, Validation Accuracy: 0.4706\n",
            "Epoch 65/100, Loss: 29.9413, Validation Accuracy: 0.5364\n",
            "Epoch 66/100, Loss: 12.2581, Validation Accuracy: 0.6630\n",
            "Epoch 67/100, Loss: 24.7644, Validation Accuracy: 0.4855\n",
            "Epoch 68/100, Loss: 60.0663, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 54.6868, Validation Accuracy: 0.5174\n",
            "Epoch 70/100, Loss: 25.6088, Validation Accuracy: 0.5793\n",
            "Epoch 71/100, Loss: 13.1639, Validation Accuracy: 0.5444\n",
            "Epoch 72/100, Loss: 8.0299, Validation Accuracy: 0.5793\n",
            "Epoch 73/100, Loss: 19.4051, Validation Accuracy: 0.6441\n",
            "Epoch 74/100, Loss: 31.9363, Validation Accuracy: 0.5593\n",
            "Epoch 75/100, Loss: 67.1804, Validation Accuracy: 0.5932\n",
            "Epoch 76/100, Loss: 42.3598, Validation Accuracy: 0.5633\n",
            "Epoch 77/100, Loss: 26.3512, Validation Accuracy: 0.6381\n",
            "Epoch 78/100, Loss: 55.4694, Validation Accuracy: 0.3878\n",
            "Epoch 79/100, Loss: 20.4554, Validation Accuracy: 0.6421\n",
            "Epoch 80/100, Loss: 21.2185, Validation Accuracy: 0.5783\n",
            "Epoch 81/100, Loss: 30.8416, Validation Accuracy: 0.6660\n",
            "Epoch 82/100, Loss: 143.5387, Validation Accuracy: 0.5713\n",
            "Epoch 83/100, Loss: 13.2336, Validation Accuracy: 0.4925\n",
            "Epoch 84/100, Loss: 9.0492, Validation Accuracy: 0.6700\n",
            "Epoch 85/100, Loss: 16.3401, Validation Accuracy: 0.6221\n",
            "Epoch 86/100, Loss: 14.7196, Validation Accuracy: 0.6441\n",
            "Epoch 87/100, Loss: 28.1290, Validation Accuracy: 0.4516\n",
            "Epoch 88/100, Loss: 30.5886, Validation Accuracy: 0.5733\n",
            "Epoch 89/100, Loss: 93.5617, Validation Accuracy: 0.5284\n",
            "Epoch 90/100, Loss: 18.8543, Validation Accuracy: 0.4895\n",
            "Epoch 91/100, Loss: 93.1957, Validation Accuracy: 0.6530\n",
            "Epoch 92/100, Loss: 46.2961, Validation Accuracy: 0.6181\n",
            "Epoch 93/100, Loss: 38.3960, Validation Accuracy: 0.4915\n",
            "Epoch 94/100, Loss: 29.7922, Validation Accuracy: 0.6261\n",
            "Epoch 95/100, Loss: 36.5103, Validation Accuracy: 0.6580\n",
            "Epoch 96/100, Loss: 41.7938, Validation Accuracy: 0.6351\n",
            "Epoch 97/100, Loss: 50.8307, Validation Accuracy: 0.6122\n",
            "Epoch 98/100, Loss: 26.0783, Validation Accuracy: 0.6152\n",
            "Epoch 99/100, Loss: 12.2763, Validation Accuracy: 0.6361\n",
            "Epoch 100/100, Loss: 12.6402, Validation Accuracy: 0.6800\n",
            "Epoch 101/100, Loss: 27.6142, Validation Accuracy: 0.5892\n",
            "Epoch 102/100, Loss: 22.4503, Validation Accuracy: 0.5055\n",
            "Epoch 103/100, Loss: 37.8234, Validation Accuracy: 0.5523\n",
            "Epoch 104/100, Loss: 20.3206, Validation Accuracy: 0.5783\n",
            "Epoch 105/100, Loss: 20.6702, Validation Accuracy: 0.6152\n",
            "Epoch 106/100, Loss: 11.7456, Validation Accuracy: 0.5942\n",
            "Epoch 107/100, Loss: 65.1567, Validation Accuracy: 0.5833\n",
            "Epoch 108/100, Loss: 34.6532, Validation Accuracy: 0.5902\n",
            "Epoch 109/100, Loss: 15.5268, Validation Accuracy: 0.5553\n",
            "Epoch 110/100, Loss: 28.1875, Validation Accuracy: 0.5354\n",
            "Epoch 111/100, Loss: 21.7235, Validation Accuracy: 0.5523\n",
            "Epoch 112/100, Loss: 25.9435, Validation Accuracy: 0.6461\n",
            "Epoch 113/100, Loss: 54.6221, Validation Accuracy: 0.5932\n",
            "Epoch 114/100, Loss: 20.6404, Validation Accuracy: 0.6500\n",
            "Epoch 115/100, Loss: 25.4156, Validation Accuracy: 0.5733\n",
            "Epoch 116/100, Loss: 122.8535, Validation Accuracy: 0.5503\n",
            "Epoch 117/100, Loss: 38.1067, Validation Accuracy: 0.6321\n",
            "Epoch 118/100, Loss: 27.2797, Validation Accuracy: 0.6271\n",
            "Epoch 119/100, Loss: 5.2803, Validation Accuracy: 0.5474\n",
            "Epoch 120/100, Loss: 30.7717, Validation Accuracy: 0.5065\n",
            "Epoch 121/100, Loss: 25.9688, Validation Accuracy: 0.6102\n",
            "Epoch 122/100, Loss: 27.0723, Validation Accuracy: 0.6142\n",
            "Epoch 123/100, Loss: 12.6516, Validation Accuracy: 0.6620\n",
            "Epoch 124/100, Loss: 45.8906, Validation Accuracy: 0.6201\n",
            "Epoch 125/100, Loss: 26.4428, Validation Accuracy: 0.5553\n",
            "Epoch 126/100, Loss: 178.2191, Validation Accuracy: 0.5992\n",
            "Epoch 127/100, Loss: 22.0550, Validation Accuracy: 0.6082\n",
            "Epoch 128/100, Loss: 44.4121, Validation Accuracy: 0.6152\n",
            "Epoch 129/100, Loss: 25.0317, Validation Accuracy: 0.4945\n",
            "Epoch 130/100, Loss: 20.1699, Validation Accuracy: 0.5922\n",
            "Epoch 131/100, Loss: 37.5684, Validation Accuracy: 0.6670\n",
            "Epoch 132/100, Loss: 16.9821, Validation Accuracy: 0.5234\n",
            "Epoch 133/100, Loss: 7.4728, Validation Accuracy: 0.6740\n",
            "Epoch 134/100, Loss: 12.7144, Validation Accuracy: 0.5374\n",
            "Epoch 135/100, Loss: 15.4617, Validation Accuracy: 0.6720\n",
            "Epoch 136/100, Loss: 52.0981, Validation Accuracy: 0.5743\n",
            "Epoch 137/100, Loss: 89.2301, Validation Accuracy: 0.4387\n",
            "Epoch 138/100, Loss: 16.7896, Validation Accuracy: 0.4078\n",
            "Epoch 139/100, Loss: 45.9357, Validation Accuracy: 0.6191\n",
            "Epoch 140/100, Loss: 38.9188, Validation Accuracy: 0.5135\n",
            "Epoch 141/100, Loss: 20.9372, Validation Accuracy: 0.6520\n",
            "Epoch 142/100, Loss: 14.1653, Validation Accuracy: 0.6351\n",
            "Epoch 143/100, Loss: 27.6277, Validation Accuracy: 0.4816\n",
            "Epoch 144/100, Loss: 67.3202, Validation Accuracy: 0.4417\n",
            "Epoch 145/100, Loss: 19.5337, Validation Accuracy: 0.4985\n",
            "Epoch 146/100, Loss: 8.9453, Validation Accuracy: 0.6650\n",
            "Epoch 147/100, Loss: 38.8719, Validation Accuracy: 0.6261\n",
            "Epoch 148/100, Loss: 36.6038, Validation Accuracy: 0.5613\n",
            "Epoch 149/100, Loss: 25.4377, Validation Accuracy: 0.5882\n",
            "Epoch 150/100, Loss: 56.5038, Validation Accuracy: 0.6491\n",
            "Epoch 151/100, Loss: 32.9876, Validation Accuracy: 0.5823\n",
            "Epoch 152/100, Loss: 31.3717, Validation Accuracy: 0.6471\n",
            "Epoch 153/100, Loss: 12.2504, Validation Accuracy: 0.6431\n",
            "Epoch 154/100, Loss: 23.7680, Validation Accuracy: 0.6730\n",
            "Epoch 155/100, Loss: 26.8968, Validation Accuracy: 0.5613\n",
            "Epoch 156/100, Loss: 15.4152, Validation Accuracy: 0.4945\n",
            "Epoch 157/100, Loss: 15.8682, Validation Accuracy: 0.6780\n",
            "Epoch 158/100, Loss: 27.7793, Validation Accuracy: 0.5882\n",
            "Epoch 159/100, Loss: 25.1669, Validation Accuracy: 0.5434\n",
            "Epoch 160/100, Loss: 35.4141, Validation Accuracy: 0.5523\n",
            "Epoch 161/100, Loss: 51.2068, Validation Accuracy: 0.6421\n",
            "Epoch 162/100, Loss: 58.9731, Validation Accuracy: 0.5902\n",
            "Epoch 163/100, Loss: 15.1295, Validation Accuracy: 0.6321\n",
            "Epoch 164/100, Loss: 28.9748, Validation Accuracy: 0.5234\n",
            "Epoch 165/100, Loss: 41.7491, Validation Accuracy: 0.6331\n",
            "Epoch 166/100, Loss: 70.7629, Validation Accuracy: 0.6481\n",
            "Epoch 167/100, Loss: 26.4017, Validation Accuracy: 0.5563\n",
            "Epoch 168/100, Loss: 23.3686, Validation Accuracy: 0.5095\n",
            "Epoch 169/100, Loss: 92.4470, Validation Accuracy: 0.6032\n",
            "Epoch 170/100, Loss: 35.6170, Validation Accuracy: 0.5414\n",
            "Epoch 171/100, Loss: 44.6359, Validation Accuracy: 0.5952\n",
            "Epoch 172/100, Loss: 17.1350, Validation Accuracy: 0.6112\n",
            "Epoch 173/100, Loss: 35.6370, Validation Accuracy: 0.6062\n",
            "Epoch 174/100, Loss: 83.0772, Validation Accuracy: 0.4935\n",
            "Epoch 175/100, Loss: 11.1762, Validation Accuracy: 0.5803\n",
            "Epoch 176/100, Loss: 40.7085, Validation Accuracy: 0.6301\n",
            "Epoch 177/100, Loss: 56.8206, Validation Accuracy: 0.6032\n",
            "Epoch 178/100, Loss: 14.9700, Validation Accuracy: 0.6471\n",
            "Epoch 179/100, Loss: 20.6150, Validation Accuracy: 0.6231\n",
            "Epoch 180/100, Loss: 24.4865, Validation Accuracy: 0.6072\n",
            "Epoch 181/100, Loss: 20.2343, Validation Accuracy: 0.6610\n",
            "Epoch 182/100, Loss: 23.4217, Validation Accuracy: 0.5653\n",
            "Epoch 183/100, Loss: 22.6324, Validation Accuracy: 0.5464\n",
            "Epoch 184/100, Loss: 33.0475, Validation Accuracy: 0.6072\n",
            "Epoch 185/100, Loss: 66.9604, Validation Accuracy: 0.6251\n",
            "Epoch 186/100, Loss: 29.9003, Validation Accuracy: 0.5224\n",
            "Epoch 187/100, Loss: 20.4793, Validation Accuracy: 0.6162\n",
            "Epoch 188/100, Loss: 13.4040, Validation Accuracy: 0.6570\n",
            "Epoch 189/100, Loss: 17.4184, Validation Accuracy: 0.5484\n",
            "Epoch 190/100, Loss: 101.5636, Validation Accuracy: 0.6122\n",
            "Epoch 191/100, Loss: 13.3803, Validation Accuracy: 0.6132\n",
            "Epoch 192/100, Loss: 16.3925, Validation Accuracy: 0.5603\n",
            "Epoch 193/100, Loss: 14.7690, Validation Accuracy: 0.5922\n",
            "Epoch 194/100, Loss: 14.3546, Validation Accuracy: 0.5902\n",
            "Epoch 195/100, Loss: 28.4592, Validation Accuracy: 0.6401\n",
            "Epoch 196/100, Loss: 12.7634, Validation Accuracy: 0.6491\n",
            "Epoch 197/100, Loss: 27.2283, Validation Accuracy: 0.5982\n",
            "Epoch 198/100, Loss: 42.4171, Validation Accuracy: 0.4855\n",
            "Epoch 199/100, Loss: 27.5539, Validation Accuracy: 0.5733\n",
            "Epoch 200/100, Loss: 67.1263, Validation Accuracy: 0.6411\n",
            "Reward for Child Model: 0.2734262250836617\n",
            "Child_72:  {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, [2, 0, 1, 2, 0, 2, 2, 0, 3, 0, 3, 0, 1, 3, 2], 0.2734262250836617\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 24, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(60, 64, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(224, 36, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=199584, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 22, 28]             792\n",
            "       BatchNorm2d-2           [-1, 36, 22, 28]              72\n",
            "            Conv2d-3           [-1, 24, 20, 26]           7,800\n",
            "       BatchNorm2d-4           [-1, 24, 20, 26]              48\n",
            "              ReLU-5           [-1, 24, 20, 26]               0\n",
            "            Conv2d-6           [-1, 64, 16, 28]          26,944\n",
            "       BatchNorm2d-7           [-1, 64, 16, 28]             128\n",
            "              ReLU-8           [-1, 64, 16, 28]               0\n",
            "            Conv2d-9           [-1, 64, 12, 28]          20,544\n",
            "      BatchNorm2d-10           [-1, 64, 12, 28]             128\n",
            "             ReLU-11           [-1, 64, 12, 28]               0\n",
            "           Conv2d-12           [-1, 36, 16, 26]         169,380\n",
            "      BatchNorm2d-13           [-1, 36, 16, 26]              72\n",
            "             ReLU-14           [-1, 36, 16, 26]               0\n",
            "           Linear-15                    [-1, 7]       1,397,095\n",
            "================================================================\n",
            "Total params: 1,623,003\n",
            "Trainable params: 1,623,003\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.12\n",
            "Params size (MB): 6.19\n",
            "Estimated Total Size (MB): 8.32\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 122.6353, Validation Accuracy: 0.4845\n",
            "Epoch 2/100, Loss: 31.5474, Validation Accuracy: 0.2971\n",
            "Epoch 3/100, Loss: 59.3949, Validation Accuracy: 0.1107\n",
            "Epoch 4/100, Loss: 235.9146, Validation Accuracy: 0.6261\n",
            "Epoch 5/100, Loss: 835.7672, Validation Accuracy: 0.4247\n",
            "Epoch 6/100, Loss: 41.1316, Validation Accuracy: 0.6411\n",
            "Epoch 7/100, Loss: 17.6804, Validation Accuracy: 0.3190\n",
            "Epoch 8/100, Loss: 134.0694, Validation Accuracy: 0.5723\n",
            "Epoch 9/100, Loss: 25.4869, Validation Accuracy: 0.5474\n",
            "Epoch 10/100, Loss: 5.6652, Validation Accuracy: 0.6620\n",
            "Epoch 11/100, Loss: 21.4686, Validation Accuracy: 0.5145\n",
            "Epoch 12/100, Loss: 423.9224, Validation Accuracy: 0.5743\n",
            "Epoch 13/100, Loss: 80.8282, Validation Accuracy: 0.3180\n",
            "Epoch 14/100, Loss: 25.5360, Validation Accuracy: 0.4696\n",
            "Epoch 15/100, Loss: 206.5138, Validation Accuracy: 0.6680\n",
            "Epoch 16/100, Loss: 805.0954, Validation Accuracy: 0.6720\n",
            "Epoch 17/100, Loss: 75.6687, Validation Accuracy: 0.6122\n",
            "Epoch 18/100, Loss: 70.5949, Validation Accuracy: 0.6471\n",
            "Epoch 19/100, Loss: 13.5977, Validation Accuracy: 0.5713\n",
            "Epoch 20/100, Loss: 18.8771, Validation Accuracy: 0.6830\n",
            "Epoch 21/100, Loss: 9.6103, Validation Accuracy: 0.6670\n",
            "Epoch 22/100, Loss: 1087.8416, Validation Accuracy: 0.6281\n",
            "Epoch 23/100, Loss: 25.4015, Validation Accuracy: 0.6281\n",
            "Epoch 24/100, Loss: 18.2009, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 30.7669, Validation Accuracy: 0.5733\n",
            "Epoch 26/100, Loss: 13.7276, Validation Accuracy: 0.6421\n",
            "Epoch 27/100, Loss: 63.2189, Validation Accuracy: 0.5693\n",
            "Epoch 28/100, Loss: 6.7263, Validation Accuracy: 0.5663\n",
            "Epoch 29/100, Loss: 7.0180, Validation Accuracy: 0.6251\n",
            "Epoch 30/100, Loss: 14.6483, Validation Accuracy: 0.6600\n",
            "Epoch 31/100, Loss: 22.0013, Validation Accuracy: 0.5763\n",
            "Epoch 32/100, Loss: 15.2221, Validation Accuracy: 0.5882\n",
            "Epoch 33/100, Loss: 69.6472, Validation Accuracy: 0.6540\n",
            "Epoch 34/100, Loss: 67.6452, Validation Accuracy: 0.6092\n",
            "Epoch 35/100, Loss: 67.8424, Validation Accuracy: 0.5932\n",
            "Epoch 36/100, Loss: 434.4761, Validation Accuracy: 0.5065\n",
            "Epoch 37/100, Loss: 79.5083, Validation Accuracy: 0.6211\n",
            "Epoch 38/100, Loss: 11.5453, Validation Accuracy: 0.6730\n",
            "Epoch 39/100, Loss: 88.8602, Validation Accuracy: 0.1107\n",
            "Epoch 40/100, Loss: 12.7050, Validation Accuracy: 0.5553\n",
            "Epoch 41/100, Loss: 21.5437, Validation Accuracy: 0.5773\n",
            "Epoch 42/100, Loss: 23.0332, Validation Accuracy: 0.6291\n",
            "Epoch 43/100, Loss: 9.4956, Validation Accuracy: 0.5513\n",
            "Epoch 44/100, Loss: 18.4943, Validation Accuracy: 0.6281\n",
            "Epoch 45/100, Loss: 87.5184, Validation Accuracy: 0.4686\n",
            "Epoch 46/100, Loss: 41.0368, Validation Accuracy: 0.5025\n",
            "Epoch 47/100, Loss: 5.4480, Validation Accuracy: 0.5723\n",
            "Epoch 48/100, Loss: 31.9917, Validation Accuracy: 0.6311\n",
            "Epoch 49/100, Loss: 19.5480, Validation Accuracy: 0.6700\n",
            "Epoch 50/100, Loss: 29.8421, Validation Accuracy: 0.5204\n",
            "Epoch 51/100, Loss: 61.5664, Validation Accuracy: 0.6092\n",
            "Epoch 52/100, Loss: 123.4488, Validation Accuracy: 0.5075\n",
            "Epoch 53/100, Loss: 63.3162, Validation Accuracy: 0.5872\n",
            "Epoch 54/100, Loss: 49.2961, Validation Accuracy: 0.6102\n",
            "Epoch 55/100, Loss: 31.6409, Validation Accuracy: 0.6012\n",
            "Epoch 56/100, Loss: 7.6012, Validation Accuracy: 0.5872\n",
            "Epoch 57/100, Loss: 720.2237, Validation Accuracy: 0.4576\n",
            "Epoch 58/100, Loss: 255.0779, Validation Accuracy: 0.5603\n",
            "Epoch 59/100, Loss: 32.3720, Validation Accuracy: 0.6301\n",
            "Epoch 60/100, Loss: 10.5423, Validation Accuracy: 0.6441\n",
            "Epoch 61/100, Loss: 23.1365, Validation Accuracy: 0.6032\n",
            "Epoch 62/100, Loss: 12.2480, Validation Accuracy: 0.4895\n",
            "Epoch 63/100, Loss: 23.6464, Validation Accuracy: 0.6102\n",
            "Epoch 64/100, Loss: 270.8597, Validation Accuracy: 0.3579\n",
            "Epoch 65/100, Loss: 530.7864, Validation Accuracy: 0.5095\n",
            "Epoch 66/100, Loss: 21.5533, Validation Accuracy: 0.5932\n",
            "Epoch 67/100, Loss: 10.8804, Validation Accuracy: 0.6710\n",
            "Epoch 68/100, Loss: 20.7752, Validation Accuracy: 0.6510\n",
            "Epoch 69/100, Loss: 7.5147, Validation Accuracy: 0.6371\n",
            "Epoch 70/100, Loss: 21.0181, Validation Accuracy: 0.4616\n",
            "Epoch 71/100, Loss: 27.0021, Validation Accuracy: 0.6351\n",
            "Epoch 72/100, Loss: 19.7469, Validation Accuracy: 0.4277\n",
            "Epoch 73/100, Loss: 27.7870, Validation Accuracy: 0.6670\n",
            "Epoch 74/100, Loss: 31.3040, Validation Accuracy: 0.6032\n",
            "Epoch 75/100, Loss: 1115.4567, Validation Accuracy: 0.1765\n",
            "Epoch 76/100, Loss: 88.2819, Validation Accuracy: 0.6510\n",
            "Epoch 77/100, Loss: 847.9761, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 25.8541, Validation Accuracy: 0.6032\n",
            "Epoch 79/100, Loss: 33.4979, Validation Accuracy: 0.6152\n",
            "Epoch 80/100, Loss: 9.0019, Validation Accuracy: 0.5842\n",
            "Epoch 81/100, Loss: 31.0608, Validation Accuracy: 0.6580\n",
            "Epoch 82/100, Loss: 22.0152, Validation Accuracy: 0.5992\n",
            "Epoch 83/100, Loss: 27.1154, Validation Accuracy: 0.6879\n",
            "Epoch 84/100, Loss: 1038.8889, Validation Accuracy: 0.1107\n",
            "Epoch 85/100, Loss: 23.8906, Validation Accuracy: 0.5284\n",
            "Epoch 86/100, Loss: 19.5369, Validation Accuracy: 0.5972\n",
            "Epoch 87/100, Loss: 20.3346, Validation Accuracy: 0.6082\n",
            "Epoch 88/100, Loss: 19.8222, Validation Accuracy: 0.5713\n",
            "Epoch 89/100, Loss: 1639.1783, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 121.0168, Validation Accuracy: 0.5553\n",
            "Epoch 91/100, Loss: 14.3963, Validation Accuracy: 0.5603\n",
            "Epoch 92/100, Loss: 20.2003, Validation Accuracy: 0.5643\n",
            "Epoch 93/100, Loss: 31.4110, Validation Accuracy: 0.5912\n",
            "Epoch 94/100, Loss: 11.2208, Validation Accuracy: 0.5224\n",
            "Epoch 95/100, Loss: 30.5862, Validation Accuracy: 0.5773\n",
            "Epoch 96/100, Loss: 10.5634, Validation Accuracy: 0.6461\n",
            "Epoch 97/100, Loss: 8.4377, Validation Accuracy: 0.6261\n",
            "Epoch 98/100, Loss: 15.4779, Validation Accuracy: 0.6122\n",
            "Epoch 99/100, Loss: 14.0994, Validation Accuracy: 0.6640\n",
            "Epoch 100/100, Loss: 19.4632, Validation Accuracy: 0.4187\n",
            "Epoch 101/100, Loss: 49.6841, Validation Accuracy: 0.5254\n",
            "Epoch 102/100, Loss: 27.2972, Validation Accuracy: 0.5145\n",
            "Epoch 103/100, Loss: 11.8514, Validation Accuracy: 0.6680\n",
            "Epoch 104/100, Loss: 48.3104, Validation Accuracy: 0.6560\n",
            "Epoch 105/100, Loss: 348.1295, Validation Accuracy: 0.4407\n",
            "Epoch 106/100, Loss: 19.7148, Validation Accuracy: 0.6550\n",
            "Epoch 107/100, Loss: 26.6837, Validation Accuracy: 0.6630\n",
            "Epoch 108/100, Loss: 33.9395, Validation Accuracy: 0.6092\n",
            "Epoch 109/100, Loss: 10.2925, Validation Accuracy: 0.6670\n",
            "Epoch 110/100, Loss: 23.9458, Validation Accuracy: 0.6660\n",
            "Epoch 111/100, Loss: 23.1988, Validation Accuracy: 0.6132\n",
            "Epoch 112/100, Loss: 168.6347, Validation Accuracy: 0.4696\n",
            "Epoch 113/100, Loss: 29.4857, Validation Accuracy: 0.6530\n",
            "Epoch 114/100, Loss: 29.0855, Validation Accuracy: 0.6670\n",
            "Epoch 115/100, Loss: 23.2448, Validation Accuracy: 0.6321\n",
            "Epoch 116/100, Loss: 28.8481, Validation Accuracy: 0.5065\n",
            "Epoch 117/100, Loss: 47.9957, Validation Accuracy: 0.5862\n",
            "Epoch 118/100, Loss: 53.5240, Validation Accuracy: 0.5474\n",
            "Epoch 119/100, Loss: 46.3284, Validation Accuracy: 0.6909\n",
            "Epoch 120/100, Loss: 59.3127, Validation Accuracy: 0.4716\n",
            "Epoch 121/100, Loss: 13.7013, Validation Accuracy: 0.6481\n",
            "Epoch 122/100, Loss: 31.0114, Validation Accuracy: 0.6082\n",
            "Epoch 123/100, Loss: 62.2696, Validation Accuracy: 0.5494\n",
            "Epoch 124/100, Loss: 30.4099, Validation Accuracy: 0.3848\n",
            "Epoch 125/100, Loss: 149.7961, Validation Accuracy: 0.6381\n",
            "Epoch 126/100, Loss: 49.8479, Validation Accuracy: 0.6361\n",
            "Epoch 127/100, Loss: 38.9040, Validation Accuracy: 0.4915\n",
            "Epoch 128/100, Loss: 52.8707, Validation Accuracy: 0.6142\n",
            "Epoch 129/100, Loss: 33.6938, Validation Accuracy: 0.4895\n",
            "Epoch 130/100, Loss: 72.7232, Validation Accuracy: 0.5882\n",
            "Epoch 131/100, Loss: 66.9972, Validation Accuracy: 0.6221\n",
            "Epoch 132/100, Loss: 55.9290, Validation Accuracy: 0.6680\n",
            "Epoch 133/100, Loss: 123.9004, Validation Accuracy: 0.6500\n",
            "Epoch 134/100, Loss: 92.6854, Validation Accuracy: 0.6201\n",
            "Epoch 135/100, Loss: 42.7822, Validation Accuracy: 0.6580\n",
            "Epoch 136/100, Loss: 31.0279, Validation Accuracy: 0.5932\n",
            "Epoch 137/100, Loss: 30.4003, Validation Accuracy: 0.5982\n",
            "Epoch 138/100, Loss: 8.9857, Validation Accuracy: 0.6670\n",
            "Epoch 139/100, Loss: 33.3907, Validation Accuracy: 0.4337\n",
            "Epoch 140/100, Loss: 33.2458, Validation Accuracy: 0.3769\n",
            "Epoch 141/100, Loss: 175.9978, Validation Accuracy: 0.5623\n",
            "Epoch 142/100, Loss: 91.8527, Validation Accuracy: 0.6750\n",
            "Epoch 143/100, Loss: 39.8222, Validation Accuracy: 0.6221\n",
            "Epoch 144/100, Loss: 479.9386, Validation Accuracy: 0.6570\n",
            "Epoch 145/100, Loss: 48.8622, Validation Accuracy: 0.5902\n",
            "Epoch 146/100, Loss: 16.8986, Validation Accuracy: 0.5982\n",
            "Epoch 147/100, Loss: 66.8200, Validation Accuracy: 0.5334\n",
            "Epoch 148/100, Loss: 22.5905, Validation Accuracy: 0.6680\n",
            "Epoch 149/100, Loss: 51.9605, Validation Accuracy: 0.5952\n",
            "Epoch 150/100, Loss: 66.1415, Validation Accuracy: 0.5753\n",
            "Epoch 151/100, Loss: 22.8531, Validation Accuracy: 0.5204\n",
            "Epoch 152/100, Loss: 251.2375, Validation Accuracy: 0.3988\n",
            "Epoch 153/100, Loss: 75.2936, Validation Accuracy: 0.5942\n",
            "Epoch 154/100, Loss: 48.1149, Validation Accuracy: 0.5593\n",
            "Epoch 155/100, Loss: 32.1034, Validation Accuracy: 0.5972\n",
            "Epoch 156/100, Loss: 13.9754, Validation Accuracy: 0.5783\n",
            "Epoch 157/100, Loss: 42.5540, Validation Accuracy: 0.6291\n",
            "Epoch 158/100, Loss: 467.6249, Validation Accuracy: 0.5653\n",
            "Epoch 159/100, Loss: 79.9766, Validation Accuracy: 0.5533\n",
            "Epoch 160/100, Loss: 39.1431, Validation Accuracy: 0.4686\n",
            "Epoch 161/100, Loss: 15.5152, Validation Accuracy: 0.6211\n",
            "Epoch 162/100, Loss: 18.3201, Validation Accuracy: 0.6660\n",
            "Epoch 163/100, Loss: 22.2556, Validation Accuracy: 0.6710\n",
            "Epoch 164/100, Loss: 31.3992, Validation Accuracy: 0.6052\n",
            "Epoch 165/100, Loss: 46.1706, Validation Accuracy: 0.4676\n",
            "Epoch 166/100, Loss: 20.6773, Validation Accuracy: 0.6670\n",
            "Epoch 167/100, Loss: 42.0168, Validation Accuracy: 0.5424\n",
            "Epoch 168/100, Loss: 39.6744, Validation Accuracy: 0.6281\n",
            "Epoch 169/100, Loss: 94.4059, Validation Accuracy: 0.6640\n",
            "Epoch 170/100, Loss: 226.7294, Validation Accuracy: 0.6311\n",
            "Epoch 171/100, Loss: 223.1227, Validation Accuracy: 0.6301\n",
            "Epoch 172/100, Loss: 74.8033, Validation Accuracy: 0.6760\n",
            "Epoch 173/100, Loss: 40.7826, Validation Accuracy: 0.6112\n",
            "Epoch 174/100, Loss: 303.5970, Validation Accuracy: 0.6750\n",
            "Epoch 175/100, Loss: 35.5776, Validation Accuracy: 0.5753\n",
            "Epoch 176/100, Loss: 24.4807, Validation Accuracy: 0.6231\n",
            "Epoch 177/100, Loss: 14.5712, Validation Accuracy: 0.6361\n",
            "Epoch 178/100, Loss: 31.0309, Validation Accuracy: 0.5912\n",
            "Epoch 179/100, Loss: 83.8501, Validation Accuracy: 0.6481\n",
            "Epoch 180/100, Loss: 48.5627, Validation Accuracy: 0.6451\n",
            "Epoch 181/100, Loss: 9.4174, Validation Accuracy: 0.5643\n",
            "Epoch 182/100, Loss: 160.7743, Validation Accuracy: 0.5922\n",
            "Epoch 183/100, Loss: 39.3698, Validation Accuracy: 0.6211\n",
            "Epoch 184/100, Loss: 44.4243, Validation Accuracy: 0.3340\n",
            "Epoch 185/100, Loss: 33.8200, Validation Accuracy: 0.6740\n",
            "Epoch 186/100, Loss: 32.6923, Validation Accuracy: 0.5922\n",
            "Epoch 187/100, Loss: 36.6731, Validation Accuracy: 0.5713\n",
            "Epoch 188/100, Loss: 36.9193, Validation Accuracy: 0.6740\n",
            "Epoch 189/100, Loss: 44.1075, Validation Accuracy: 0.6421\n",
            "Epoch 190/100, Loss: 76.2583, Validation Accuracy: 0.6142\n",
            "Epoch 191/100, Loss: 80.0282, Validation Accuracy: 0.5922\n",
            "Epoch 192/100, Loss: 75.9147, Validation Accuracy: 0.6491\n",
            "Epoch 193/100, Loss: 82.3620, Validation Accuracy: 0.6491\n",
            "Epoch 194/100, Loss: 44.2482, Validation Accuracy: 0.6411\n",
            "Epoch 195/100, Loss: 31.0296, Validation Accuracy: 0.5862\n",
            "Epoch 196/100, Loss: 63.7242, Validation Accuracy: 0.5165\n",
            "Epoch 197/100, Loss: 25.9953, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 65.0894, Validation Accuracy: 0.5952\n",
            "Epoch 199/100, Loss: 101.6082, Validation Accuracy: 0.6700\n",
            "Epoch 200/100, Loss: 43.3936, Validation Accuracy: 0.6171\n",
            "Reward for Child Model: 0.300749573479958\n",
            "Child_73:  {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, [3, 0, 1, 1, 1, 0, 3, 0, 3, 2, 0, 3, 3, 1, 1], 0.300749573479958\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 24, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(72, 48, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(48, 24, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(144, 48, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=152064, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 24, 22]           5,088\n",
            "       BatchNorm2d-2           [-1, 48, 24, 22]              96\n",
            "            Conv2d-3           [-1, 24, 22, 22]           3,480\n",
            "       BatchNorm2d-4           [-1, 24, 22, 22]              48\n",
            "              ReLU-5           [-1, 24, 22, 22]               0\n",
            "            Conv2d-6           [-1, 48, 20, 20]          51,888\n",
            "       BatchNorm2d-7           [-1, 48, 20, 20]              96\n",
            "              ReLU-8           [-1, 48, 20, 20]               0\n",
            "            Conv2d-9           [-1, 24, 16, 20]           5,784\n",
            "      BatchNorm2d-10           [-1, 24, 16, 20]              48\n",
            "             ReLU-11           [-1, 24, 16, 20]               0\n",
            "           Conv2d-12           [-1, 48, 18, 22]          48,432\n",
            "      BatchNorm2d-13           [-1, 48, 18, 22]              96\n",
            "             ReLU-14           [-1, 48, 18, 22]               0\n",
            "           Linear-15                    [-1, 7]       1,064,455\n",
            "================================================================\n",
            "Total params: 1,179,511\n",
            "Trainable params: 1,179,511\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.70\n",
            "Params size (MB): 4.50\n",
            "Estimated Total Size (MB): 6.21\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 18.4615, Validation Accuracy: 0.5912\n",
            "Epoch 2/100, Loss: 83.7291, Validation Accuracy: 0.6191\n",
            "Epoch 3/100, Loss: 565.2070, Validation Accuracy: 0.6610\n",
            "Epoch 4/100, Loss: 16.3568, Validation Accuracy: 0.6082\n",
            "Epoch 5/100, Loss: 29.4102, Validation Accuracy: 0.4945\n",
            "Epoch 6/100, Loss: 135.4144, Validation Accuracy: 0.5703\n",
            "Epoch 7/100, Loss: 73.7953, Validation Accuracy: 0.3858\n",
            "Epoch 8/100, Loss: 18.3647, Validation Accuracy: 0.5703\n",
            "Epoch 9/100, Loss: 55.9462, Validation Accuracy: 0.4945\n",
            "Epoch 10/100, Loss: 62.3257, Validation Accuracy: 0.5823\n",
            "Epoch 11/100, Loss: 37.3261, Validation Accuracy: 0.5852\n",
            "Epoch 12/100, Loss: 30.7799, Validation Accuracy: 0.5274\n",
            "Epoch 13/100, Loss: 276.5970, Validation Accuracy: 0.6032\n",
            "Epoch 14/100, Loss: 53.8351, Validation Accuracy: 0.4407\n",
            "Epoch 15/100, Loss: 66.3890, Validation Accuracy: 0.5414\n",
            "Epoch 16/100, Loss: 31.2916, Validation Accuracy: 0.6650\n",
            "Epoch 17/100, Loss: 55.8478, Validation Accuracy: 0.6520\n",
            "Epoch 18/100, Loss: 27.9489, Validation Accuracy: 0.4865\n",
            "Epoch 19/100, Loss: 18.4565, Validation Accuracy: 0.6142\n",
            "Epoch 20/100, Loss: 5.5659, Validation Accuracy: 0.6421\n",
            "Epoch 21/100, Loss: 47.6836, Validation Accuracy: 0.6730\n",
            "Epoch 22/100, Loss: 23.2451, Validation Accuracy: 0.6700\n",
            "Epoch 23/100, Loss: 13.5503, Validation Accuracy: 0.4935\n",
            "Epoch 24/100, Loss: 39.2537, Validation Accuracy: 0.6012\n",
            "Epoch 25/100, Loss: 47.2232, Validation Accuracy: 0.5155\n",
            "Epoch 26/100, Loss: 101.5481, Validation Accuracy: 0.5713\n",
            "Epoch 27/100, Loss: 14.5907, Validation Accuracy: 0.6341\n",
            "Epoch 28/100, Loss: 41.7858, Validation Accuracy: 0.6162\n",
            "Epoch 29/100, Loss: 59.2635, Validation Accuracy: 0.6142\n",
            "Epoch 30/100, Loss: 59.4816, Validation Accuracy: 0.5992\n",
            "Epoch 31/100, Loss: 50.1144, Validation Accuracy: 0.5045\n",
            "Epoch 32/100, Loss: 11.4946, Validation Accuracy: 0.6670\n",
            "Epoch 33/100, Loss: 47.2420, Validation Accuracy: 0.5394\n",
            "Epoch 34/100, Loss: 485.6894, Validation Accuracy: 0.5783\n",
            "Epoch 35/100, Loss: 26.3087, Validation Accuracy: 0.5902\n",
            "Epoch 36/100, Loss: 47.6802, Validation Accuracy: 0.5523\n",
            "Epoch 37/100, Loss: 43.7405, Validation Accuracy: 0.4875\n",
            "Epoch 38/100, Loss: 20.5141, Validation Accuracy: 0.6630\n",
            "Epoch 39/100, Loss: 30.7669, Validation Accuracy: 0.5264\n",
            "Epoch 40/100, Loss: 137.2008, Validation Accuracy: 0.6401\n",
            "Epoch 41/100, Loss: 23.2031, Validation Accuracy: 0.6630\n",
            "Epoch 42/100, Loss: 75.2551, Validation Accuracy: 0.6082\n",
            "Epoch 43/100, Loss: 65.9512, Validation Accuracy: 0.6211\n",
            "Epoch 44/100, Loss: 68.7442, Validation Accuracy: 0.5394\n",
            "Epoch 45/100, Loss: 103.8927, Validation Accuracy: 0.6211\n",
            "Epoch 46/100, Loss: 71.1975, Validation Accuracy: 0.5503\n",
            "Epoch 47/100, Loss: 13.9201, Validation Accuracy: 0.6441\n",
            "Epoch 48/100, Loss: 13.7708, Validation Accuracy: 0.6550\n",
            "Epoch 49/100, Loss: 62.1935, Validation Accuracy: 0.6331\n",
            "Epoch 50/100, Loss: 60.1166, Validation Accuracy: 0.6022\n",
            "Epoch 51/100, Loss: 2503.2964, Validation Accuracy: 0.4915\n",
            "Epoch 52/100, Loss: 48.8668, Validation Accuracy: 0.6122\n",
            "Epoch 53/100, Loss: 87.4911, Validation Accuracy: 0.6241\n",
            "Epoch 54/100, Loss: 30.3144, Validation Accuracy: 0.4865\n",
            "Epoch 55/100, Loss: 872.9727, Validation Accuracy: 0.5643\n",
            "Epoch 56/100, Loss: 66.0179, Validation Accuracy: 0.6550\n",
            "Epoch 57/100, Loss: 46.9571, Validation Accuracy: 0.4247\n",
            "Epoch 58/100, Loss: 50.7177, Validation Accuracy: 0.5932\n",
            "Epoch 59/100, Loss: 16.9508, Validation Accuracy: 0.6570\n",
            "Epoch 60/100, Loss: 16.4457, Validation Accuracy: 0.5593\n",
            "Epoch 61/100, Loss: 115.6963, Validation Accuracy: 0.4716\n",
            "Epoch 62/100, Loss: 41.4195, Validation Accuracy: 0.6441\n",
            "Epoch 63/100, Loss: 33.4602, Validation Accuracy: 0.5563\n",
            "Epoch 64/100, Loss: 17.2045, Validation Accuracy: 0.6241\n",
            "Epoch 65/100, Loss: 894.6600, Validation Accuracy: 0.5503\n",
            "Epoch 66/100, Loss: 422.3991, Validation Accuracy: 0.6181\n",
            "Epoch 67/100, Loss: 164.0798, Validation Accuracy: 0.6022\n",
            "Epoch 68/100, Loss: 171.3035, Validation Accuracy: 0.6550\n",
            "Epoch 69/100, Loss: 239.0836, Validation Accuracy: 0.5224\n",
            "Epoch 70/100, Loss: 141.1234, Validation Accuracy: 0.5713\n",
            "Epoch 71/100, Loss: 49.6015, Validation Accuracy: 0.6351\n",
            "Epoch 72/100, Loss: 28.9377, Validation Accuracy: 0.6132\n",
            "Epoch 73/100, Loss: 68.7149, Validation Accuracy: 0.5424\n",
            "Epoch 74/100, Loss: 55.4841, Validation Accuracy: 0.6251\n",
            "Epoch 75/100, Loss: 21.0601, Validation Accuracy: 0.6720\n",
            "Epoch 76/100, Loss: 13.9961, Validation Accuracy: 0.5184\n",
            "Epoch 77/100, Loss: 55.0106, Validation Accuracy: 0.6630\n",
            "Epoch 78/100, Loss: 29.9413, Validation Accuracy: 0.6730\n",
            "Epoch 79/100, Loss: 28.5520, Validation Accuracy: 0.4297\n",
            "Epoch 80/100, Loss: 38.4989, Validation Accuracy: 0.3659\n",
            "Epoch 81/100, Loss: 47.9894, Validation Accuracy: 0.6301\n",
            "Epoch 82/100, Loss: 34.0096, Validation Accuracy: 0.5434\n",
            "Epoch 83/100, Loss: 41.1635, Validation Accuracy: 0.5842\n",
            "Epoch 84/100, Loss: 58.0251, Validation Accuracy: 0.6201\n",
            "Epoch 85/100, Loss: 45.8644, Validation Accuracy: 0.6660\n",
            "Epoch 86/100, Loss: 41.2080, Validation Accuracy: 0.5803\n",
            "Epoch 87/100, Loss: 206.4425, Validation Accuracy: 0.4706\n",
            "Epoch 88/100, Loss: 73.0824, Validation Accuracy: 0.6331\n",
            "Epoch 89/100, Loss: 24.0443, Validation Accuracy: 0.6431\n",
            "Epoch 90/100, Loss: 38.0152, Validation Accuracy: 0.5942\n",
            "Epoch 91/100, Loss: 16.1804, Validation Accuracy: 0.3290\n",
            "Epoch 92/100, Loss: 24.1534, Validation Accuracy: 0.6281\n",
            "Epoch 93/100, Loss: 86.9359, Validation Accuracy: 0.4776\n",
            "Epoch 94/100, Loss: 75.8828, Validation Accuracy: 0.6142\n",
            "Epoch 95/100, Loss: 143.6912, Validation Accuracy: 0.6391\n",
            "Epoch 96/100, Loss: 56.0967, Validation Accuracy: 0.6610\n",
            "Epoch 97/100, Loss: 134.9640, Validation Accuracy: 0.6321\n",
            "Epoch 98/100, Loss: 22.9089, Validation Accuracy: 0.6231\n",
            "Epoch 99/100, Loss: 37.5147, Validation Accuracy: 0.6700\n",
            "Epoch 100/100, Loss: 70.1336, Validation Accuracy: 0.5942\n",
            "Epoch 101/100, Loss: 83.2317, Validation Accuracy: 0.6341\n",
            "Epoch 102/100, Loss: 115.0486, Validation Accuracy: 0.5464\n",
            "Epoch 103/100, Loss: 71.6873, Validation Accuracy: 0.6491\n",
            "Epoch 104/100, Loss: 197.0457, Validation Accuracy: 0.6251\n",
            "Epoch 105/100, Loss: 71.2340, Validation Accuracy: 0.4915\n",
            "Epoch 106/100, Loss: 45.3432, Validation Accuracy: 0.5085\n",
            "Epoch 107/100, Loss: 40.8723, Validation Accuracy: 0.3928\n",
            "Epoch 108/100, Loss: 26.7935, Validation Accuracy: 0.5354\n",
            "Epoch 109/100, Loss: 114.1550, Validation Accuracy: 0.6411\n",
            "Epoch 110/100, Loss: 40.1560, Validation Accuracy: 0.5793\n",
            "Epoch 111/100, Loss: 39.9716, Validation Accuracy: 0.6211\n",
            "Epoch 112/100, Loss: 23.2586, Validation Accuracy: 0.6142\n",
            "Epoch 113/100, Loss: 18.4144, Validation Accuracy: 0.6540\n",
            "Epoch 114/100, Loss: 86.2519, Validation Accuracy: 0.6361\n",
            "Epoch 115/100, Loss: 78.8638, Validation Accuracy: 0.6730\n",
            "Epoch 116/100, Loss: 15.8229, Validation Accuracy: 0.6710\n",
            "Epoch 117/100, Loss: 164.6900, Validation Accuracy: 0.5553\n",
            "Epoch 118/100, Loss: 95.6982, Validation Accuracy: 0.6351\n",
            "Epoch 119/100, Loss: 50.7134, Validation Accuracy: 0.6082\n",
            "Epoch 120/100, Loss: 67.9701, Validation Accuracy: 0.5992\n",
            "Epoch 121/100, Loss: 285.3349, Validation Accuracy: 0.6251\n",
            "Epoch 122/100, Loss: 48.8089, Validation Accuracy: 0.6560\n",
            "Epoch 123/100, Loss: 44.8704, Validation Accuracy: 0.6062\n",
            "Epoch 124/100, Loss: 76.2152, Validation Accuracy: 0.6481\n",
            "Epoch 125/100, Loss: 56.5215, Validation Accuracy: 0.4277\n",
            "Epoch 126/100, Loss: 87.1206, Validation Accuracy: 0.5005\n",
            "Epoch 127/100, Loss: 64.5960, Validation Accuracy: 0.6810\n",
            "Epoch 128/100, Loss: 146.9067, Validation Accuracy: 0.4467\n",
            "Epoch 129/100, Loss: 64.2565, Validation Accuracy: 0.5573\n",
            "Epoch 130/100, Loss: 21.5535, Validation Accuracy: 0.6251\n",
            "Epoch 131/100, Loss: 44.1504, Validation Accuracy: 0.6341\n",
            "Epoch 132/100, Loss: 20.2201, Validation Accuracy: 0.6132\n",
            "Epoch 133/100, Loss: 59.0270, Validation Accuracy: 0.6221\n",
            "Epoch 134/100, Loss: 81.7361, Validation Accuracy: 0.5404\n",
            "Epoch 135/100, Loss: 75.1287, Validation Accuracy: 0.6740\n",
            "Epoch 136/100, Loss: 24.1860, Validation Accuracy: 0.7089\n",
            "Epoch 137/100, Loss: 28.6625, Validation Accuracy: 0.6670\n",
            "Epoch 138/100, Loss: 66.2856, Validation Accuracy: 0.5713\n",
            "Epoch 139/100, Loss: 99.7021, Validation Accuracy: 0.6112\n",
            "Epoch 140/100, Loss: 125.1452, Validation Accuracy: 0.6859\n",
            "Epoch 141/100, Loss: 49.2900, Validation Accuracy: 0.6082\n",
            "Epoch 142/100, Loss: 31.6357, Validation Accuracy: 0.6451\n",
            "Epoch 143/100, Loss: 61.1896, Validation Accuracy: 0.6062\n",
            "Epoch 144/100, Loss: 46.1558, Validation Accuracy: 0.6610\n",
            "Epoch 145/100, Loss: 20.5398, Validation Accuracy: 0.6251\n",
            "Epoch 146/100, Loss: 71.0086, Validation Accuracy: 0.5902\n",
            "Epoch 147/100, Loss: 47.5222, Validation Accuracy: 0.5703\n",
            "Epoch 148/100, Loss: 410.5533, Validation Accuracy: 0.4726\n",
            "Epoch 149/100, Loss: 209.5701, Validation Accuracy: 0.5992\n",
            "Epoch 150/100, Loss: 69.2523, Validation Accuracy: 0.6610\n",
            "Epoch 151/100, Loss: 26.8589, Validation Accuracy: 0.6750\n",
            "Epoch 152/100, Loss: 171.6869, Validation Accuracy: 0.6142\n",
            "Epoch 153/100, Loss: 53.5821, Validation Accuracy: 0.6431\n",
            "Epoch 154/100, Loss: 41.2296, Validation Accuracy: 0.6002\n",
            "Epoch 155/100, Loss: 212.6598, Validation Accuracy: 0.5484\n",
            "Epoch 156/100, Loss: 129.4070, Validation Accuracy: 0.6780\n",
            "Epoch 157/100, Loss: 127.0807, Validation Accuracy: 0.6740\n",
            "Epoch 158/100, Loss: 46.6821, Validation Accuracy: 0.6012\n",
            "Epoch 159/100, Loss: 14.6065, Validation Accuracy: 0.5204\n",
            "Epoch 160/100, Loss: 24.0489, Validation Accuracy: 0.1167\n",
            "Epoch 161/100, Loss: 119.7463, Validation Accuracy: 0.5553\n",
            "Epoch 162/100, Loss: 64.6237, Validation Accuracy: 0.6291\n",
            "Epoch 163/100, Loss: 33.6495, Validation Accuracy: 0.6421\n",
            "Epoch 164/100, Loss: 25.7913, Validation Accuracy: 0.5892\n",
            "Epoch 165/100, Loss: 29.5084, Validation Accuracy: 0.5454\n",
            "Epoch 166/100, Loss: 75.9195, Validation Accuracy: 0.6869\n",
            "Epoch 167/100, Loss: 346.2150, Validation Accuracy: 0.6451\n",
            "Epoch 168/100, Loss: 227.2091, Validation Accuracy: 0.5603\n",
            "Epoch 169/100, Loss: 67.2136, Validation Accuracy: 0.4915\n",
            "Epoch 170/100, Loss: 35.7303, Validation Accuracy: 0.4845\n",
            "Epoch 171/100, Loss: 35.4075, Validation Accuracy: 0.6560\n",
            "Epoch 172/100, Loss: 25.4915, Validation Accuracy: 0.5852\n",
            "Epoch 173/100, Loss: 59.6678, Validation Accuracy: 0.6002\n",
            "Epoch 174/100, Loss: 11.2495, Validation Accuracy: 0.6700\n",
            "Epoch 175/100, Loss: 56.7009, Validation Accuracy: 0.5543\n",
            "Epoch 176/100, Loss: 40.6905, Validation Accuracy: 0.4606\n",
            "Epoch 177/100, Loss: 62.3454, Validation Accuracy: 0.5583\n",
            "Epoch 178/100, Loss: 36.6471, Validation Accuracy: 0.6181\n",
            "Epoch 179/100, Loss: 21.4101, Validation Accuracy: 0.5663\n",
            "Epoch 180/100, Loss: 25.8008, Validation Accuracy: 0.6600\n",
            "Epoch 181/100, Loss: 43.7548, Validation Accuracy: 0.5972\n",
            "Epoch 182/100, Loss: 247.2042, Validation Accuracy: 0.5743\n",
            "Epoch 183/100, Loss: 181.6273, Validation Accuracy: 0.6251\n",
            "Epoch 184/100, Loss: 71.8289, Validation Accuracy: 0.5404\n",
            "Epoch 185/100, Loss: 30.3953, Validation Accuracy: 0.5823\n",
            "Epoch 186/100, Loss: 52.3939, Validation Accuracy: 0.5354\n",
            "Epoch 187/100, Loss: 92.3430, Validation Accuracy: 0.6181\n",
            "Epoch 188/100, Loss: 39.2272, Validation Accuracy: 0.5813\n",
            "Epoch 189/100, Loss: 35.0881, Validation Accuracy: 0.5344\n",
            "Epoch 190/100, Loss: 34.3660, Validation Accuracy: 0.6201\n",
            "Epoch 191/100, Loss: 110.8224, Validation Accuracy: 0.6670\n",
            "Epoch 192/100, Loss: 70.5545, Validation Accuracy: 0.5852\n",
            "Epoch 193/100, Loss: 53.4775, Validation Accuracy: 0.5005\n",
            "Epoch 194/100, Loss: 208.5766, Validation Accuracy: 0.4277\n",
            "Epoch 195/100, Loss: 50.4675, Validation Accuracy: 0.5334\n",
            "Epoch 196/100, Loss: 26.9214, Validation Accuracy: 0.6800\n",
            "Epoch 197/100, Loss: 88.1653, Validation Accuracy: 0.5025\n",
            "Epoch 198/100, Loss: 58.3766, Validation Accuracy: 0.6580\n",
            "Epoch 199/100, Loss: 104.0209, Validation Accuracy: 0.5424\n",
            "Epoch 200/100, Loss: 45.2796, Validation Accuracy: 0.5364\n",
            "Reward for Child Model: 0.31437668121054196\n",
            "Child_74:  {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, [2, 3, 2, 1, 0, 0, 2, 1, 2, 2, 0, 0, 3, 0, 2], 0.31437668121054196\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 24, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 24, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(72, 48, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(144, 64, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=92160, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 24, 24]           1,824\n",
            "       BatchNorm2d-2           [-1, 24, 24, 24]              48\n",
            "            Conv2d-3           [-1, 24, 18, 18]          28,248\n",
            "       BatchNorm2d-4           [-1, 24, 18, 18]              48\n",
            "              ReLU-5           [-1, 24, 18, 18]               0\n",
            "            Conv2d-6           [-1, 24, 18, 22]          24,216\n",
            "       BatchNorm2d-7           [-1, 24, 18, 22]              48\n",
            "              ReLU-8           [-1, 24, 18, 22]               0\n",
            "            Conv2d-9           [-1, 48, 24, 18]          24,240\n",
            "      BatchNorm2d-10           [-1, 48, 24, 18]              96\n",
            "             ReLU-11           [-1, 48, 24, 18]               0\n",
            "           Conv2d-12           [-1, 64, 22, 24]          27,712\n",
            "      BatchNorm2d-13           [-1, 64, 22, 24]             128\n",
            "             ReLU-14           [-1, 64, 22, 24]               0\n",
            "           Linear-15                    [-1, 7]         645,127\n",
            "================================================================\n",
            "Total params: 751,735\n",
            "Trainable params: 751,735\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.85\n",
            "Params size (MB): 2.87\n",
            "Estimated Total Size (MB): 4.73\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 3.3012, Validation Accuracy: 0.2901\n",
            "Epoch 2/100, Loss: 17.1581, Validation Accuracy: 0.6600\n",
            "Epoch 3/100, Loss: 127.0253, Validation Accuracy: 0.6650\n",
            "Epoch 4/100, Loss: 9.4552, Validation Accuracy: 0.6271\n",
            "Epoch 5/100, Loss: 2.3693, Validation Accuracy: 0.3579\n",
            "Epoch 6/100, Loss: 1.3034, Validation Accuracy: 0.6152\n",
            "Epoch 7/100, Loss: 1.5810, Validation Accuracy: 0.4975\n",
            "Epoch 8/100, Loss: 914.5156, Validation Accuracy: 0.5264\n",
            "Epoch 9/100, Loss: 31.5087, Validation Accuracy: 0.5733\n",
            "Epoch 10/100, Loss: 7.5197, Validation Accuracy: 0.5633\n",
            "Epoch 11/100, Loss: 5.0390, Validation Accuracy: 0.5304\n",
            "Epoch 12/100, Loss: 1.1608, Validation Accuracy: 0.6012\n",
            "Epoch 13/100, Loss: 6.9681, Validation Accuracy: 0.6072\n",
            "Epoch 14/100, Loss: 4.8322, Validation Accuracy: 0.5912\n",
            "Epoch 15/100, Loss: 14.1893, Validation Accuracy: 0.5484\n",
            "Epoch 16/100, Loss: 11.1063, Validation Accuracy: 0.6042\n",
            "Epoch 17/100, Loss: 135.8434, Validation Accuracy: 0.6760\n",
            "Epoch 18/100, Loss: 12.0532, Validation Accuracy: 0.6471\n",
            "Epoch 19/100, Loss: 7.1202, Validation Accuracy: 0.5882\n",
            "Epoch 20/100, Loss: 11.4599, Validation Accuracy: 0.5663\n",
            "Epoch 21/100, Loss: 9.9845, Validation Accuracy: 0.5912\n",
            "Epoch 22/100, Loss: 8.8576, Validation Accuracy: 0.4746\n",
            "Epoch 23/100, Loss: 27.8437, Validation Accuracy: 0.6211\n",
            "Epoch 24/100, Loss: 91.6418, Validation Accuracy: 0.4337\n",
            "Epoch 25/100, Loss: 22.1720, Validation Accuracy: 0.6401\n",
            "Epoch 26/100, Loss: 7.5140, Validation Accuracy: 0.6570\n",
            "Epoch 27/100, Loss: 4.4402, Validation Accuracy: 0.5055\n",
            "Epoch 28/100, Loss: 17.0302, Validation Accuracy: 0.5763\n",
            "Epoch 29/100, Loss: 72.0406, Validation Accuracy: 0.5783\n",
            "Epoch 30/100, Loss: 15.8942, Validation Accuracy: 0.5454\n",
            "Epoch 31/100, Loss: 13.5161, Validation Accuracy: 0.6072\n",
            "Epoch 32/100, Loss: 8.9591, Validation Accuracy: 0.6670\n",
            "Epoch 33/100, Loss: 5.6617, Validation Accuracy: 0.5464\n",
            "Epoch 34/100, Loss: 11.4065, Validation Accuracy: 0.4975\n",
            "Epoch 35/100, Loss: 15.2210, Validation Accuracy: 0.6441\n",
            "Epoch 36/100, Loss: 174.0786, Validation Accuracy: 0.3898\n",
            "Epoch 37/100, Loss: 74.0390, Validation Accuracy: 0.5005\n",
            "Epoch 38/100, Loss: 44.9771, Validation Accuracy: 0.6102\n",
            "Epoch 39/100, Loss: 14.1453, Validation Accuracy: 0.6500\n",
            "Epoch 40/100, Loss: 5.5141, Validation Accuracy: 0.4796\n",
            "Epoch 41/100, Loss: 16.7458, Validation Accuracy: 0.6740\n",
            "Epoch 42/100, Loss: 22.2456, Validation Accuracy: 0.6760\n",
            "Epoch 43/100, Loss: 26.2011, Validation Accuracy: 0.6461\n",
            "Epoch 44/100, Loss: 93.8916, Validation Accuracy: 0.6810\n",
            "Epoch 45/100, Loss: 8.0395, Validation Accuracy: 0.5015\n",
            "Epoch 46/100, Loss: 10.3990, Validation Accuracy: 0.5763\n",
            "Epoch 47/100, Loss: 13.8748, Validation Accuracy: 0.5992\n",
            "Epoch 48/100, Loss: 33.9755, Validation Accuracy: 0.5294\n",
            "Epoch 49/100, Loss: 62.3641, Validation Accuracy: 0.5723\n",
            "Epoch 50/100, Loss: 25.2149, Validation Accuracy: 0.5783\n",
            "Epoch 51/100, Loss: 36.3185, Validation Accuracy: 0.6142\n",
            "Epoch 52/100, Loss: 14.8938, Validation Accuracy: 0.4128\n",
            "Epoch 53/100, Loss: 44.7215, Validation Accuracy: 0.4536\n",
            "Epoch 54/100, Loss: 294.8175, Validation Accuracy: 0.6062\n",
            "Epoch 55/100, Loss: 26.5178, Validation Accuracy: 0.6271\n",
            "Epoch 56/100, Loss: 8.2229, Validation Accuracy: 0.6471\n",
            "Epoch 57/100, Loss: 8.8434, Validation Accuracy: 0.6461\n",
            "Epoch 58/100, Loss: 13.6939, Validation Accuracy: 0.6929\n",
            "Epoch 59/100, Loss: 12.7192, Validation Accuracy: 0.6082\n",
            "Epoch 60/100, Loss: 19.0115, Validation Accuracy: 0.2502\n",
            "Epoch 61/100, Loss: 33.9520, Validation Accuracy: 0.6401\n",
            "Epoch 62/100, Loss: 33.4457, Validation Accuracy: 0.2762\n",
            "Epoch 63/100, Loss: 110.6664, Validation Accuracy: 0.5294\n",
            "Epoch 64/100, Loss: 18.5409, Validation Accuracy: 0.5523\n",
            "Epoch 65/100, Loss: 20.2094, Validation Accuracy: 0.6770\n",
            "Epoch 66/100, Loss: 25.6755, Validation Accuracy: 0.6002\n",
            "Epoch 67/100, Loss: 23.8441, Validation Accuracy: 0.6022\n",
            "Epoch 68/100, Loss: 135.1776, Validation Accuracy: 0.6441\n",
            "Epoch 69/100, Loss: 31.5784, Validation Accuracy: 0.6002\n",
            "Epoch 70/100, Loss: 32.0448, Validation Accuracy: 0.6152\n",
            "Epoch 71/100, Loss: 12.8608, Validation Accuracy: 0.6301\n",
            "Epoch 72/100, Loss: 66.2839, Validation Accuracy: 0.6241\n",
            "Epoch 73/100, Loss: 53.7923, Validation Accuracy: 0.6600\n",
            "Epoch 74/100, Loss: 8.1834, Validation Accuracy: 0.6012\n",
            "Epoch 75/100, Loss: 11.3313, Validation Accuracy: 0.5892\n",
            "Epoch 76/100, Loss: 11.9638, Validation Accuracy: 0.6112\n",
            "Epoch 77/100, Loss: 11.6912, Validation Accuracy: 0.6520\n",
            "Epoch 78/100, Loss: 61.2145, Validation Accuracy: 0.6331\n",
            "Epoch 79/100, Loss: 35.2104, Validation Accuracy: 0.6152\n",
            "Epoch 80/100, Loss: 23.3099, Validation Accuracy: 0.6062\n",
            "Epoch 81/100, Loss: 50.1158, Validation Accuracy: 0.5623\n",
            "Epoch 82/100, Loss: 11.4436, Validation Accuracy: 0.5932\n",
            "Epoch 83/100, Loss: 13.3504, Validation Accuracy: 0.6680\n",
            "Epoch 84/100, Loss: 16.8247, Validation Accuracy: 0.5992\n",
            "Epoch 85/100, Loss: 27.5332, Validation Accuracy: 0.2951\n",
            "Epoch 86/100, Loss: 47.1174, Validation Accuracy: 0.6032\n",
            "Epoch 87/100, Loss: 22.8160, Validation Accuracy: 0.4367\n",
            "Epoch 88/100, Loss: 20.9238, Validation Accuracy: 0.6481\n",
            "Epoch 89/100, Loss: 97.5674, Validation Accuracy: 0.6471\n",
            "Epoch 90/100, Loss: 27.4079, Validation Accuracy: 0.6560\n",
            "Epoch 91/100, Loss: 18.8765, Validation Accuracy: 0.5115\n",
            "Epoch 92/100, Loss: 96.0570, Validation Accuracy: 0.6311\n",
            "Epoch 93/100, Loss: 22.4075, Validation Accuracy: 0.6281\n",
            "Epoch 94/100, Loss: 11.8248, Validation Accuracy: 0.6760\n",
            "Epoch 95/100, Loss: 19.1934, Validation Accuracy: 0.6371\n",
            "Epoch 96/100, Loss: 19.4119, Validation Accuracy: 0.6431\n",
            "Epoch 97/100, Loss: 33.2783, Validation Accuracy: 0.6650\n",
            "Epoch 98/100, Loss: 45.1427, Validation Accuracy: 0.5444\n",
            "Epoch 99/100, Loss: 17.9847, Validation Accuracy: 0.6600\n",
            "Epoch 100/100, Loss: 58.3063, Validation Accuracy: 0.4975\n",
            "Epoch 101/100, Loss: 41.5588, Validation Accuracy: 0.5404\n",
            "Epoch 102/100, Loss: 38.8146, Validation Accuracy: 0.6102\n",
            "Epoch 103/100, Loss: 15.5007, Validation Accuracy: 0.6311\n",
            "Epoch 104/100, Loss: 21.3258, Validation Accuracy: 0.6381\n",
            "Epoch 105/100, Loss: 13.6399, Validation Accuracy: 0.5404\n",
            "Epoch 106/100, Loss: 81.7636, Validation Accuracy: 0.5793\n",
            "Epoch 107/100, Loss: 33.0707, Validation Accuracy: 0.6062\n",
            "Epoch 108/100, Loss: 39.3343, Validation Accuracy: 0.6241\n",
            "Epoch 109/100, Loss: 15.4761, Validation Accuracy: 0.6012\n",
            "Epoch 110/100, Loss: 51.3731, Validation Accuracy: 0.6112\n",
            "Epoch 111/100, Loss: 102.9551, Validation Accuracy: 0.3470\n",
            "Epoch 112/100, Loss: 30.6860, Validation Accuracy: 0.6211\n",
            "Epoch 113/100, Loss: 2.8480, Validation Accuracy: 0.6730\n",
            "Epoch 114/100, Loss: 17.3323, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 44.2763, Validation Accuracy: 0.6600\n",
            "Epoch 116/100, Loss: 37.1023, Validation Accuracy: 0.4397\n",
            "Epoch 117/100, Loss: 57.6915, Validation Accuracy: 0.6281\n",
            "Epoch 118/100, Loss: 49.5230, Validation Accuracy: 0.6102\n",
            "Epoch 119/100, Loss: 34.1750, Validation Accuracy: 0.5573\n",
            "Epoch 120/100, Loss: 23.2916, Validation Accuracy: 0.5952\n",
            "Epoch 121/100, Loss: 14.9315, Validation Accuracy: 0.5882\n",
            "Epoch 122/100, Loss: 26.2029, Validation Accuracy: 0.5842\n",
            "Epoch 123/100, Loss: 14.5033, Validation Accuracy: 0.6241\n",
            "Epoch 124/100, Loss: 58.5655, Validation Accuracy: 0.6451\n",
            "Epoch 125/100, Loss: 37.0429, Validation Accuracy: 0.5184\n",
            "Epoch 126/100, Loss: 18.7339, Validation Accuracy: 0.5972\n",
            "Epoch 127/100, Loss: 30.0316, Validation Accuracy: 0.6730\n",
            "Epoch 128/100, Loss: 19.9974, Validation Accuracy: 0.5135\n",
            "Epoch 129/100, Loss: 24.3534, Validation Accuracy: 0.6321\n",
            "Epoch 130/100, Loss: 120.5101, Validation Accuracy: 0.4696\n",
            "Epoch 131/100, Loss: 29.6866, Validation Accuracy: 0.5753\n",
            "Epoch 132/100, Loss: 17.9908, Validation Accuracy: 0.6231\n",
            "Epoch 133/100, Loss: 20.9390, Validation Accuracy: 0.6530\n",
            "Epoch 134/100, Loss: 32.4386, Validation Accuracy: 0.6231\n",
            "Epoch 135/100, Loss: 27.1480, Validation Accuracy: 0.6510\n",
            "Epoch 136/100, Loss: 29.4685, Validation Accuracy: 0.6640\n",
            "Epoch 137/100, Loss: 19.0341, Validation Accuracy: 0.5803\n",
            "Epoch 138/100, Loss: 13.7019, Validation Accuracy: 0.5404\n",
            "Epoch 139/100, Loss: 59.2436, Validation Accuracy: 0.4626\n",
            "Epoch 140/100, Loss: 33.7590, Validation Accuracy: 0.5852\n",
            "Epoch 141/100, Loss: 65.1213, Validation Accuracy: 0.5992\n",
            "Epoch 142/100, Loss: 30.8083, Validation Accuracy: 0.5842\n",
            "Epoch 143/100, Loss: 10.7744, Validation Accuracy: 0.5683\n",
            "Epoch 144/100, Loss: 12.6204, Validation Accuracy: 0.6142\n",
            "Epoch 145/100, Loss: 49.8883, Validation Accuracy: 0.5404\n",
            "Epoch 146/100, Loss: 30.3704, Validation Accuracy: 0.5613\n",
            "Epoch 147/100, Loss: 13.3083, Validation Accuracy: 0.6361\n",
            "Epoch 148/100, Loss: 25.0722, Validation Accuracy: 0.6381\n",
            "Epoch 149/100, Loss: 44.0058, Validation Accuracy: 0.5982\n",
            "Epoch 150/100, Loss: 46.5088, Validation Accuracy: 0.6281\n",
            "Epoch 151/100, Loss: 332.9649, Validation Accuracy: 0.5055\n",
            "Epoch 152/100, Loss: 30.7038, Validation Accuracy: 0.5852\n",
            "Epoch 153/100, Loss: 15.9948, Validation Accuracy: 0.6221\n",
            "Epoch 154/100, Loss: 29.7628, Validation Accuracy: 0.5573\n",
            "Epoch 155/100, Loss: 6.8102, Validation Accuracy: 0.5135\n",
            "Epoch 156/100, Loss: 22.3368, Validation Accuracy: 0.6481\n",
            "Epoch 157/100, Loss: 27.5961, Validation Accuracy: 0.5583\n",
            "Epoch 158/100, Loss: 41.7292, Validation Accuracy: 0.5603\n",
            "Epoch 159/100, Loss: 116.0600, Validation Accuracy: 0.4776\n",
            "Epoch 160/100, Loss: 32.1114, Validation Accuracy: 0.4875\n",
            "Epoch 161/100, Loss: 18.2896, Validation Accuracy: 0.5902\n",
            "Epoch 162/100, Loss: 17.1729, Validation Accuracy: 0.5753\n",
            "Epoch 163/100, Loss: 16.3826, Validation Accuracy: 0.6481\n",
            "Epoch 164/100, Loss: 58.3748, Validation Accuracy: 0.6580\n",
            "Epoch 165/100, Loss: 77.2736, Validation Accuracy: 0.5414\n",
            "Epoch 166/100, Loss: 36.4504, Validation Accuracy: 0.6620\n",
            "Epoch 167/100, Loss: 49.7480, Validation Accuracy: 0.5932\n",
            "Epoch 168/100, Loss: 48.8065, Validation Accuracy: 0.6381\n",
            "Epoch 169/100, Loss: 18.3379, Validation Accuracy: 0.5095\n",
            "Epoch 170/100, Loss: 14.6377, Validation Accuracy: 0.6560\n",
            "Epoch 171/100, Loss: 79.4702, Validation Accuracy: 0.6790\n",
            "Epoch 172/100, Loss: 50.9328, Validation Accuracy: 0.6221\n",
            "Epoch 173/100, Loss: 17.6919, Validation Accuracy: 0.6231\n",
            "Epoch 174/100, Loss: 15.1125, Validation Accuracy: 0.6441\n",
            "Epoch 175/100, Loss: 55.4725, Validation Accuracy: 0.6211\n",
            "Epoch 176/100, Loss: 79.1155, Validation Accuracy: 0.6142\n",
            "Epoch 177/100, Loss: 22.5511, Validation Accuracy: 0.6361\n",
            "Epoch 178/100, Loss: 25.7255, Validation Accuracy: 0.6032\n",
            "Epoch 179/100, Loss: 17.6225, Validation Accuracy: 0.6790\n",
            "Epoch 180/100, Loss: 19.3026, Validation Accuracy: 0.6700\n",
            "Epoch 181/100, Loss: 26.2032, Validation Accuracy: 0.6142\n",
            "Epoch 182/100, Loss: 52.7862, Validation Accuracy: 0.5583\n",
            "Epoch 183/100, Loss: 25.4824, Validation Accuracy: 0.6102\n",
            "Epoch 184/100, Loss: 15.9769, Validation Accuracy: 0.6391\n",
            "Epoch 185/100, Loss: 9.3263, Validation Accuracy: 0.5035\n",
            "Epoch 186/100, Loss: 41.1034, Validation Accuracy: 0.5733\n",
            "Epoch 187/100, Loss: 54.4638, Validation Accuracy: 0.5194\n",
            "Epoch 188/100, Loss: 97.0418, Validation Accuracy: 0.5703\n",
            "Epoch 189/100, Loss: 43.6627, Validation Accuracy: 0.6510\n",
            "Epoch 190/100, Loss: 15.6544, Validation Accuracy: 0.5394\n",
            "Epoch 191/100, Loss: 21.9987, Validation Accuracy: 0.5394\n",
            "Epoch 192/100, Loss: 60.8999, Validation Accuracy: 0.5464\n",
            "Epoch 193/100, Loss: 26.8570, Validation Accuracy: 0.6122\n",
            "Epoch 194/100, Loss: 10.8133, Validation Accuracy: 0.6421\n",
            "Epoch 195/100, Loss: 19.6151, Validation Accuracy: 0.5065\n",
            "Epoch 196/100, Loss: 12.5807, Validation Accuracy: 0.5603\n",
            "Epoch 197/100, Loss: 2.1715, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 35.1899, Validation Accuracy: 0.5095\n",
            "Epoch 199/100, Loss: 32.6461, Validation Accuracy: 0.6201\n",
            "Epoch 200/100, Loss: 28.1414, Validation Accuracy: 0.5882\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_75:  {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, [2, 2, 0, 3, 3, 0, 3, 1, 0, 0, 3, 2, 1, 0, 3], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 48, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(84, 48, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(48, 24, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(60, 36, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=96096, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 28, 26]             360\n",
            "       BatchNorm2d-2           [-1, 36, 28, 26]              72\n",
            "            Conv2d-3           [-1, 48, 24, 20]          60,528\n",
            "       BatchNorm2d-4           [-1, 48, 24, 20]              96\n",
            "              ReLU-5           [-1, 48, 24, 20]               0\n",
            "            Conv2d-6           [-1, 48, 26, 24]          36,336\n",
            "       BatchNorm2d-7           [-1, 48, 26, 24]              96\n",
            "              ReLU-8           [-1, 48, 26, 24]               0\n",
            "            Conv2d-9           [-1, 24, 24, 18]          24,216\n",
            "      BatchNorm2d-10           [-1, 24, 24, 18]              48\n",
            "             ReLU-11           [-1, 24, 24, 18]               0\n",
            "           Conv2d-12           [-1, 36, 22, 20]         105,876\n",
            "      BatchNorm2d-13           [-1, 36, 22, 20]              72\n",
            "             ReLU-14           [-1, 36, 22, 20]               0\n",
            "           Linear-15                    [-1, 7]         672,679\n",
            "================================================================\n",
            "Total params: 900,379\n",
            "Trainable params: 900,379\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.21\n",
            "Params size (MB): 3.43\n",
            "Estimated Total Size (MB): 5.66\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 42.4414, Validation Accuracy: 0.6680\n",
            "Epoch 2/100, Loss: 117.1885, Validation Accuracy: 0.4686\n",
            "Epoch 3/100, Loss: 29.7786, Validation Accuracy: 0.6042\n",
            "Epoch 4/100, Loss: 28.8408, Validation Accuracy: 0.3729\n",
            "Epoch 5/100, Loss: 47.9202, Validation Accuracy: 0.6580\n",
            "Epoch 6/100, Loss: 41.2830, Validation Accuracy: 0.1854\n",
            "Epoch 7/100, Loss: 43.1444, Validation Accuracy: 0.3998\n",
            "Epoch 8/100, Loss: 79.9811, Validation Accuracy: 0.5035\n",
            "Epoch 9/100, Loss: 47.0258, Validation Accuracy: 0.6421\n",
            "Epoch 10/100, Loss: 111.9672, Validation Accuracy: 0.4516\n",
            "Epoch 11/100, Loss: 45.1485, Validation Accuracy: 0.4816\n",
            "Epoch 12/100, Loss: 74.1865, Validation Accuracy: 0.6171\n",
            "Epoch 13/100, Loss: 182.2015, Validation Accuracy: 0.5145\n",
            "Epoch 14/100, Loss: 32.0715, Validation Accuracy: 0.5573\n",
            "Epoch 15/100, Loss: 39.5664, Validation Accuracy: 0.6201\n",
            "Epoch 16/100, Loss: 71.9838, Validation Accuracy: 0.5434\n",
            "Epoch 17/100, Loss: 19.2135, Validation Accuracy: 0.3460\n",
            "Epoch 18/100, Loss: 160.6175, Validation Accuracy: 0.6570\n",
            "Epoch 19/100, Loss: 83.8888, Validation Accuracy: 0.4247\n",
            "Epoch 20/100, Loss: 75.6061, Validation Accuracy: 0.6580\n",
            "Epoch 21/100, Loss: 45.8969, Validation Accuracy: 0.5743\n",
            "Epoch 22/100, Loss: 73.6993, Validation Accuracy: 0.6301\n",
            "Epoch 23/100, Loss: 7.9266, Validation Accuracy: 0.4506\n",
            "Epoch 24/100, Loss: 24.7026, Validation Accuracy: 0.5862\n",
            "Epoch 25/100, Loss: 120.9514, Validation Accuracy: 0.4716\n",
            "Epoch 26/100, Loss: 25.2975, Validation Accuracy: 0.6371\n",
            "Epoch 27/100, Loss: 71.0125, Validation Accuracy: 0.6032\n",
            "Epoch 28/100, Loss: 375.6309, Validation Accuracy: 0.3559\n",
            "Epoch 29/100, Loss: 20.9057, Validation Accuracy: 0.6162\n",
            "Epoch 30/100, Loss: 51.0625, Validation Accuracy: 0.5005\n",
            "Epoch 31/100, Loss: 25.7443, Validation Accuracy: 0.6560\n",
            "Epoch 32/100, Loss: 35.7634, Validation Accuracy: 0.5005\n",
            "Epoch 33/100, Loss: 18.7057, Validation Accuracy: 0.6381\n",
            "Epoch 34/100, Loss: 52.2753, Validation Accuracy: 0.6750\n",
            "Epoch 35/100, Loss: 135.2281, Validation Accuracy: 0.5922\n",
            "Epoch 36/100, Loss: 58.6710, Validation Accuracy: 0.6570\n",
            "Epoch 37/100, Loss: 47.8421, Validation Accuracy: 0.5424\n",
            "Epoch 38/100, Loss: 253.3859, Validation Accuracy: 0.6760\n",
            "Epoch 39/100, Loss: 77.4935, Validation Accuracy: 0.6471\n",
            "Epoch 40/100, Loss: 25.0543, Validation Accuracy: 0.6401\n",
            "Epoch 41/100, Loss: 40.5364, Validation Accuracy: 0.6530\n",
            "Epoch 42/100, Loss: 27.7293, Validation Accuracy: 0.6082\n",
            "Epoch 43/100, Loss: 62.6997, Validation Accuracy: 0.6072\n",
            "Epoch 44/100, Loss: 42.2346, Validation Accuracy: 0.5444\n",
            "Epoch 45/100, Loss: 169.0415, Validation Accuracy: 0.5902\n",
            "Epoch 46/100, Loss: 44.3302, Validation Accuracy: 0.5603\n",
            "Epoch 47/100, Loss: 54.2673, Validation Accuracy: 0.6421\n",
            "Epoch 48/100, Loss: 38.5032, Validation Accuracy: 0.6022\n",
            "Epoch 49/100, Loss: 44.0761, Validation Accuracy: 0.6510\n",
            "Epoch 50/100, Loss: 44.2870, Validation Accuracy: 0.4606\n",
            "Epoch 51/100, Loss: 38.8521, Validation Accuracy: 0.6012\n",
            "Epoch 52/100, Loss: 23.0056, Validation Accuracy: 0.6122\n",
            "Epoch 53/100, Loss: 154.0352, Validation Accuracy: 0.6331\n",
            "Epoch 54/100, Loss: 165.6485, Validation Accuracy: 0.5015\n",
            "Epoch 55/100, Loss: 20.5168, Validation Accuracy: 0.6570\n",
            "Epoch 56/100, Loss: 13.1526, Validation Accuracy: 0.5823\n",
            "Epoch 57/100, Loss: 55.8854, Validation Accuracy: 0.6391\n",
            "Epoch 58/100, Loss: 55.6936, Validation Accuracy: 0.6391\n",
            "Epoch 59/100, Loss: 59.3602, Validation Accuracy: 0.5803\n",
            "Epoch 60/100, Loss: 17.2079, Validation Accuracy: 0.5234\n",
            "Epoch 61/100, Loss: 19.6406, Validation Accuracy: 0.5962\n",
            "Epoch 62/100, Loss: 39.0337, Validation Accuracy: 0.5823\n",
            "Epoch 63/100, Loss: 46.2658, Validation Accuracy: 0.6002\n",
            "Epoch 64/100, Loss: 34.3207, Validation Accuracy: 0.5005\n",
            "Epoch 65/100, Loss: 149.2562, Validation Accuracy: 0.4347\n",
            "Epoch 66/100, Loss: 23.6422, Validation Accuracy: 0.5643\n",
            "Epoch 67/100, Loss: 47.0355, Validation Accuracy: 0.6022\n",
            "Epoch 68/100, Loss: 120.3706, Validation Accuracy: 0.6550\n",
            "Epoch 69/100, Loss: 62.4293, Validation Accuracy: 0.5852\n",
            "Epoch 70/100, Loss: 33.0742, Validation Accuracy: 0.6451\n",
            "Epoch 71/100, Loss: 65.1781, Validation Accuracy: 0.6640\n",
            "Epoch 72/100, Loss: 41.2089, Validation Accuracy: 0.6261\n",
            "Epoch 73/100, Loss: 25.9596, Validation Accuracy: 0.6002\n",
            "Epoch 74/100, Loss: 119.8865, Validation Accuracy: 0.6231\n",
            "Epoch 75/100, Loss: 71.1420, Validation Accuracy: 0.6351\n",
            "Epoch 76/100, Loss: 41.7266, Validation Accuracy: 0.6530\n",
            "Epoch 77/100, Loss: 111.6101, Validation Accuracy: 0.6241\n",
            "Epoch 78/100, Loss: 46.6848, Validation Accuracy: 0.6540\n",
            "Epoch 79/100, Loss: 121.7368, Validation Accuracy: 0.2881\n",
            "Epoch 80/100, Loss: 61.8399, Validation Accuracy: 0.5862\n",
            "Epoch 81/100, Loss: 12.9420, Validation Accuracy: 0.6491\n",
            "Epoch 82/100, Loss: 99.6420, Validation Accuracy: 0.6351\n",
            "Epoch 83/100, Loss: 15.1014, Validation Accuracy: 0.6271\n",
            "Epoch 84/100, Loss: 24.4566, Validation Accuracy: 0.5743\n",
            "Epoch 85/100, Loss: 102.3031, Validation Accuracy: 0.6162\n",
            "Epoch 86/100, Loss: 23.6109, Validation Accuracy: 0.6271\n",
            "Epoch 87/100, Loss: 52.7370, Validation Accuracy: 0.6152\n",
            "Epoch 88/100, Loss: 33.9546, Validation Accuracy: 0.5683\n",
            "Epoch 89/100, Loss: 95.6610, Validation Accuracy: 0.5912\n",
            "Epoch 90/100, Loss: 74.7393, Validation Accuracy: 0.6580\n",
            "Epoch 91/100, Loss: 131.0917, Validation Accuracy: 0.6171\n",
            "Epoch 92/100, Loss: 179.1950, Validation Accuracy: 0.6072\n",
            "Epoch 93/100, Loss: 94.5112, Validation Accuracy: 0.4925\n",
            "Epoch 94/100, Loss: 14.1043, Validation Accuracy: 0.5224\n",
            "Epoch 95/100, Loss: 98.2580, Validation Accuracy: 0.5045\n",
            "Epoch 96/100, Loss: 216.5344, Validation Accuracy: 0.5503\n",
            "Epoch 97/100, Loss: 128.2030, Validation Accuracy: 0.6630\n",
            "Epoch 98/100, Loss: 28.2386, Validation Accuracy: 0.6171\n",
            "Epoch 99/100, Loss: 45.1552, Validation Accuracy: 0.5414\n",
            "Epoch 100/100, Loss: 61.6295, Validation Accuracy: 0.6750\n",
            "Epoch 101/100, Loss: 62.6823, Validation Accuracy: 0.5354\n",
            "Epoch 102/100, Loss: 83.2290, Validation Accuracy: 0.5882\n",
            "Epoch 103/100, Loss: 54.1634, Validation Accuracy: 0.5783\n",
            "Epoch 104/100, Loss: 121.8320, Validation Accuracy: 0.3410\n",
            "Epoch 105/100, Loss: 10.5607, Validation Accuracy: 0.5793\n",
            "Epoch 106/100, Loss: 59.6026, Validation Accuracy: 0.6271\n",
            "Epoch 107/100, Loss: 97.0660, Validation Accuracy: 0.6122\n",
            "Epoch 108/100, Loss: 60.4453, Validation Accuracy: 0.5743\n",
            "Epoch 109/100, Loss: 29.2554, Validation Accuracy: 0.5364\n",
            "Epoch 110/100, Loss: 18.8830, Validation Accuracy: 0.4357\n",
            "Epoch 111/100, Loss: 82.1946, Validation Accuracy: 0.4875\n",
            "Epoch 112/100, Loss: 171.3499, Validation Accuracy: 0.6770\n",
            "Epoch 113/100, Loss: 69.6380, Validation Accuracy: 0.5324\n",
            "Epoch 114/100, Loss: 60.7864, Validation Accuracy: 0.6441\n",
            "Epoch 115/100, Loss: 25.6463, Validation Accuracy: 0.5952\n",
            "Epoch 116/100, Loss: 34.6266, Validation Accuracy: 0.6491\n",
            "Epoch 117/100, Loss: 29.3378, Validation Accuracy: 0.4816\n",
            "Epoch 118/100, Loss: 103.0530, Validation Accuracy: 0.6281\n",
            "Epoch 119/100, Loss: 172.1170, Validation Accuracy: 0.5892\n",
            "Epoch 120/100, Loss: 61.8325, Validation Accuracy: 0.5394\n",
            "Epoch 121/100, Loss: 29.3908, Validation Accuracy: 0.6700\n",
            "Epoch 122/100, Loss: 25.9129, Validation Accuracy: 0.6520\n",
            "Epoch 123/100, Loss: 51.7013, Validation Accuracy: 0.5892\n",
            "Epoch 124/100, Loss: 42.1923, Validation Accuracy: 0.3878\n",
            "Epoch 125/100, Loss: 55.1431, Validation Accuracy: 0.5174\n",
            "Epoch 126/100, Loss: 241.0709, Validation Accuracy: 0.6560\n",
            "Epoch 127/100, Loss: 92.3189, Validation Accuracy: 0.5354\n",
            "Epoch 128/100, Loss: 80.7949, Validation Accuracy: 0.5444\n",
            "Epoch 129/100, Loss: 54.3321, Validation Accuracy: 0.5484\n",
            "Epoch 130/100, Loss: 47.3309, Validation Accuracy: 0.6012\n",
            "Epoch 131/100, Loss: 53.2408, Validation Accuracy: 0.5972\n",
            "Epoch 132/100, Loss: 52.4818, Validation Accuracy: 0.6540\n",
            "Epoch 133/100, Loss: 126.3720, Validation Accuracy: 0.5404\n",
            "Epoch 134/100, Loss: 13.2565, Validation Accuracy: 0.6291\n",
            "Epoch 135/100, Loss: 41.5694, Validation Accuracy: 0.6810\n",
            "Epoch 136/100, Loss: 89.9935, Validation Accuracy: 0.4905\n",
            "Epoch 137/100, Loss: 58.1936, Validation Accuracy: 0.6790\n",
            "Epoch 138/100, Loss: 70.2440, Validation Accuracy: 0.5015\n",
            "Epoch 139/100, Loss: 42.3542, Validation Accuracy: 0.6660\n",
            "Epoch 140/100, Loss: 46.6951, Validation Accuracy: 0.6122\n",
            "Epoch 141/100, Loss: 55.7153, Validation Accuracy: 0.5872\n",
            "Epoch 142/100, Loss: 13.2219, Validation Accuracy: 0.5573\n",
            "Epoch 143/100, Loss: 53.3725, Validation Accuracy: 0.6251\n",
            "Epoch 144/100, Loss: 68.8719, Validation Accuracy: 0.5803\n",
            "Epoch 145/100, Loss: 136.5483, Validation Accuracy: 0.6720\n",
            "Epoch 146/100, Loss: 38.9050, Validation Accuracy: 0.4576\n",
            "Epoch 147/100, Loss: 65.2336, Validation Accuracy: 0.6650\n",
            "Epoch 148/100, Loss: 72.7543, Validation Accuracy: 0.6520\n",
            "Epoch 149/100, Loss: 117.8152, Validation Accuracy: 0.4955\n",
            "Epoch 150/100, Loss: 13.1645, Validation Accuracy: 0.6301\n",
            "Epoch 151/100, Loss: 113.9373, Validation Accuracy: 0.6082\n",
            "Epoch 152/100, Loss: 124.4656, Validation Accuracy: 0.5793\n",
            "Epoch 153/100, Loss: 51.5264, Validation Accuracy: 0.5264\n",
            "Epoch 154/100, Loss: 45.4057, Validation Accuracy: 0.6411\n",
            "Epoch 155/100, Loss: 37.9817, Validation Accuracy: 0.6231\n",
            "Epoch 156/100, Loss: 121.4804, Validation Accuracy: 0.6441\n",
            "Epoch 157/100, Loss: 36.0789, Validation Accuracy: 0.5912\n",
            "Epoch 158/100, Loss: 82.4115, Validation Accuracy: 0.6530\n",
            "Epoch 159/100, Loss: 58.3296, Validation Accuracy: 0.5713\n",
            "Epoch 160/100, Loss: 63.9804, Validation Accuracy: 0.6281\n",
            "Epoch 161/100, Loss: 38.0873, Validation Accuracy: 0.5833\n",
            "Epoch 162/100, Loss: 53.2957, Validation Accuracy: 0.3928\n",
            "Epoch 163/100, Loss: 219.0128, Validation Accuracy: 0.5623\n",
            "Epoch 164/100, Loss: 85.7926, Validation Accuracy: 0.5474\n",
            "Epoch 165/100, Loss: 74.1402, Validation Accuracy: 0.6251\n",
            "Epoch 166/100, Loss: 43.2134, Validation Accuracy: 0.6770\n",
            "Epoch 167/100, Loss: 38.4487, Validation Accuracy: 0.6810\n",
            "Epoch 168/100, Loss: 113.2260, Validation Accuracy: 0.4845\n",
            "Epoch 169/100, Loss: 68.5681, Validation Accuracy: 0.4437\n",
            "Epoch 170/100, Loss: 37.6931, Validation Accuracy: 0.6381\n",
            "Epoch 171/100, Loss: 79.7422, Validation Accuracy: 0.5813\n",
            "Epoch 172/100, Loss: 102.2536, Validation Accuracy: 0.4875\n",
            "Epoch 173/100, Loss: 62.3162, Validation Accuracy: 0.5823\n",
            "Epoch 174/100, Loss: 70.9656, Validation Accuracy: 0.5244\n",
            "Epoch 175/100, Loss: 31.5061, Validation Accuracy: 0.6580\n",
            "Epoch 176/100, Loss: 29.9345, Validation Accuracy: 0.5025\n",
            "Epoch 177/100, Loss: 62.4427, Validation Accuracy: 0.6600\n",
            "Epoch 178/100, Loss: 24.3014, Validation Accuracy: 0.5892\n",
            "Epoch 179/100, Loss: 161.2709, Validation Accuracy: 0.6431\n",
            "Epoch 180/100, Loss: 86.1664, Validation Accuracy: 0.5563\n",
            "Epoch 181/100, Loss: 55.1108, Validation Accuracy: 0.5563\n",
            "Epoch 182/100, Loss: 55.9553, Validation Accuracy: 0.6650\n",
            "Epoch 183/100, Loss: 6.3398, Validation Accuracy: 0.5673\n",
            "Epoch 184/100, Loss: 76.1906, Validation Accuracy: 0.6371\n",
            "Epoch 185/100, Loss: 55.3711, Validation Accuracy: 0.5972\n",
            "Epoch 186/100, Loss: 69.3709, Validation Accuracy: 0.6361\n",
            "Epoch 187/100, Loss: 141.0127, Validation Accuracy: 0.5763\n",
            "Epoch 188/100, Loss: 96.4937, Validation Accuracy: 0.5683\n",
            "Epoch 189/100, Loss: 61.3650, Validation Accuracy: 0.5842\n",
            "Epoch 190/100, Loss: 152.7058, Validation Accuracy: 0.5902\n",
            "Epoch 191/100, Loss: 45.1990, Validation Accuracy: 0.5623\n",
            "Epoch 192/100, Loss: 61.3720, Validation Accuracy: 0.6221\n",
            "Epoch 193/100, Loss: 99.4905, Validation Accuracy: 0.5484\n",
            "Epoch 194/100, Loss: 87.0166, Validation Accuracy: 0.5464\n",
            "Epoch 195/100, Loss: 46.1947, Validation Accuracy: 0.6142\n",
            "Epoch 196/100, Loss: 41.5978, Validation Accuracy: 0.6550\n",
            "Epoch 197/100, Loss: 132.5736, Validation Accuracy: 0.6062\n",
            "Epoch 198/100, Loss: 43.6660, Validation Accuracy: 0.5743\n",
            "Epoch 199/100, Loss: 39.0766, Validation Accuracy: 0.6760\n",
            "Epoch 200/100, Loss: 32.3525, Validation Accuracy: 0.6082\n",
            "Reward for Child Model: 0.3088775064099447\n",
            "Child_76:  {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, [0, 1, 1, 2, 3, 2, 1, 1, 2, 1, 3, 0, 3, 3, 1], 0.3088775064099447\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 36, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(72, 24, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(132, 24, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(96, 36, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=137088, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 28, 24]             576\n",
            "       BatchNorm2d-2           [-1, 36, 28, 24]              72\n",
            "            Conv2d-3           [-1, 36, 22, 20]          45,396\n",
            "       BatchNorm2d-4           [-1, 36, 22, 20]              72\n",
            "              ReLU-5           [-1, 36, 22, 20]               0\n",
            "            Conv2d-6           [-1, 24, 22, 22]          36,312\n",
            "       BatchNorm2d-7           [-1, 24, 22, 22]              48\n",
            "              ReLU-8           [-1, 24, 22, 22]               0\n",
            "            Conv2d-9           [-1, 24, 24, 22]          47,544\n",
            "      BatchNorm2d-10           [-1, 24, 24, 22]              48\n",
            "             ReLU-11           [-1, 24, 24, 22]               0\n",
            "           Conv2d-12           [-1, 36, 22, 22]          72,612\n",
            "      BatchNorm2d-13           [-1, 36, 22, 22]              72\n",
            "             ReLU-14           [-1, 36, 22, 22]               0\n",
            "           Linear-15                    [-1, 7]         959,623\n",
            "================================================================\n",
            "Total params: 1,162,375\n",
            "Trainable params: 1,162,375\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.69\n",
            "Params size (MB): 4.43\n",
            "Estimated Total Size (MB): 6.13\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 23.0296, Validation Accuracy: 0.5723\n",
            "Epoch 2/100, Loss: 43.0972, Validation Accuracy: 0.6550\n",
            "Epoch 3/100, Loss: 117.8272, Validation Accuracy: 0.6660\n",
            "Epoch 4/100, Loss: 43.8875, Validation Accuracy: 0.6401\n",
            "Epoch 5/100, Loss: 25.4657, Validation Accuracy: 0.5753\n",
            "Epoch 6/100, Loss: 34.6759, Validation Accuracy: 0.6401\n",
            "Epoch 7/100, Loss: 42.1187, Validation Accuracy: 0.6680\n",
            "Epoch 8/100, Loss: 87.7395, Validation Accuracy: 0.5155\n",
            "Epoch 9/100, Loss: 66.6010, Validation Accuracy: 0.5284\n",
            "Epoch 10/100, Loss: 113.9284, Validation Accuracy: 0.3320\n",
            "Epoch 11/100, Loss: 254.7111, Validation Accuracy: 0.3589\n",
            "Epoch 12/100, Loss: 36.6290, Validation Accuracy: 0.5474\n",
            "Epoch 13/100, Loss: 61.8197, Validation Accuracy: 0.6700\n",
            "Epoch 14/100, Loss: 68.1223, Validation Accuracy: 0.6750\n",
            "Epoch 15/100, Loss: 85.6658, Validation Accuracy: 0.5733\n",
            "Epoch 16/100, Loss: 57.4664, Validation Accuracy: 0.6411\n",
            "Epoch 17/100, Loss: 60.2738, Validation Accuracy: 0.5274\n",
            "Epoch 18/100, Loss: 120.3184, Validation Accuracy: 0.6510\n",
            "Epoch 19/100, Loss: 39.9749, Validation Accuracy: 0.5573\n",
            "Epoch 20/100, Loss: 34.0523, Validation Accuracy: 0.6361\n",
            "Epoch 21/100, Loss: 35.8572, Validation Accuracy: 0.6790\n",
            "Epoch 22/100, Loss: 102.4176, Validation Accuracy: 0.4177\n",
            "Epoch 23/100, Loss: 120.1294, Validation Accuracy: 0.5803\n",
            "Epoch 24/100, Loss: 104.5650, Validation Accuracy: 0.6849\n",
            "Epoch 25/100, Loss: 30.4727, Validation Accuracy: 0.6520\n",
            "Epoch 26/100, Loss: 40.0044, Validation Accuracy: 0.6221\n",
            "Epoch 27/100, Loss: 30.9556, Validation Accuracy: 0.5613\n",
            "Epoch 28/100, Loss: 86.7676, Validation Accuracy: 0.6381\n",
            "Epoch 29/100, Loss: 177.8474, Validation Accuracy: 0.4806\n",
            "Epoch 30/100, Loss: 228.7366, Validation Accuracy: 0.5474\n",
            "Epoch 31/100, Loss: 79.7714, Validation Accuracy: 0.6321\n",
            "Epoch 32/100, Loss: 20.6209, Validation Accuracy: 0.5952\n",
            "Epoch 33/100, Loss: 84.9864, Validation Accuracy: 0.6271\n",
            "Epoch 34/100, Loss: 161.7850, Validation Accuracy: 0.4696\n",
            "Epoch 35/100, Loss: 74.6803, Validation Accuracy: 0.4995\n",
            "Epoch 36/100, Loss: 73.3430, Validation Accuracy: 0.6630\n",
            "Epoch 37/100, Loss: 78.3235, Validation Accuracy: 0.6670\n",
            "Epoch 38/100, Loss: 95.1721, Validation Accuracy: 0.4955\n",
            "Epoch 39/100, Loss: 87.9826, Validation Accuracy: 0.4985\n",
            "Epoch 40/100, Loss: 60.8547, Validation Accuracy: 0.4257\n",
            "Epoch 41/100, Loss: 70.5115, Validation Accuracy: 0.5683\n",
            "Epoch 42/100, Loss: 61.1777, Validation Accuracy: 0.6132\n",
            "Epoch 43/100, Loss: 113.2630, Validation Accuracy: 0.6231\n",
            "Epoch 44/100, Loss: 23.9575, Validation Accuracy: 0.6520\n",
            "Epoch 45/100, Loss: 85.8259, Validation Accuracy: 0.6730\n",
            "Epoch 46/100, Loss: 146.1031, Validation Accuracy: 0.5813\n",
            "Epoch 47/100, Loss: 101.1276, Validation Accuracy: 0.6540\n",
            "Epoch 48/100, Loss: 81.8675, Validation Accuracy: 0.5962\n",
            "Epoch 49/100, Loss: 114.2750, Validation Accuracy: 0.3141\n",
            "Epoch 50/100, Loss: 107.6086, Validation Accuracy: 0.5354\n",
            "Epoch 51/100, Loss: 52.0325, Validation Accuracy: 0.6132\n",
            "Epoch 52/100, Loss: 75.5333, Validation Accuracy: 0.5862\n",
            "Epoch 53/100, Loss: 107.9861, Validation Accuracy: 0.5254\n",
            "Epoch 54/100, Loss: 94.0031, Validation Accuracy: 0.5962\n",
            "Epoch 55/100, Loss: 67.7024, Validation Accuracy: 0.5613\n",
            "Epoch 56/100, Loss: 44.0843, Validation Accuracy: 0.6640\n",
            "Epoch 57/100, Loss: 115.6781, Validation Accuracy: 0.6530\n",
            "Epoch 58/100, Loss: 31.8795, Validation Accuracy: 0.6191\n",
            "Epoch 59/100, Loss: 82.4051, Validation Accuracy: 0.3928\n",
            "Epoch 60/100, Loss: 127.9627, Validation Accuracy: 0.6630\n",
            "Epoch 61/100, Loss: 63.6109, Validation Accuracy: 0.5892\n",
            "Epoch 62/100, Loss: 64.7492, Validation Accuracy: 0.3031\n",
            "Epoch 63/100, Loss: 79.8958, Validation Accuracy: 0.6401\n",
            "Epoch 64/100, Loss: 77.4084, Validation Accuracy: 0.5444\n",
            "Epoch 65/100, Loss: 73.9387, Validation Accuracy: 0.5982\n",
            "Epoch 66/100, Loss: 75.4267, Validation Accuracy: 0.4965\n",
            "Epoch 67/100, Loss: 184.1826, Validation Accuracy: 0.4606\n",
            "Epoch 68/100, Loss: 139.5564, Validation Accuracy: 0.6401\n",
            "Epoch 69/100, Loss: 161.9063, Validation Accuracy: 0.6271\n",
            "Epoch 70/100, Loss: 80.2315, Validation Accuracy: 0.4556\n",
            "Epoch 71/100, Loss: 32.4222, Validation Accuracy: 0.6181\n",
            "Epoch 72/100, Loss: 48.4374, Validation Accuracy: 0.6780\n",
            "Epoch 73/100, Loss: 22.9635, Validation Accuracy: 0.6012\n",
            "Epoch 74/100, Loss: 93.5343, Validation Accuracy: 0.5095\n",
            "Epoch 75/100, Loss: 26.4210, Validation Accuracy: 0.4806\n",
            "Epoch 76/100, Loss: 306.8476, Validation Accuracy: 0.5842\n",
            "Epoch 77/100, Loss: 67.6475, Validation Accuracy: 0.6221\n",
            "Epoch 78/100, Loss: 46.6337, Validation Accuracy: 0.6730\n",
            "Epoch 79/100, Loss: 43.5201, Validation Accuracy: 0.5852\n",
            "Epoch 80/100, Loss: 168.6367, Validation Accuracy: 0.5264\n",
            "Epoch 81/100, Loss: 34.6378, Validation Accuracy: 0.5922\n",
            "Epoch 82/100, Loss: 205.3673, Validation Accuracy: 0.6780\n",
            "Epoch 83/100, Loss: 75.2959, Validation Accuracy: 0.5464\n",
            "Epoch 84/100, Loss: 100.4638, Validation Accuracy: 0.6620\n",
            "Epoch 85/100, Loss: 64.8888, Validation Accuracy: 0.6321\n",
            "Epoch 86/100, Loss: 85.4519, Validation Accuracy: 0.5623\n",
            "Epoch 87/100, Loss: 128.3468, Validation Accuracy: 0.5344\n",
            "Epoch 88/100, Loss: 156.2060, Validation Accuracy: 0.5932\n",
            "Epoch 89/100, Loss: 146.7389, Validation Accuracy: 0.4845\n",
            "Epoch 90/100, Loss: 89.0258, Validation Accuracy: 0.6500\n",
            "Epoch 91/100, Loss: 96.3738, Validation Accuracy: 0.6491\n",
            "Epoch 92/100, Loss: 134.5066, Validation Accuracy: 0.4516\n",
            "Epoch 93/100, Loss: 89.2521, Validation Accuracy: 0.5533\n",
            "Epoch 94/100, Loss: 56.9268, Validation Accuracy: 0.5892\n",
            "Epoch 95/100, Loss: 64.6910, Validation Accuracy: 0.5364\n",
            "Epoch 96/100, Loss: 117.7284, Validation Accuracy: 0.5125\n",
            "Epoch 97/100, Loss: 110.5019, Validation Accuracy: 0.6630\n",
            "Epoch 98/100, Loss: 75.6724, Validation Accuracy: 0.4287\n",
            "Epoch 99/100, Loss: 192.4650, Validation Accuracy: 0.5992\n",
            "Epoch 100/100, Loss: 61.4864, Validation Accuracy: 0.5813\n",
            "Epoch 101/100, Loss: 268.0424, Validation Accuracy: 0.5733\n",
            "Epoch 102/100, Loss: 101.8326, Validation Accuracy: 0.6171\n",
            "Epoch 103/100, Loss: 133.9426, Validation Accuracy: 0.6820\n",
            "Epoch 104/100, Loss: 83.7999, Validation Accuracy: 0.6122\n",
            "Epoch 105/100, Loss: 55.9246, Validation Accuracy: 0.5394\n",
            "Epoch 106/100, Loss: 105.3264, Validation Accuracy: 0.5673\n",
            "Epoch 107/100, Loss: 90.9044, Validation Accuracy: 0.6211\n",
            "Epoch 108/100, Loss: 123.4608, Validation Accuracy: 0.6540\n",
            "Epoch 109/100, Loss: 102.4716, Validation Accuracy: 0.6191\n",
            "Epoch 110/100, Loss: 63.7763, Validation Accuracy: 0.4497\n",
            "Epoch 111/100, Loss: 159.5154, Validation Accuracy: 0.4148\n",
            "Epoch 112/100, Loss: 219.6729, Validation Accuracy: 0.4477\n",
            "Epoch 113/100, Loss: 26.3207, Validation Accuracy: 0.5942\n",
            "Epoch 114/100, Loss: 58.7703, Validation Accuracy: 0.4816\n",
            "Epoch 115/100, Loss: 40.9058, Validation Accuracy: 0.6122\n",
            "Epoch 116/100, Loss: 93.1516, Validation Accuracy: 0.5304\n",
            "Epoch 117/100, Loss: 106.0224, Validation Accuracy: 0.6072\n",
            "Epoch 118/100, Loss: 83.8263, Validation Accuracy: 0.5244\n",
            "Epoch 119/100, Loss: 132.6311, Validation Accuracy: 0.4865\n",
            "Epoch 120/100, Loss: 164.9389, Validation Accuracy: 0.5912\n",
            "Epoch 121/100, Loss: 92.1088, Validation Accuracy: 0.6231\n",
            "Epoch 122/100, Loss: 160.5857, Validation Accuracy: 0.6471\n",
            "Epoch 123/100, Loss: 52.5022, Validation Accuracy: 0.6461\n",
            "Epoch 124/100, Loss: 6.9922, Validation Accuracy: 0.6331\n",
            "Epoch 125/100, Loss: 59.6529, Validation Accuracy: 0.5693\n",
            "Epoch 126/100, Loss: 162.9657, Validation Accuracy: 0.4686\n",
            "Epoch 127/100, Loss: 89.8594, Validation Accuracy: 0.5982\n",
            "Epoch 128/100, Loss: 32.6978, Validation Accuracy: 0.4885\n",
            "Epoch 129/100, Loss: 91.6324, Validation Accuracy: 0.6421\n",
            "Epoch 130/100, Loss: 78.2312, Validation Accuracy: 0.4347\n",
            "Epoch 131/100, Loss: 128.2337, Validation Accuracy: 0.6590\n",
            "Epoch 132/100, Loss: 276.1318, Validation Accuracy: 0.5872\n",
            "Epoch 133/100, Loss: 158.3537, Validation Accuracy: 0.6520\n",
            "Epoch 134/100, Loss: 45.5717, Validation Accuracy: 0.3609\n",
            "Epoch 135/100, Loss: 80.8728, Validation Accuracy: 0.6191\n",
            "Epoch 136/100, Loss: 80.9702, Validation Accuracy: 0.6271\n",
            "Epoch 137/100, Loss: 197.1426, Validation Accuracy: 0.3918\n",
            "Epoch 138/100, Loss: 111.5291, Validation Accuracy: 0.6610\n",
            "Epoch 139/100, Loss: 39.6262, Validation Accuracy: 0.5045\n",
            "Epoch 140/100, Loss: 105.7970, Validation Accuracy: 0.5593\n",
            "Epoch 141/100, Loss: 39.1700, Validation Accuracy: 0.6730\n",
            "Epoch 142/100, Loss: 60.8738, Validation Accuracy: 0.6421\n",
            "Epoch 143/100, Loss: 130.2637, Validation Accuracy: 0.6271\n",
            "Epoch 144/100, Loss: 100.2447, Validation Accuracy: 0.6142\n",
            "Epoch 145/100, Loss: 172.9094, Validation Accuracy: 0.4337\n",
            "Epoch 146/100, Loss: 71.6852, Validation Accuracy: 0.6112\n",
            "Epoch 147/100, Loss: 83.7599, Validation Accuracy: 0.6550\n",
            "Epoch 148/100, Loss: 245.8499, Validation Accuracy: 0.5085\n",
            "Epoch 149/100, Loss: 79.6358, Validation Accuracy: 0.5703\n",
            "Epoch 150/100, Loss: 26.7043, Validation Accuracy: 0.4905\n",
            "Epoch 151/100, Loss: 106.0733, Validation Accuracy: 0.6481\n",
            "Epoch 152/100, Loss: 70.5141, Validation Accuracy: 0.5773\n",
            "Epoch 153/100, Loss: 179.1170, Validation Accuracy: 0.6231\n",
            "Epoch 154/100, Loss: 101.9619, Validation Accuracy: 0.6481\n",
            "Epoch 155/100, Loss: 83.3583, Validation Accuracy: 0.6032\n",
            "Epoch 156/100, Loss: 100.1582, Validation Accuracy: 0.6321\n",
            "Epoch 157/100, Loss: 230.3019, Validation Accuracy: 0.6271\n",
            "Epoch 158/100, Loss: 63.1075, Validation Accuracy: 0.6032\n",
            "Epoch 159/100, Loss: 150.8276, Validation Accuracy: 0.5494\n",
            "Epoch 160/100, Loss: 77.1395, Validation Accuracy: 0.6461\n",
            "Epoch 161/100, Loss: 73.3431, Validation Accuracy: 0.5882\n",
            "Epoch 162/100, Loss: 47.5996, Validation Accuracy: 0.6461\n",
            "Epoch 163/100, Loss: 11.6082, Validation Accuracy: 0.6132\n",
            "Epoch 164/100, Loss: 75.1769, Validation Accuracy: 0.6810\n",
            "Epoch 165/100, Loss: 104.3675, Validation Accuracy: 0.5045\n",
            "Epoch 166/100, Loss: 88.2724, Validation Accuracy: 0.5543\n",
            "Epoch 167/100, Loss: 63.5920, Validation Accuracy: 0.6431\n",
            "Epoch 168/100, Loss: 73.6899, Validation Accuracy: 0.6291\n",
            "Epoch 169/100, Loss: 22.8867, Validation Accuracy: 0.6162\n",
            "Epoch 170/100, Loss: 48.1192, Validation Accuracy: 0.5025\n",
            "Epoch 171/100, Loss: 96.4424, Validation Accuracy: 0.6371\n",
            "Epoch 172/100, Loss: 171.3931, Validation Accuracy: 0.6590\n",
            "Epoch 173/100, Loss: 52.6450, Validation Accuracy: 0.6152\n",
            "Epoch 174/100, Loss: 46.1578, Validation Accuracy: 0.6281\n",
            "Epoch 175/100, Loss: 42.7623, Validation Accuracy: 0.6381\n",
            "Epoch 176/100, Loss: 81.4534, Validation Accuracy: 0.5294\n",
            "Epoch 177/100, Loss: 69.3664, Validation Accuracy: 0.6421\n",
            "Epoch 178/100, Loss: 82.7932, Validation Accuracy: 0.5165\n",
            "Epoch 179/100, Loss: 51.1252, Validation Accuracy: 0.6152\n",
            "Epoch 180/100, Loss: 98.0976, Validation Accuracy: 0.2393\n",
            "Epoch 181/100, Loss: 113.1610, Validation Accuracy: 0.6171\n",
            "Epoch 182/100, Loss: 102.8396, Validation Accuracy: 0.5553\n",
            "Epoch 183/100, Loss: 44.4766, Validation Accuracy: 0.5942\n",
            "Epoch 184/100, Loss: 134.1194, Validation Accuracy: 0.6540\n",
            "Epoch 185/100, Loss: 36.6969, Validation Accuracy: 0.6411\n",
            "Epoch 186/100, Loss: 211.0446, Validation Accuracy: 0.6580\n",
            "Epoch 187/100, Loss: 51.0754, Validation Accuracy: 0.5494\n",
            "Epoch 188/100, Loss: 377.0490, Validation Accuracy: 0.5733\n",
            "Epoch 189/100, Loss: 75.5693, Validation Accuracy: 0.6072\n",
            "Epoch 190/100, Loss: 82.8540, Validation Accuracy: 0.6431\n",
            "Epoch 191/100, Loss: 50.0310, Validation Accuracy: 0.4177\n",
            "Epoch 192/100, Loss: 44.5187, Validation Accuracy: 0.6461\n",
            "Epoch 193/100, Loss: 44.4351, Validation Accuracy: 0.5334\n",
            "Epoch 194/100, Loss: 120.6605, Validation Accuracy: 0.6421\n",
            "Epoch 195/100, Loss: 78.9190, Validation Accuracy: 0.5613\n",
            "Epoch 196/100, Loss: 56.8397, Validation Accuracy: 0.6510\n",
            "Epoch 197/100, Loss: 350.2602, Validation Accuracy: 0.6201\n",
            "Epoch 198/100, Loss: 29.0422, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 59.2056, Validation Accuracy: 0.6421\n",
            "Epoch 200/100, Loss: 148.1410, Validation Accuracy: 0.6062\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_77:  {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, [0, 2, 1, 3, 2, 1, 3, 1, 0, 2, 1, 0, 3, 1, 1], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 24, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(88, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(112, 64, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(264, 24, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=254176, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 26, 26]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 26, 26]             128\n",
            "            Conv2d-3           [-1, 24, 24, 26]           4,632\n",
            "       BatchNorm2d-4           [-1, 24, 24, 26]              48\n",
            "              ReLU-5           [-1, 24, 24, 26]               0\n",
            "            Conv2d-6           [-1, 48, 24, 26]          12,720\n",
            "       BatchNorm2d-7           [-1, 48, 24, 26]              96\n",
            "              ReLU-8           [-1, 48, 24, 26]               0\n",
            "            Conv2d-9           [-1, 64, 26, 22]          35,904\n",
            "      BatchNorm2d-10           [-1, 64, 26, 22]             128\n",
            "             ReLU-11           [-1, 64, 26, 22]               0\n",
            "           Conv2d-12           [-1, 24, 24, 22]          95,064\n",
            "      BatchNorm2d-13           [-1, 24, 24, 22]              48\n",
            "             ReLU-14           [-1, 24, 24, 22]               0\n",
            "           Linear-15                    [-1, 7]       1,779,239\n",
            "================================================================\n",
            "Total params: 1,929,799\n",
            "Trainable params: 1,929,799\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.82\n",
            "Params size (MB): 7.36\n",
            "Estimated Total Size (MB): 10.19\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 77.9039, Validation Accuracy: 0.6142\n",
            "Epoch 2/100, Loss: 60.9185, Validation Accuracy: 0.4756\n",
            "Epoch 3/100, Loss: 106.2411, Validation Accuracy: 0.6500\n",
            "Epoch 4/100, Loss: 60.3499, Validation Accuracy: 0.3280\n",
            "Epoch 5/100, Loss: 221.9702, Validation Accuracy: 0.5155\n",
            "Epoch 6/100, Loss: 102.6380, Validation Accuracy: 0.4536\n",
            "Epoch 7/100, Loss: 187.6813, Validation Accuracy: 0.4586\n",
            "Epoch 8/100, Loss: 135.4033, Validation Accuracy: 0.2273\n",
            "Epoch 9/100, Loss: 125.4945, Validation Accuracy: 0.5703\n",
            "Epoch 10/100, Loss: 32.1106, Validation Accuracy: 0.5025\n",
            "Epoch 11/100, Loss: 42.2005, Validation Accuracy: 0.6351\n",
            "Epoch 12/100, Loss: 79.2887, Validation Accuracy: 0.6291\n",
            "Epoch 13/100, Loss: 76.6743, Validation Accuracy: 0.5414\n",
            "Epoch 14/100, Loss: 43.7006, Validation Accuracy: 0.6241\n",
            "Epoch 15/100, Loss: 181.7915, Validation Accuracy: 0.5982\n",
            "Epoch 16/100, Loss: 331.1064, Validation Accuracy: 0.5523\n",
            "Epoch 17/100, Loss: 303.0656, Validation Accuracy: 0.6491\n",
            "Epoch 18/100, Loss: 75.0323, Validation Accuracy: 0.4028\n",
            "Epoch 19/100, Loss: 202.8343, Validation Accuracy: 0.6800\n",
            "Epoch 20/100, Loss: 522.0685, Validation Accuracy: 0.6431\n",
            "Epoch 21/100, Loss: 221.3595, Validation Accuracy: 0.6441\n",
            "Epoch 22/100, Loss: 77.1585, Validation Accuracy: 0.6191\n",
            "Epoch 23/100, Loss: 143.1498, Validation Accuracy: 0.6142\n",
            "Epoch 24/100, Loss: 274.7351, Validation Accuracy: 0.3848\n",
            "Epoch 25/100, Loss: 182.6875, Validation Accuracy: 0.6271\n",
            "Epoch 26/100, Loss: 161.6302, Validation Accuracy: 0.5533\n",
            "Epoch 27/100, Loss: 173.8304, Validation Accuracy: 0.5204\n",
            "Epoch 28/100, Loss: 161.1078, Validation Accuracy: 0.5813\n",
            "Epoch 29/100, Loss: 110.7957, Validation Accuracy: 0.6510\n",
            "Epoch 30/100, Loss: 82.2740, Validation Accuracy: 0.5823\n",
            "Epoch 31/100, Loss: 104.5433, Validation Accuracy: 0.6002\n",
            "Epoch 32/100, Loss: 239.6787, Validation Accuracy: 0.5663\n",
            "Epoch 33/100, Loss: 110.8010, Validation Accuracy: 0.6391\n",
            "Epoch 34/100, Loss: 291.2168, Validation Accuracy: 0.5912\n",
            "Epoch 35/100, Loss: 253.7938, Validation Accuracy: 0.6012\n",
            "Epoch 36/100, Loss: 534.3992, Validation Accuracy: 0.6351\n",
            "Epoch 37/100, Loss: 116.5021, Validation Accuracy: 0.5254\n",
            "Epoch 38/100, Loss: 117.7296, Validation Accuracy: 0.6471\n",
            "Epoch 39/100, Loss: 81.4037, Validation Accuracy: 0.5842\n",
            "Epoch 40/100, Loss: 258.9771, Validation Accuracy: 0.6590\n",
            "Epoch 41/100, Loss: 383.4083, Validation Accuracy: 0.4656\n",
            "Epoch 42/100, Loss: 182.5937, Validation Accuracy: 0.3230\n",
            "Epoch 43/100, Loss: 239.5233, Validation Accuracy: 0.6032\n",
            "Epoch 44/100, Loss: 149.4134, Validation Accuracy: 0.5982\n",
            "Epoch 45/100, Loss: 140.3327, Validation Accuracy: 0.6072\n",
            "Epoch 46/100, Loss: 292.0104, Validation Accuracy: 0.6181\n",
            "Epoch 47/100, Loss: 276.6834, Validation Accuracy: 0.6162\n",
            "Epoch 48/100, Loss: 147.2458, Validation Accuracy: 0.6052\n",
            "Epoch 49/100, Loss: 221.8322, Validation Accuracy: 0.6630\n",
            "Epoch 50/100, Loss: 78.9785, Validation Accuracy: 0.5274\n",
            "Epoch 51/100, Loss: 79.4579, Validation Accuracy: 0.6401\n",
            "Epoch 52/100, Loss: 391.0295, Validation Accuracy: 0.6152\n",
            "Epoch 53/100, Loss: 213.1959, Validation Accuracy: 0.5892\n",
            "Epoch 54/100, Loss: 161.8974, Validation Accuracy: 0.5723\n",
            "Epoch 55/100, Loss: 118.5517, Validation Accuracy: 0.5603\n",
            "Epoch 56/100, Loss: 310.1355, Validation Accuracy: 0.5982\n",
            "Epoch 57/100, Loss: 104.9607, Validation Accuracy: 0.6530\n",
            "Epoch 58/100, Loss: 449.0327, Validation Accuracy: 0.6471\n",
            "Epoch 59/100, Loss: 63.1853, Validation Accuracy: 0.6620\n",
            "Epoch 60/100, Loss: 324.3219, Validation Accuracy: 0.5683\n",
            "Epoch 61/100, Loss: 257.7683, Validation Accuracy: 0.4716\n",
            "Epoch 62/100, Loss: 199.5247, Validation Accuracy: 0.5145\n",
            "Epoch 63/100, Loss: 188.9361, Validation Accuracy: 0.6052\n",
            "Epoch 64/100, Loss: 144.3359, Validation Accuracy: 0.6441\n",
            "Epoch 65/100, Loss: 297.0385, Validation Accuracy: 0.6072\n",
            "Epoch 66/100, Loss: 209.6304, Validation Accuracy: 0.6112\n",
            "Epoch 67/100, Loss: 170.0478, Validation Accuracy: 0.6311\n",
            "Epoch 68/100, Loss: 94.5876, Validation Accuracy: 0.6520\n",
            "Epoch 69/100, Loss: 244.9146, Validation Accuracy: 0.4835\n",
            "Epoch 70/100, Loss: 128.3847, Validation Accuracy: 0.5673\n",
            "Epoch 71/100, Loss: 260.9102, Validation Accuracy: 0.5304\n",
            "Epoch 72/100, Loss: 265.4895, Validation Accuracy: 0.4845\n",
            "Epoch 73/100, Loss: 217.3550, Validation Accuracy: 0.6142\n",
            "Epoch 74/100, Loss: 130.1717, Validation Accuracy: 0.5623\n",
            "Epoch 75/100, Loss: 279.3450, Validation Accuracy: 0.6152\n",
            "Epoch 76/100, Loss: 124.6026, Validation Accuracy: 0.6780\n",
            "Epoch 77/100, Loss: 705.1163, Validation Accuracy: 0.6351\n",
            "Epoch 78/100, Loss: 105.1792, Validation Accuracy: 0.6431\n",
            "Epoch 79/100, Loss: 360.5263, Validation Accuracy: 0.6730\n",
            "Epoch 80/100, Loss: 535.1115, Validation Accuracy: 0.5982\n",
            "Epoch 81/100, Loss: 135.1061, Validation Accuracy: 0.6042\n",
            "Epoch 82/100, Loss: 218.6008, Validation Accuracy: 0.4905\n",
            "Epoch 83/100, Loss: 303.5311, Validation Accuracy: 0.5663\n",
            "Epoch 84/100, Loss: 302.6694, Validation Accuracy: 0.5284\n",
            "Epoch 85/100, Loss: 125.5710, Validation Accuracy: 0.5693\n",
            "Epoch 86/100, Loss: 183.4291, Validation Accuracy: 0.5374\n",
            "Epoch 87/100, Loss: 145.5896, Validation Accuracy: 0.5314\n",
            "Epoch 88/100, Loss: 126.5994, Validation Accuracy: 0.5972\n",
            "Epoch 89/100, Loss: 188.4276, Validation Accuracy: 0.5703\n",
            "Epoch 90/100, Loss: 80.2296, Validation Accuracy: 0.5653\n",
            "Epoch 91/100, Loss: 508.5224, Validation Accuracy: 0.6012\n",
            "Epoch 92/100, Loss: 557.1409, Validation Accuracy: 0.6152\n",
            "Epoch 93/100, Loss: 107.0912, Validation Accuracy: 0.6261\n",
            "Epoch 94/100, Loss: 175.2620, Validation Accuracy: 0.6191\n",
            "Epoch 95/100, Loss: 407.1699, Validation Accuracy: 0.6331\n",
            "Epoch 96/100, Loss: 198.9969, Validation Accuracy: 0.6221\n",
            "Epoch 97/100, Loss: 67.2901, Validation Accuracy: 0.6351\n",
            "Epoch 98/100, Loss: 268.8465, Validation Accuracy: 0.6321\n",
            "Epoch 99/100, Loss: 139.4212, Validation Accuracy: 0.6371\n",
            "Epoch 100/100, Loss: 146.1679, Validation Accuracy: 0.5922\n",
            "Epoch 101/100, Loss: 84.8045, Validation Accuracy: 0.5484\n",
            "Epoch 102/100, Loss: 221.2717, Validation Accuracy: 0.4686\n",
            "Epoch 103/100, Loss: 143.1205, Validation Accuracy: 0.6361\n",
            "Epoch 104/100, Loss: 336.1615, Validation Accuracy: 0.5952\n",
            "Epoch 105/100, Loss: 222.5916, Validation Accuracy: 0.4307\n",
            "Epoch 106/100, Loss: 243.1161, Validation Accuracy: 0.5653\n",
            "Epoch 107/100, Loss: 119.1306, Validation Accuracy: 0.6650\n",
            "Epoch 108/100, Loss: 185.0973, Validation Accuracy: 0.6042\n",
            "Epoch 109/100, Loss: 186.3560, Validation Accuracy: 0.3878\n",
            "Epoch 110/100, Loss: 292.1337, Validation Accuracy: 0.6361\n",
            "Epoch 111/100, Loss: 156.0207, Validation Accuracy: 0.5693\n",
            "Epoch 112/100, Loss: 173.3331, Validation Accuracy: 0.6610\n",
            "Epoch 113/100, Loss: 193.5865, Validation Accuracy: 0.5005\n",
            "Epoch 114/100, Loss: 129.5271, Validation Accuracy: 0.5833\n",
            "Epoch 115/100, Loss: 177.7935, Validation Accuracy: 0.6142\n",
            "Epoch 116/100, Loss: 111.5680, Validation Accuracy: 0.6510\n",
            "Epoch 117/100, Loss: 148.9785, Validation Accuracy: 0.6471\n",
            "Epoch 118/100, Loss: 260.1441, Validation Accuracy: 0.6022\n",
            "Epoch 119/100, Loss: 440.5569, Validation Accuracy: 0.5284\n",
            "Epoch 120/100, Loss: 269.9936, Validation Accuracy: 0.6311\n",
            "Epoch 121/100, Loss: 164.7101, Validation Accuracy: 0.5902\n",
            "Epoch 122/100, Loss: 53.4249, Validation Accuracy: 0.6421\n",
            "Epoch 123/100, Loss: 248.5908, Validation Accuracy: 0.6381\n",
            "Epoch 124/100, Loss: 202.2387, Validation Accuracy: 0.6032\n",
            "Epoch 125/100, Loss: 201.5743, Validation Accuracy: 0.6022\n",
            "Epoch 126/100, Loss: 126.7676, Validation Accuracy: 0.6231\n",
            "Epoch 127/100, Loss: 140.7596, Validation Accuracy: 0.6012\n",
            "Epoch 128/100, Loss: 337.3459, Validation Accuracy: 0.5982\n",
            "Epoch 129/100, Loss: 460.4505, Validation Accuracy: 0.5294\n",
            "Epoch 130/100, Loss: 110.4641, Validation Accuracy: 0.6132\n",
            "Epoch 131/100, Loss: 139.8479, Validation Accuracy: 0.6052\n",
            "Epoch 132/100, Loss: 107.7328, Validation Accuracy: 0.6570\n",
            "Epoch 133/100, Loss: 183.1636, Validation Accuracy: 0.5414\n",
            "Epoch 134/100, Loss: 182.2007, Validation Accuracy: 0.6092\n",
            "Epoch 135/100, Loss: 461.7292, Validation Accuracy: 0.6062\n",
            "Epoch 136/100, Loss: 498.7502, Validation Accuracy: 0.6650\n",
            "Epoch 137/100, Loss: 353.3718, Validation Accuracy: 0.5284\n",
            "Epoch 138/100, Loss: 674.2943, Validation Accuracy: 0.5314\n",
            "Epoch 139/100, Loss: 305.2668, Validation Accuracy: 0.5513\n",
            "Epoch 140/100, Loss: 354.3548, Validation Accuracy: 0.6660\n",
            "Epoch 141/100, Loss: 196.2169, Validation Accuracy: 0.5653\n",
            "Epoch 142/100, Loss: 358.1717, Validation Accuracy: 0.5852\n",
            "Epoch 143/100, Loss: 265.6060, Validation Accuracy: 0.4925\n",
            "Epoch 144/100, Loss: 261.8002, Validation Accuracy: 0.6451\n",
            "Epoch 145/100, Loss: 400.6244, Validation Accuracy: 0.6211\n",
            "Epoch 146/100, Loss: 88.6742, Validation Accuracy: 0.6461\n",
            "Epoch 147/100, Loss: 127.8830, Validation Accuracy: 0.6241\n",
            "Epoch 148/100, Loss: 182.4226, Validation Accuracy: 0.5922\n",
            "Epoch 149/100, Loss: 261.4485, Validation Accuracy: 0.6491\n",
            "Epoch 150/100, Loss: 127.9895, Validation Accuracy: 0.6181\n",
            "Epoch 151/100, Loss: 104.9226, Validation Accuracy: 0.5962\n",
            "Epoch 152/100, Loss: 224.3505, Validation Accuracy: 0.6012\n",
            "Epoch 153/100, Loss: 89.8209, Validation Accuracy: 0.5932\n",
            "Epoch 154/100, Loss: 744.6063, Validation Accuracy: 0.5663\n",
            "Epoch 155/100, Loss: 375.3346, Validation Accuracy: 0.6311\n",
            "Epoch 156/100, Loss: 134.1610, Validation Accuracy: 0.5972\n",
            "Epoch 157/100, Loss: 384.2404, Validation Accuracy: 0.5773\n",
            "Epoch 158/100, Loss: 94.9011, Validation Accuracy: 0.5962\n",
            "Epoch 159/100, Loss: 59.2510, Validation Accuracy: 0.5813\n",
            "Epoch 160/100, Loss: 212.3515, Validation Accuracy: 0.6461\n",
            "Epoch 161/100, Loss: 207.1918, Validation Accuracy: 0.6421\n",
            "Epoch 162/100, Loss: 87.7698, Validation Accuracy: 0.6082\n",
            "Epoch 163/100, Loss: 327.4728, Validation Accuracy: 0.6361\n",
            "Epoch 164/100, Loss: 97.9554, Validation Accuracy: 0.5653\n",
            "Epoch 165/100, Loss: 273.2450, Validation Accuracy: 0.5713\n",
            "Epoch 166/100, Loss: 220.0903, Validation Accuracy: 0.6351\n",
            "Epoch 167/100, Loss: 505.3041, Validation Accuracy: 0.6162\n",
            "Epoch 168/100, Loss: 150.1103, Validation Accuracy: 0.6471\n",
            "Epoch 169/100, Loss: 183.5057, Validation Accuracy: 0.6022\n",
            "Epoch 170/100, Loss: 140.2486, Validation Accuracy: 0.6022\n",
            "Epoch 171/100, Loss: 33.3450, Validation Accuracy: 0.6122\n",
            "Epoch 172/100, Loss: 509.3328, Validation Accuracy: 0.4566\n",
            "Epoch 173/100, Loss: 166.9926, Validation Accuracy: 0.5683\n",
            "Epoch 174/100, Loss: 259.5501, Validation Accuracy: 0.6361\n",
            "Epoch 175/100, Loss: 517.9307, Validation Accuracy: 0.5503\n",
            "Epoch 176/100, Loss: 157.8273, Validation Accuracy: 0.6152\n",
            "Epoch 177/100, Loss: 159.7734, Validation Accuracy: 0.6660\n",
            "Epoch 178/100, Loss: 198.5114, Validation Accuracy: 0.5992\n",
            "Epoch 179/100, Loss: 279.9231, Validation Accuracy: 0.5773\n",
            "Epoch 180/100, Loss: 361.1420, Validation Accuracy: 0.6052\n",
            "Epoch 181/100, Loss: 397.8426, Validation Accuracy: 0.5454\n",
            "Epoch 182/100, Loss: 385.3803, Validation Accuracy: 0.6401\n",
            "Epoch 183/100, Loss: 53.9879, Validation Accuracy: 0.6481\n",
            "Epoch 184/100, Loss: 392.4079, Validation Accuracy: 0.6181\n",
            "Epoch 185/100, Loss: 181.3674, Validation Accuracy: 0.6211\n",
            "Epoch 186/100, Loss: 273.1908, Validation Accuracy: 0.5982\n",
            "Epoch 187/100, Loss: 335.4584, Validation Accuracy: 0.5952\n",
            "Epoch 188/100, Loss: 392.0969, Validation Accuracy: 0.5803\n",
            "Epoch 189/100, Loss: 145.6160, Validation Accuracy: 0.6351\n",
            "Epoch 190/100, Loss: 152.1858, Validation Accuracy: 0.5563\n",
            "Epoch 191/100, Loss: 135.2799, Validation Accuracy: 0.5713\n",
            "Epoch 192/100, Loss: 334.2839, Validation Accuracy: 0.6072\n",
            "Epoch 193/100, Loss: 293.6058, Validation Accuracy: 0.6012\n",
            "Epoch 194/100, Loss: 144.8559, Validation Accuracy: 0.5833\n",
            "Epoch 195/100, Loss: 175.7238, Validation Accuracy: 0.5613\n",
            "Epoch 196/100, Loss: 121.7491, Validation Accuracy: 0.5852\n",
            "Epoch 197/100, Loss: 109.0419, Validation Accuracy: 0.6301\n",
            "Epoch 198/100, Loss: 272.4172, Validation Accuracy: 0.4826\n",
            "Epoch 199/100, Loss: 109.0669, Validation Accuracy: 0.5025\n",
            "Epoch 200/100, Loss: 65.7249, Validation Accuracy: 0.5793\n",
            "Reward for Child Model: 0.25017760797798727\n",
            "Child_78:  {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, [1, 1, 3, 1, 0, 0, 1, 0, 2, 0, 2, 3, 1, 2, 0], 0.25017760797798727\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 48, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(112, 36, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(212, 24, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(200, 48, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=186624, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 24, 24]           4,864\n",
            "       BatchNorm2d-2           [-1, 64, 24, 24]             128\n",
            "            Conv2d-3           [-1, 48, 20, 20]          76,848\n",
            "       BatchNorm2d-4           [-1, 48, 20, 20]              96\n",
            "              ReLU-5           [-1, 48, 20, 20]               0\n",
            "            Conv2d-6           [-1, 36, 18, 24]          28,260\n",
            "       BatchNorm2d-7           [-1, 36, 18, 24]              72\n",
            "              ReLU-8           [-1, 36, 18, 24]               0\n",
            "            Conv2d-9           [-1, 24, 22, 20]          76,344\n",
            "      BatchNorm2d-10           [-1, 24, 22, 20]              48\n",
            "             ReLU-11           [-1, 24, 22, 20]               0\n",
            "           Conv2d-12           [-1, 48, 24, 22]          28,848\n",
            "      BatchNorm2d-13           [-1, 48, 24, 22]              96\n",
            "             ReLU-14           [-1, 48, 24, 22]               0\n",
            "           Linear-15                    [-1, 7]       1,306,375\n",
            "================================================================\n",
            "Total params: 1,521,979\n",
            "Trainable params: 1,521,979\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.18\n",
            "Params size (MB): 5.81\n",
            "Estimated Total Size (MB): 7.99\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 59.6502, Validation Accuracy: 0.6181\n",
            "Epoch 2/100, Loss: 41.6650, Validation Accuracy: 0.4786\n",
            "Epoch 3/100, Loss: 161.5967, Validation Accuracy: 0.4646\n",
            "Epoch 4/100, Loss: 139.6338, Validation Accuracy: 0.5354\n",
            "Epoch 5/100, Loss: 89.4266, Validation Accuracy: 0.5573\n",
            "Epoch 6/100, Loss: 600.8624, Validation Accuracy: 0.2682\n",
            "Epoch 7/100, Loss: 115.7702, Validation Accuracy: 0.5234\n",
            "Epoch 8/100, Loss: 53.4060, Validation Accuracy: 0.5683\n",
            "Epoch 9/100, Loss: 61.3781, Validation Accuracy: 0.4217\n",
            "Epoch 10/100, Loss: 49.7926, Validation Accuracy: 0.2712\n",
            "Epoch 11/100, Loss: 276.1242, Validation Accuracy: 0.6700\n",
            "Epoch 12/100, Loss: 163.6231, Validation Accuracy: 0.4566\n",
            "Epoch 13/100, Loss: 63.6925, Validation Accuracy: 0.4287\n",
            "Epoch 14/100, Loss: 131.2695, Validation Accuracy: 0.6540\n",
            "Epoch 15/100, Loss: 216.7227, Validation Accuracy: 0.5872\n",
            "Epoch 16/100, Loss: 227.9788, Validation Accuracy: 0.6281\n",
            "Epoch 17/100, Loss: 400.1665, Validation Accuracy: 0.6102\n",
            "Epoch 18/100, Loss: 10.5451, Validation Accuracy: 0.5174\n",
            "Epoch 19/100, Loss: 52.1254, Validation Accuracy: 0.5693\n",
            "Epoch 20/100, Loss: 137.9865, Validation Accuracy: 0.5204\n",
            "Epoch 21/100, Loss: 198.5591, Validation Accuracy: 0.4447\n",
            "Epoch 22/100, Loss: 104.1470, Validation Accuracy: 0.4506\n",
            "Epoch 23/100, Loss: 79.0544, Validation Accuracy: 0.4367\n",
            "Epoch 24/100, Loss: 197.2727, Validation Accuracy: 0.6221\n",
            "Epoch 25/100, Loss: 174.0816, Validation Accuracy: 0.6082\n",
            "Epoch 26/100, Loss: 152.5578, Validation Accuracy: 0.6510\n",
            "Epoch 27/100, Loss: 95.5896, Validation Accuracy: 0.6241\n",
            "Epoch 28/100, Loss: 445.6625, Validation Accuracy: 0.5962\n",
            "Epoch 29/100, Loss: 34.1380, Validation Accuracy: 0.6142\n",
            "Epoch 30/100, Loss: 173.6853, Validation Accuracy: 0.6331\n",
            "Epoch 31/100, Loss: 229.9750, Validation Accuracy: 0.6730\n",
            "Epoch 32/100, Loss: 154.9351, Validation Accuracy: 0.5673\n",
            "Epoch 33/100, Loss: 138.0013, Validation Accuracy: 0.5354\n",
            "Epoch 34/100, Loss: 312.6947, Validation Accuracy: 0.6700\n",
            "Epoch 35/100, Loss: 208.8213, Validation Accuracy: 0.6670\n",
            "Epoch 36/100, Loss: 190.8416, Validation Accuracy: 0.6919\n",
            "Epoch 37/100, Loss: 86.7150, Validation Accuracy: 0.5862\n",
            "Epoch 38/100, Loss: 81.2288, Validation Accuracy: 0.2802\n",
            "Epoch 39/100, Loss: 15.4817, Validation Accuracy: 0.5892\n",
            "Epoch 40/100, Loss: 36.9906, Validation Accuracy: 0.5852\n",
            "Epoch 41/100, Loss: 231.5742, Validation Accuracy: 0.2652\n",
            "Epoch 42/100, Loss: 135.2068, Validation Accuracy: 0.5713\n",
            "Epoch 43/100, Loss: 93.8111, Validation Accuracy: 0.6530\n",
            "Epoch 44/100, Loss: 35.3639, Validation Accuracy: 0.6899\n",
            "Epoch 45/100, Loss: 68.2672, Validation Accuracy: 0.6730\n",
            "Epoch 46/100, Loss: 182.1174, Validation Accuracy: 0.5165\n",
            "Epoch 47/100, Loss: 113.9710, Validation Accuracy: 0.5663\n",
            "Epoch 48/100, Loss: 512.7296, Validation Accuracy: 0.5543\n",
            "Epoch 49/100, Loss: 212.6759, Validation Accuracy: 0.5543\n",
            "Epoch 50/100, Loss: 136.1431, Validation Accuracy: 0.6949\n",
            "Epoch 51/100, Loss: 90.5400, Validation Accuracy: 0.5773\n",
            "Epoch 52/100, Loss: 133.8461, Validation Accuracy: 0.6221\n",
            "Epoch 53/100, Loss: 47.6086, Validation Accuracy: 0.5693\n",
            "Epoch 54/100, Loss: 87.9364, Validation Accuracy: 0.5693\n",
            "Epoch 55/100, Loss: 945.8967, Validation Accuracy: 0.5165\n",
            "Epoch 56/100, Loss: 128.4566, Validation Accuracy: 0.5902\n",
            "Epoch 57/100, Loss: 93.4438, Validation Accuracy: 0.6331\n",
            "Epoch 58/100, Loss: 48.4210, Validation Accuracy: 0.6102\n",
            "Epoch 59/100, Loss: 53.0391, Validation Accuracy: 0.6331\n",
            "Epoch 60/100, Loss: 135.8989, Validation Accuracy: 0.6750\n",
            "Epoch 61/100, Loss: 195.3201, Validation Accuracy: 0.5424\n",
            "Epoch 62/100, Loss: 144.2500, Validation Accuracy: 0.1755\n",
            "Epoch 63/100, Loss: 194.2785, Validation Accuracy: 0.6760\n",
            "Epoch 64/100, Loss: 140.2311, Validation Accuracy: 0.5533\n",
            "Epoch 65/100, Loss: 127.3395, Validation Accuracy: 0.6919\n",
            "Epoch 66/100, Loss: 79.0949, Validation Accuracy: 0.6201\n",
            "Epoch 67/100, Loss: 137.9501, Validation Accuracy: 0.5763\n",
            "Epoch 68/100, Loss: 200.6479, Validation Accuracy: 0.6301\n",
            "Epoch 69/100, Loss: 157.0560, Validation Accuracy: 0.5274\n",
            "Epoch 70/100, Loss: 158.4250, Validation Accuracy: 0.6461\n",
            "Epoch 71/100, Loss: 33.4812, Validation Accuracy: 0.6790\n",
            "Epoch 72/100, Loss: 124.5198, Validation Accuracy: 0.6800\n",
            "Epoch 73/100, Loss: 165.8886, Validation Accuracy: 0.3948\n",
            "Epoch 74/100, Loss: 102.8425, Validation Accuracy: 0.6361\n",
            "Epoch 75/100, Loss: 170.4617, Validation Accuracy: 0.6331\n",
            "Epoch 76/100, Loss: 168.3150, Validation Accuracy: 0.5972\n",
            "Epoch 77/100, Loss: 104.7231, Validation Accuracy: 0.5683\n",
            "Epoch 78/100, Loss: 64.5543, Validation Accuracy: 0.6391\n",
            "Epoch 79/100, Loss: 188.0699, Validation Accuracy: 0.5872\n",
            "Epoch 80/100, Loss: 87.7718, Validation Accuracy: 0.6401\n",
            "Epoch 81/100, Loss: 164.1805, Validation Accuracy: 0.6770\n",
            "Epoch 82/100, Loss: 77.9277, Validation Accuracy: 0.6461\n",
            "Epoch 83/100, Loss: 160.4924, Validation Accuracy: 0.5234\n",
            "Epoch 84/100, Loss: 32.7267, Validation Accuracy: 0.6371\n",
            "Epoch 85/100, Loss: 70.5379, Validation Accuracy: 0.6869\n",
            "Epoch 86/100, Loss: 107.6643, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 184.8452, Validation Accuracy: 0.5194\n",
            "Epoch 88/100, Loss: 283.1056, Validation Accuracy: 0.6381\n",
            "Epoch 89/100, Loss: 145.2111, Validation Accuracy: 0.6022\n",
            "Epoch 90/100, Loss: 96.0169, Validation Accuracy: 0.5533\n",
            "Epoch 91/100, Loss: 51.4943, Validation Accuracy: 0.4267\n",
            "Epoch 92/100, Loss: 143.2466, Validation Accuracy: 0.6730\n",
            "Epoch 93/100, Loss: 173.7876, Validation Accuracy: 0.6790\n",
            "Epoch 94/100, Loss: 149.9739, Validation Accuracy: 0.4965\n",
            "Epoch 95/100, Loss: 21.8255, Validation Accuracy: 0.5573\n",
            "Epoch 96/100, Loss: 169.7755, Validation Accuracy: 0.5962\n",
            "Epoch 97/100, Loss: 108.5739, Validation Accuracy: 0.5533\n",
            "Epoch 98/100, Loss: 263.0576, Validation Accuracy: 0.6600\n",
            "Epoch 99/100, Loss: 156.0070, Validation Accuracy: 0.6171\n",
            "Epoch 100/100, Loss: 70.4776, Validation Accuracy: 0.5603\n",
            "Epoch 101/100, Loss: 422.1261, Validation Accuracy: 0.5334\n",
            "Epoch 102/100, Loss: 46.8483, Validation Accuracy: 0.6640\n",
            "Epoch 103/100, Loss: 214.1987, Validation Accuracy: 0.6540\n",
            "Epoch 104/100, Loss: 97.0194, Validation Accuracy: 0.5444\n",
            "Epoch 105/100, Loss: 368.7906, Validation Accuracy: 0.6780\n",
            "Epoch 106/100, Loss: 84.2948, Validation Accuracy: 0.6540\n",
            "Epoch 107/100, Loss: 90.6388, Validation Accuracy: 0.5773\n",
            "Epoch 108/100, Loss: 114.0578, Validation Accuracy: 0.5384\n",
            "Epoch 109/100, Loss: 70.4854, Validation Accuracy: 0.3988\n",
            "Epoch 110/100, Loss: 66.5019, Validation Accuracy: 0.6471\n",
            "Epoch 111/100, Loss: 282.0536, Validation Accuracy: 0.5573\n",
            "Epoch 112/100, Loss: 11.4524, Validation Accuracy: 0.6790\n",
            "Epoch 113/100, Loss: 63.0579, Validation Accuracy: 0.6022\n",
            "Epoch 114/100, Loss: 84.0424, Validation Accuracy: 0.6810\n",
            "Epoch 115/100, Loss: 77.6685, Validation Accuracy: 0.5095\n",
            "Epoch 116/100, Loss: 156.9243, Validation Accuracy: 0.6720\n",
            "Epoch 117/100, Loss: 63.1064, Validation Accuracy: 0.5484\n",
            "Epoch 118/100, Loss: 224.7604, Validation Accuracy: 0.5693\n",
            "Epoch 119/100, Loss: 130.7222, Validation Accuracy: 0.6810\n",
            "Epoch 120/100, Loss: 95.4148, Validation Accuracy: 0.6102\n",
            "Epoch 121/100, Loss: 425.1906, Validation Accuracy: 0.5833\n",
            "Epoch 122/100, Loss: 191.5184, Validation Accuracy: 0.6790\n",
            "Epoch 123/100, Loss: 81.2436, Validation Accuracy: 0.5174\n",
            "Epoch 124/100, Loss: 106.9529, Validation Accuracy: 0.5214\n",
            "Epoch 125/100, Loss: 113.8889, Validation Accuracy: 0.6341\n",
            "Epoch 126/100, Loss: 1276.4365, Validation Accuracy: 0.6839\n",
            "Epoch 127/100, Loss: 109.1838, Validation Accuracy: 0.6281\n",
            "Epoch 128/100, Loss: 81.2817, Validation Accuracy: 0.6152\n",
            "Epoch 129/100, Loss: 33.6929, Validation Accuracy: 0.5135\n",
            "Epoch 130/100, Loss: 162.7432, Validation Accuracy: 0.6510\n",
            "Epoch 131/100, Loss: 119.6377, Validation Accuracy: 0.5882\n",
            "Epoch 132/100, Loss: 79.9199, Validation Accuracy: 0.7149\n",
            "Epoch 133/100, Loss: 159.8726, Validation Accuracy: 0.5174\n",
            "Epoch 134/100, Loss: 109.3545, Validation Accuracy: 0.6062\n",
            "Epoch 135/100, Loss: 85.5056, Validation Accuracy: 0.5583\n",
            "Epoch 136/100, Loss: 63.3711, Validation Accuracy: 0.4287\n",
            "Epoch 137/100, Loss: 295.0217, Validation Accuracy: 0.6062\n",
            "Epoch 138/100, Loss: 32.7533, Validation Accuracy: 0.5912\n",
            "Epoch 139/100, Loss: 57.9697, Validation Accuracy: 0.6092\n",
            "Epoch 140/100, Loss: 27.0154, Validation Accuracy: 0.5972\n",
            "Epoch 141/100, Loss: 101.2702, Validation Accuracy: 0.6431\n",
            "Epoch 142/100, Loss: 77.6601, Validation Accuracy: 0.6710\n",
            "Epoch 143/100, Loss: 126.6186, Validation Accuracy: 0.6839\n",
            "Epoch 144/100, Loss: 75.8383, Validation Accuracy: 0.5563\n",
            "Epoch 145/100, Loss: 356.3590, Validation Accuracy: 0.5842\n",
            "Epoch 146/100, Loss: 43.6412, Validation Accuracy: 0.6331\n",
            "Epoch 147/100, Loss: 55.4220, Validation Accuracy: 0.6600\n",
            "Epoch 148/100, Loss: 65.5038, Validation Accuracy: 0.6411\n",
            "Epoch 149/100, Loss: 55.2150, Validation Accuracy: 0.3898\n",
            "Epoch 150/100, Loss: 118.9171, Validation Accuracy: 0.6810\n",
            "Epoch 151/100, Loss: 307.1273, Validation Accuracy: 0.2752\n",
            "Epoch 152/100, Loss: 151.4837, Validation Accuracy: 0.5813\n",
            "Epoch 153/100, Loss: 302.5883, Validation Accuracy: 0.5384\n",
            "Epoch 154/100, Loss: 65.9146, Validation Accuracy: 0.6620\n",
            "Epoch 155/100, Loss: 42.9443, Validation Accuracy: 0.5952\n",
            "Epoch 156/100, Loss: 95.9802, Validation Accuracy: 0.6530\n",
            "Epoch 157/100, Loss: 179.3927, Validation Accuracy: 0.5922\n",
            "Epoch 158/100, Loss: 50.3271, Validation Accuracy: 0.6600\n",
            "Epoch 159/100, Loss: 104.0950, Validation Accuracy: 0.6820\n",
            "Epoch 160/100, Loss: 168.0266, Validation Accuracy: 0.6341\n",
            "Epoch 161/100, Loss: 157.1104, Validation Accuracy: 0.6640\n",
            "Epoch 162/100, Loss: 57.1474, Validation Accuracy: 0.5733\n",
            "Epoch 163/100, Loss: 71.5328, Validation Accuracy: 0.6949\n",
            "Epoch 164/100, Loss: 81.4026, Validation Accuracy: 0.6012\n",
            "Epoch 165/100, Loss: 14.3258, Validation Accuracy: 0.6351\n",
            "Epoch 166/100, Loss: 224.8549, Validation Accuracy: 0.5653\n",
            "Epoch 167/100, Loss: 96.2650, Validation Accuracy: 0.6271\n",
            "Epoch 168/100, Loss: 114.6612, Validation Accuracy: 0.5982\n",
            "Epoch 169/100, Loss: 164.6128, Validation Accuracy: 0.4237\n",
            "Epoch 170/100, Loss: 164.3569, Validation Accuracy: 0.6221\n",
            "Epoch 171/100, Loss: 238.7143, Validation Accuracy: 0.6830\n",
            "Epoch 172/100, Loss: 33.5410, Validation Accuracy: 0.6461\n",
            "Epoch 173/100, Loss: 301.8662, Validation Accuracy: 0.6710\n",
            "Epoch 174/100, Loss: 45.5469, Validation Accuracy: 0.6610\n",
            "Epoch 175/100, Loss: 65.0937, Validation Accuracy: 0.2881\n",
            "Epoch 176/100, Loss: 184.8678, Validation Accuracy: 0.6241\n",
            "Epoch 177/100, Loss: 156.1121, Validation Accuracy: 0.5693\n",
            "Epoch 178/100, Loss: 114.3114, Validation Accuracy: 0.6062\n",
            "Epoch 179/100, Loss: 289.1203, Validation Accuracy: 0.6431\n",
            "Epoch 180/100, Loss: 294.5051, Validation Accuracy: 0.5603\n",
            "Epoch 181/100, Loss: 195.7734, Validation Accuracy: 0.6371\n",
            "Epoch 182/100, Loss: 79.5466, Validation Accuracy: 0.6660\n",
            "Epoch 183/100, Loss: 98.5376, Validation Accuracy: 0.5693\n",
            "Epoch 184/100, Loss: 211.2688, Validation Accuracy: 0.6301\n",
            "Epoch 185/100, Loss: 172.3869, Validation Accuracy: 0.5354\n",
            "Epoch 186/100, Loss: 123.7472, Validation Accuracy: 0.5523\n",
            "Epoch 187/100, Loss: 116.7689, Validation Accuracy: 0.6181\n",
            "Epoch 188/100, Loss: 136.5440, Validation Accuracy: 0.6510\n",
            "Epoch 189/100, Loss: 102.8805, Validation Accuracy: 0.6640\n",
            "Epoch 190/100, Loss: 78.4835, Validation Accuracy: 0.5932\n",
            "Epoch 191/100, Loss: 200.2146, Validation Accuracy: 0.6371\n",
            "Epoch 192/100, Loss: 50.5921, Validation Accuracy: 0.6241\n",
            "Epoch 193/100, Loss: 63.3166, Validation Accuracy: 0.6371\n",
            "Epoch 194/100, Loss: 71.6854, Validation Accuracy: 0.5912\n",
            "Epoch 195/100, Loss: 50.5665, Validation Accuracy: 0.6251\n",
            "Epoch 196/100, Loss: 164.9730, Validation Accuracy: 0.6231\n",
            "Epoch 197/100, Loss: 120.4958, Validation Accuracy: 0.6590\n",
            "Epoch 198/100, Loss: 114.9084, Validation Accuracy: 0.6710\n",
            "Epoch 199/100, Loss: 361.2000, Validation Accuracy: 0.5085\n",
            "Epoch 200/100, Loss: 50.9405, Validation Accuracy: 0.5284\n",
            "Reward for Child Model: 0.30209420445979795\n",
            "Child_79:  {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, [2, 2, 3, 2, 2, 2, 3, 0, 1, 1, 2, 0, 0, 1, 2], 0.30209420445979795\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(88, 36, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(188, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(64, 36, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=78400, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 28, 28]             256\n",
            "       BatchNorm2d-2           [-1, 64, 28, 28]             128\n",
            "            Conv2d-3           [-1, 24, 28, 28]           1,560\n",
            "       BatchNorm2d-4           [-1, 24, 28, 28]              48\n",
            "              ReLU-5           [-1, 24, 28, 28]               0\n",
            "            Conv2d-6           [-1, 36, 28, 24]          15,876\n",
            "       BatchNorm2d-7           [-1, 36, 28, 24]              72\n",
            "              ReLU-8           [-1, 36, 28, 24]               0\n",
            "            Conv2d-9           [-1, 64, 24, 28]          60,224\n",
            "      BatchNorm2d-10           [-1, 64, 24, 28]             128\n",
            "             ReLU-11           [-1, 64, 24, 28]               0\n",
            "           Conv2d-12           [-1, 36, 24, 28]           2,340\n",
            "      BatchNorm2d-13           [-1, 36, 24, 28]              72\n",
            "             ReLU-14           [-1, 36, 24, 28]               0\n",
            "           Linear-15                    [-1, 7]         548,807\n",
            "================================================================\n",
            "Total params: 629,511\n",
            "Trainable params: 629,511\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.29\n",
            "Params size (MB): 2.40\n",
            "Estimated Total Size (MB): 5.70\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 16.7971, Validation Accuracy: 0.3749\n",
            "Epoch 2/100, Loss: 102.7957, Validation Accuracy: 0.6321\n",
            "Epoch 3/100, Loss: 23.7019, Validation Accuracy: 0.6730\n",
            "Epoch 4/100, Loss: 19.9426, Validation Accuracy: 0.6201\n",
            "Epoch 5/100, Loss: 24.0466, Validation Accuracy: 0.6331\n",
            "Epoch 6/100, Loss: 135.4073, Validation Accuracy: 0.5444\n",
            "Epoch 7/100, Loss: 38.1940, Validation Accuracy: 0.5005\n",
            "Epoch 8/100, Loss: 28.0364, Validation Accuracy: 0.4317\n",
            "Epoch 9/100, Loss: 23.9729, Validation Accuracy: 0.6431\n",
            "Epoch 10/100, Loss: 77.3848, Validation Accuracy: 0.4377\n",
            "Epoch 11/100, Loss: 158.3120, Validation Accuracy: 0.3848\n",
            "Epoch 12/100, Loss: 26.9891, Validation Accuracy: 0.5374\n",
            "Epoch 13/100, Loss: 28.6357, Validation Accuracy: 0.6371\n",
            "Epoch 14/100, Loss: 50.4527, Validation Accuracy: 0.6859\n",
            "Epoch 15/100, Loss: 26.8661, Validation Accuracy: 0.5753\n",
            "Epoch 16/100, Loss: 15.1992, Validation Accuracy: 0.5194\n",
            "Epoch 17/100, Loss: 23.5116, Validation Accuracy: 0.4656\n",
            "Epoch 18/100, Loss: 106.9150, Validation Accuracy: 0.4865\n",
            "Epoch 19/100, Loss: 36.7643, Validation Accuracy: 0.6640\n",
            "Epoch 20/100, Loss: 65.3550, Validation Accuracy: 0.5882\n",
            "Epoch 21/100, Loss: 45.3328, Validation Accuracy: 0.6261\n",
            "Epoch 22/100, Loss: 87.6259, Validation Accuracy: 0.5972\n",
            "Epoch 23/100, Loss: 60.7929, Validation Accuracy: 0.4716\n",
            "Epoch 24/100, Loss: 63.1421, Validation Accuracy: 0.5155\n",
            "Epoch 25/100, Loss: 40.1864, Validation Accuracy: 0.6102\n",
            "Epoch 26/100, Loss: 61.4110, Validation Accuracy: 0.5214\n",
            "Epoch 27/100, Loss: 98.4340, Validation Accuracy: 0.5155\n",
            "Epoch 28/100, Loss: 103.3430, Validation Accuracy: 0.6052\n",
            "Epoch 29/100, Loss: 71.7323, Validation Accuracy: 0.2483\n",
            "Epoch 30/100, Loss: 69.7708, Validation Accuracy: 0.4746\n",
            "Epoch 31/100, Loss: 13.9766, Validation Accuracy: 0.6032\n",
            "Epoch 32/100, Loss: 69.4013, Validation Accuracy: 0.6780\n",
            "Epoch 33/100, Loss: 125.3832, Validation Accuracy: 0.5972\n",
            "Epoch 34/100, Loss: 83.2149, Validation Accuracy: 0.5833\n",
            "Epoch 35/100, Loss: 52.7489, Validation Accuracy: 0.6670\n",
            "Epoch 36/100, Loss: 59.2714, Validation Accuracy: 0.6431\n",
            "Epoch 37/100, Loss: 73.1480, Validation Accuracy: 0.6072\n",
            "Epoch 38/100, Loss: 88.6666, Validation Accuracy: 0.5424\n",
            "Epoch 39/100, Loss: 46.5336, Validation Accuracy: 0.5643\n",
            "Epoch 40/100, Loss: 44.0809, Validation Accuracy: 0.5204\n",
            "Epoch 41/100, Loss: 41.9069, Validation Accuracy: 0.6660\n",
            "Epoch 42/100, Loss: 30.2097, Validation Accuracy: 0.6381\n",
            "Epoch 43/100, Loss: 19.2304, Validation Accuracy: 0.6869\n",
            "Epoch 44/100, Loss: 58.8673, Validation Accuracy: 0.6640\n",
            "Epoch 45/100, Loss: 53.5296, Validation Accuracy: 0.6760\n",
            "Epoch 46/100, Loss: 143.6645, Validation Accuracy: 0.6092\n",
            "Epoch 47/100, Loss: 59.5527, Validation Accuracy: 0.2293\n",
            "Epoch 48/100, Loss: 57.4003, Validation Accuracy: 0.6730\n",
            "Epoch 49/100, Loss: 33.9622, Validation Accuracy: 0.6191\n",
            "Epoch 50/100, Loss: 50.5627, Validation Accuracy: 0.5902\n",
            "Epoch 51/100, Loss: 48.4053, Validation Accuracy: 0.6491\n",
            "Epoch 52/100, Loss: 86.9056, Validation Accuracy: 0.6580\n",
            "Epoch 53/100, Loss: 56.1977, Validation Accuracy: 0.5613\n",
            "Epoch 54/100, Loss: 57.4556, Validation Accuracy: 0.6331\n",
            "Epoch 55/100, Loss: 157.6006, Validation Accuracy: 0.4925\n",
            "Epoch 56/100, Loss: 22.3948, Validation Accuracy: 0.6411\n",
            "Epoch 57/100, Loss: 49.9728, Validation Accuracy: 0.4955\n",
            "Epoch 58/100, Loss: 65.3843, Validation Accuracy: 0.5533\n",
            "Epoch 59/100, Loss: 32.5010, Validation Accuracy: 0.6381\n",
            "Epoch 60/100, Loss: 46.5517, Validation Accuracy: 0.4467\n",
            "Epoch 61/100, Loss: 26.4721, Validation Accuracy: 0.6162\n",
            "Epoch 62/100, Loss: 143.5511, Validation Accuracy: 0.6122\n",
            "Epoch 63/100, Loss: 120.8760, Validation Accuracy: 0.4975\n",
            "Epoch 64/100, Loss: 60.8660, Validation Accuracy: 0.6371\n",
            "Epoch 65/100, Loss: 70.3713, Validation Accuracy: 0.5344\n",
            "Epoch 66/100, Loss: 26.7065, Validation Accuracy: 0.6520\n",
            "Epoch 67/100, Loss: 48.2321, Validation Accuracy: 0.6191\n",
            "Epoch 68/100, Loss: 15.9461, Validation Accuracy: 0.6191\n",
            "Epoch 69/100, Loss: 37.8483, Validation Accuracy: 0.6590\n",
            "Epoch 70/100, Loss: 45.5909, Validation Accuracy: 0.6221\n",
            "Epoch 71/100, Loss: 83.6679, Validation Accuracy: 0.6171\n",
            "Epoch 72/100, Loss: 29.5229, Validation Accuracy: 0.5364\n",
            "Epoch 73/100, Loss: 65.0814, Validation Accuracy: 0.5095\n",
            "Epoch 74/100, Loss: 60.2773, Validation Accuracy: 0.6201\n",
            "Epoch 75/100, Loss: 19.7667, Validation Accuracy: 0.5523\n",
            "Epoch 76/100, Loss: 71.2851, Validation Accuracy: 0.6251\n",
            "Epoch 77/100, Loss: 131.6857, Validation Accuracy: 0.6012\n",
            "Epoch 78/100, Loss: 166.1351, Validation Accuracy: 0.6162\n",
            "Epoch 79/100, Loss: 84.9119, Validation Accuracy: 0.6700\n",
            "Epoch 80/100, Loss: 35.9815, Validation Accuracy: 0.5962\n",
            "Epoch 81/100, Loss: 16.7272, Validation Accuracy: 0.5583\n",
            "Epoch 82/100, Loss: 24.0281, Validation Accuracy: 0.5404\n",
            "Epoch 83/100, Loss: 83.2338, Validation Accuracy: 0.5304\n",
            "Epoch 84/100, Loss: 86.2639, Validation Accuracy: 0.6341\n",
            "Epoch 85/100, Loss: 34.7347, Validation Accuracy: 0.6381\n",
            "Epoch 86/100, Loss: 145.3625, Validation Accuracy: 0.5344\n",
            "Epoch 87/100, Loss: 105.3436, Validation Accuracy: 0.5214\n",
            "Epoch 88/100, Loss: 99.7728, Validation Accuracy: 0.6431\n",
            "Epoch 89/100, Loss: 77.5210, Validation Accuracy: 0.6391\n",
            "Epoch 90/100, Loss: 49.7342, Validation Accuracy: 0.6680\n",
            "Epoch 91/100, Loss: 17.1588, Validation Accuracy: 0.6142\n",
            "Epoch 92/100, Loss: 81.9800, Validation Accuracy: 0.6520\n",
            "Epoch 93/100, Loss: 106.6025, Validation Accuracy: 0.6152\n",
            "Epoch 94/100, Loss: 101.8308, Validation Accuracy: 0.5703\n",
            "Epoch 95/100, Loss: 81.0149, Validation Accuracy: 0.6431\n",
            "Epoch 96/100, Loss: 62.4728, Validation Accuracy: 0.6171\n",
            "Epoch 97/100, Loss: 41.3424, Validation Accuracy: 0.5623\n",
            "Epoch 98/100, Loss: 81.9043, Validation Accuracy: 0.6441\n",
            "Epoch 99/100, Loss: 159.9878, Validation Accuracy: 0.6132\n",
            "Epoch 100/100, Loss: 55.4650, Validation Accuracy: 0.2712\n",
            "Epoch 101/100, Loss: 15.2525, Validation Accuracy: 0.6291\n",
            "Epoch 102/100, Loss: 80.8002, Validation Accuracy: 0.6191\n",
            "Epoch 103/100, Loss: 124.5949, Validation Accuracy: 0.5992\n",
            "Epoch 104/100, Loss: 86.3101, Validation Accuracy: 0.6032\n",
            "Epoch 105/100, Loss: 59.1834, Validation Accuracy: 0.5813\n",
            "Epoch 106/100, Loss: 60.0664, Validation Accuracy: 0.5095\n",
            "Epoch 107/100, Loss: 44.2513, Validation Accuracy: 0.6122\n",
            "Epoch 108/100, Loss: 68.4982, Validation Accuracy: 0.6261\n",
            "Epoch 109/100, Loss: 119.8193, Validation Accuracy: 0.6331\n",
            "Epoch 110/100, Loss: 74.1217, Validation Accuracy: 0.6550\n",
            "Epoch 111/100, Loss: 33.2924, Validation Accuracy: 0.5294\n",
            "Epoch 112/100, Loss: 88.0432, Validation Accuracy: 0.6790\n",
            "Epoch 113/100, Loss: 82.4921, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 56.2906, Validation Accuracy: 0.5623\n",
            "Epoch 115/100, Loss: 123.3346, Validation Accuracy: 0.4925\n",
            "Epoch 116/100, Loss: 21.3662, Validation Accuracy: 0.6630\n",
            "Epoch 117/100, Loss: 67.4187, Validation Accuracy: 0.5005\n",
            "Epoch 118/100, Loss: 71.1804, Validation Accuracy: 0.6471\n",
            "Epoch 119/100, Loss: 53.6578, Validation Accuracy: 0.5683\n",
            "Epoch 120/100, Loss: 54.7973, Validation Accuracy: 0.6241\n",
            "Epoch 121/100, Loss: 58.6003, Validation Accuracy: 0.5942\n",
            "Epoch 122/100, Loss: 31.5375, Validation Accuracy: 0.6411\n",
            "Epoch 123/100, Loss: 46.1881, Validation Accuracy: 0.6012\n",
            "Epoch 124/100, Loss: 109.0132, Validation Accuracy: 0.5474\n",
            "Epoch 125/100, Loss: 42.8170, Validation Accuracy: 0.6401\n",
            "Epoch 126/100, Loss: 30.2689, Validation Accuracy: 0.6261\n",
            "Epoch 127/100, Loss: 66.9082, Validation Accuracy: 0.6311\n",
            "Epoch 128/100, Loss: 49.9653, Validation Accuracy: 0.6042\n",
            "Epoch 129/100, Loss: 33.0002, Validation Accuracy: 0.5723\n",
            "Epoch 130/100, Loss: 18.3451, Validation Accuracy: 0.5633\n",
            "Epoch 131/100, Loss: 46.5271, Validation Accuracy: 0.6072\n",
            "Epoch 132/100, Loss: 31.4921, Validation Accuracy: 0.6102\n",
            "Epoch 133/100, Loss: 103.6529, Validation Accuracy: 0.6092\n",
            "Epoch 134/100, Loss: 35.8003, Validation Accuracy: 0.6640\n",
            "Epoch 135/100, Loss: 144.5241, Validation Accuracy: 0.6132\n",
            "Epoch 136/100, Loss: 71.0491, Validation Accuracy: 0.6610\n",
            "Epoch 137/100, Loss: 37.2756, Validation Accuracy: 0.6331\n",
            "Epoch 138/100, Loss: 38.3318, Validation Accuracy: 0.6152\n",
            "Epoch 139/100, Loss: 59.8059, Validation Accuracy: 0.6520\n",
            "Epoch 140/100, Loss: 39.3258, Validation Accuracy: 0.5633\n",
            "Epoch 141/100, Loss: 41.5298, Validation Accuracy: 0.5912\n",
            "Epoch 142/100, Loss: 41.9706, Validation Accuracy: 0.5952\n",
            "Epoch 143/100, Loss: 179.3501, Validation Accuracy: 0.5503\n",
            "Epoch 144/100, Loss: 43.7203, Validation Accuracy: 0.5982\n",
            "Epoch 145/100, Loss: 90.1382, Validation Accuracy: 0.5603\n",
            "Epoch 146/100, Loss: 141.3562, Validation Accuracy: 0.5603\n",
            "Epoch 147/100, Loss: 83.7460, Validation Accuracy: 0.6052\n",
            "Epoch 148/100, Loss: 21.8333, Validation Accuracy: 0.6650\n",
            "Epoch 149/100, Loss: 51.7056, Validation Accuracy: 0.4865\n",
            "Epoch 150/100, Loss: 132.2210, Validation Accuracy: 0.6740\n",
            "Epoch 151/100, Loss: 71.1050, Validation Accuracy: 0.5184\n",
            "Epoch 152/100, Loss: 39.3873, Validation Accuracy: 0.5763\n",
            "Epoch 153/100, Loss: 43.4435, Validation Accuracy: 0.6730\n",
            "Epoch 154/100, Loss: 65.7342, Validation Accuracy: 0.6241\n",
            "Epoch 155/100, Loss: 39.1240, Validation Accuracy: 0.5354\n",
            "Epoch 156/100, Loss: 58.3744, Validation Accuracy: 0.6022\n",
            "Epoch 157/100, Loss: 81.6863, Validation Accuracy: 0.6780\n",
            "Epoch 158/100, Loss: 139.1849, Validation Accuracy: 0.6650\n",
            "Epoch 159/100, Loss: 119.9874, Validation Accuracy: 0.6052\n",
            "Epoch 160/100, Loss: 50.3162, Validation Accuracy: 0.6491\n",
            "Epoch 161/100, Loss: 77.9364, Validation Accuracy: 0.6481\n",
            "Epoch 162/100, Loss: 64.5185, Validation Accuracy: 0.6082\n",
            "Epoch 163/100, Loss: 99.4238, Validation Accuracy: 0.6530\n",
            "Epoch 164/100, Loss: 51.7976, Validation Accuracy: 0.5743\n",
            "Epoch 165/100, Loss: 207.5588, Validation Accuracy: 0.6181\n",
            "Epoch 166/100, Loss: 88.5526, Validation Accuracy: 0.5773\n",
            "Epoch 167/100, Loss: 45.3502, Validation Accuracy: 0.5753\n",
            "Epoch 168/100, Loss: 149.7693, Validation Accuracy: 0.6710\n",
            "Epoch 169/100, Loss: 76.0424, Validation Accuracy: 0.6421\n",
            "Epoch 170/100, Loss: 24.0319, Validation Accuracy: 0.6710\n",
            "Epoch 171/100, Loss: 66.3159, Validation Accuracy: 0.6650\n",
            "Epoch 172/100, Loss: 67.4769, Validation Accuracy: 0.6042\n",
            "Epoch 173/100, Loss: 78.6969, Validation Accuracy: 0.6241\n",
            "Epoch 174/100, Loss: 51.4347, Validation Accuracy: 0.6441\n",
            "Epoch 175/100, Loss: 44.7138, Validation Accuracy: 0.6142\n",
            "Epoch 176/100, Loss: 100.5065, Validation Accuracy: 0.5852\n",
            "Epoch 177/100, Loss: 36.4311, Validation Accuracy: 0.4088\n",
            "Epoch 178/100, Loss: 46.3399, Validation Accuracy: 0.6092\n",
            "Epoch 179/100, Loss: 129.8762, Validation Accuracy: 0.5334\n",
            "Epoch 180/100, Loss: 77.8581, Validation Accuracy: 0.6341\n",
            "Epoch 181/100, Loss: 54.2708, Validation Accuracy: 0.5882\n",
            "Epoch 182/100, Loss: 87.1662, Validation Accuracy: 0.4935\n",
            "Epoch 183/100, Loss: 69.9650, Validation Accuracy: 0.5603\n",
            "Epoch 184/100, Loss: 49.9456, Validation Accuracy: 0.5703\n",
            "Epoch 185/100, Loss: 107.3078, Validation Accuracy: 0.6142\n",
            "Epoch 186/100, Loss: 67.7819, Validation Accuracy: 0.6012\n",
            "Epoch 187/100, Loss: 92.1149, Validation Accuracy: 0.6401\n",
            "Epoch 188/100, Loss: 25.5969, Validation Accuracy: 0.6391\n",
            "Epoch 189/100, Loss: 83.6794, Validation Accuracy: 0.6610\n",
            "Epoch 190/100, Loss: 50.9297, Validation Accuracy: 0.6251\n",
            "Epoch 191/100, Loss: 89.0637, Validation Accuracy: 0.5733\n",
            "Epoch 192/100, Loss: 81.4284, Validation Accuracy: 0.5982\n",
            "Epoch 193/100, Loss: 64.8147, Validation Accuracy: 0.5842\n",
            "Epoch 194/100, Loss: 19.0344, Validation Accuracy: 0.6451\n",
            "Epoch 195/100, Loss: 106.4419, Validation Accuracy: 0.5244\n",
            "Epoch 196/100, Loss: 40.2714, Validation Accuracy: 0.6530\n",
            "Epoch 197/100, Loss: 32.0245, Validation Accuracy: 0.6321\n",
            "Epoch 198/100, Loss: 51.5842, Validation Accuracy: 0.5723\n",
            "Epoch 199/100, Loss: 138.2223, Validation Accuracy: 0.3968\n",
            "Epoch 200/100, Loss: 47.2871, Validation Accuracy: 0.6441\n",
            "Reward for Child Model: 0.2784973717061793\n",
            "Child_80:  {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, [0, 0, 3, 0, 0, 0, 0, 2, 1, 2, 0, 3, 0, 0, 1], 0.2784973717061793\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(48, 48, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(84, 24, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=70928, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 26, 22]           4,096\n",
            "       BatchNorm2d-2           [-1, 64, 26, 22]             128\n",
            "            Conv2d-3           [-1, 36, 22, 18]          57,636\n",
            "       BatchNorm2d-4           [-1, 36, 22, 18]              72\n",
            "              ReLU-5           [-1, 36, 22, 18]               0\n",
            "            Conv2d-6           [-1, 48, 20, 18]           5,232\n",
            "       BatchNorm2d-7           [-1, 48, 20, 18]              96\n",
            "              ReLU-8           [-1, 48, 20, 18]               0\n",
            "            Conv2d-9           [-1, 48, 16, 16]          34,608\n",
            "      BatchNorm2d-10           [-1, 48, 16, 16]              96\n",
            "             ReLU-11           [-1, 48, 16, 16]               0\n",
            "           Conv2d-12           [-1, 24, 16, 18]          14,136\n",
            "      BatchNorm2d-13           [-1, 24, 16, 18]              48\n",
            "             ReLU-14           [-1, 24, 16, 18]               0\n",
            "           Linear-15                    [-1, 7]         496,503\n",
            "================================================================\n",
            "Total params: 612,651\n",
            "Trainable params: 612,651\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.72\n",
            "Params size (MB): 2.34\n",
            "Estimated Total Size (MB): 4.07\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 32.6820, Validation Accuracy: 0.3709\n",
            "Epoch 2/100, Loss: 175.2084, Validation Accuracy: 0.4965\n",
            "Epoch 3/100, Loss: 19.0629, Validation Accuracy: 0.6431\n",
            "Epoch 4/100, Loss: 8.3247, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 32.2677, Validation Accuracy: 0.5773\n",
            "Epoch 6/100, Loss: 190.2533, Validation Accuracy: 0.5902\n",
            "Epoch 7/100, Loss: 23.2198, Validation Accuracy: 0.6341\n",
            "Epoch 8/100, Loss: 37.7409, Validation Accuracy: 0.4337\n",
            "Epoch 9/100, Loss: 13.2190, Validation Accuracy: 0.6102\n",
            "Epoch 10/100, Loss: 41.7852, Validation Accuracy: 0.6022\n",
            "Epoch 11/100, Loss: 39.1177, Validation Accuracy: 0.6142\n",
            "Epoch 12/100, Loss: 257.6927, Validation Accuracy: 0.5105\n",
            "Epoch 13/100, Loss: 30.3289, Validation Accuracy: 0.5872\n",
            "Epoch 14/100, Loss: 20.9026, Validation Accuracy: 0.5494\n",
            "Epoch 15/100, Loss: 5.8484, Validation Accuracy: 0.5354\n",
            "Epoch 16/100, Loss: 38.9225, Validation Accuracy: 0.6271\n",
            "Epoch 17/100, Loss: 25.0782, Validation Accuracy: 0.6002\n",
            "Epoch 18/100, Loss: 45.9435, Validation Accuracy: 0.0788\n",
            "Epoch 19/100, Loss: 111.6374, Validation Accuracy: 0.6770\n",
            "Epoch 20/100, Loss: 10.1023, Validation Accuracy: 0.6441\n",
            "Epoch 21/100, Loss: 18.3502, Validation Accuracy: 0.6580\n",
            "Epoch 22/100, Loss: 59.6248, Validation Accuracy: 0.6261\n",
            "Epoch 23/100, Loss: 41.6793, Validation Accuracy: 0.5633\n",
            "Epoch 24/100, Loss: 102.7332, Validation Accuracy: 0.6680\n",
            "Epoch 25/100, Loss: 43.3919, Validation Accuracy: 0.5404\n",
            "Epoch 26/100, Loss: 54.2421, Validation Accuracy: 0.4736\n",
            "Epoch 27/100, Loss: 22.6434, Validation Accuracy: 0.6022\n",
            "Epoch 28/100, Loss: 45.8687, Validation Accuracy: 0.4845\n",
            "Epoch 29/100, Loss: 49.5789, Validation Accuracy: 0.6690\n",
            "Epoch 30/100, Loss: 48.6851, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 32.4642, Validation Accuracy: 0.6690\n",
            "Epoch 32/100, Loss: 31.6134, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 10.0382, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 88.4056, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 32.5369, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 33.2182, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 41.7256, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 65.6206, Validation Accuracy: 0.6491\n",
            "Epoch 39/100, Loss: 45.4155, Validation Accuracy: 0.6590\n",
            "Epoch 40/100, Loss: 201.1957, Validation Accuracy: 0.6012\n",
            "Epoch 41/100, Loss: 83.9922, Validation Accuracy: 0.3779\n",
            "Epoch 42/100, Loss: 27.1968, Validation Accuracy: 0.5125\n",
            "Epoch 43/100, Loss: 28.5882, Validation Accuracy: 0.6510\n",
            "Epoch 44/100, Loss: 105.3507, Validation Accuracy: 0.4835\n",
            "Epoch 45/100, Loss: 22.5542, Validation Accuracy: 0.5793\n",
            "Epoch 46/100, Loss: 78.7555, Validation Accuracy: 0.6630\n",
            "Epoch 47/100, Loss: 139.2905, Validation Accuracy: 0.6032\n",
            "Epoch 48/100, Loss: 55.9047, Validation Accuracy: 0.5852\n",
            "Epoch 49/100, Loss: 108.2509, Validation Accuracy: 0.6560\n",
            "Epoch 50/100, Loss: 38.0635, Validation Accuracy: 0.6351\n",
            "Epoch 51/100, Loss: 10.6552, Validation Accuracy: 0.6520\n",
            "Epoch 52/100, Loss: 35.0354, Validation Accuracy: 0.6590\n",
            "Epoch 53/100, Loss: 15.5876, Validation Accuracy: 0.5922\n",
            "Epoch 54/100, Loss: 40.5454, Validation Accuracy: 0.6510\n",
            "Epoch 55/100, Loss: 65.4091, Validation Accuracy: 0.6341\n",
            "Epoch 56/100, Loss: 28.3144, Validation Accuracy: 0.6072\n",
            "Epoch 57/100, Loss: 16.5386, Validation Accuracy: 0.5503\n",
            "Epoch 58/100, Loss: 26.9619, Validation Accuracy: 0.6530\n",
            "Epoch 59/100, Loss: 36.0678, Validation Accuracy: 0.6431\n",
            "Epoch 60/100, Loss: 192.9039, Validation Accuracy: 0.6800\n",
            "Epoch 61/100, Loss: 85.0564, Validation Accuracy: 0.5912\n",
            "Epoch 62/100, Loss: 36.7141, Validation Accuracy: 0.6012\n",
            "Epoch 63/100, Loss: 31.8767, Validation Accuracy: 0.5603\n",
            "Epoch 64/100, Loss: 25.3270, Validation Accuracy: 0.6231\n",
            "Epoch 65/100, Loss: 46.8303, Validation Accuracy: 0.6002\n",
            "Epoch 66/100, Loss: 68.6138, Validation Accuracy: 0.5454\n",
            "Epoch 67/100, Loss: 64.3943, Validation Accuracy: 0.5683\n",
            "Epoch 68/100, Loss: 48.3650, Validation Accuracy: 0.5793\n",
            "Epoch 69/100, Loss: 38.2753, Validation Accuracy: 0.6271\n",
            "Epoch 70/100, Loss: 42.7186, Validation Accuracy: 0.5603\n",
            "Epoch 71/100, Loss: 75.8143, Validation Accuracy: 0.5444\n",
            "Epoch 72/100, Loss: 32.1871, Validation Accuracy: 0.5464\n",
            "Epoch 73/100, Loss: 48.1526, Validation Accuracy: 0.6680\n",
            "Epoch 74/100, Loss: 43.8072, Validation Accuracy: 0.6760\n",
            "Epoch 75/100, Loss: 53.8229, Validation Accuracy: 0.6162\n",
            "Epoch 76/100, Loss: 105.7293, Validation Accuracy: 0.5663\n",
            "Epoch 77/100, Loss: 341.3217, Validation Accuracy: 0.4786\n",
            "Epoch 78/100, Loss: 21.0050, Validation Accuracy: 0.4955\n",
            "Epoch 79/100, Loss: 27.7009, Validation Accuracy: 0.6122\n",
            "Epoch 80/100, Loss: 333.7740, Validation Accuracy: 0.5294\n",
            "Epoch 81/100, Loss: 47.6690, Validation Accuracy: 0.3091\n",
            "Epoch 82/100, Loss: 46.3038, Validation Accuracy: 0.5304\n",
            "Epoch 83/100, Loss: 42.1596, Validation Accuracy: 0.6082\n",
            "Epoch 84/100, Loss: 28.9714, Validation Accuracy: 0.5842\n",
            "Epoch 85/100, Loss: 28.2826, Validation Accuracy: 0.3829\n",
            "Epoch 86/100, Loss: 68.0440, Validation Accuracy: 0.6431\n",
            "Epoch 87/100, Loss: 87.2588, Validation Accuracy: 0.6201\n",
            "Epoch 88/100, Loss: 28.5198, Validation Accuracy: 0.5952\n",
            "Epoch 89/100, Loss: 110.8340, Validation Accuracy: 0.5593\n",
            "Epoch 90/100, Loss: 76.2739, Validation Accuracy: 0.6301\n",
            "Epoch 91/100, Loss: 57.0329, Validation Accuracy: 0.6181\n",
            "Epoch 92/100, Loss: 29.3562, Validation Accuracy: 0.5633\n",
            "Epoch 93/100, Loss: 38.9377, Validation Accuracy: 0.6381\n",
            "Epoch 94/100, Loss: 226.3674, Validation Accuracy: 0.4776\n",
            "Epoch 95/100, Loss: 44.4451, Validation Accuracy: 0.5823\n",
            "Epoch 96/100, Loss: 59.3252, Validation Accuracy: 0.6700\n",
            "Epoch 97/100, Loss: 74.8583, Validation Accuracy: 0.4068\n",
            "Epoch 98/100, Loss: 15.3206, Validation Accuracy: 0.6142\n",
            "Epoch 99/100, Loss: 49.8048, Validation Accuracy: 0.6780\n",
            "Epoch 100/100, Loss: 61.9322, Validation Accuracy: 0.3200\n",
            "Epoch 101/100, Loss: 17.8492, Validation Accuracy: 0.6700\n",
            "Epoch 102/100, Loss: 11.8674, Validation Accuracy: 0.6132\n",
            "Epoch 103/100, Loss: 69.8220, Validation Accuracy: 0.6082\n",
            "Epoch 104/100, Loss: 41.7606, Validation Accuracy: 0.6072\n",
            "Epoch 105/100, Loss: 23.1040, Validation Accuracy: 0.6530\n",
            "Epoch 106/100, Loss: 40.9718, Validation Accuracy: 0.6052\n",
            "Epoch 107/100, Loss: 50.1190, Validation Accuracy: 0.6142\n",
            "Epoch 108/100, Loss: 52.7208, Validation Accuracy: 0.5962\n",
            "Epoch 109/100, Loss: 30.4608, Validation Accuracy: 0.6720\n",
            "Epoch 110/100, Loss: 53.4526, Validation Accuracy: 0.6500\n",
            "Epoch 111/100, Loss: 37.1730, Validation Accuracy: 0.5653\n",
            "Epoch 112/100, Loss: 58.5008, Validation Accuracy: 0.5214\n",
            "Epoch 113/100, Loss: 32.3112, Validation Accuracy: 0.6790\n",
            "Epoch 114/100, Loss: 77.0479, Validation Accuracy: 0.6112\n",
            "Epoch 115/100, Loss: 38.7236, Validation Accuracy: 0.6022\n",
            "Epoch 116/100, Loss: 21.5902, Validation Accuracy: 0.5165\n",
            "Epoch 117/100, Loss: 100.5053, Validation Accuracy: 0.5583\n",
            "Epoch 118/100, Loss: 58.2644, Validation Accuracy: 0.5852\n",
            "Epoch 119/100, Loss: 57.6462, Validation Accuracy: 0.5414\n",
            "Epoch 120/100, Loss: 13.7927, Validation Accuracy: 0.5663\n",
            "Epoch 121/100, Loss: 31.0890, Validation Accuracy: 0.6032\n",
            "Epoch 122/100, Loss: 44.9689, Validation Accuracy: 0.6401\n",
            "Epoch 123/100, Loss: 34.3678, Validation Accuracy: 0.6102\n",
            "Epoch 124/100, Loss: 24.8389, Validation Accuracy: 0.6052\n",
            "Epoch 125/100, Loss: 19.0250, Validation Accuracy: 0.6291\n",
            "Epoch 126/100, Loss: 138.6519, Validation Accuracy: 0.6919\n",
            "Epoch 127/100, Loss: 46.4433, Validation Accuracy: 0.3689\n",
            "Epoch 128/100, Loss: 47.2422, Validation Accuracy: 0.6251\n",
            "Epoch 129/100, Loss: 39.8326, Validation Accuracy: 0.6072\n",
            "Epoch 130/100, Loss: 46.6960, Validation Accuracy: 0.6401\n",
            "Epoch 131/100, Loss: 65.0007, Validation Accuracy: 0.5673\n",
            "Epoch 132/100, Loss: 112.5370, Validation Accuracy: 0.6740\n",
            "Epoch 133/100, Loss: 102.5139, Validation Accuracy: 0.6500\n",
            "Epoch 134/100, Loss: 61.6476, Validation Accuracy: 0.5872\n",
            "Epoch 135/100, Loss: 34.9056, Validation Accuracy: 0.5633\n",
            "Epoch 136/100, Loss: 14.1736, Validation Accuracy: 0.6012\n",
            "Epoch 137/100, Loss: 86.6331, Validation Accuracy: 0.6351\n",
            "Epoch 138/100, Loss: 83.5961, Validation Accuracy: 0.5284\n",
            "Epoch 139/100, Loss: 18.6116, Validation Accuracy: 0.6461\n",
            "Epoch 140/100, Loss: 23.6291, Validation Accuracy: 0.6132\n",
            "Epoch 141/100, Loss: 53.4271, Validation Accuracy: 0.5972\n",
            "Epoch 142/100, Loss: 19.9288, Validation Accuracy: 0.4975\n",
            "Epoch 143/100, Loss: 19.7825, Validation Accuracy: 0.6700\n",
            "Epoch 144/100, Loss: 22.6494, Validation Accuracy: 0.6361\n",
            "Epoch 145/100, Loss: 19.7282, Validation Accuracy: 0.5852\n",
            "Epoch 146/100, Loss: 18.0220, Validation Accuracy: 0.6032\n",
            "Epoch 147/100, Loss: 9.5538, Validation Accuracy: 0.5902\n",
            "Epoch 148/100, Loss: 44.3837, Validation Accuracy: 0.6451\n",
            "Epoch 149/100, Loss: 41.1374, Validation Accuracy: 0.5424\n",
            "Epoch 150/100, Loss: 90.1019, Validation Accuracy: 0.4656\n",
            "Epoch 151/100, Loss: 50.1448, Validation Accuracy: 0.5075\n",
            "Epoch 152/100, Loss: 49.7104, Validation Accuracy: 0.4307\n",
            "Epoch 153/100, Loss: 39.6682, Validation Accuracy: 0.3480\n",
            "Epoch 154/100, Loss: 52.0432, Validation Accuracy: 0.6401\n",
            "Epoch 155/100, Loss: 83.3370, Validation Accuracy: 0.5842\n",
            "Epoch 156/100, Loss: 54.6249, Validation Accuracy: 0.6072\n",
            "Epoch 157/100, Loss: 53.2218, Validation Accuracy: 0.6361\n",
            "Epoch 158/100, Loss: 91.9986, Validation Accuracy: 0.5653\n",
            "Epoch 159/100, Loss: 20.6563, Validation Accuracy: 0.6570\n",
            "Epoch 160/100, Loss: 36.9322, Validation Accuracy: 0.6650\n",
            "Epoch 161/100, Loss: 32.6676, Validation Accuracy: 0.6221\n",
            "Epoch 162/100, Loss: 43.7747, Validation Accuracy: 0.6411\n",
            "Epoch 163/100, Loss: 69.6493, Validation Accuracy: 0.6251\n",
            "Epoch 164/100, Loss: 124.1319, Validation Accuracy: 0.6730\n",
            "Epoch 165/100, Loss: 19.4177, Validation Accuracy: 0.6191\n",
            "Epoch 166/100, Loss: 40.9869, Validation Accuracy: 0.5374\n",
            "Epoch 167/100, Loss: 31.3337, Validation Accuracy: 0.6052\n",
            "Epoch 168/100, Loss: 24.0201, Validation Accuracy: 0.6012\n",
            "Epoch 169/100, Loss: 80.1689, Validation Accuracy: 0.5823\n",
            "Epoch 170/100, Loss: 80.0965, Validation Accuracy: 0.6261\n",
            "Epoch 171/100, Loss: 57.4517, Validation Accuracy: 0.6421\n",
            "Epoch 172/100, Loss: 14.6887, Validation Accuracy: 0.6650\n",
            "Epoch 173/100, Loss: 45.0370, Validation Accuracy: 0.5713\n",
            "Epoch 174/100, Loss: 27.8322, Validation Accuracy: 0.5623\n",
            "Epoch 175/100, Loss: 124.1646, Validation Accuracy: 0.6191\n",
            "Epoch 176/100, Loss: 51.1797, Validation Accuracy: 0.6381\n",
            "Epoch 177/100, Loss: 13.1484, Validation Accuracy: 0.6022\n",
            "Epoch 178/100, Loss: 94.1023, Validation Accuracy: 0.5733\n",
            "Epoch 179/100, Loss: 87.7842, Validation Accuracy: 0.5563\n",
            "Epoch 180/100, Loss: 27.5393, Validation Accuracy: 0.3480\n",
            "Epoch 181/100, Loss: 73.7546, Validation Accuracy: 0.6491\n",
            "Epoch 182/100, Loss: 187.7119, Validation Accuracy: 0.6610\n",
            "Epoch 183/100, Loss: 87.4029, Validation Accuracy: 0.5005\n",
            "Epoch 184/100, Loss: 56.6478, Validation Accuracy: 0.6351\n",
            "Epoch 185/100, Loss: 89.2901, Validation Accuracy: 0.6740\n",
            "Epoch 186/100, Loss: 29.0742, Validation Accuracy: 0.5862\n",
            "Epoch 187/100, Loss: 19.9394, Validation Accuracy: 0.4726\n",
            "Epoch 188/100, Loss: 40.3564, Validation Accuracy: 0.6122\n",
            "Epoch 189/100, Loss: 43.0963, Validation Accuracy: 0.6610\n",
            "Epoch 190/100, Loss: 52.1743, Validation Accuracy: 0.5813\n",
            "Epoch 191/100, Loss: 111.4222, Validation Accuracy: 0.4895\n",
            "Epoch 192/100, Loss: 65.8457, Validation Accuracy: 0.5972\n",
            "Epoch 193/100, Loss: 61.0193, Validation Accuracy: 0.6640\n",
            "Epoch 194/100, Loss: 41.7325, Validation Accuracy: 0.6540\n",
            "Epoch 195/100, Loss: 63.8174, Validation Accuracy: 0.6142\n",
            "Epoch 196/100, Loss: 62.5215, Validation Accuracy: 0.6600\n",
            "Epoch 197/100, Loss: 68.5567, Validation Accuracy: 0.5025\n",
            "Epoch 198/100, Loss: 68.7402, Validation Accuracy: 0.5284\n",
            "Epoch 199/100, Loss: 27.3456, Validation Accuracy: 0.6331\n",
            "Epoch 200/100, Loss: 43.2010, Validation Accuracy: 0.6590\n",
            "Reward for Child Model: 0.2875220586137977\n",
            "Child_81:  {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, [1, 3, 3, 2, 2, 1, 1, 0, 2, 2, 1, 2, 3, 0, 0], 0.2875220586137977\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(100, 48, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(212, 36, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=217152, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 24, 26]           2,944\n",
            "       BatchNorm2d-2           [-1, 64, 24, 26]             128\n",
            "            Conv2d-3           [-1, 36, 22, 24]          20,772\n",
            "       BatchNorm2d-4           [-1, 36, 22, 24]              72\n",
            "              ReLU-5           [-1, 36, 22, 24]               0\n",
            "            Conv2d-6           [-1, 36, 22, 18]           9,108\n",
            "       BatchNorm2d-7           [-1, 36, 22, 18]              72\n",
            "              ReLU-8           [-1, 36, 22, 18]               0\n",
            "            Conv2d-9           [-1, 48, 18, 24]         100,848\n",
            "      BatchNorm2d-10           [-1, 48, 18, 24]              96\n",
            "             ReLU-11           [-1, 48, 18, 24]               0\n",
            "           Conv2d-12           [-1, 36, 22, 22]         114,516\n",
            "      BatchNorm2d-13           [-1, 36, 22, 22]              72\n",
            "             ReLU-14           [-1, 36, 22, 22]               0\n",
            "           Linear-15                    [-1, 7]       1,520,071\n",
            "================================================================\n",
            "Total params: 1,768,699\n",
            "Trainable params: 1,768,699\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.24\n",
            "Params size (MB): 6.75\n",
            "Estimated Total Size (MB): 9.00\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 43.1764, Validation Accuracy: 0.5603\n",
            "Epoch 2/100, Loss: 70.6742, Validation Accuracy: 0.6640\n",
            "Epoch 3/100, Loss: 416.7285, Validation Accuracy: 0.6670\n",
            "Epoch 4/100, Loss: 71.6767, Validation Accuracy: 0.6171\n",
            "Epoch 5/100, Loss: 16.7011, Validation Accuracy: 0.4666\n",
            "Epoch 6/100, Loss: 91.9258, Validation Accuracy: 0.6660\n",
            "Epoch 7/100, Loss: 90.0512, Validation Accuracy: 0.6102\n",
            "Epoch 8/100, Loss: 182.5066, Validation Accuracy: 0.6491\n",
            "Epoch 9/100, Loss: 32.5907, Validation Accuracy: 0.4397\n",
            "Epoch 10/100, Loss: 72.4768, Validation Accuracy: 0.6181\n",
            "Epoch 11/100, Loss: 40.2718, Validation Accuracy: 0.6371\n",
            "Epoch 12/100, Loss: 16.6534, Validation Accuracy: 0.6760\n",
            "Epoch 13/100, Loss: 169.2064, Validation Accuracy: 0.6301\n",
            "Epoch 14/100, Loss: 277.3214, Validation Accuracy: 0.4845\n",
            "Epoch 15/100, Loss: 274.6497, Validation Accuracy: 0.6620\n",
            "Epoch 16/100, Loss: 56.5389, Validation Accuracy: 0.6201\n",
            "Epoch 17/100, Loss: 46.9763, Validation Accuracy: 0.4427\n",
            "Epoch 18/100, Loss: 57.2736, Validation Accuracy: 0.6530\n",
            "Epoch 19/100, Loss: 356.5157, Validation Accuracy: 0.5135\n",
            "Epoch 20/100, Loss: 527.1875, Validation Accuracy: 0.6690\n",
            "Epoch 21/100, Loss: 256.3565, Validation Accuracy: 0.5882\n",
            "Epoch 22/100, Loss: 101.2145, Validation Accuracy: 0.6570\n",
            "Epoch 23/100, Loss: 272.2554, Validation Accuracy: 0.6221\n",
            "Epoch 24/100, Loss: 224.7453, Validation Accuracy: 0.6780\n",
            "Epoch 25/100, Loss: 137.2685, Validation Accuracy: 0.6710\n",
            "Epoch 26/100, Loss: 90.5648, Validation Accuracy: 0.6421\n",
            "Epoch 27/100, Loss: 160.5530, Validation Accuracy: 0.6092\n",
            "Epoch 28/100, Loss: 285.5563, Validation Accuracy: 0.5264\n",
            "Epoch 29/100, Loss: 75.6938, Validation Accuracy: 0.4835\n",
            "Epoch 30/100, Loss: 40.4840, Validation Accuracy: 0.6750\n",
            "Epoch 31/100, Loss: 64.4961, Validation Accuracy: 0.6710\n",
            "Epoch 32/100, Loss: 105.7145, Validation Accuracy: 0.6640\n",
            "Epoch 33/100, Loss: 132.4487, Validation Accuracy: 0.3170\n",
            "Epoch 34/100, Loss: 169.3952, Validation Accuracy: 0.5533\n",
            "Epoch 35/100, Loss: 121.5433, Validation Accuracy: 0.5803\n",
            "Epoch 36/100, Loss: 52.4690, Validation Accuracy: 0.6471\n",
            "Epoch 37/100, Loss: 39.5288, Validation Accuracy: 0.5613\n",
            "Epoch 38/100, Loss: 306.8512, Validation Accuracy: 0.6201\n",
            "Epoch 39/100, Loss: 235.9429, Validation Accuracy: 0.6132\n",
            "Epoch 40/100, Loss: 550.3784, Validation Accuracy: 0.6610\n",
            "Epoch 41/100, Loss: 458.5158, Validation Accuracy: 0.6122\n",
            "Epoch 42/100, Loss: 110.6098, Validation Accuracy: 0.6341\n",
            "Epoch 43/100, Loss: 420.6959, Validation Accuracy: 0.6730\n",
            "Epoch 44/100, Loss: 46.0018, Validation Accuracy: 0.6740\n",
            "Epoch 45/100, Loss: 119.2594, Validation Accuracy: 0.5573\n",
            "Epoch 46/100, Loss: 203.3680, Validation Accuracy: 0.6341\n",
            "Epoch 47/100, Loss: 125.7545, Validation Accuracy: 0.6839\n",
            "Epoch 48/100, Loss: 148.4479, Validation Accuracy: 0.5942\n",
            "Epoch 49/100, Loss: 192.2214, Validation Accuracy: 0.5543\n",
            "Epoch 50/100, Loss: 521.4540, Validation Accuracy: 0.6271\n",
            "Epoch 51/100, Loss: 151.9039, Validation Accuracy: 0.6660\n",
            "Epoch 52/100, Loss: 233.7592, Validation Accuracy: 0.6510\n",
            "Epoch 53/100, Loss: 295.6242, Validation Accuracy: 0.5763\n",
            "Epoch 54/100, Loss: 294.6270, Validation Accuracy: 0.5035\n",
            "Epoch 55/100, Loss: 100.4703, Validation Accuracy: 0.6859\n",
            "Epoch 56/100, Loss: 70.5524, Validation Accuracy: 0.5274\n",
            "Epoch 57/100, Loss: 176.0648, Validation Accuracy: 0.5613\n",
            "Epoch 58/100, Loss: 315.8193, Validation Accuracy: 0.6550\n",
            "Epoch 59/100, Loss: 77.7319, Validation Accuracy: 0.5364\n",
            "Epoch 60/100, Loss: 148.9271, Validation Accuracy: 0.5065\n",
            "Epoch 61/100, Loss: 55.9743, Validation Accuracy: 0.6859\n",
            "Epoch 62/100, Loss: 226.4672, Validation Accuracy: 0.6720\n",
            "Epoch 63/100, Loss: 83.5517, Validation Accuracy: 0.6062\n",
            "Epoch 64/100, Loss: 782.6969, Validation Accuracy: 0.5952\n",
            "Epoch 65/100, Loss: 120.3350, Validation Accuracy: 0.6620\n",
            "Epoch 66/100, Loss: 103.5262, Validation Accuracy: 0.6431\n",
            "Epoch 67/100, Loss: 206.3728, Validation Accuracy: 0.6610\n",
            "Epoch 68/100, Loss: 127.2099, Validation Accuracy: 0.4138\n",
            "Epoch 69/100, Loss: 224.7763, Validation Accuracy: 0.6371\n",
            "Epoch 70/100, Loss: 256.8118, Validation Accuracy: 0.5404\n",
            "Epoch 71/100, Loss: 262.2644, Validation Accuracy: 0.5872\n",
            "Epoch 72/100, Loss: 221.5032, Validation Accuracy: 0.6510\n",
            "Epoch 73/100, Loss: 138.4831, Validation Accuracy: 0.6281\n",
            "Epoch 74/100, Loss: 235.8029, Validation Accuracy: 0.5454\n",
            "Epoch 75/100, Loss: 121.9779, Validation Accuracy: 0.6132\n",
            "Epoch 76/100, Loss: 81.8767, Validation Accuracy: 0.6132\n",
            "Epoch 77/100, Loss: 189.1567, Validation Accuracy: 0.5643\n",
            "Epoch 78/100, Loss: 178.5581, Validation Accuracy: 0.5743\n",
            "Epoch 79/100, Loss: 184.4497, Validation Accuracy: 0.5882\n",
            "Epoch 80/100, Loss: 20.9078, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 96.9955, Validation Accuracy: 0.6839\n",
            "Epoch 82/100, Loss: 187.8085, Validation Accuracy: 0.5793\n",
            "Epoch 83/100, Loss: 216.1327, Validation Accuracy: 0.6122\n",
            "Epoch 84/100, Loss: 245.4163, Validation Accuracy: 0.6909\n",
            "Epoch 85/100, Loss: 40.4037, Validation Accuracy: 0.5573\n",
            "Epoch 86/100, Loss: 370.4922, Validation Accuracy: 0.6092\n",
            "Epoch 87/100, Loss: 193.2154, Validation Accuracy: 0.6471\n",
            "Epoch 88/100, Loss: 127.0220, Validation Accuracy: 0.5713\n",
            "Epoch 89/100, Loss: 302.3211, Validation Accuracy: 0.5633\n",
            "Epoch 90/100, Loss: 188.3972, Validation Accuracy: 0.5992\n",
            "Epoch 91/100, Loss: 504.7620, Validation Accuracy: 0.4467\n",
            "Epoch 92/100, Loss: 33.8276, Validation Accuracy: 0.5743\n",
            "Epoch 93/100, Loss: 160.4964, Validation Accuracy: 0.5294\n",
            "Epoch 94/100, Loss: 79.3502, Validation Accuracy: 0.6600\n",
            "Epoch 95/100, Loss: 286.8974, Validation Accuracy: 0.6580\n",
            "Epoch 96/100, Loss: 162.9832, Validation Accuracy: 0.6510\n",
            "Epoch 97/100, Loss: 202.3017, Validation Accuracy: 0.6361\n",
            "Epoch 98/100, Loss: 139.4646, Validation Accuracy: 0.6800\n",
            "Epoch 99/100, Loss: 166.7105, Validation Accuracy: 0.5902\n",
            "Epoch 100/100, Loss: 108.7795, Validation Accuracy: 0.6371\n",
            "Epoch 101/100, Loss: 85.4650, Validation Accuracy: 0.5992\n",
            "Epoch 102/100, Loss: 106.6189, Validation Accuracy: 0.5284\n",
            "Epoch 103/100, Loss: 205.4502, Validation Accuracy: 0.6341\n",
            "Epoch 104/100, Loss: 182.5421, Validation Accuracy: 0.6929\n",
            "Epoch 105/100, Loss: 65.3013, Validation Accuracy: 0.6710\n",
            "Epoch 106/100, Loss: 130.0487, Validation Accuracy: 0.6072\n",
            "Epoch 107/100, Loss: 69.7341, Validation Accuracy: 0.6710\n",
            "Epoch 108/100, Loss: 141.0308, Validation Accuracy: 0.6441\n",
            "Epoch 109/100, Loss: 109.5527, Validation Accuracy: 0.5613\n",
            "Epoch 110/100, Loss: 64.0811, Validation Accuracy: 0.6700\n",
            "Epoch 111/100, Loss: 53.7786, Validation Accuracy: 0.6371\n",
            "Epoch 112/100, Loss: 233.3037, Validation Accuracy: 0.7039\n",
            "Epoch 113/100, Loss: 169.0692, Validation Accuracy: 0.6241\n",
            "Epoch 114/100, Loss: 161.2055, Validation Accuracy: 0.6590\n",
            "Epoch 115/100, Loss: 132.0766, Validation Accuracy: 0.5882\n",
            "Epoch 116/100, Loss: 94.3959, Validation Accuracy: 0.5643\n",
            "Epoch 117/100, Loss: 130.2304, Validation Accuracy: 0.6830\n",
            "Epoch 118/100, Loss: 282.1407, Validation Accuracy: 0.6411\n",
            "Epoch 119/100, Loss: 296.8776, Validation Accuracy: 0.6092\n",
            "Epoch 120/100, Loss: 136.6078, Validation Accuracy: 0.6411\n",
            "Epoch 121/100, Loss: 6.0916, Validation Accuracy: 0.5523\n",
            "Epoch 122/100, Loss: 532.5528, Validation Accuracy: 0.6391\n",
            "Epoch 123/100, Loss: 138.4677, Validation Accuracy: 0.6341\n",
            "Epoch 124/100, Loss: 176.8783, Validation Accuracy: 0.5454\n",
            "Epoch 125/100, Loss: 172.7480, Validation Accuracy: 0.6491\n",
            "Epoch 126/100, Loss: 86.8578, Validation Accuracy: 0.3898\n",
            "Epoch 127/100, Loss: 102.1153, Validation Accuracy: 0.6421\n",
            "Epoch 128/100, Loss: 83.7798, Validation Accuracy: 0.6700\n",
            "Epoch 129/100, Loss: 185.9847, Validation Accuracy: 0.6211\n",
            "Epoch 130/100, Loss: 303.9288, Validation Accuracy: 0.5992\n",
            "Epoch 131/100, Loss: 168.3605, Validation Accuracy: 0.4835\n",
            "Epoch 132/100, Loss: 61.1468, Validation Accuracy: 0.5793\n",
            "Epoch 133/100, Loss: 347.5756, Validation Accuracy: 0.6022\n",
            "Epoch 134/100, Loss: 87.1355, Validation Accuracy: 0.5683\n",
            "Epoch 135/100, Loss: 87.9336, Validation Accuracy: 0.6321\n",
            "Epoch 136/100, Loss: 162.3518, Validation Accuracy: 0.6371\n",
            "Epoch 137/100, Loss: 249.4486, Validation Accuracy: 0.6102\n",
            "Epoch 138/100, Loss: 131.0736, Validation Accuracy: 0.6560\n",
            "Epoch 139/100, Loss: 146.4615, Validation Accuracy: 0.6201\n",
            "Epoch 140/100, Loss: 242.4409, Validation Accuracy: 0.5663\n",
            "Epoch 141/100, Loss: 154.1239, Validation Accuracy: 0.6451\n",
            "Epoch 142/100, Loss: 348.1225, Validation Accuracy: 0.6221\n",
            "Epoch 143/100, Loss: 118.0051, Validation Accuracy: 0.5494\n",
            "Epoch 144/100, Loss: 102.9053, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 359.9021, Validation Accuracy: 0.6620\n",
            "Epoch 146/100, Loss: 74.6650, Validation Accuracy: 0.5992\n",
            "Epoch 147/100, Loss: 367.8600, Validation Accuracy: 0.6431\n",
            "Epoch 148/100, Loss: 111.0096, Validation Accuracy: 0.4138\n",
            "Epoch 149/100, Loss: 173.9919, Validation Accuracy: 0.6142\n",
            "Epoch 150/100, Loss: 313.5431, Validation Accuracy: 0.6271\n",
            "Epoch 151/100, Loss: 275.0858, Validation Accuracy: 0.6391\n",
            "Epoch 152/100, Loss: 2.2127, Validation Accuracy: 0.5932\n",
            "Epoch 153/100, Loss: 149.7281, Validation Accuracy: 0.6331\n",
            "Epoch 154/100, Loss: 148.1130, Validation Accuracy: 0.6251\n",
            "Epoch 155/100, Loss: 248.8538, Validation Accuracy: 0.6401\n",
            "Epoch 156/100, Loss: 249.1154, Validation Accuracy: 0.6261\n",
            "Epoch 157/100, Loss: 335.9371, Validation Accuracy: 0.6481\n",
            "Epoch 158/100, Loss: 178.8003, Validation Accuracy: 0.6112\n",
            "Epoch 159/100, Loss: 300.8043, Validation Accuracy: 0.6660\n",
            "Epoch 160/100, Loss: 194.8616, Validation Accuracy: 0.6431\n",
            "Epoch 161/100, Loss: 208.0259, Validation Accuracy: 0.6092\n",
            "Epoch 162/100, Loss: 287.3861, Validation Accuracy: 0.5813\n",
            "Epoch 163/100, Loss: 44.0304, Validation Accuracy: 0.6830\n",
            "Epoch 164/100, Loss: 185.2777, Validation Accuracy: 0.5773\n",
            "Epoch 165/100, Loss: 153.3924, Validation Accuracy: 0.6710\n",
            "Epoch 166/100, Loss: 245.5394, Validation Accuracy: 0.6660\n",
            "Epoch 167/100, Loss: 292.3411, Validation Accuracy: 0.6331\n",
            "Epoch 168/100, Loss: 44.9992, Validation Accuracy: 0.5962\n",
            "Epoch 169/100, Loss: 234.1549, Validation Accuracy: 0.6700\n",
            "Epoch 170/100, Loss: 106.5371, Validation Accuracy: 0.6500\n",
            "Epoch 171/100, Loss: 572.0216, Validation Accuracy: 0.5862\n",
            "Epoch 172/100, Loss: 178.8851, Validation Accuracy: 0.6740\n",
            "Epoch 173/100, Loss: 169.3335, Validation Accuracy: 0.5882\n",
            "Epoch 174/100, Loss: 78.7021, Validation Accuracy: 0.5693\n",
            "Epoch 175/100, Loss: 190.2930, Validation Accuracy: 0.5513\n",
            "Epoch 176/100, Loss: 270.8851, Validation Accuracy: 0.6291\n",
            "Epoch 177/100, Loss: 135.0238, Validation Accuracy: 0.5833\n",
            "Epoch 178/100, Loss: 411.0210, Validation Accuracy: 0.5743\n",
            "Epoch 179/100, Loss: 232.7359, Validation Accuracy: 0.6122\n",
            "Epoch 180/100, Loss: 127.9883, Validation Accuracy: 0.6720\n",
            "Epoch 181/100, Loss: 45.4810, Validation Accuracy: 0.6620\n",
            "Epoch 182/100, Loss: 120.6417, Validation Accuracy: 0.6720\n",
            "Epoch 183/100, Loss: 142.9934, Validation Accuracy: 0.6520\n",
            "Epoch 184/100, Loss: 183.8636, Validation Accuracy: 0.5892\n",
            "Epoch 185/100, Loss: 104.3769, Validation Accuracy: 0.5902\n",
            "Epoch 186/100, Loss: 338.3261, Validation Accuracy: 0.6610\n",
            "Epoch 187/100, Loss: 99.3982, Validation Accuracy: 0.6849\n",
            "Epoch 188/100, Loss: 264.9788, Validation Accuracy: 0.6281\n",
            "Epoch 189/100, Loss: 196.5807, Validation Accuracy: 0.6082\n",
            "Epoch 190/100, Loss: 166.0270, Validation Accuracy: 0.5713\n",
            "Epoch 191/100, Loss: 206.3223, Validation Accuracy: 0.6241\n",
            "Epoch 192/100, Loss: 155.2992, Validation Accuracy: 0.6381\n",
            "Epoch 193/100, Loss: 199.7119, Validation Accuracy: 0.6022\n",
            "Epoch 194/100, Loss: 99.7703, Validation Accuracy: 0.5793\n",
            "Epoch 195/100, Loss: 93.7402, Validation Accuracy: 0.5683\n",
            "Epoch 196/100, Loss: 206.9654, Validation Accuracy: 0.6560\n",
            "Epoch 197/100, Loss: 233.8856, Validation Accuracy: 0.6431\n",
            "Epoch 198/100, Loss: 130.5251, Validation Accuracy: 0.6331\n",
            "Epoch 199/100, Loss: 153.8011, Validation Accuracy: 0.5852\n",
            "Epoch 200/100, Loss: 218.0479, Validation Accuracy: 0.6341\n",
            "Reward for Child Model: 0.28234160669315744\n",
            "Child_82:  {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, [2, 1, 3, 1, 1, 1, 0, 3, 1, 3, 1, 2, 1, 2, 1], 0.28234160669315744\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 64, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(128, 64, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(64, 24, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(152, 36, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=136864, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 26, 28]             640\n",
            "       BatchNorm2d-2           [-1, 64, 26, 28]             128\n",
            "            Conv2d-3           [-1, 64, 22, 26]          61,504\n",
            "       BatchNorm2d-4           [-1, 64, 22, 26]             128\n",
            "              ReLU-5           [-1, 64, 22, 26]               0\n",
            "            Conv2d-6           [-1, 64, 24, 24]         122,944\n",
            "       BatchNorm2d-7           [-1, 64, 24, 24]             128\n",
            "              ReLU-8           [-1, 64, 24, 24]               0\n",
            "            Conv2d-9           [-1, 24, 20, 24]           7,704\n",
            "      BatchNorm2d-10           [-1, 24, 20, 24]              48\n",
            "             ReLU-11           [-1, 24, 20, 24]               0\n",
            "           Conv2d-12           [-1, 36, 20, 24]         191,556\n",
            "      BatchNorm2d-13           [-1, 36, 20, 24]              72\n",
            "             ReLU-14           [-1, 36, 20, 24]               0\n",
            "           Linear-15                    [-1, 7]         958,055\n",
            "================================================================\n",
            "Total params: 1,342,907\n",
            "Trainable params: 1,342,907\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.05\n",
            "Params size (MB): 5.12\n",
            "Estimated Total Size (MB): 8.18\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 16.6075, Validation Accuracy: 0.6540\n",
            "Epoch 2/100, Loss: 67.4517, Validation Accuracy: 0.6550\n",
            "Epoch 3/100, Loss: 615.6055, Validation Accuracy: 0.3759\n",
            "Epoch 4/100, Loss: 60.1500, Validation Accuracy: 0.6770\n",
            "Epoch 5/100, Loss: 43.4732, Validation Accuracy: 0.2154\n",
            "Epoch 6/100, Loss: 9.8766, Validation Accuracy: 0.5793\n",
            "Epoch 7/100, Loss: 7.1119, Validation Accuracy: 0.6431\n",
            "Epoch 8/100, Loss: 31.7120, Validation Accuracy: 0.5414\n",
            "Epoch 9/100, Loss: 27.4544, Validation Accuracy: 0.6620\n",
            "Epoch 10/100, Loss: 45.0569, Validation Accuracy: 0.5912\n",
            "Epoch 11/100, Loss: 44.1868, Validation Accuracy: 0.6650\n",
            "Epoch 12/100, Loss: 21.0490, Validation Accuracy: 0.6341\n",
            "Epoch 13/100, Loss: 16.4641, Validation Accuracy: 0.5364\n",
            "Epoch 14/100, Loss: 70.5773, Validation Accuracy: 0.3599\n",
            "Epoch 15/100, Loss: 91.3635, Validation Accuracy: 0.6670\n",
            "Epoch 16/100, Loss: 137.1171, Validation Accuracy: 0.6022\n",
            "Epoch 17/100, Loss: 54.2740, Validation Accuracy: 0.6500\n",
            "Epoch 18/100, Loss: 26.9408, Validation Accuracy: 0.6859\n",
            "Epoch 19/100, Loss: 133.2168, Validation Accuracy: 0.6341\n",
            "Epoch 20/100, Loss: 30.8362, Validation Accuracy: 0.6640\n",
            "Epoch 21/100, Loss: 60.5399, Validation Accuracy: 0.6241\n",
            "Epoch 22/100, Loss: 58.2299, Validation Accuracy: 0.5613\n",
            "Epoch 23/100, Loss: 53.2974, Validation Accuracy: 0.5912\n",
            "Epoch 24/100, Loss: 83.9585, Validation Accuracy: 0.6281\n",
            "Epoch 25/100, Loss: 54.0479, Validation Accuracy: 0.6680\n",
            "Epoch 26/100, Loss: 81.9272, Validation Accuracy: 0.5703\n",
            "Epoch 27/100, Loss: 157.2171, Validation Accuracy: 0.6720\n",
            "Epoch 28/100, Loss: 14.8258, Validation Accuracy: 0.5613\n",
            "Epoch 29/100, Loss: 66.7630, Validation Accuracy: 0.6500\n",
            "Epoch 30/100, Loss: 93.8038, Validation Accuracy: 0.5603\n",
            "Epoch 31/100, Loss: 83.8623, Validation Accuracy: 0.6560\n",
            "Epoch 32/100, Loss: 76.0796, Validation Accuracy: 0.6321\n",
            "Epoch 33/100, Loss: 41.6330, Validation Accuracy: 0.6261\n",
            "Epoch 34/100, Loss: 30.7352, Validation Accuracy: 0.5484\n",
            "Epoch 35/100, Loss: 41.4472, Validation Accuracy: 0.5244\n",
            "Epoch 36/100, Loss: 67.0527, Validation Accuracy: 0.6421\n",
            "Epoch 37/100, Loss: 48.0771, Validation Accuracy: 0.4596\n",
            "Epoch 38/100, Loss: 45.5190, Validation Accuracy: 0.6281\n",
            "Epoch 39/100, Loss: 162.3339, Validation Accuracy: 0.6032\n",
            "Epoch 40/100, Loss: 78.3075, Validation Accuracy: 0.5803\n",
            "Epoch 41/100, Loss: 38.0776, Validation Accuracy: 0.6391\n",
            "Epoch 42/100, Loss: 89.3359, Validation Accuracy: 0.6152\n",
            "Epoch 43/100, Loss: 25.2328, Validation Accuracy: 0.3490\n",
            "Epoch 44/100, Loss: 52.8247, Validation Accuracy: 0.6670\n",
            "Epoch 45/100, Loss: 40.0718, Validation Accuracy: 0.6660\n",
            "Epoch 46/100, Loss: 38.5856, Validation Accuracy: 0.5952\n",
            "Epoch 47/100, Loss: 47.0992, Validation Accuracy: 0.6102\n",
            "Epoch 48/100, Loss: 22.4471, Validation Accuracy: 0.6820\n",
            "Epoch 49/100, Loss: 21.7471, Validation Accuracy: 0.3719\n",
            "Epoch 50/100, Loss: 39.3373, Validation Accuracy: 0.4845\n",
            "Epoch 51/100, Loss: 82.0646, Validation Accuracy: 0.6441\n",
            "Epoch 52/100, Loss: 35.4024, Validation Accuracy: 0.6500\n",
            "Epoch 53/100, Loss: 80.7746, Validation Accuracy: 0.5852\n",
            "Epoch 54/100, Loss: 42.4584, Validation Accuracy: 0.6042\n",
            "Epoch 55/100, Loss: 50.1115, Validation Accuracy: 0.6491\n",
            "Epoch 56/100, Loss: 98.4327, Validation Accuracy: 0.5553\n",
            "Epoch 57/100, Loss: 60.8977, Validation Accuracy: 0.5713\n",
            "Epoch 58/100, Loss: 102.1169, Validation Accuracy: 0.6800\n",
            "Epoch 59/100, Loss: 114.8924, Validation Accuracy: 0.6171\n",
            "Epoch 60/100, Loss: 59.3998, Validation Accuracy: 0.4746\n",
            "Epoch 61/100, Loss: 63.1293, Validation Accuracy: 0.6461\n",
            "Epoch 62/100, Loss: 60.1430, Validation Accuracy: 0.4875\n",
            "Epoch 63/100, Loss: 52.5556, Validation Accuracy: 0.5125\n",
            "Epoch 64/100, Loss: 58.7330, Validation Accuracy: 0.5693\n",
            "Epoch 65/100, Loss: 116.2657, Validation Accuracy: 0.6012\n",
            "Epoch 66/100, Loss: 55.8547, Validation Accuracy: 0.6670\n",
            "Epoch 67/100, Loss: 191.4518, Validation Accuracy: 0.6520\n",
            "Epoch 68/100, Loss: 101.4816, Validation Accuracy: 0.6820\n",
            "Epoch 69/100, Loss: 45.2179, Validation Accuracy: 0.6351\n",
            "Epoch 70/100, Loss: 93.6449, Validation Accuracy: 0.6271\n",
            "Epoch 71/100, Loss: 142.3582, Validation Accuracy: 0.5364\n",
            "Epoch 72/100, Loss: 100.5233, Validation Accuracy: 0.5773\n",
            "Epoch 73/100, Loss: 33.3442, Validation Accuracy: 0.6590\n",
            "Epoch 74/100, Loss: 34.1199, Validation Accuracy: 0.5304\n",
            "Epoch 75/100, Loss: 30.2222, Validation Accuracy: 0.5643\n",
            "Epoch 76/100, Loss: 57.9845, Validation Accuracy: 0.6142\n",
            "Epoch 77/100, Loss: 65.0444, Validation Accuracy: 0.6221\n",
            "Epoch 78/100, Loss: 118.2018, Validation Accuracy: 0.5284\n",
            "Epoch 79/100, Loss: 90.3018, Validation Accuracy: 0.5972\n",
            "Epoch 80/100, Loss: 52.4047, Validation Accuracy: 0.6640\n",
            "Epoch 81/100, Loss: 72.0423, Validation Accuracy: 0.6770\n",
            "Epoch 82/100, Loss: 55.0219, Validation Accuracy: 0.6251\n",
            "Epoch 83/100, Loss: 56.4450, Validation Accuracy: 0.6600\n",
            "Epoch 84/100, Loss: 60.8748, Validation Accuracy: 0.6650\n",
            "Epoch 85/100, Loss: 46.0593, Validation Accuracy: 0.6142\n",
            "Epoch 86/100, Loss: 49.5095, Validation Accuracy: 0.6670\n",
            "Epoch 87/100, Loss: 96.4874, Validation Accuracy: 0.6700\n",
            "Epoch 88/100, Loss: 14.4662, Validation Accuracy: 0.4835\n",
            "Epoch 89/100, Loss: 59.4315, Validation Accuracy: 0.6730\n",
            "Epoch 90/100, Loss: 62.2230, Validation Accuracy: 0.6142\n",
            "Epoch 91/100, Loss: 71.9148, Validation Accuracy: 0.5284\n",
            "Epoch 92/100, Loss: 185.2524, Validation Accuracy: 0.5494\n",
            "Epoch 93/100, Loss: 131.2866, Validation Accuracy: 0.5823\n",
            "Epoch 94/100, Loss: 102.3857, Validation Accuracy: 0.6391\n",
            "Epoch 95/100, Loss: 91.5896, Validation Accuracy: 0.3390\n",
            "Epoch 96/100, Loss: 77.2414, Validation Accuracy: 0.6291\n",
            "Epoch 97/100, Loss: 54.2878, Validation Accuracy: 0.5294\n",
            "Epoch 98/100, Loss: 84.8810, Validation Accuracy: 0.5952\n",
            "Epoch 99/100, Loss: 18.8742, Validation Accuracy: 0.6381\n",
            "Epoch 100/100, Loss: 66.0073, Validation Accuracy: 0.6112\n",
            "Epoch 101/100, Loss: 91.1749, Validation Accuracy: 0.5992\n",
            "Epoch 102/100, Loss: 27.0382, Validation Accuracy: 0.6211\n",
            "Epoch 103/100, Loss: 100.4780, Validation Accuracy: 0.6670\n",
            "Epoch 104/100, Loss: 144.1105, Validation Accuracy: 0.4816\n",
            "Epoch 105/100, Loss: 148.2358, Validation Accuracy: 0.5583\n",
            "Epoch 106/100, Loss: 135.7343, Validation Accuracy: 0.6461\n",
            "Epoch 107/100, Loss: 20.1226, Validation Accuracy: 0.5773\n",
            "Epoch 108/100, Loss: 97.5299, Validation Accuracy: 0.6590\n",
            "Epoch 109/100, Loss: 173.6514, Validation Accuracy: 0.6361\n",
            "Epoch 110/100, Loss: 46.8551, Validation Accuracy: 0.6231\n",
            "Epoch 111/100, Loss: 118.1806, Validation Accuracy: 0.6052\n",
            "Epoch 112/100, Loss: 73.6545, Validation Accuracy: 0.5174\n",
            "Epoch 113/100, Loss: 60.5350, Validation Accuracy: 0.6221\n",
            "Epoch 114/100, Loss: 49.9391, Validation Accuracy: 0.6271\n",
            "Epoch 115/100, Loss: 115.7625, Validation Accuracy: 0.6859\n",
            "Epoch 116/100, Loss: 43.5044, Validation Accuracy: 0.6291\n",
            "Epoch 117/100, Loss: 56.2740, Validation Accuracy: 0.5543\n",
            "Epoch 118/100, Loss: 37.2144, Validation Accuracy: 0.5862\n",
            "Epoch 119/100, Loss: 136.0143, Validation Accuracy: 0.6491\n",
            "Epoch 120/100, Loss: 33.5116, Validation Accuracy: 0.6491\n",
            "Epoch 121/100, Loss: 91.1631, Validation Accuracy: 0.6271\n",
            "Epoch 122/100, Loss: 34.6743, Validation Accuracy: 0.6002\n",
            "Epoch 123/100, Loss: 29.6552, Validation Accuracy: 0.5753\n",
            "Epoch 124/100, Loss: 48.1260, Validation Accuracy: 0.6072\n",
            "Epoch 125/100, Loss: 114.8709, Validation Accuracy: 0.6072\n",
            "Epoch 126/100, Loss: 23.0875, Validation Accuracy: 0.6401\n",
            "Epoch 127/100, Loss: 122.8576, Validation Accuracy: 0.6241\n",
            "Epoch 128/100, Loss: 79.3952, Validation Accuracy: 0.6471\n",
            "Epoch 129/100, Loss: 91.7901, Validation Accuracy: 0.5444\n",
            "Epoch 130/100, Loss: 15.0823, Validation Accuracy: 0.6530\n",
            "Epoch 131/100, Loss: 92.2221, Validation Accuracy: 0.6371\n",
            "Epoch 132/100, Loss: 22.0019, Validation Accuracy: 0.6820\n",
            "Epoch 133/100, Loss: 54.7437, Validation Accuracy: 0.6471\n",
            "Epoch 134/100, Loss: 45.0284, Validation Accuracy: 0.5653\n",
            "Epoch 135/100, Loss: 37.3407, Validation Accuracy: 0.5663\n",
            "Epoch 136/100, Loss: 98.9314, Validation Accuracy: 0.6371\n",
            "Epoch 137/100, Loss: 69.9676, Validation Accuracy: 0.6481\n",
            "Epoch 138/100, Loss: 53.2962, Validation Accuracy: 0.6211\n",
            "Epoch 139/100, Loss: 69.4142, Validation Accuracy: 0.6770\n",
            "Epoch 140/100, Loss: 124.0604, Validation Accuracy: 0.5763\n",
            "Epoch 141/100, Loss: 68.2412, Validation Accuracy: 0.6221\n",
            "Epoch 142/100, Loss: 56.8151, Validation Accuracy: 0.6191\n",
            "Epoch 143/100, Loss: 93.7804, Validation Accuracy: 0.6361\n",
            "Epoch 144/100, Loss: 172.4528, Validation Accuracy: 0.5982\n",
            "Epoch 145/100, Loss: 52.4030, Validation Accuracy: 0.6062\n",
            "Epoch 146/100, Loss: 83.9562, Validation Accuracy: 0.6461\n",
            "Epoch 147/100, Loss: 53.8345, Validation Accuracy: 0.6261\n",
            "Epoch 148/100, Loss: 22.2546, Validation Accuracy: 0.6281\n",
            "Epoch 149/100, Loss: 95.4061, Validation Accuracy: 0.6231\n",
            "Epoch 150/100, Loss: 52.1722, Validation Accuracy: 0.5942\n",
            "Epoch 151/100, Loss: 59.3191, Validation Accuracy: 0.5244\n",
            "Epoch 152/100, Loss: 50.5321, Validation Accuracy: 0.5942\n",
            "Epoch 153/100, Loss: 34.3443, Validation Accuracy: 0.6002\n",
            "Epoch 154/100, Loss: 59.5341, Validation Accuracy: 0.6481\n",
            "Epoch 155/100, Loss: 194.2975, Validation Accuracy: 0.6052\n",
            "Epoch 156/100, Loss: 62.4254, Validation Accuracy: 0.6062\n",
            "Epoch 157/100, Loss: 25.0618, Validation Accuracy: 0.6431\n",
            "Epoch 158/100, Loss: 51.1940, Validation Accuracy: 0.6620\n",
            "Epoch 159/100, Loss: 74.0695, Validation Accuracy: 0.5643\n",
            "Epoch 160/100, Loss: 186.8035, Validation Accuracy: 0.6331\n",
            "Epoch 161/100, Loss: 76.4330, Validation Accuracy: 0.6132\n",
            "Epoch 162/100, Loss: 68.6364, Validation Accuracy: 0.6461\n",
            "Epoch 163/100, Loss: 31.6999, Validation Accuracy: 0.6162\n",
            "Epoch 164/100, Loss: 52.8899, Validation Accuracy: 0.6331\n",
            "Epoch 165/100, Loss: 46.3703, Validation Accuracy: 0.5892\n",
            "Epoch 166/100, Loss: 18.3585, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 145.5251, Validation Accuracy: 0.6720\n",
            "Epoch 168/100, Loss: 89.1515, Validation Accuracy: 0.5733\n",
            "Epoch 169/100, Loss: 53.0037, Validation Accuracy: 0.6012\n",
            "Epoch 170/100, Loss: 59.5636, Validation Accuracy: 0.5743\n",
            "Epoch 171/100, Loss: 75.4718, Validation Accuracy: 0.6481\n",
            "Epoch 172/100, Loss: 13.4440, Validation Accuracy: 0.6411\n",
            "Epoch 173/100, Loss: 123.3878, Validation Accuracy: 0.6760\n",
            "Epoch 174/100, Loss: 76.8338, Validation Accuracy: 0.6351\n",
            "Epoch 175/100, Loss: 99.8921, Validation Accuracy: 0.6281\n",
            "Epoch 176/100, Loss: 88.7707, Validation Accuracy: 0.6231\n",
            "Epoch 177/100, Loss: 57.4259, Validation Accuracy: 0.5892\n",
            "Epoch 178/100, Loss: 144.0766, Validation Accuracy: 0.5972\n",
            "Epoch 179/100, Loss: 58.4810, Validation Accuracy: 0.6301\n",
            "Epoch 180/100, Loss: 68.9981, Validation Accuracy: 0.6271\n",
            "Epoch 181/100, Loss: 28.8422, Validation Accuracy: 0.6461\n",
            "Epoch 182/100, Loss: 44.2794, Validation Accuracy: 0.5573\n",
            "Epoch 183/100, Loss: 16.3253, Validation Accuracy: 0.5912\n",
            "Epoch 184/100, Loss: 70.8325, Validation Accuracy: 0.5892\n",
            "Epoch 185/100, Loss: 34.5193, Validation Accuracy: 0.6191\n",
            "Epoch 186/100, Loss: 36.3473, Validation Accuracy: 0.5523\n",
            "Epoch 187/100, Loss: 69.6849, Validation Accuracy: 0.5723\n",
            "Epoch 188/100, Loss: 59.5952, Validation Accuracy: 0.5882\n",
            "Epoch 189/100, Loss: 82.5635, Validation Accuracy: 0.6341\n",
            "Epoch 190/100, Loss: 109.7398, Validation Accuracy: 0.5623\n",
            "Epoch 191/100, Loss: 77.5850, Validation Accuracy: 0.6042\n",
            "Epoch 192/100, Loss: 136.6606, Validation Accuracy: 0.5882\n",
            "Epoch 193/100, Loss: 83.4658, Validation Accuracy: 0.6132\n",
            "Epoch 194/100, Loss: 23.0033, Validation Accuracy: 0.6590\n",
            "Epoch 195/100, Loss: 67.2699, Validation Accuracy: 0.6142\n",
            "Epoch 196/100, Loss: 26.0420, Validation Accuracy: 0.6162\n",
            "Epoch 197/100, Loss: 22.0803, Validation Accuracy: 0.6002\n",
            "Epoch 198/100, Loss: 65.5645, Validation Accuracy: 0.6371\n",
            "Epoch 199/100, Loss: 113.1974, Validation Accuracy: 0.6072\n",
            "Epoch 200/100, Loss: 119.6222, Validation Accuracy: 0.5932\n",
            "Reward for Child Model: 0.258582884321492\n",
            "Child_83:  {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, [1, 0, 3, 2, 1, 3, 1, 2, 3, 2, 0, 0, 3, 2, 1], 0.258582884321492\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(84, 36, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(120, 48, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=112896, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 28, 28]             144\n",
            "       BatchNorm2d-2           [-1, 36, 28, 28]              72\n",
            "            Conv2d-3           [-1, 48, 26, 28]           5,232\n",
            "       BatchNorm2d-4           [-1, 48, 26, 28]              96\n",
            "              ReLU-5           [-1, 48, 26, 28]               0\n",
            "            Conv2d-6           [-1, 36, 26, 26]          27,252\n",
            "       BatchNorm2d-7           [-1, 36, 26, 26]              72\n",
            "              ReLU-8           [-1, 36, 26, 26]               0\n",
            "            Conv2d-9           [-1, 48, 26, 24]          86,448\n",
            "      BatchNorm2d-10           [-1, 48, 26, 24]              96\n",
            "             ReLU-11           [-1, 48, 26, 24]               0\n",
            "           Conv2d-12           [-1, 24, 24, 22]          10,392\n",
            "      BatchNorm2d-13           [-1, 24, 24, 22]              48\n",
            "             ReLU-14           [-1, 24, 24, 22]               0\n",
            "           Linear-15                    [-1, 7]         790,279\n",
            "================================================================\n",
            "Total params: 920,131\n",
            "Trainable params: 920,131\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.76\n",
            "Params size (MB): 3.51\n",
            "Estimated Total Size (MB): 6.28\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 20.0980, Validation Accuracy: 0.5105\n",
            "Epoch 2/100, Loss: 10.9803, Validation Accuracy: 0.6640\n",
            "Epoch 3/100, Loss: 31.3513, Validation Accuracy: 0.2273\n",
            "Epoch 4/100, Loss: 16.6501, Validation Accuracy: 0.5364\n",
            "Epoch 5/100, Loss: 8.3087, Validation Accuracy: 0.4267\n",
            "Epoch 6/100, Loss: 20.1349, Validation Accuracy: 0.6630\n",
            "Epoch 7/100, Loss: 18.2819, Validation Accuracy: 0.5553\n",
            "Epoch 8/100, Loss: 60.3098, Validation Accuracy: 0.6520\n",
            "Epoch 9/100, Loss: 80.4972, Validation Accuracy: 0.6690\n",
            "Epoch 10/100, Loss: 129.0801, Validation Accuracy: 0.6650\n",
            "Epoch 11/100, Loss: 39.4989, Validation Accuracy: 0.4646\n",
            "Epoch 12/100, Loss: 110.5072, Validation Accuracy: 0.4287\n",
            "Epoch 13/100, Loss: 92.4738, Validation Accuracy: 0.5733\n",
            "Epoch 14/100, Loss: 56.0709, Validation Accuracy: 0.5972\n",
            "Epoch 15/100, Loss: 40.4010, Validation Accuracy: 0.6072\n",
            "Epoch 16/100, Loss: 19.7148, Validation Accuracy: 0.5174\n",
            "Epoch 17/100, Loss: 94.1855, Validation Accuracy: 0.5852\n",
            "Epoch 18/100, Loss: 45.6736, Validation Accuracy: 0.3440\n",
            "Epoch 19/100, Loss: 160.9099, Validation Accuracy: 0.6181\n",
            "Epoch 20/100, Loss: 59.7054, Validation Accuracy: 0.5992\n",
            "Epoch 21/100, Loss: 48.8302, Validation Accuracy: 0.6201\n",
            "Epoch 22/100, Loss: 41.0860, Validation Accuracy: 0.5224\n",
            "Epoch 23/100, Loss: 144.9587, Validation Accuracy: 0.6491\n",
            "Epoch 24/100, Loss: 91.9412, Validation Accuracy: 0.6201\n",
            "Epoch 25/100, Loss: 54.4424, Validation Accuracy: 0.5324\n",
            "Epoch 26/100, Loss: 91.2362, Validation Accuracy: 0.6361\n",
            "Epoch 27/100, Loss: 34.8270, Validation Accuracy: 0.6540\n",
            "Epoch 28/100, Loss: 37.5899, Validation Accuracy: 0.6780\n",
            "Epoch 29/100, Loss: 20.2936, Validation Accuracy: 0.6341\n",
            "Epoch 30/100, Loss: 39.5369, Validation Accuracy: 0.6351\n",
            "Epoch 31/100, Loss: 27.7500, Validation Accuracy: 0.5503\n",
            "Epoch 32/100, Loss: 54.7536, Validation Accuracy: 0.6600\n",
            "Epoch 33/100, Loss: 88.8060, Validation Accuracy: 0.5613\n",
            "Epoch 34/100, Loss: 76.3127, Validation Accuracy: 0.6839\n",
            "Epoch 35/100, Loss: 28.0828, Validation Accuracy: 0.5553\n",
            "Epoch 36/100, Loss: 86.8103, Validation Accuracy: 0.6411\n",
            "Epoch 37/100, Loss: 135.5629, Validation Accuracy: 0.6760\n",
            "Epoch 38/100, Loss: 72.9128, Validation Accuracy: 0.3779\n",
            "Epoch 39/100, Loss: 68.4513, Validation Accuracy: 0.5733\n",
            "Epoch 40/100, Loss: 22.3868, Validation Accuracy: 0.5254\n",
            "Epoch 41/100, Loss: 26.2537, Validation Accuracy: 0.6730\n",
            "Epoch 42/100, Loss: 128.1434, Validation Accuracy: 0.5474\n",
            "Epoch 43/100, Loss: 64.5885, Validation Accuracy: 0.4855\n",
            "Epoch 44/100, Loss: 32.8389, Validation Accuracy: 0.6381\n",
            "Epoch 45/100, Loss: 78.2732, Validation Accuracy: 0.6072\n",
            "Epoch 46/100, Loss: 45.5092, Validation Accuracy: 0.6431\n",
            "Epoch 47/100, Loss: 87.7231, Validation Accuracy: 0.6680\n",
            "Epoch 48/100, Loss: 83.6525, Validation Accuracy: 0.3240\n",
            "Epoch 49/100, Loss: 127.1988, Validation Accuracy: 0.5892\n",
            "Epoch 50/100, Loss: 98.2534, Validation Accuracy: 0.4875\n",
            "Epoch 51/100, Loss: 68.8701, Validation Accuracy: 0.6451\n",
            "Epoch 52/100, Loss: 84.2309, Validation Accuracy: 0.5593\n",
            "Epoch 53/100, Loss: 67.1299, Validation Accuracy: 0.6740\n",
            "Epoch 54/100, Loss: 53.5050, Validation Accuracy: 0.5902\n",
            "Epoch 55/100, Loss: 29.8445, Validation Accuracy: 0.3390\n",
            "Epoch 56/100, Loss: 52.8080, Validation Accuracy: 0.6331\n",
            "Epoch 57/100, Loss: 105.9155, Validation Accuracy: 0.5992\n",
            "Epoch 58/100, Loss: 37.9886, Validation Accuracy: 0.6441\n",
            "Epoch 59/100, Loss: 141.8201, Validation Accuracy: 0.5793\n",
            "Epoch 60/100, Loss: 126.8527, Validation Accuracy: 0.6481\n",
            "Epoch 61/100, Loss: 42.1424, Validation Accuracy: 0.6201\n",
            "Epoch 62/100, Loss: 83.4698, Validation Accuracy: 0.6341\n",
            "Epoch 63/100, Loss: 135.2374, Validation Accuracy: 0.6461\n",
            "Epoch 64/100, Loss: 54.0963, Validation Accuracy: 0.4786\n",
            "Epoch 65/100, Loss: 30.5234, Validation Accuracy: 0.6132\n",
            "Epoch 66/100, Loss: 88.2082, Validation Accuracy: 0.5982\n",
            "Epoch 67/100, Loss: 33.7316, Validation Accuracy: 0.5952\n",
            "Epoch 68/100, Loss: 74.4064, Validation Accuracy: 0.5364\n",
            "Epoch 69/100, Loss: 49.8995, Validation Accuracy: 0.6491\n",
            "Epoch 70/100, Loss: 61.9759, Validation Accuracy: 0.6181\n",
            "Epoch 71/100, Loss: 83.2066, Validation Accuracy: 0.6710\n",
            "Epoch 72/100, Loss: 93.7265, Validation Accuracy: 0.5135\n",
            "Epoch 73/100, Loss: 63.3797, Validation Accuracy: 0.6281\n",
            "Epoch 74/100, Loss: 65.6145, Validation Accuracy: 0.5015\n",
            "Epoch 75/100, Loss: 33.6456, Validation Accuracy: 0.6032\n",
            "Epoch 76/100, Loss: 69.2295, Validation Accuracy: 0.5653\n",
            "Epoch 77/100, Loss: 144.2537, Validation Accuracy: 0.6640\n",
            "Epoch 78/100, Loss: 18.5453, Validation Accuracy: 0.6221\n",
            "Epoch 79/100, Loss: 49.1411, Validation Accuracy: 0.6859\n",
            "Epoch 80/100, Loss: 27.3134, Validation Accuracy: 0.6162\n",
            "Epoch 81/100, Loss: 59.4145, Validation Accuracy: 0.4865\n",
            "Epoch 82/100, Loss: 133.4291, Validation Accuracy: 0.5862\n",
            "Epoch 83/100, Loss: 92.2013, Validation Accuracy: 0.6540\n",
            "Epoch 84/100, Loss: 55.6132, Validation Accuracy: 0.6401\n",
            "Epoch 85/100, Loss: 97.3627, Validation Accuracy: 0.5125\n",
            "Epoch 86/100, Loss: 77.2241, Validation Accuracy: 0.6261\n",
            "Epoch 87/100, Loss: 208.4048, Validation Accuracy: 0.5643\n",
            "Epoch 88/100, Loss: 100.2085, Validation Accuracy: 0.6530\n",
            "Epoch 89/100, Loss: 20.0005, Validation Accuracy: 0.6421\n",
            "Epoch 90/100, Loss: 46.9628, Validation Accuracy: 0.5663\n",
            "Epoch 91/100, Loss: 66.8148, Validation Accuracy: 0.6042\n",
            "Epoch 92/100, Loss: 18.4692, Validation Accuracy: 0.6560\n",
            "Epoch 93/100, Loss: 34.6268, Validation Accuracy: 0.6102\n",
            "Epoch 94/100, Loss: 154.5490, Validation Accuracy: 0.6002\n",
            "Epoch 95/100, Loss: 35.3074, Validation Accuracy: 0.5902\n",
            "Epoch 96/100, Loss: 39.6885, Validation Accuracy: 0.4706\n",
            "Epoch 97/100, Loss: 27.7512, Validation Accuracy: 0.5494\n",
            "Epoch 98/100, Loss: 45.8273, Validation Accuracy: 0.5085\n",
            "Epoch 99/100, Loss: 43.2415, Validation Accuracy: 0.6730\n",
            "Epoch 100/100, Loss: 257.7952, Validation Accuracy: 0.6750\n",
            "Epoch 101/100, Loss: 79.9584, Validation Accuracy: 0.3380\n",
            "Epoch 102/100, Loss: 30.0581, Validation Accuracy: 0.6879\n",
            "Epoch 103/100, Loss: 105.3108, Validation Accuracy: 0.5773\n",
            "Epoch 104/100, Loss: 48.2807, Validation Accuracy: 0.5533\n",
            "Epoch 105/100, Loss: 241.3912, Validation Accuracy: 0.6590\n",
            "Epoch 106/100, Loss: 104.0916, Validation Accuracy: 0.6670\n",
            "Epoch 107/100, Loss: 171.2743, Validation Accuracy: 0.5633\n",
            "Epoch 108/100, Loss: 109.7371, Validation Accuracy: 0.5952\n",
            "Epoch 109/100, Loss: 55.9828, Validation Accuracy: 0.6520\n",
            "Epoch 110/100, Loss: 28.0420, Validation Accuracy: 0.5394\n",
            "Epoch 111/100, Loss: 81.4790, Validation Accuracy: 0.6032\n",
            "Epoch 112/100, Loss: 72.5271, Validation Accuracy: 0.5842\n",
            "Epoch 113/100, Loss: 60.0745, Validation Accuracy: 0.2453\n",
            "Epoch 114/100, Loss: 105.4068, Validation Accuracy: 0.6032\n",
            "Epoch 115/100, Loss: 46.4959, Validation Accuracy: 0.6351\n",
            "Epoch 116/100, Loss: 106.9190, Validation Accuracy: 0.4467\n",
            "Epoch 117/100, Loss: 42.7469, Validation Accuracy: 0.6401\n",
            "Epoch 118/100, Loss: 48.2708, Validation Accuracy: 0.5304\n",
            "Epoch 119/100, Loss: 38.1370, Validation Accuracy: 0.5474\n",
            "Epoch 120/100, Loss: 493.4961, Validation Accuracy: 0.4955\n",
            "Epoch 121/100, Loss: 51.7532, Validation Accuracy: 0.6102\n",
            "Epoch 122/100, Loss: 38.8381, Validation Accuracy: 0.4048\n",
            "Epoch 123/100, Loss: 25.7036, Validation Accuracy: 0.6102\n",
            "Epoch 124/100, Loss: 59.0977, Validation Accuracy: 0.6251\n",
            "Epoch 125/100, Loss: 89.4763, Validation Accuracy: 0.4377\n",
            "Epoch 126/100, Loss: 51.5623, Validation Accuracy: 0.3918\n",
            "Epoch 127/100, Loss: 369.1624, Validation Accuracy: 0.6590\n",
            "Epoch 128/100, Loss: 75.2643, Validation Accuracy: 0.6660\n",
            "Epoch 129/100, Loss: 109.3221, Validation Accuracy: 0.6291\n",
            "Epoch 130/100, Loss: 45.2915, Validation Accuracy: 0.6082\n",
            "Epoch 131/100, Loss: 61.8810, Validation Accuracy: 0.6790\n",
            "Epoch 132/100, Loss: 86.1451, Validation Accuracy: 0.6680\n",
            "Epoch 133/100, Loss: 91.0661, Validation Accuracy: 0.6500\n",
            "Epoch 134/100, Loss: 43.2931, Validation Accuracy: 0.6052\n",
            "Epoch 135/100, Loss: 95.3404, Validation Accuracy: 0.6461\n",
            "Epoch 136/100, Loss: 80.9579, Validation Accuracy: 0.6311\n",
            "Epoch 137/100, Loss: 292.6858, Validation Accuracy: 0.6630\n",
            "Epoch 138/100, Loss: 78.8168, Validation Accuracy: 0.6590\n",
            "Epoch 139/100, Loss: 28.2549, Validation Accuracy: 0.6321\n",
            "Epoch 140/100, Loss: 83.1741, Validation Accuracy: 0.6540\n",
            "Epoch 141/100, Loss: 56.4939, Validation Accuracy: 0.6251\n",
            "Epoch 142/100, Loss: 43.4222, Validation Accuracy: 0.5833\n",
            "Epoch 143/100, Loss: 96.3173, Validation Accuracy: 0.6500\n",
            "Epoch 144/100, Loss: 54.2276, Validation Accuracy: 0.5862\n",
            "Epoch 145/100, Loss: 31.8415, Validation Accuracy: 0.6032\n",
            "Epoch 146/100, Loss: 137.5288, Validation Accuracy: 0.5862\n",
            "Epoch 147/100, Loss: 51.0404, Validation Accuracy: 0.5274\n",
            "Epoch 148/100, Loss: 39.9599, Validation Accuracy: 0.6391\n",
            "Epoch 149/100, Loss: 62.9576, Validation Accuracy: 0.6660\n",
            "Epoch 150/100, Loss: 88.8917, Validation Accuracy: 0.6550\n",
            "Epoch 151/100, Loss: 178.0617, Validation Accuracy: 0.6311\n",
            "Epoch 152/100, Loss: 47.9377, Validation Accuracy: 0.6510\n",
            "Epoch 153/100, Loss: 43.0209, Validation Accuracy: 0.6321\n",
            "Epoch 154/100, Loss: 134.3161, Validation Accuracy: 0.4337\n",
            "Epoch 155/100, Loss: 112.5218, Validation Accuracy: 0.5115\n",
            "Epoch 156/100, Loss: 70.9117, Validation Accuracy: 0.5513\n",
            "Epoch 157/100, Loss: 92.4587, Validation Accuracy: 0.5952\n",
            "Epoch 158/100, Loss: 63.0402, Validation Accuracy: 0.6540\n",
            "Epoch 159/100, Loss: 58.4422, Validation Accuracy: 0.6301\n",
            "Epoch 160/100, Loss: 58.0319, Validation Accuracy: 0.5813\n",
            "Epoch 161/100, Loss: 46.5658, Validation Accuracy: 0.5703\n",
            "Epoch 162/100, Loss: 88.2254, Validation Accuracy: 0.6461\n",
            "Epoch 163/100, Loss: 50.7983, Validation Accuracy: 0.6520\n",
            "Epoch 164/100, Loss: 146.0649, Validation Accuracy: 0.5523\n",
            "Epoch 165/100, Loss: 83.4695, Validation Accuracy: 0.5972\n",
            "Epoch 166/100, Loss: 33.0167, Validation Accuracy: 0.5653\n",
            "Epoch 167/100, Loss: 371.2614, Validation Accuracy: 0.5204\n",
            "Epoch 168/100, Loss: 128.6094, Validation Accuracy: 0.5693\n",
            "Epoch 169/100, Loss: 43.8110, Validation Accuracy: 0.6132\n",
            "Epoch 170/100, Loss: 39.8749, Validation Accuracy: 0.5723\n",
            "Epoch 171/100, Loss: 189.5012, Validation Accuracy: 0.4048\n",
            "Epoch 172/100, Loss: 83.7150, Validation Accuracy: 0.6421\n",
            "Epoch 173/100, Loss: 32.0833, Validation Accuracy: 0.6760\n",
            "Epoch 174/100, Loss: 30.2087, Validation Accuracy: 0.6550\n",
            "Epoch 175/100, Loss: 122.4086, Validation Accuracy: 0.5244\n",
            "Epoch 176/100, Loss: 501.0543, Validation Accuracy: 0.5125\n",
            "Epoch 177/100, Loss: 96.7305, Validation Accuracy: 0.6520\n",
            "Epoch 178/100, Loss: 76.9212, Validation Accuracy: 0.5135\n",
            "Epoch 179/100, Loss: 46.8482, Validation Accuracy: 0.6261\n",
            "Epoch 180/100, Loss: 67.6292, Validation Accuracy: 0.6191\n",
            "Epoch 181/100, Loss: 25.4556, Validation Accuracy: 0.5952\n",
            "Epoch 182/100, Loss: 31.0971, Validation Accuracy: 0.6281\n",
            "Epoch 183/100, Loss: 87.9389, Validation Accuracy: 0.6211\n",
            "Epoch 184/100, Loss: 80.0496, Validation Accuracy: 0.6780\n",
            "Epoch 185/100, Loss: 52.2500, Validation Accuracy: 0.6481\n",
            "Epoch 186/100, Loss: 85.6181, Validation Accuracy: 0.6042\n",
            "Epoch 187/100, Loss: 29.6961, Validation Accuracy: 0.6889\n",
            "Epoch 188/100, Loss: 84.2484, Validation Accuracy: 0.3460\n",
            "Epoch 189/100, Loss: 21.7968, Validation Accuracy: 0.6451\n",
            "Epoch 190/100, Loss: 44.1429, Validation Accuracy: 0.6042\n",
            "Epoch 191/100, Loss: 78.5872, Validation Accuracy: 0.6720\n",
            "Epoch 192/100, Loss: 779.9431, Validation Accuracy: 0.5204\n",
            "Epoch 193/100, Loss: 47.0489, Validation Accuracy: 0.4935\n",
            "Epoch 194/100, Loss: 40.4824, Validation Accuracy: 0.5713\n",
            "Epoch 195/100, Loss: 55.9645, Validation Accuracy: 0.6770\n",
            "Epoch 196/100, Loss: 14.5617, Validation Accuracy: 0.6241\n",
            "Epoch 197/100, Loss: 37.0359, Validation Accuracy: 0.6341\n",
            "Epoch 198/100, Loss: 45.3349, Validation Accuracy: 0.6451\n",
            "Epoch 199/100, Loss: 111.0398, Validation Accuracy: 0.6162\n",
            "Epoch 200/100, Loss: 103.7509, Validation Accuracy: 0.6271\n",
            "Reward for Child Model: 0.2684170153551299\n",
            "Child_84:  {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, [0, 0, 1, 1, 0, 2, 1, 1, 1, 1, 2, 2, 1, 1, 0], 0.2684170153551299\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(24, 36, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(60, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(124, 24, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=105952, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 28, 22]             528\n",
            "       BatchNorm2d-2           [-1, 24, 28, 22]              48\n",
            "            Conv2d-3           [-1, 24, 28, 16]           4,056\n",
            "       BatchNorm2d-4           [-1, 24, 28, 16]              48\n",
            "              ReLU-5           [-1, 24, 28, 16]               0\n",
            "            Conv2d-6           [-1, 36, 22, 14]          18,180\n",
            "       BatchNorm2d-7           [-1, 36, 22, 14]              72\n",
            "              ReLU-8           [-1, 36, 22, 14]               0\n",
            "            Conv2d-9           [-1, 64, 24, 16]          19,264\n",
            "      BatchNorm2d-10           [-1, 64, 24, 16]             128\n",
            "             ReLU-11           [-1, 64, 24, 16]               0\n",
            "           Conv2d-12           [-1, 24, 22, 16]          20,856\n",
            "      BatchNorm2d-13           [-1, 24, 22, 16]              48\n",
            "             ReLU-14           [-1, 24, 22, 16]               0\n",
            "           Linear-15                    [-1, 7]         741,671\n",
            "================================================================\n",
            "Total params: 804,899\n",
            "Trainable params: 804,899\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.48\n",
            "Params size (MB): 3.07\n",
            "Estimated Total Size (MB): 4.56\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 9.2101, Validation Accuracy: 0.5055\n",
            "Epoch 2/100, Loss: 34.6802, Validation Accuracy: 0.5503\n",
            "Epoch 3/100, Loss: 16.3981, Validation Accuracy: 0.6391\n",
            "Epoch 4/100, Loss: 122.7638, Validation Accuracy: 0.4227\n",
            "Epoch 5/100, Loss: 6.4676, Validation Accuracy: 0.5035\n",
            "Epoch 6/100, Loss: 20.5964, Validation Accuracy: 0.4566\n",
            "Epoch 7/100, Loss: 2.9130, Validation Accuracy: 0.4955\n",
            "Epoch 8/100, Loss: 43.7517, Validation Accuracy: 0.6211\n",
            "Epoch 9/100, Loss: 22.3587, Validation Accuracy: 0.5254\n",
            "Epoch 10/100, Loss: 4.1195, Validation Accuracy: 0.5314\n",
            "Epoch 11/100, Loss: 18.6371, Validation Accuracy: 0.5902\n",
            "Epoch 12/100, Loss: 278.7299, Validation Accuracy: 0.6371\n",
            "Epoch 13/100, Loss: 26.5116, Validation Accuracy: 0.4646\n",
            "Epoch 14/100, Loss: 125.6301, Validation Accuracy: 0.6042\n",
            "Epoch 15/100, Loss: 32.5013, Validation Accuracy: 0.5553\n",
            "Epoch 16/100, Loss: 7.1350, Validation Accuracy: 0.5543\n",
            "Epoch 17/100, Loss: 389.8748, Validation Accuracy: 0.5055\n",
            "Epoch 18/100, Loss: 97.9822, Validation Accuracy: 0.6281\n",
            "Epoch 19/100, Loss: 26.7630, Validation Accuracy: 0.5444\n",
            "Epoch 20/100, Loss: 23.1860, Validation Accuracy: 0.5942\n",
            "Epoch 21/100, Loss: 11.5306, Validation Accuracy: 0.6012\n",
            "Epoch 22/100, Loss: 6.5552, Validation Accuracy: 0.5553\n",
            "Epoch 23/100, Loss: 6.5873, Validation Accuracy: 0.6770\n",
            "Epoch 24/100, Loss: 919.1939, Validation Accuracy: 0.6152\n",
            "Epoch 25/100, Loss: 347.9184, Validation Accuracy: 0.5833\n",
            "Epoch 26/100, Loss: 99.8606, Validation Accuracy: 0.6451\n",
            "Epoch 27/100, Loss: 126.2352, Validation Accuracy: 0.5444\n",
            "Epoch 28/100, Loss: 93.0742, Validation Accuracy: 0.6351\n",
            "Epoch 29/100, Loss: 58.2807, Validation Accuracy: 0.6580\n",
            "Epoch 30/100, Loss: 20.9444, Validation Accuracy: 0.6650\n",
            "Epoch 31/100, Loss: 82.7943, Validation Accuracy: 0.6301\n",
            "Epoch 32/100, Loss: 27.7654, Validation Accuracy: 0.6002\n",
            "Epoch 33/100, Loss: 17.8130, Validation Accuracy: 0.6550\n",
            "Epoch 34/100, Loss: 34.2365, Validation Accuracy: 0.6201\n",
            "Epoch 35/100, Loss: 18.3285, Validation Accuracy: 0.6112\n",
            "Epoch 36/100, Loss: 14.9392, Validation Accuracy: 0.4696\n",
            "Epoch 37/100, Loss: 11.3924, Validation Accuracy: 0.5842\n",
            "Epoch 38/100, Loss: 6.6396, Validation Accuracy: 0.5952\n",
            "Epoch 39/100, Loss: 17.5588, Validation Accuracy: 0.6630\n",
            "Epoch 40/100, Loss: 4.7281, Validation Accuracy: 0.5424\n",
            "Epoch 41/100, Loss: 10.5519, Validation Accuracy: 0.6371\n",
            "Epoch 42/100, Loss: 5.2852, Validation Accuracy: 0.6152\n",
            "Epoch 43/100, Loss: 6.8120, Validation Accuracy: 0.6331\n",
            "Epoch 44/100, Loss: 53.4641, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 6.4996, Validation Accuracy: 0.6361\n",
            "Epoch 46/100, Loss: 6.4305, Validation Accuracy: 0.5763\n",
            "Epoch 47/100, Loss: 80.6548, Validation Accuracy: 0.6411\n",
            "Epoch 48/100, Loss: 17.3336, Validation Accuracy: 0.5603\n",
            "Epoch 49/100, Loss: 878.0959, Validation Accuracy: 0.6281\n",
            "Epoch 50/100, Loss: 447.9144, Validation Accuracy: 0.6341\n",
            "Epoch 51/100, Loss: 244.5086, Validation Accuracy: 0.6231\n",
            "Epoch 52/100, Loss: 270.2104, Validation Accuracy: 0.5145\n",
            "Epoch 53/100, Loss: 390.4840, Validation Accuracy: 0.4596\n",
            "Epoch 54/100, Loss: 194.9042, Validation Accuracy: 0.6042\n",
            "Epoch 55/100, Loss: 169.1434, Validation Accuracy: 0.5793\n",
            "Epoch 56/100, Loss: 377.9008, Validation Accuracy: 0.5643\n",
            "Epoch 57/100, Loss: 228.5176, Validation Accuracy: 0.6271\n",
            "Epoch 58/100, Loss: 85.6058, Validation Accuracy: 0.5633\n",
            "Epoch 59/100, Loss: 102.7362, Validation Accuracy: 0.4596\n",
            "Epoch 60/100, Loss: 16.3123, Validation Accuracy: 0.6221\n",
            "Epoch 61/100, Loss: 85.8990, Validation Accuracy: 0.6570\n",
            "Epoch 62/100, Loss: 69.4649, Validation Accuracy: 0.5484\n",
            "Epoch 63/100, Loss: 23.0594, Validation Accuracy: 0.5394\n",
            "Epoch 64/100, Loss: 59.9607, Validation Accuracy: 0.5902\n",
            "Epoch 65/100, Loss: 20.1602, Validation Accuracy: 0.5553\n",
            "Epoch 66/100, Loss: 45.9708, Validation Accuracy: 0.5653\n",
            "Epoch 67/100, Loss: 31.8441, Validation Accuracy: 0.5693\n",
            "Epoch 68/100, Loss: 32.6069, Validation Accuracy: 0.5942\n",
            "Epoch 69/100, Loss: 10.2794, Validation Accuracy: 0.6750\n",
            "Epoch 70/100, Loss: 4.8564, Validation Accuracy: 0.6181\n",
            "Epoch 71/100, Loss: 5.8879, Validation Accuracy: 0.5533\n",
            "Epoch 72/100, Loss: 4.9206, Validation Accuracy: 0.4995\n",
            "Epoch 73/100, Loss: 5.9537, Validation Accuracy: 0.4307\n",
            "Epoch 74/100, Loss: 5.5516, Validation Accuracy: 0.6341\n",
            "Epoch 75/100, Loss: 3.5481, Validation Accuracy: 0.6421\n",
            "Epoch 76/100, Loss: 3.3888, Validation Accuracy: 0.6191\n",
            "Epoch 77/100, Loss: 9.3053, Validation Accuracy: 0.6550\n",
            "Epoch 78/100, Loss: 6.8681, Validation Accuracy: 0.5593\n",
            "Epoch 79/100, Loss: 24.1404, Validation Accuracy: 0.3739\n",
            "Epoch 80/100, Loss: 2.8112, Validation Accuracy: 0.4516\n",
            "Epoch 81/100, Loss: 4.5354, Validation Accuracy: 0.4526\n",
            "Epoch 82/100, Loss: 3.4925, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 9.5192, Validation Accuracy: 0.6590\n",
            "Epoch 84/100, Loss: 33.0274, Validation Accuracy: 0.6291\n",
            "Epoch 85/100, Loss: 24.3311, Validation Accuracy: 0.5912\n",
            "Epoch 86/100, Loss: 15.6333, Validation Accuracy: 0.6570\n",
            "Epoch 87/100, Loss: 22.9262, Validation Accuracy: 0.1107\n",
            "Epoch 88/100, Loss: 6.9385, Validation Accuracy: 0.6012\n",
            "Epoch 89/100, Loss: 7.8722, Validation Accuracy: 0.5972\n",
            "Epoch 90/100, Loss: 9.5936, Validation Accuracy: 0.6790\n",
            "Epoch 91/100, Loss: 3.1116, Validation Accuracy: 0.6132\n",
            "Epoch 92/100, Loss: 8.9726, Validation Accuracy: 0.6181\n",
            "Epoch 93/100, Loss: 38.8714, Validation Accuracy: 0.6550\n",
            "Epoch 94/100, Loss: 4.2781, Validation Accuracy: 0.6550\n",
            "Epoch 95/100, Loss: 37.0653, Validation Accuracy: 0.6281\n",
            "Epoch 96/100, Loss: 8.3445, Validation Accuracy: 0.6770\n",
            "Epoch 97/100, Loss: 69.9585, Validation Accuracy: 0.6680\n",
            "Epoch 98/100, Loss: 5.6296, Validation Accuracy: 0.6361\n",
            "Epoch 99/100, Loss: 6.7732, Validation Accuracy: 0.6471\n",
            "Epoch 100/100, Loss: 9.9432, Validation Accuracy: 0.6800\n",
            "Epoch 101/100, Loss: 8.6074, Validation Accuracy: 0.6640\n",
            "Epoch 102/100, Loss: 2.5528, Validation Accuracy: 0.5783\n",
            "Epoch 103/100, Loss: 11.8324, Validation Accuracy: 0.6281\n",
            "Epoch 104/100, Loss: 79.8556, Validation Accuracy: 0.4546\n",
            "Epoch 105/100, Loss: 7.7754, Validation Accuracy: 0.6481\n",
            "Epoch 106/100, Loss: 21.1479, Validation Accuracy: 0.5244\n",
            "Epoch 107/100, Loss: 8.5971, Validation Accuracy: 0.6620\n",
            "Epoch 108/100, Loss: 7.9147, Validation Accuracy: 0.6540\n",
            "Epoch 109/100, Loss: 190.2489, Validation Accuracy: 0.5743\n",
            "Epoch 110/100, Loss: 10.8915, Validation Accuracy: 0.6520\n",
            "Epoch 111/100, Loss: 6.0263, Validation Accuracy: 0.5743\n",
            "Epoch 112/100, Loss: 5.7332, Validation Accuracy: 0.5982\n",
            "Epoch 113/100, Loss: 3.5398, Validation Accuracy: 0.5264\n",
            "Epoch 114/100, Loss: 3.2301, Validation Accuracy: 0.5733\n",
            "Epoch 115/100, Loss: 6.4404, Validation Accuracy: 0.6351\n",
            "Epoch 116/100, Loss: 6.8023, Validation Accuracy: 0.6171\n",
            "Epoch 117/100, Loss: 11.7331, Validation Accuracy: 0.4197\n",
            "Epoch 118/100, Loss: 15.8233, Validation Accuracy: 0.5055\n",
            "Epoch 119/100, Loss: 9.1087, Validation Accuracy: 0.5942\n",
            "Epoch 120/100, Loss: 10.0065, Validation Accuracy: 0.5105\n",
            "Epoch 121/100, Loss: 6.3435, Validation Accuracy: 0.5922\n",
            "Epoch 122/100, Loss: 37.8823, Validation Accuracy: 0.5633\n",
            "Epoch 123/100, Loss: 24.5660, Validation Accuracy: 0.6590\n",
            "Epoch 124/100, Loss: 7.3778, Validation Accuracy: 0.6231\n",
            "Epoch 125/100, Loss: 7.1918, Validation Accuracy: 0.5563\n",
            "Epoch 126/100, Loss: 15.0461, Validation Accuracy: 0.6102\n",
            "Epoch 127/100, Loss: 53.9868, Validation Accuracy: 0.3948\n",
            "Epoch 128/100, Loss: 26.6733, Validation Accuracy: 0.5454\n",
            "Epoch 129/100, Loss: 9.6192, Validation Accuracy: 0.4257\n",
            "Epoch 130/100, Loss: 11.5073, Validation Accuracy: 0.6171\n",
            "Epoch 131/100, Loss: 28.8074, Validation Accuracy: 0.4197\n",
            "Epoch 132/100, Loss: 20.4920, Validation Accuracy: 0.6730\n",
            "Epoch 133/100, Loss: 17.6656, Validation Accuracy: 0.6391\n",
            "Epoch 134/100, Loss: 18.5964, Validation Accuracy: 0.6181\n",
            "Epoch 135/100, Loss: 16.9972, Validation Accuracy: 0.6401\n",
            "Epoch 136/100, Loss: 15.4647, Validation Accuracy: 0.4885\n",
            "Epoch 137/100, Loss: 17.0371, Validation Accuracy: 0.6481\n",
            "Epoch 138/100, Loss: 25.8812, Validation Accuracy: 0.4267\n",
            "Epoch 139/100, Loss: 30.1641, Validation Accuracy: 0.6311\n",
            "Epoch 140/100, Loss: 28.8175, Validation Accuracy: 0.6481\n",
            "Epoch 141/100, Loss: 10.6357, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 5.2072, Validation Accuracy: 0.6241\n",
            "Epoch 143/100, Loss: 9.6471, Validation Accuracy: 0.5972\n",
            "Epoch 144/100, Loss: 6.8280, Validation Accuracy: 0.5135\n",
            "Epoch 145/100, Loss: 8.8795, Validation Accuracy: 0.6530\n",
            "Epoch 146/100, Loss: 51.9126, Validation Accuracy: 0.6570\n",
            "Epoch 147/100, Loss: 11.0539, Validation Accuracy: 0.6550\n",
            "Epoch 148/100, Loss: 31.6932, Validation Accuracy: 0.5484\n",
            "Epoch 149/100, Loss: 10.5256, Validation Accuracy: 0.4726\n",
            "Epoch 150/100, Loss: 4.7261, Validation Accuracy: 0.5693\n",
            "Epoch 151/100, Loss: 19.1079, Validation Accuracy: 0.6092\n",
            "Epoch 152/100, Loss: 25.2687, Validation Accuracy: 0.6650\n",
            "Epoch 153/100, Loss: 27.0288, Validation Accuracy: 0.5494\n",
            "Epoch 154/100, Loss: 82.1000, Validation Accuracy: 0.6431\n",
            "Epoch 155/100, Loss: 20.7966, Validation Accuracy: 0.5135\n",
            "Epoch 156/100, Loss: 9.5450, Validation Accuracy: 0.5813\n",
            "Epoch 157/100, Loss: 10.0914, Validation Accuracy: 0.6221\n",
            "Epoch 158/100, Loss: 6.7714, Validation Accuracy: 0.6231\n",
            "Epoch 159/100, Loss: 62.9166, Validation Accuracy: 0.4437\n",
            "Epoch 160/100, Loss: 15.4765, Validation Accuracy: 0.5823\n",
            "Epoch 161/100, Loss: 10.3465, Validation Accuracy: 0.6381\n",
            "Epoch 162/100, Loss: 16.9223, Validation Accuracy: 0.6191\n",
            "Epoch 163/100, Loss: 25.4414, Validation Accuracy: 0.5494\n",
            "Epoch 164/100, Loss: 31.4971, Validation Accuracy: 0.4885\n",
            "Epoch 165/100, Loss: 24.5742, Validation Accuracy: 0.5872\n",
            "Epoch 166/100, Loss: 13.8313, Validation Accuracy: 0.6221\n",
            "Epoch 167/100, Loss: 5.2253, Validation Accuracy: 0.6092\n",
            "Epoch 168/100, Loss: 8.8236, Validation Accuracy: 0.5254\n",
            "Epoch 169/100, Loss: 12.8107, Validation Accuracy: 0.5324\n",
            "Epoch 170/100, Loss: 77.2288, Validation Accuracy: 0.3669\n",
            "Epoch 171/100, Loss: 21.3645, Validation Accuracy: 0.6720\n",
            "Epoch 172/100, Loss: 11.8755, Validation Accuracy: 0.6152\n",
            "Epoch 173/100, Loss: 6.8683, Validation Accuracy: 0.6152\n",
            "Epoch 174/100, Loss: 8.0768, Validation Accuracy: 0.6550\n",
            "Epoch 175/100, Loss: 11.6314, Validation Accuracy: 0.5982\n",
            "Epoch 176/100, Loss: 10.7334, Validation Accuracy: 0.6431\n",
            "Epoch 177/100, Loss: 10.7549, Validation Accuracy: 0.6002\n",
            "Epoch 178/100, Loss: 48.8960, Validation Accuracy: 0.6181\n",
            "Epoch 179/100, Loss: 30.3142, Validation Accuracy: 0.5912\n",
            "Epoch 180/100, Loss: 24.3919, Validation Accuracy: 0.5474\n",
            "Epoch 181/100, Loss: 7.1259, Validation Accuracy: 0.6510\n",
            "Epoch 182/100, Loss: 9.2864, Validation Accuracy: 0.6441\n",
            "Epoch 183/100, Loss: 18.3656, Validation Accuracy: 0.6481\n",
            "Epoch 184/100, Loss: 6.8569, Validation Accuracy: 0.6281\n",
            "Epoch 185/100, Loss: 5.3595, Validation Accuracy: 0.6530\n",
            "Epoch 186/100, Loss: 17.6821, Validation Accuracy: 0.5344\n",
            "Epoch 187/100, Loss: 26.7165, Validation Accuracy: 0.4945\n",
            "Epoch 188/100, Loss: 21.9308, Validation Accuracy: 0.4736\n",
            "Epoch 189/100, Loss: 13.3503, Validation Accuracy: 0.5663\n",
            "Epoch 190/100, Loss: 7.2085, Validation Accuracy: 0.6301\n",
            "Epoch 191/100, Loss: 19.0861, Validation Accuracy: 0.6142\n",
            "Epoch 192/100, Loss: 7.8078, Validation Accuracy: 0.6391\n",
            "Epoch 193/100, Loss: 21.3155, Validation Accuracy: 0.5922\n",
            "Epoch 194/100, Loss: 18.8819, Validation Accuracy: 0.5823\n",
            "Epoch 195/100, Loss: 25.4381, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 47.0791, Validation Accuracy: 0.4676\n",
            "Epoch 197/100, Loss: 12.0346, Validation Accuracy: 0.6341\n",
            "Epoch 198/100, Loss: 5.0686, Validation Accuracy: 0.5563\n",
            "Epoch 199/100, Loss: 34.2086, Validation Accuracy: 0.5803\n",
            "Epoch 200/100, Loss: 323.3940, Validation Accuracy: 0.5743\n",
            "Reward for Child Model: 0.2549579437578336\n",
            "Child_85:  {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, [0, 3, 0, 0, 3, 0, 3, 1, 1, 2, 0, 3, 3, 0, 0], 0.2549579437578336\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 64, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(100, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(84, 48, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(232, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=239616, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 24, 24]           2,736\n",
            "       BatchNorm2d-2           [-1, 36, 24, 24]              72\n",
            "            Conv2d-3           [-1, 64, 22, 18]          48,448\n",
            "       BatchNorm2d-4           [-1, 64, 22, 18]             128\n",
            "              ReLU-5           [-1, 64, 22, 18]               0\n",
            "            Conv2d-6           [-1, 48, 24, 20]          24,048\n",
            "       BatchNorm2d-7           [-1, 48, 24, 20]              96\n",
            "              ReLU-8           [-1, 48, 24, 20]               0\n",
            "            Conv2d-9           [-1, 48, 24, 22]          12,144\n",
            "      BatchNorm2d-10           [-1, 48, 24, 22]              96\n",
            "             ReLU-11           [-1, 48, 24, 22]               0\n",
            "           Conv2d-12           [-1, 64, 20, 20]         371,264\n",
            "      BatchNorm2d-13           [-1, 64, 20, 20]             128\n",
            "             ReLU-14           [-1, 64, 20, 20]               0\n",
            "           Linear-15                    [-1, 7]       1,677,319\n",
            "================================================================\n",
            "Total params: 2,136,479\n",
            "Trainable params: 2,136,479\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.59\n",
            "Params size (MB): 8.15\n",
            "Estimated Total Size (MB): 10.75\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 182.3367, Validation Accuracy: 0.6311\n",
            "Epoch 2/100, Loss: 26.7852, Validation Accuracy: 0.5862\n",
            "Epoch 3/100, Loss: 9.7853, Validation Accuracy: 0.5713\n",
            "Epoch 4/100, Loss: 433.8799, Validation Accuracy: 0.5424\n",
            "Epoch 5/100, Loss: 86.2218, Validation Accuracy: 0.5324\n",
            "Epoch 6/100, Loss: 63.0781, Validation Accuracy: 0.6700\n",
            "Epoch 7/100, Loss: 73.4212, Validation Accuracy: 0.5573\n",
            "Epoch 8/100, Loss: 22.3909, Validation Accuracy: 0.6680\n",
            "Epoch 9/100, Loss: 86.0008, Validation Accuracy: 0.4666\n",
            "Epoch 10/100, Loss: 63.7282, Validation Accuracy: 0.3968\n",
            "Epoch 11/100, Loss: 125.9648, Validation Accuracy: 0.5783\n",
            "Epoch 12/100, Loss: 138.2880, Validation Accuracy: 0.6042\n",
            "Epoch 13/100, Loss: 81.5764, Validation Accuracy: 0.5234\n",
            "Epoch 14/100, Loss: 115.3999, Validation Accuracy: 0.5862\n",
            "Epoch 15/100, Loss: 32.7177, Validation Accuracy: 0.6072\n",
            "Epoch 16/100, Loss: 99.6451, Validation Accuracy: 0.5862\n",
            "Epoch 17/100, Loss: 172.8083, Validation Accuracy: 0.5703\n",
            "Epoch 18/100, Loss: 44.0714, Validation Accuracy: 0.5823\n",
            "Epoch 19/100, Loss: 36.3972, Validation Accuracy: 0.6660\n",
            "Epoch 20/100, Loss: 23.5716, Validation Accuracy: 0.6291\n",
            "Epoch 21/100, Loss: 46.6784, Validation Accuracy: 0.5912\n",
            "Epoch 22/100, Loss: 496.2696, Validation Accuracy: 0.6640\n",
            "Epoch 23/100, Loss: 147.6211, Validation Accuracy: 0.5484\n",
            "Epoch 24/100, Loss: 52.5380, Validation Accuracy: 0.3819\n",
            "Epoch 25/100, Loss: 31.2291, Validation Accuracy: 0.6520\n",
            "Epoch 26/100, Loss: 46.3427, Validation Accuracy: 0.5932\n",
            "Epoch 27/100, Loss: 46.5954, Validation Accuracy: 0.6002\n",
            "Epoch 28/100, Loss: 19.2186, Validation Accuracy: 0.4626\n",
            "Epoch 29/100, Loss: 53.7930, Validation Accuracy: 0.6580\n",
            "Epoch 30/100, Loss: 34.6870, Validation Accuracy: 0.4746\n",
            "Epoch 31/100, Loss: 60.7146, Validation Accuracy: 0.4626\n",
            "Epoch 32/100, Loss: 94.0750, Validation Accuracy: 0.6710\n",
            "Epoch 33/100, Loss: 167.4326, Validation Accuracy: 0.6740\n",
            "Epoch 34/100, Loss: 141.3676, Validation Accuracy: 0.5902\n",
            "Epoch 35/100, Loss: 34.7720, Validation Accuracy: 0.6351\n",
            "Epoch 36/100, Loss: 86.1856, Validation Accuracy: 0.5264\n",
            "Epoch 37/100, Loss: 49.1101, Validation Accuracy: 0.6072\n",
            "Epoch 38/100, Loss: 37.7651, Validation Accuracy: 0.5932\n",
            "Epoch 39/100, Loss: 119.7180, Validation Accuracy: 0.5155\n",
            "Epoch 40/100, Loss: 124.3923, Validation Accuracy: 0.5882\n",
            "Epoch 41/100, Loss: 259.4597, Validation Accuracy: 0.6102\n",
            "Epoch 42/100, Loss: 54.4263, Validation Accuracy: 0.5294\n",
            "Epoch 43/100, Loss: 58.0646, Validation Accuracy: 0.5035\n",
            "Epoch 44/100, Loss: 50.7029, Validation Accuracy: 0.5793\n",
            "Epoch 45/100, Loss: 42.9711, Validation Accuracy: 0.6481\n",
            "Epoch 46/100, Loss: 198.3768, Validation Accuracy: 0.5932\n",
            "Epoch 47/100, Loss: 31.8442, Validation Accuracy: 0.6261\n",
            "Epoch 48/100, Loss: 75.6496, Validation Accuracy: 0.5693\n",
            "Epoch 49/100, Loss: 128.2383, Validation Accuracy: 0.5922\n",
            "Epoch 50/100, Loss: 257.9890, Validation Accuracy: 0.6152\n",
            "Epoch 51/100, Loss: 32.9203, Validation Accuracy: 0.6730\n",
            "Epoch 52/100, Loss: 101.6465, Validation Accuracy: 0.5304\n",
            "Epoch 53/100, Loss: 45.3703, Validation Accuracy: 0.5992\n",
            "Epoch 54/100, Loss: 112.8904, Validation Accuracy: 0.6650\n",
            "Epoch 55/100, Loss: 159.5137, Validation Accuracy: 0.6052\n",
            "Epoch 56/100, Loss: 53.4231, Validation Accuracy: 0.4267\n",
            "Epoch 57/100, Loss: 50.9832, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 43.4836, Validation Accuracy: 0.6042\n",
            "Epoch 59/100, Loss: 30.6963, Validation Accuracy: 0.6341\n",
            "Epoch 60/100, Loss: 46.4357, Validation Accuracy: 0.5513\n",
            "Epoch 61/100, Loss: 81.0076, Validation Accuracy: 0.6810\n",
            "Epoch 62/100, Loss: 423.6581, Validation Accuracy: 0.6620\n",
            "Epoch 63/100, Loss: 156.1891, Validation Accuracy: 0.5085\n",
            "Epoch 64/100, Loss: 114.5180, Validation Accuracy: 0.5663\n",
            "Epoch 65/100, Loss: 68.2143, Validation Accuracy: 0.5513\n",
            "Epoch 66/100, Loss: 51.8166, Validation Accuracy: 0.6341\n",
            "Epoch 67/100, Loss: 150.3413, Validation Accuracy: 0.5753\n",
            "Epoch 68/100, Loss: 93.1279, Validation Accuracy: 0.4536\n",
            "Epoch 69/100, Loss: 106.7852, Validation Accuracy: 0.5155\n",
            "Epoch 70/100, Loss: 43.6340, Validation Accuracy: 0.5803\n",
            "Epoch 71/100, Loss: 22.6068, Validation Accuracy: 0.6770\n",
            "Epoch 72/100, Loss: 82.2502, Validation Accuracy: 0.6620\n",
            "Epoch 73/100, Loss: 55.1278, Validation Accuracy: 0.6441\n",
            "Epoch 74/100, Loss: 214.1928, Validation Accuracy: 0.3988\n",
            "Epoch 75/100, Loss: 29.6155, Validation Accuracy: 0.6032\n",
            "Epoch 76/100, Loss: 153.8264, Validation Accuracy: 0.5613\n",
            "Epoch 77/100, Loss: 241.9323, Validation Accuracy: 0.5494\n",
            "Epoch 78/100, Loss: 89.5373, Validation Accuracy: 0.4626\n",
            "Epoch 79/100, Loss: 39.6362, Validation Accuracy: 0.6102\n",
            "Epoch 80/100, Loss: 78.0475, Validation Accuracy: 0.6790\n",
            "Epoch 81/100, Loss: 127.9304, Validation Accuracy: 0.6491\n",
            "Epoch 82/100, Loss: 55.8152, Validation Accuracy: 0.5783\n",
            "Epoch 83/100, Loss: 79.9544, Validation Accuracy: 0.5174\n",
            "Epoch 84/100, Loss: 254.1035, Validation Accuracy: 0.5444\n",
            "Epoch 85/100, Loss: 186.7124, Validation Accuracy: 0.5494\n",
            "Epoch 86/100, Loss: 30.7789, Validation Accuracy: 0.5723\n",
            "Epoch 87/100, Loss: 57.3437, Validation Accuracy: 0.5065\n",
            "Epoch 88/100, Loss: 71.8091, Validation Accuracy: 0.6062\n",
            "Epoch 89/100, Loss: 121.9954, Validation Accuracy: 0.3659\n",
            "Epoch 90/100, Loss: 62.8929, Validation Accuracy: 0.6152\n",
            "Epoch 91/100, Loss: 73.1281, Validation Accuracy: 0.6660\n",
            "Epoch 92/100, Loss: 60.8788, Validation Accuracy: 0.5424\n",
            "Epoch 93/100, Loss: 89.6377, Validation Accuracy: 0.6221\n",
            "Epoch 94/100, Loss: 189.0467, Validation Accuracy: 0.4158\n",
            "Epoch 95/100, Loss: 462.4555, Validation Accuracy: 0.6371\n",
            "Epoch 96/100, Loss: 47.2378, Validation Accuracy: 0.6341\n",
            "Epoch 97/100, Loss: 150.8648, Validation Accuracy: 0.6092\n",
            "Epoch 98/100, Loss: 39.1506, Validation Accuracy: 0.6231\n",
            "Epoch 99/100, Loss: 196.8891, Validation Accuracy: 0.5503\n",
            "Epoch 100/100, Loss: 84.0292, Validation Accuracy: 0.6720\n",
            "Epoch 101/100, Loss: 152.8189, Validation Accuracy: 0.4586\n",
            "Epoch 102/100, Loss: 145.2579, Validation Accuracy: 0.6082\n",
            "Epoch 103/100, Loss: 91.4422, Validation Accuracy: 0.6481\n",
            "Epoch 104/100, Loss: 280.6816, Validation Accuracy: 0.6421\n",
            "Epoch 105/100, Loss: 106.2678, Validation Accuracy: 0.5484\n",
            "Epoch 106/100, Loss: 60.5092, Validation Accuracy: 0.4875\n",
            "Epoch 107/100, Loss: 64.0108, Validation Accuracy: 0.4975\n",
            "Epoch 108/100, Loss: 179.6903, Validation Accuracy: 0.5882\n",
            "Epoch 109/100, Loss: 183.3459, Validation Accuracy: 0.5713\n",
            "Epoch 110/100, Loss: 94.8663, Validation Accuracy: 0.4905\n",
            "Epoch 111/100, Loss: 68.7603, Validation Accuracy: 0.6132\n",
            "Epoch 112/100, Loss: 30.8831, Validation Accuracy: 0.6142\n",
            "Epoch 113/100, Loss: 329.0194, Validation Accuracy: 0.5374\n",
            "Epoch 114/100, Loss: 258.7884, Validation Accuracy: 0.6660\n",
            "Epoch 115/100, Loss: 52.7740, Validation Accuracy: 0.5902\n",
            "Epoch 116/100, Loss: 57.3335, Validation Accuracy: 0.6431\n",
            "Epoch 117/100, Loss: 37.6363, Validation Accuracy: 0.6560\n",
            "Epoch 118/100, Loss: 93.4279, Validation Accuracy: 0.4746\n",
            "Epoch 119/100, Loss: 33.2834, Validation Accuracy: 0.5314\n",
            "Epoch 120/100, Loss: 68.3260, Validation Accuracy: 0.4955\n",
            "Epoch 121/100, Loss: 88.8447, Validation Accuracy: 0.6750\n",
            "Epoch 122/100, Loss: 86.5115, Validation Accuracy: 0.5464\n",
            "Epoch 123/100, Loss: 88.2596, Validation Accuracy: 0.5912\n",
            "Epoch 124/100, Loss: 70.9697, Validation Accuracy: 0.6361\n",
            "Epoch 125/100, Loss: 39.1498, Validation Accuracy: 0.6680\n",
            "Epoch 126/100, Loss: 74.8938, Validation Accuracy: 0.4467\n",
            "Epoch 127/100, Loss: 216.0191, Validation Accuracy: 0.5254\n",
            "Epoch 128/100, Loss: 176.9688, Validation Accuracy: 0.6271\n",
            "Epoch 129/100, Loss: 26.1816, Validation Accuracy: 0.5872\n",
            "Epoch 130/100, Loss: 37.9968, Validation Accuracy: 0.4586\n",
            "Epoch 131/100, Loss: 67.1720, Validation Accuracy: 0.6471\n",
            "Epoch 132/100, Loss: 95.3729, Validation Accuracy: 0.5085\n",
            "Epoch 133/100, Loss: 146.2811, Validation Accuracy: 0.6052\n",
            "Epoch 134/100, Loss: 169.1412, Validation Accuracy: 0.5842\n",
            "Epoch 135/100, Loss: 83.7541, Validation Accuracy: 0.5503\n",
            "Epoch 136/100, Loss: 139.4313, Validation Accuracy: 0.5075\n",
            "Epoch 137/100, Loss: 74.3520, Validation Accuracy: 0.5533\n",
            "Epoch 138/100, Loss: 96.9820, Validation Accuracy: 0.4616\n",
            "Epoch 139/100, Loss: 258.2478, Validation Accuracy: 0.5484\n",
            "Epoch 140/100, Loss: 250.8773, Validation Accuracy: 0.5224\n",
            "Epoch 141/100, Loss: 141.4749, Validation Accuracy: 0.5813\n",
            "Epoch 142/100, Loss: 52.4484, Validation Accuracy: 0.5174\n",
            "Epoch 143/100, Loss: 197.7516, Validation Accuracy: 0.5783\n",
            "Epoch 144/100, Loss: 70.0372, Validation Accuracy: 0.5603\n",
            "Epoch 145/100, Loss: 69.3308, Validation Accuracy: 0.5533\n",
            "Epoch 146/100, Loss: 32.6553, Validation Accuracy: 0.5872\n",
            "Epoch 147/100, Loss: 152.7346, Validation Accuracy: 0.4636\n",
            "Epoch 148/100, Loss: 148.0392, Validation Accuracy: 0.6550\n",
            "Epoch 149/100, Loss: 123.6186, Validation Accuracy: 0.6471\n",
            "Epoch 150/100, Loss: 209.6649, Validation Accuracy: 0.5823\n",
            "Epoch 151/100, Loss: 82.6416, Validation Accuracy: 0.6750\n",
            "Epoch 152/100, Loss: 55.0896, Validation Accuracy: 0.6311\n",
            "Epoch 153/100, Loss: 101.9069, Validation Accuracy: 0.6630\n",
            "Epoch 154/100, Loss: 140.7093, Validation Accuracy: 0.6351\n",
            "Epoch 155/100, Loss: 141.2833, Validation Accuracy: 0.5962\n",
            "Epoch 156/100, Loss: 176.4681, Validation Accuracy: 0.5912\n",
            "Epoch 157/100, Loss: 61.1731, Validation Accuracy: 0.5015\n",
            "Epoch 158/100, Loss: 201.5218, Validation Accuracy: 0.3809\n",
            "Epoch 159/100, Loss: 68.2961, Validation Accuracy: 0.6720\n",
            "Epoch 160/100, Loss: 162.8490, Validation Accuracy: 0.5902\n",
            "Epoch 161/100, Loss: 56.5240, Validation Accuracy: 0.6281\n",
            "Epoch 162/100, Loss: 532.8901, Validation Accuracy: 0.6610\n",
            "Epoch 163/100, Loss: 143.9919, Validation Accuracy: 0.6162\n",
            "Epoch 164/100, Loss: 16.9621, Validation Accuracy: 0.5593\n",
            "Epoch 165/100, Loss: 54.9976, Validation Accuracy: 0.5324\n",
            "Epoch 166/100, Loss: 52.9839, Validation Accuracy: 0.5454\n",
            "Epoch 167/100, Loss: 36.2388, Validation Accuracy: 0.6022\n",
            "Epoch 168/100, Loss: 35.6550, Validation Accuracy: 0.5723\n",
            "Epoch 169/100, Loss: 402.6114, Validation Accuracy: 0.6700\n",
            "Epoch 170/100, Loss: 258.4738, Validation Accuracy: 0.5204\n",
            "Epoch 171/100, Loss: 106.9801, Validation Accuracy: 0.6261\n",
            "Epoch 172/100, Loss: 78.5897, Validation Accuracy: 0.5932\n",
            "Epoch 173/100, Loss: 40.6958, Validation Accuracy: 0.6042\n",
            "Epoch 174/100, Loss: 125.0207, Validation Accuracy: 0.6032\n",
            "Epoch 175/100, Loss: 81.5195, Validation Accuracy: 0.6391\n",
            "Epoch 176/100, Loss: 50.9468, Validation Accuracy: 0.5513\n",
            "Epoch 177/100, Loss: 114.4885, Validation Accuracy: 0.5693\n",
            "Epoch 178/100, Loss: 268.5387, Validation Accuracy: 0.1954\n",
            "Epoch 179/100, Loss: 209.2109, Validation Accuracy: 0.5673\n",
            "Epoch 180/100, Loss: 155.8095, Validation Accuracy: 0.5753\n",
            "Epoch 181/100, Loss: 46.1837, Validation Accuracy: 0.6171\n",
            "Epoch 182/100, Loss: 178.8662, Validation Accuracy: 0.6251\n",
            "Epoch 183/100, Loss: 98.9359, Validation Accuracy: 0.5653\n",
            "Epoch 184/100, Loss: 18.4819, Validation Accuracy: 0.6181\n",
            "Epoch 185/100, Loss: 67.7871, Validation Accuracy: 0.6231\n",
            "Epoch 186/100, Loss: 86.6422, Validation Accuracy: 0.4885\n",
            "Epoch 187/100, Loss: 20.6787, Validation Accuracy: 0.5593\n",
            "Epoch 188/100, Loss: 103.7325, Validation Accuracy: 0.5743\n",
            "Epoch 189/100, Loss: 142.3176, Validation Accuracy: 0.6311\n",
            "Epoch 190/100, Loss: 47.7158, Validation Accuracy: 0.6002\n",
            "Epoch 191/100, Loss: 211.2098, Validation Accuracy: 0.6261\n",
            "Epoch 192/100, Loss: 103.8936, Validation Accuracy: 0.5404\n",
            "Epoch 193/100, Loss: 85.6477, Validation Accuracy: 0.4776\n",
            "Epoch 194/100, Loss: 22.3953, Validation Accuracy: 0.6640\n",
            "Epoch 195/100, Loss: 129.2399, Validation Accuracy: 0.5364\n",
            "Epoch 196/100, Loss: 137.5920, Validation Accuracy: 0.6082\n",
            "Epoch 197/100, Loss: 146.0580, Validation Accuracy: 0.6451\n",
            "Epoch 198/100, Loss: 38.6665, Validation Accuracy: 0.5743\n",
            "Epoch 199/100, Loss: 90.3774, Validation Accuracy: 0.6530\n",
            "Epoch 200/100, Loss: 127.7872, Validation Accuracy: 0.5942\n",
            "Reward for Child Model: 0.2784973717061793\n",
            "Child_86:  {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, [2, 2, 1, 1, 3, 3, 0, 2, 2, 0, 1, 2, 2, 2, 3], 0.2784973717061793\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(88, 36, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(36, 48, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(48, 36, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=57600, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 24, 24]           4,864\n",
            "       BatchNorm2d-2           [-1, 64, 24, 24]             128\n",
            "            Conv2d-3           [-1, 24, 24, 18]          10,776\n",
            "       BatchNorm2d-4           [-1, 24, 24, 18]              48\n",
            "              ReLU-5           [-1, 24, 24, 18]               0\n",
            "            Conv2d-6           [-1, 36, 22, 22]          28,548\n",
            "       BatchNorm2d-7           [-1, 36, 22, 22]              72\n",
            "              ReLU-8           [-1, 36, 22, 22]               0\n",
            "            Conv2d-9           [-1, 48, 18, 22]           8,688\n",
            "      BatchNorm2d-10           [-1, 48, 18, 22]              96\n",
            "             ReLU-11           [-1, 48, 18, 22]               0\n",
            "           Conv2d-12           [-1, 36, 18, 22]           1,764\n",
            "      BatchNorm2d-13           [-1, 36, 18, 22]              72\n",
            "             ReLU-14           [-1, 36, 18, 22]               0\n",
            "           Linear-15                    [-1, 7]         403,207\n",
            "================================================================\n",
            "Total params: 458,263\n",
            "Trainable params: 458,263\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.96\n",
            "Params size (MB): 1.75\n",
            "Estimated Total Size (MB): 3.72\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 19.3955, Validation Accuracy: 0.5703\n",
            "Epoch 2/100, Loss: 3.6971, Validation Accuracy: 0.5892\n",
            "Epoch 3/100, Loss: 59.8631, Validation Accuracy: 0.5194\n",
            "Epoch 4/100, Loss: 19.0152, Validation Accuracy: 0.5344\n",
            "Epoch 5/100, Loss: 10.6050, Validation Accuracy: 0.4826\n",
            "Epoch 6/100, Loss: 8.2805, Validation Accuracy: 0.5902\n",
            "Epoch 7/100, Loss: 81.6516, Validation Accuracy: 0.3380\n",
            "Epoch 8/100, Loss: 52.0533, Validation Accuracy: 0.4187\n",
            "Epoch 9/100, Loss: 40.4399, Validation Accuracy: 0.6760\n",
            "Epoch 10/100, Loss: 20.2677, Validation Accuracy: 0.5623\n",
            "Epoch 11/100, Loss: 57.1679, Validation Accuracy: 0.4586\n",
            "Epoch 12/100, Loss: 23.2042, Validation Accuracy: 0.6261\n",
            "Epoch 13/100, Loss: 14.6888, Validation Accuracy: 0.4865\n",
            "Epoch 14/100, Loss: 56.8890, Validation Accuracy: 0.6032\n",
            "Epoch 15/100, Loss: 32.4159, Validation Accuracy: 0.6291\n",
            "Epoch 16/100, Loss: 27.6760, Validation Accuracy: 0.6650\n",
            "Epoch 17/100, Loss: 57.4104, Validation Accuracy: 0.5444\n",
            "Epoch 18/100, Loss: 110.4836, Validation Accuracy: 0.6231\n",
            "Epoch 19/100, Loss: 32.7015, Validation Accuracy: 0.6122\n",
            "Epoch 20/100, Loss: 58.4739, Validation Accuracy: 0.5454\n",
            "Epoch 21/100, Loss: 30.0043, Validation Accuracy: 0.6082\n",
            "Epoch 22/100, Loss: 47.9042, Validation Accuracy: 0.5703\n",
            "Epoch 23/100, Loss: 157.3336, Validation Accuracy: 0.6281\n",
            "Epoch 24/100, Loss: 80.2418, Validation Accuracy: 0.5613\n",
            "Epoch 25/100, Loss: 30.3193, Validation Accuracy: 0.6351\n",
            "Epoch 26/100, Loss: 20.6237, Validation Accuracy: 0.5803\n",
            "Epoch 27/100, Loss: 57.5840, Validation Accuracy: 0.5184\n",
            "Epoch 28/100, Loss: 144.4460, Validation Accuracy: 0.6351\n",
            "Epoch 29/100, Loss: 98.7975, Validation Accuracy: 0.5643\n",
            "Epoch 30/100, Loss: 40.7879, Validation Accuracy: 0.6879\n",
            "Epoch 31/100, Loss: 34.1549, Validation Accuracy: 0.5942\n",
            "Epoch 32/100, Loss: 49.1700, Validation Accuracy: 0.5852\n",
            "Epoch 33/100, Loss: 35.7869, Validation Accuracy: 0.5803\n",
            "Epoch 34/100, Loss: 9.5659, Validation Accuracy: 0.4835\n",
            "Epoch 35/100, Loss: 63.8904, Validation Accuracy: 0.3340\n",
            "Epoch 36/100, Loss: 23.6413, Validation Accuracy: 0.6421\n",
            "Epoch 37/100, Loss: 47.5657, Validation Accuracy: 0.6451\n",
            "Epoch 38/100, Loss: 43.9673, Validation Accuracy: 0.5284\n",
            "Epoch 39/100, Loss: 37.9743, Validation Accuracy: 0.5085\n",
            "Epoch 40/100, Loss: 59.7915, Validation Accuracy: 0.5165\n",
            "Epoch 41/100, Loss: 73.3009, Validation Accuracy: 0.6640\n",
            "Epoch 42/100, Loss: 41.5585, Validation Accuracy: 0.4058\n",
            "Epoch 43/100, Loss: 11.1780, Validation Accuracy: 0.5773\n",
            "Epoch 44/100, Loss: 42.8688, Validation Accuracy: 0.6730\n",
            "Epoch 45/100, Loss: 17.3268, Validation Accuracy: 0.5045\n",
            "Epoch 46/100, Loss: 80.8129, Validation Accuracy: 0.5364\n",
            "Epoch 47/100, Loss: 148.2302, Validation Accuracy: 0.5494\n",
            "Epoch 48/100, Loss: 15.4855, Validation Accuracy: 0.5085\n",
            "Epoch 49/100, Loss: 33.0815, Validation Accuracy: 0.6042\n",
            "Epoch 50/100, Loss: 29.0509, Validation Accuracy: 0.5573\n",
            "Epoch 51/100, Loss: 82.3078, Validation Accuracy: 0.6371\n",
            "Epoch 52/100, Loss: 70.4084, Validation Accuracy: 0.5813\n",
            "Epoch 53/100, Loss: 37.2131, Validation Accuracy: 0.4955\n",
            "Epoch 54/100, Loss: 29.7290, Validation Accuracy: 0.5204\n",
            "Epoch 55/100, Loss: 46.4298, Validation Accuracy: 0.6471\n",
            "Epoch 56/100, Loss: 42.2107, Validation Accuracy: 0.4367\n",
            "Epoch 57/100, Loss: 26.3907, Validation Accuracy: 0.6491\n",
            "Epoch 58/100, Loss: 31.9173, Validation Accuracy: 0.5892\n",
            "Epoch 59/100, Loss: 31.0064, Validation Accuracy: 0.4307\n",
            "Epoch 60/100, Loss: 48.2801, Validation Accuracy: 0.6211\n",
            "Epoch 61/100, Loss: 30.5887, Validation Accuracy: 0.6730\n",
            "Epoch 62/100, Loss: 16.6271, Validation Accuracy: 0.6720\n",
            "Epoch 63/100, Loss: 80.9897, Validation Accuracy: 0.5474\n",
            "Epoch 64/100, Loss: 53.5218, Validation Accuracy: 0.4786\n",
            "Epoch 65/100, Loss: 97.8719, Validation Accuracy: 0.5862\n",
            "Epoch 66/100, Loss: 26.5184, Validation Accuracy: 0.5962\n",
            "Epoch 67/100, Loss: 76.2198, Validation Accuracy: 0.4935\n",
            "Epoch 68/100, Loss: 116.5374, Validation Accuracy: 0.5952\n",
            "Epoch 69/100, Loss: 77.4235, Validation Accuracy: 0.5184\n",
            "Epoch 70/100, Loss: 68.6013, Validation Accuracy: 0.6580\n",
            "Epoch 71/100, Loss: 90.4192, Validation Accuracy: 0.6311\n",
            "Epoch 72/100, Loss: 29.7785, Validation Accuracy: 0.6201\n",
            "Epoch 73/100, Loss: 16.1596, Validation Accuracy: 0.5603\n",
            "Epoch 74/100, Loss: 38.7275, Validation Accuracy: 0.6451\n",
            "Epoch 75/100, Loss: 54.9840, Validation Accuracy: 0.4497\n",
            "Epoch 76/100, Loss: 86.4509, Validation Accuracy: 0.5673\n",
            "Epoch 77/100, Loss: 108.1903, Validation Accuracy: 0.6072\n",
            "Epoch 78/100, Loss: 24.4368, Validation Accuracy: 0.6241\n",
            "Epoch 79/100, Loss: 66.5664, Validation Accuracy: 0.6241\n",
            "Epoch 80/100, Loss: 23.5908, Validation Accuracy: 0.6600\n",
            "Epoch 81/100, Loss: 22.6873, Validation Accuracy: 0.5583\n",
            "Epoch 82/100, Loss: 23.1331, Validation Accuracy: 0.5603\n",
            "Epoch 83/100, Loss: 82.1114, Validation Accuracy: 0.6590\n",
            "Epoch 84/100, Loss: 33.8497, Validation Accuracy: 0.5793\n",
            "Epoch 85/100, Loss: 33.4675, Validation Accuracy: 0.4686\n",
            "Epoch 86/100, Loss: 49.3195, Validation Accuracy: 0.5394\n",
            "Epoch 87/100, Loss: 28.7621, Validation Accuracy: 0.6261\n",
            "Epoch 88/100, Loss: 26.2983, Validation Accuracy: 0.5324\n",
            "Epoch 89/100, Loss: 89.9524, Validation Accuracy: 0.2921\n",
            "Epoch 90/100, Loss: 17.6252, Validation Accuracy: 0.6700\n",
            "Epoch 91/100, Loss: 33.2163, Validation Accuracy: 0.5254\n",
            "Epoch 92/100, Loss: 26.2091, Validation Accuracy: 0.5623\n",
            "Epoch 93/100, Loss: 43.2257, Validation Accuracy: 0.5663\n",
            "Epoch 94/100, Loss: 29.2168, Validation Accuracy: 0.6610\n",
            "Epoch 95/100, Loss: 22.6305, Validation Accuracy: 0.6211\n",
            "Epoch 96/100, Loss: 57.4675, Validation Accuracy: 0.6102\n",
            "Epoch 97/100, Loss: 138.3432, Validation Accuracy: 0.4806\n",
            "Epoch 98/100, Loss: 35.9724, Validation Accuracy: 0.6102\n",
            "Epoch 99/100, Loss: 44.7734, Validation Accuracy: 0.6550\n",
            "Epoch 100/100, Loss: 123.2828, Validation Accuracy: 0.6012\n",
            "Epoch 101/100, Loss: 64.3871, Validation Accuracy: 0.6431\n",
            "Epoch 102/100, Loss: 32.6870, Validation Accuracy: 0.6181\n",
            "Epoch 103/100, Loss: 29.1729, Validation Accuracy: 0.5773\n",
            "Epoch 104/100, Loss: 81.1179, Validation Accuracy: 0.6181\n",
            "Epoch 105/100, Loss: 52.9913, Validation Accuracy: 0.4526\n",
            "Epoch 106/100, Loss: 59.6226, Validation Accuracy: 0.6022\n",
            "Epoch 107/100, Loss: 42.3186, Validation Accuracy: 0.6411\n",
            "Epoch 108/100, Loss: 35.6983, Validation Accuracy: 0.6181\n",
            "Epoch 109/100, Loss: 40.7409, Validation Accuracy: 0.6042\n",
            "Epoch 110/100, Loss: 94.9929, Validation Accuracy: 0.4088\n",
            "Epoch 111/100, Loss: 49.0513, Validation Accuracy: 0.5842\n",
            "Epoch 112/100, Loss: 47.7559, Validation Accuracy: 0.6600\n",
            "Epoch 113/100, Loss: 42.7625, Validation Accuracy: 0.5733\n",
            "Epoch 114/100, Loss: 60.8217, Validation Accuracy: 0.6800\n",
            "Epoch 115/100, Loss: 27.4509, Validation Accuracy: 0.5872\n",
            "Epoch 116/100, Loss: 70.1092, Validation Accuracy: 0.6401\n",
            "Epoch 117/100, Loss: 26.2609, Validation Accuracy: 0.6062\n",
            "Epoch 118/100, Loss: 40.8347, Validation Accuracy: 0.6201\n",
            "Epoch 119/100, Loss: 25.2648, Validation Accuracy: 0.6491\n",
            "Epoch 120/100, Loss: 369.5785, Validation Accuracy: 0.6171\n",
            "Epoch 121/100, Loss: 74.4319, Validation Accuracy: 0.6760\n",
            "Epoch 122/100, Loss: 65.1316, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 18.4594, Validation Accuracy: 0.6700\n",
            "Epoch 124/100, Loss: 14.9517, Validation Accuracy: 0.6251\n",
            "Epoch 125/100, Loss: 53.6852, Validation Accuracy: 0.5603\n",
            "Epoch 126/100, Loss: 28.5447, Validation Accuracy: 0.6530\n",
            "Epoch 127/100, Loss: 20.2621, Validation Accuracy: 0.5753\n",
            "Epoch 128/100, Loss: 36.3523, Validation Accuracy: 0.6590\n",
            "Epoch 129/100, Loss: 42.5372, Validation Accuracy: 0.5852\n",
            "Epoch 130/100, Loss: 37.7530, Validation Accuracy: 0.5603\n",
            "Epoch 131/100, Loss: 24.8665, Validation Accuracy: 0.4656\n",
            "Epoch 132/100, Loss: 29.5090, Validation Accuracy: 0.6112\n",
            "Epoch 133/100, Loss: 68.5405, Validation Accuracy: 0.4995\n",
            "Epoch 134/100, Loss: 44.2299, Validation Accuracy: 0.6062\n",
            "Epoch 135/100, Loss: 38.7378, Validation Accuracy: 0.5763\n",
            "Epoch 136/100, Loss: 41.6215, Validation Accuracy: 0.6431\n",
            "Epoch 137/100, Loss: 25.4180, Validation Accuracy: 0.6461\n",
            "Epoch 138/100, Loss: 112.8387, Validation Accuracy: 0.5653\n",
            "Epoch 139/100, Loss: 43.9150, Validation Accuracy: 0.6102\n",
            "Epoch 140/100, Loss: 42.6887, Validation Accuracy: 0.6800\n",
            "Epoch 141/100, Loss: 23.9031, Validation Accuracy: 0.5065\n",
            "Epoch 142/100, Loss: 120.9713, Validation Accuracy: 0.6191\n",
            "Epoch 143/100, Loss: 42.5265, Validation Accuracy: 0.6231\n",
            "Epoch 144/100, Loss: 143.2361, Validation Accuracy: 0.6730\n",
            "Epoch 145/100, Loss: 41.2682, Validation Accuracy: 0.5374\n",
            "Epoch 146/100, Loss: 26.8515, Validation Accuracy: 0.6750\n",
            "Epoch 147/100, Loss: 47.4827, Validation Accuracy: 0.6361\n",
            "Epoch 148/100, Loss: 42.8845, Validation Accuracy: 0.6610\n",
            "Epoch 149/100, Loss: 90.4211, Validation Accuracy: 0.5723\n",
            "Epoch 150/100, Loss: 57.8356, Validation Accuracy: 0.6510\n",
            "Epoch 151/100, Loss: 85.9663, Validation Accuracy: 0.5234\n",
            "Epoch 152/100, Loss: 51.2968, Validation Accuracy: 0.5623\n",
            "Epoch 153/100, Loss: 47.0060, Validation Accuracy: 0.6650\n",
            "Epoch 154/100, Loss: 61.7059, Validation Accuracy: 0.5833\n",
            "Epoch 155/100, Loss: 28.6220, Validation Accuracy: 0.6072\n",
            "Epoch 156/100, Loss: 23.9723, Validation Accuracy: 0.6211\n",
            "Epoch 157/100, Loss: 20.5516, Validation Accuracy: 0.5972\n",
            "Epoch 158/100, Loss: 47.1105, Validation Accuracy: 0.4895\n",
            "Epoch 159/100, Loss: 39.9407, Validation Accuracy: 0.5254\n",
            "Epoch 160/100, Loss: 123.5833, Validation Accuracy: 0.6301\n",
            "Epoch 161/100, Loss: 147.0036, Validation Accuracy: 0.5543\n",
            "Epoch 162/100, Loss: 31.0688, Validation Accuracy: 0.6530\n",
            "Epoch 163/100, Loss: 52.0069, Validation Accuracy: 0.2702\n",
            "Epoch 164/100, Loss: 49.7882, Validation Accuracy: 0.6092\n",
            "Epoch 165/100, Loss: 45.2595, Validation Accuracy: 0.4726\n",
            "Epoch 166/100, Loss: 46.9858, Validation Accuracy: 0.6650\n",
            "Epoch 167/100, Loss: 113.7104, Validation Accuracy: 0.6281\n",
            "Epoch 168/100, Loss: 57.3071, Validation Accuracy: 0.6291\n",
            "Epoch 169/100, Loss: 19.5158, Validation Accuracy: 0.6201\n",
            "Epoch 170/100, Loss: 30.7553, Validation Accuracy: 0.5364\n",
            "Epoch 171/100, Loss: 25.6345, Validation Accuracy: 0.5513\n",
            "Epoch 172/100, Loss: 41.7742, Validation Accuracy: 0.4347\n",
            "Epoch 173/100, Loss: 21.9332, Validation Accuracy: 0.6411\n",
            "Epoch 174/100, Loss: 114.3383, Validation Accuracy: 0.6191\n",
            "Epoch 175/100, Loss: 60.0061, Validation Accuracy: 0.4437\n",
            "Epoch 176/100, Loss: 45.1484, Validation Accuracy: 0.6391\n",
            "Epoch 177/100, Loss: 53.5434, Validation Accuracy: 0.5852\n",
            "Epoch 178/100, Loss: 29.6570, Validation Accuracy: 0.6102\n",
            "Epoch 179/100, Loss: 45.5148, Validation Accuracy: 0.5683\n",
            "Epoch 180/100, Loss: 42.4869, Validation Accuracy: 0.6790\n",
            "Epoch 181/100, Loss: 66.8666, Validation Accuracy: 0.5045\n",
            "Epoch 182/100, Loss: 96.4846, Validation Accuracy: 0.6281\n",
            "Epoch 183/100, Loss: 39.2477, Validation Accuracy: 0.6600\n",
            "Epoch 184/100, Loss: 21.0751, Validation Accuracy: 0.6660\n",
            "Epoch 185/100, Loss: 56.2683, Validation Accuracy: 0.6530\n",
            "Epoch 186/100, Loss: 62.2930, Validation Accuracy: 0.2532\n",
            "Epoch 187/100, Loss: 33.1710, Validation Accuracy: 0.6441\n",
            "Epoch 188/100, Loss: 39.7368, Validation Accuracy: 0.6520\n",
            "Epoch 189/100, Loss: 64.2920, Validation Accuracy: 0.6530\n",
            "Epoch 190/100, Loss: 68.4667, Validation Accuracy: 0.5992\n",
            "Epoch 191/100, Loss: 56.7701, Validation Accuracy: 0.6530\n",
            "Epoch 192/100, Loss: 36.4089, Validation Accuracy: 0.6800\n",
            "Epoch 193/100, Loss: 18.1166, Validation Accuracy: 0.5823\n",
            "Epoch 194/100, Loss: 43.5602, Validation Accuracy: 0.6730\n",
            "Epoch 195/100, Loss: 33.0957, Validation Accuracy: 0.6231\n",
            "Epoch 196/100, Loss: 22.6542, Validation Accuracy: 0.6082\n",
            "Epoch 197/100, Loss: 74.2095, Validation Accuracy: 0.6291\n",
            "Epoch 198/100, Loss: 113.3081, Validation Accuracy: 0.6700\n",
            "Epoch 199/100, Loss: 91.7079, Validation Accuracy: 0.6251\n",
            "Epoch 200/100, Loss: 57.2024, Validation Accuracy: 0.6570\n",
            "Reward for Child Model: 0.300749573479958\n",
            "Child_87:  {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, [2, 2, 3, 0, 3, 0, 1, 1, 1, 2, 0, 2, 0, 0, 1], 0.300749573479958\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 48, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 24, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(48, 48, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(48, 24, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=101376, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 24, 22]           2,544\n",
            "       BatchNorm2d-2           [-1, 24, 24, 22]              48\n",
            "            Conv2d-3           [-1, 48, 20, 20]          17,328\n",
            "       BatchNorm2d-4           [-1, 48, 20, 20]              96\n",
            "              ReLU-5           [-1, 48, 20, 20]               0\n",
            "            Conv2d-6           [-1, 24, 14, 18]          24,216\n",
            "       BatchNorm2d-7           [-1, 24, 14, 18]              48\n",
            "              ReLU-8           [-1, 24, 14, 18]               0\n",
            "            Conv2d-9           [-1, 48, 22, 16]          48,432\n",
            "      BatchNorm2d-10           [-1, 48, 22, 16]              96\n",
            "             ReLU-11           [-1, 48, 22, 16]               0\n",
            "           Conv2d-12           [-1, 24, 20, 10]          24,216\n",
            "      BatchNorm2d-13           [-1, 24, 20, 10]              48\n",
            "             ReLU-14           [-1, 24, 20, 10]               0\n",
            "           Linear-15                    [-1, 7]         709,639\n",
            "================================================================\n",
            "Total params: 826,711\n",
            "Trainable params: 826,711\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.27\n",
            "Params size (MB): 3.15\n",
            "Estimated Total Size (MB): 4.43\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 20.3387, Validation Accuracy: 0.2203\n",
            "Epoch 2/100, Loss: 3.1131, Validation Accuracy: 0.6630\n",
            "Epoch 3/100, Loss: 106.0558, Validation Accuracy: 0.5932\n",
            "Epoch 4/100, Loss: 16.2962, Validation Accuracy: 0.5075\n",
            "Epoch 5/100, Loss: 21.0007, Validation Accuracy: 0.5045\n",
            "Epoch 6/100, Loss: 10.6906, Validation Accuracy: 0.5922\n",
            "Epoch 7/100, Loss: 63.6246, Validation Accuracy: 0.6231\n",
            "Epoch 8/100, Loss: 236.0417, Validation Accuracy: 0.5085\n",
            "Epoch 9/100, Loss: 18.5776, Validation Accuracy: 0.3360\n",
            "Epoch 10/100, Loss: 28.8781, Validation Accuracy: 0.3988\n",
            "Epoch 11/100, Loss: 13.8581, Validation Accuracy: 0.6251\n",
            "Epoch 12/100, Loss: 30.4006, Validation Accuracy: 0.5803\n",
            "Epoch 13/100, Loss: 29.7322, Validation Accuracy: 0.5304\n",
            "Epoch 14/100, Loss: 94.7448, Validation Accuracy: 0.5284\n",
            "Epoch 15/100, Loss: 10.3834, Validation Accuracy: 0.2173\n",
            "Epoch 16/100, Loss: 51.3472, Validation Accuracy: 0.6092\n",
            "Epoch 17/100, Loss: 98.5232, Validation Accuracy: 0.5533\n",
            "Epoch 18/100, Loss: 28.4355, Validation Accuracy: 0.6102\n",
            "Epoch 19/100, Loss: 9.4402, Validation Accuracy: 0.6162\n",
            "Epoch 20/100, Loss: 6.0610, Validation Accuracy: 0.6471\n",
            "Epoch 21/100, Loss: 12.1605, Validation Accuracy: 0.6201\n",
            "Epoch 22/100, Loss: 47.5757, Validation Accuracy: 0.6271\n",
            "Epoch 23/100, Loss: 76.8798, Validation Accuracy: 0.4327\n",
            "Epoch 24/100, Loss: 34.3653, Validation Accuracy: 0.1785\n",
            "Epoch 25/100, Loss: 366.1731, Validation Accuracy: 0.5344\n",
            "Epoch 26/100, Loss: 19.3919, Validation Accuracy: 0.5105\n",
            "Epoch 27/100, Loss: 7.8831, Validation Accuracy: 0.4796\n",
            "Epoch 28/100, Loss: 7.3284, Validation Accuracy: 0.6481\n",
            "Epoch 29/100, Loss: 3.5960, Validation Accuracy: 0.6401\n",
            "Epoch 30/100, Loss: 5.6664, Validation Accuracy: 0.6331\n",
            "Epoch 31/100, Loss: 8.5103, Validation Accuracy: 0.5474\n",
            "Epoch 32/100, Loss: 99.1881, Validation Accuracy: 0.6361\n",
            "Epoch 33/100, Loss: 3.1119, Validation Accuracy: 0.5184\n",
            "Epoch 34/100, Loss: 6.9179, Validation Accuracy: 0.6351\n",
            "Epoch 35/100, Loss: 13.8374, Validation Accuracy: 0.6022\n",
            "Epoch 36/100, Loss: 15.0209, Validation Accuracy: 0.6780\n",
            "Epoch 37/100, Loss: 14.5268, Validation Accuracy: 0.2293\n",
            "Epoch 38/100, Loss: 11.3834, Validation Accuracy: 0.6580\n",
            "Epoch 39/100, Loss: 72.0675, Validation Accuracy: 0.6072\n",
            "Epoch 40/100, Loss: 8.0520, Validation Accuracy: 0.5444\n",
            "Epoch 41/100, Loss: 13.7472, Validation Accuracy: 0.6431\n",
            "Epoch 42/100, Loss: 23.2198, Validation Accuracy: 0.5823\n",
            "Epoch 43/100, Loss: 114.8307, Validation Accuracy: 0.5992\n",
            "Epoch 44/100, Loss: 41.0777, Validation Accuracy: 0.6520\n",
            "Epoch 45/100, Loss: 19.7270, Validation Accuracy: 0.5852\n",
            "Epoch 46/100, Loss: 8.1599, Validation Accuracy: 0.5932\n",
            "Epoch 47/100, Loss: 9.6483, Validation Accuracy: 0.5623\n",
            "Epoch 48/100, Loss: 112.2960, Validation Accuracy: 0.6431\n",
            "Epoch 49/100, Loss: 38.9709, Validation Accuracy: 0.6640\n",
            "Epoch 50/100, Loss: 20.4031, Validation Accuracy: 0.5882\n",
            "Epoch 51/100, Loss: 20.7803, Validation Accuracy: 0.6351\n",
            "Epoch 52/100, Loss: 14.9588, Validation Accuracy: 0.5862\n",
            "Epoch 53/100, Loss: 37.7835, Validation Accuracy: 0.3659\n",
            "Epoch 54/100, Loss: 64.5274, Validation Accuracy: 0.6221\n",
            "Epoch 55/100, Loss: 35.5594, Validation Accuracy: 0.4148\n",
            "Epoch 56/100, Loss: 8.5557, Validation Accuracy: 0.4407\n",
            "Epoch 57/100, Loss: 17.7226, Validation Accuracy: 0.5922\n",
            "Epoch 58/100, Loss: 8.0665, Validation Accuracy: 0.5823\n",
            "Epoch 59/100, Loss: 15.2404, Validation Accuracy: 0.5653\n",
            "Epoch 60/100, Loss: 24.6533, Validation Accuracy: 0.5434\n",
            "Epoch 61/100, Loss: 28.5660, Validation Accuracy: 0.6500\n",
            "Epoch 62/100, Loss: 19.9060, Validation Accuracy: 0.5703\n",
            "Epoch 63/100, Loss: 10.5947, Validation Accuracy: 0.5184\n",
            "Epoch 64/100, Loss: 12.1776, Validation Accuracy: 0.6082\n",
            "Epoch 65/100, Loss: 47.0580, Validation Accuracy: 0.6710\n",
            "Epoch 66/100, Loss: 71.9826, Validation Accuracy: 0.5513\n",
            "Epoch 67/100, Loss: 64.9843, Validation Accuracy: 0.5703\n",
            "Epoch 68/100, Loss: 20.6153, Validation Accuracy: 0.5922\n",
            "Epoch 69/100, Loss: 10.7555, Validation Accuracy: 0.6211\n",
            "Epoch 70/100, Loss: 9.6653, Validation Accuracy: 0.6680\n",
            "Epoch 71/100, Loss: 12.1818, Validation Accuracy: 0.6630\n",
            "Epoch 72/100, Loss: 29.7032, Validation Accuracy: 0.6002\n",
            "Epoch 73/100, Loss: 25.3905, Validation Accuracy: 0.6481\n",
            "Epoch 74/100, Loss: 48.8343, Validation Accuracy: 0.6680\n",
            "Epoch 75/100, Loss: 53.9028, Validation Accuracy: 0.5025\n",
            "Epoch 76/100, Loss: 18.6994, Validation Accuracy: 0.6620\n",
            "Epoch 77/100, Loss: 13.8076, Validation Accuracy: 0.5523\n",
            "Epoch 78/100, Loss: 34.1278, Validation Accuracy: 0.6042\n",
            "Epoch 79/100, Loss: 66.0606, Validation Accuracy: 0.6012\n",
            "Epoch 80/100, Loss: 23.1487, Validation Accuracy: 0.6820\n",
            "Epoch 81/100, Loss: 24.0533, Validation Accuracy: 0.5922\n",
            "Epoch 82/100, Loss: 48.2720, Validation Accuracy: 0.6152\n",
            "Epoch 83/100, Loss: 41.2653, Validation Accuracy: 0.6560\n",
            "Epoch 84/100, Loss: 18.3480, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 29.5202, Validation Accuracy: 0.6421\n",
            "Epoch 86/100, Loss: 4.5172, Validation Accuracy: 0.6899\n",
            "Epoch 87/100, Loss: 23.2884, Validation Accuracy: 0.6052\n",
            "Epoch 88/100, Loss: 7.1237, Validation Accuracy: 0.6431\n",
            "Epoch 89/100, Loss: 24.9874, Validation Accuracy: 0.6261\n",
            "Epoch 90/100, Loss: 21.4275, Validation Accuracy: 0.5234\n",
            "Epoch 91/100, Loss: 51.9152, Validation Accuracy: 0.5105\n",
            "Epoch 92/100, Loss: 36.7344, Validation Accuracy: 0.5842\n",
            "Epoch 93/100, Loss: 18.5275, Validation Accuracy: 0.5922\n",
            "Epoch 94/100, Loss: 16.5649, Validation Accuracy: 0.5872\n",
            "Epoch 95/100, Loss: 11.6875, Validation Accuracy: 0.5852\n",
            "Epoch 96/100, Loss: 25.8468, Validation Accuracy: 0.6371\n",
            "Epoch 97/100, Loss: 26.9200, Validation Accuracy: 0.5454\n",
            "Epoch 98/100, Loss: 29.8111, Validation Accuracy: 0.6152\n",
            "Epoch 99/100, Loss: 169.7809, Validation Accuracy: 0.4098\n",
            "Epoch 100/100, Loss: 21.0337, Validation Accuracy: 0.5673\n",
            "Epoch 101/100, Loss: 31.3615, Validation Accuracy: 0.5653\n",
            "Epoch 102/100, Loss: 38.0377, Validation Accuracy: 0.6291\n",
            "Epoch 103/100, Loss: 10.1562, Validation Accuracy: 0.5274\n",
            "Epoch 104/100, Loss: 13.5768, Validation Accuracy: 0.3978\n",
            "Epoch 105/100, Loss: 148.1726, Validation Accuracy: 0.3490\n",
            "Epoch 106/100, Loss: 13.1356, Validation Accuracy: 0.5813\n",
            "Epoch 107/100, Loss: 11.9197, Validation Accuracy: 0.6191\n",
            "Epoch 108/100, Loss: 61.9586, Validation Accuracy: 0.6680\n",
            "Epoch 109/100, Loss: 66.1050, Validation Accuracy: 0.6062\n",
            "Epoch 110/100, Loss: 40.2270, Validation Accuracy: 0.3988\n",
            "Epoch 111/100, Loss: 15.4586, Validation Accuracy: 0.5643\n",
            "Epoch 112/100, Loss: 19.6310, Validation Accuracy: 0.6162\n",
            "Epoch 113/100, Loss: 55.3594, Validation Accuracy: 0.6491\n",
            "Epoch 114/100, Loss: 35.9232, Validation Accuracy: 0.5623\n",
            "Epoch 115/100, Loss: 14.4694, Validation Accuracy: 0.6580\n",
            "Epoch 116/100, Loss: 82.3848, Validation Accuracy: 0.3619\n",
            "Epoch 117/100, Loss: 25.3422, Validation Accuracy: 0.5474\n",
            "Epoch 118/100, Loss: 17.3014, Validation Accuracy: 0.6152\n",
            "Epoch 119/100, Loss: 11.9905, Validation Accuracy: 0.4875\n",
            "Epoch 120/100, Loss: 95.3509, Validation Accuracy: 0.6441\n",
            "Epoch 121/100, Loss: 59.0600, Validation Accuracy: 0.5015\n",
            "Epoch 122/100, Loss: 14.3538, Validation Accuracy: 0.6540\n",
            "Epoch 123/100, Loss: 12.6201, Validation Accuracy: 0.5942\n",
            "Epoch 124/100, Loss: 16.3595, Validation Accuracy: 0.4985\n",
            "Epoch 125/100, Loss: 94.4589, Validation Accuracy: 0.5803\n",
            "Epoch 126/100, Loss: 25.7547, Validation Accuracy: 0.5254\n",
            "Epoch 127/100, Loss: 12.9297, Validation Accuracy: 0.6191\n",
            "Epoch 128/100, Loss: 156.6239, Validation Accuracy: 0.6570\n",
            "Epoch 129/100, Loss: 17.1014, Validation Accuracy: 0.6929\n",
            "Epoch 130/100, Loss: 12.1765, Validation Accuracy: 0.6132\n",
            "Epoch 131/100, Loss: 9.9646, Validation Accuracy: 0.6142\n",
            "Epoch 132/100, Loss: 37.3032, Validation Accuracy: 0.5693\n",
            "Epoch 133/100, Loss: 40.1202, Validation Accuracy: 0.5952\n",
            "Epoch 134/100, Loss: 39.3465, Validation Accuracy: 0.6530\n",
            "Epoch 135/100, Loss: 17.4856, Validation Accuracy: 0.6451\n",
            "Epoch 136/100, Loss: 49.9434, Validation Accuracy: 0.6391\n",
            "Epoch 137/100, Loss: 25.3234, Validation Accuracy: 0.4676\n",
            "Epoch 138/100, Loss: 17.4694, Validation Accuracy: 0.6590\n",
            "Epoch 139/100, Loss: 21.8039, Validation Accuracy: 0.3629\n",
            "Epoch 140/100, Loss: 51.7581, Validation Accuracy: 0.5484\n",
            "Epoch 141/100, Loss: 50.9364, Validation Accuracy: 0.6471\n",
            "Epoch 142/100, Loss: 26.9824, Validation Accuracy: 0.5523\n",
            "Epoch 143/100, Loss: 14.7060, Validation Accuracy: 0.4845\n",
            "Epoch 144/100, Loss: 24.3627, Validation Accuracy: 0.6560\n",
            "Epoch 145/100, Loss: 110.3566, Validation Accuracy: 0.5484\n",
            "Epoch 146/100, Loss: 18.1346, Validation Accuracy: 0.6680\n",
            "Epoch 147/100, Loss: 19.0818, Validation Accuracy: 0.5872\n",
            "Epoch 148/100, Loss: 13.3408, Validation Accuracy: 0.6491\n",
            "Epoch 149/100, Loss: 18.9583, Validation Accuracy: 0.6391\n",
            "Epoch 150/100, Loss: 7.8261, Validation Accuracy: 0.5823\n",
            "Epoch 151/100, Loss: 72.6645, Validation Accuracy: 0.6580\n",
            "Epoch 152/100, Loss: 29.4012, Validation Accuracy: 0.6650\n",
            "Epoch 153/100, Loss: 18.3932, Validation Accuracy: 0.6491\n",
            "Epoch 154/100, Loss: 31.7779, Validation Accuracy: 0.4227\n",
            "Epoch 155/100, Loss: 17.3306, Validation Accuracy: 0.5264\n",
            "Epoch 156/100, Loss: 29.8632, Validation Accuracy: 0.5533\n",
            "Epoch 157/100, Loss: 17.0112, Validation Accuracy: 0.5962\n",
            "Epoch 158/100, Loss: 47.7333, Validation Accuracy: 0.5553\n",
            "Epoch 159/100, Loss: 53.3582, Validation Accuracy: 0.5603\n",
            "Epoch 160/100, Loss: 50.4135, Validation Accuracy: 0.6321\n",
            "Epoch 161/100, Loss: 19.6783, Validation Accuracy: 0.2911\n",
            "Epoch 162/100, Loss: 34.1676, Validation Accuracy: 0.5055\n",
            "Epoch 163/100, Loss: 38.0622, Validation Accuracy: 0.6331\n",
            "Epoch 164/100, Loss: 21.3362, Validation Accuracy: 0.6102\n",
            "Epoch 165/100, Loss: 103.2037, Validation Accuracy: 0.5972\n",
            "Epoch 166/100, Loss: 16.0712, Validation Accuracy: 0.6540\n",
            "Epoch 167/100, Loss: 14.6897, Validation Accuracy: 0.5653\n",
            "Epoch 168/100, Loss: 15.1845, Validation Accuracy: 0.6381\n",
            "Epoch 169/100, Loss: 25.5936, Validation Accuracy: 0.5075\n",
            "Epoch 170/100, Loss: 19.6560, Validation Accuracy: 0.6391\n",
            "Epoch 171/100, Loss: 171.2625, Validation Accuracy: 0.6451\n",
            "Epoch 172/100, Loss: 61.4730, Validation Accuracy: 0.3101\n",
            "Epoch 173/100, Loss: 21.5232, Validation Accuracy: 0.6491\n",
            "Epoch 174/100, Loss: 13.3071, Validation Accuracy: 0.5952\n",
            "Epoch 175/100, Loss: 7.7835, Validation Accuracy: 0.6381\n",
            "Epoch 176/100, Loss: 12.1482, Validation Accuracy: 0.6022\n",
            "Epoch 177/100, Loss: 41.5354, Validation Accuracy: 0.2832\n",
            "Epoch 178/100, Loss: 107.7313, Validation Accuracy: 0.5733\n",
            "Epoch 179/100, Loss: 36.1411, Validation Accuracy: 0.4726\n",
            "Epoch 180/100, Loss: 12.7432, Validation Accuracy: 0.6760\n",
            "Epoch 181/100, Loss: 18.9269, Validation Accuracy: 0.6022\n",
            "Epoch 182/100, Loss: 14.2845, Validation Accuracy: 0.6042\n",
            "Epoch 183/100, Loss: 30.5256, Validation Accuracy: 0.6750\n",
            "Epoch 184/100, Loss: 29.1494, Validation Accuracy: 0.6321\n",
            "Epoch 185/100, Loss: 9.5872, Validation Accuracy: 0.5862\n",
            "Epoch 186/100, Loss: 18.9511, Validation Accuracy: 0.6530\n",
            "Epoch 187/100, Loss: 18.8504, Validation Accuracy: 0.4556\n",
            "Epoch 188/100, Loss: 16.8384, Validation Accuracy: 0.4656\n",
            "Epoch 189/100, Loss: 26.7524, Validation Accuracy: 0.4995\n",
            "Epoch 190/100, Loss: 39.7089, Validation Accuracy: 0.4477\n",
            "Epoch 191/100, Loss: 33.7122, Validation Accuracy: 0.4915\n",
            "Epoch 192/100, Loss: 50.3032, Validation Accuracy: 0.6072\n",
            "Epoch 193/100, Loss: 23.3451, Validation Accuracy: 0.6142\n",
            "Epoch 194/100, Loss: 14.4920, Validation Accuracy: 0.5553\n",
            "Epoch 195/100, Loss: 25.2589, Validation Accuracy: 0.6281\n",
            "Epoch 196/100, Loss: 42.3822, Validation Accuracy: 0.5543\n",
            "Epoch 197/100, Loss: 33.8782, Validation Accuracy: 0.6500\n",
            "Epoch 198/100, Loss: 22.1817, Validation Accuracy: 0.6491\n",
            "Epoch 199/100, Loss: 43.2530, Validation Accuracy: 0.6680\n",
            "Epoch 200/100, Loss: 34.6783, Validation Accuracy: 0.6540\n",
            "Reward for Child Model: 0.2980722933598883\n",
            "Child_88:  {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, [2, 3, 0, 2, 1, 2, 3, 1, 0, 1, 3, 2, 1, 3, 0], 0.2980722933598883\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 64, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(88, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(88, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(136, 48, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=213248, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 28, 28]              96\n",
            "       BatchNorm2d-2           [-1, 24, 28, 28]              48\n",
            "            Conv2d-3           [-1, 64, 24, 26]          23,104\n",
            "       BatchNorm2d-4           [-1, 64, 24, 26]             128\n",
            "              ReLU-5           [-1, 64, 24, 26]               0\n",
            "            Conv2d-6           [-1, 64, 22, 22]         276,032\n",
            "       BatchNorm2d-7           [-1, 64, 22, 22]             128\n",
            "              ReLU-8           [-1, 64, 22, 22]               0\n",
            "            Conv2d-9           [-1, 24, 28, 22]          14,808\n",
            "      BatchNorm2d-10           [-1, 24, 28, 22]              48\n",
            "             ReLU-11           [-1, 24, 28, 22]               0\n",
            "           Conv2d-12           [-1, 48, 24, 28]          32,688\n",
            "      BatchNorm2d-13           [-1, 48, 24, 28]              96\n",
            "             ReLU-14           [-1, 48, 24, 28]               0\n",
            "           Linear-15                    [-1, 7]       1,492,743\n",
            "================================================================\n",
            "Total params: 1,839,919\n",
            "Trainable params: 1,839,919\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.99\n",
            "Params size (MB): 7.02\n",
            "Estimated Total Size (MB): 10.01\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 39.2516, Validation Accuracy: 0.6421\n",
            "Epoch 2/100, Loss: 381.0842, Validation Accuracy: 0.5115\n",
            "Epoch 3/100, Loss: 13.0099, Validation Accuracy: 0.3719\n",
            "Epoch 4/100, Loss: 14.4471, Validation Accuracy: 0.5733\n",
            "Epoch 5/100, Loss: 8.9052, Validation Accuracy: 0.5095\n",
            "Epoch 6/100, Loss: 6.4117, Validation Accuracy: 0.6471\n",
            "Epoch 7/100, Loss: 213.2973, Validation Accuracy: 0.3948\n",
            "Epoch 8/100, Loss: 86.6004, Validation Accuracy: 0.5823\n",
            "Epoch 9/100, Loss: 26.2812, Validation Accuracy: 0.6231\n",
            "Epoch 10/100, Loss: 13.8845, Validation Accuracy: 0.6471\n",
            "Epoch 11/100, Loss: 56.4276, Validation Accuracy: 0.5833\n",
            "Epoch 12/100, Loss: 10.5329, Validation Accuracy: 0.4816\n",
            "Epoch 13/100, Loss: 14.1517, Validation Accuracy: 0.4865\n",
            "Epoch 14/100, Loss: 3.1615, Validation Accuracy: 0.5753\n",
            "Epoch 15/100, Loss: 93.2001, Validation Accuracy: 0.5683\n",
            "Epoch 16/100, Loss: 114.4754, Validation Accuracy: 0.6022\n",
            "Epoch 17/100, Loss: 24.6591, Validation Accuracy: 0.6481\n",
            "Epoch 18/100, Loss: 92.4355, Validation Accuracy: 0.5404\n",
            "Epoch 19/100, Loss: 20.9977, Validation Accuracy: 0.4367\n",
            "Epoch 20/100, Loss: 14.8920, Validation Accuracy: 0.6431\n",
            "Epoch 21/100, Loss: 157.8998, Validation Accuracy: 0.5155\n",
            "Epoch 22/100, Loss: 372.1494, Validation Accuracy: 0.6680\n",
            "Epoch 23/100, Loss: 46.7482, Validation Accuracy: 0.4307\n",
            "Epoch 24/100, Loss: 9.3865, Validation Accuracy: 0.5773\n",
            "Epoch 25/100, Loss: 40.4391, Validation Accuracy: 0.6620\n",
            "Epoch 26/100, Loss: 79.3288, Validation Accuracy: 0.6361\n",
            "Epoch 27/100, Loss: 60.8680, Validation Accuracy: 0.4297\n",
            "Epoch 28/100, Loss: 25.0724, Validation Accuracy: 0.6730\n",
            "Epoch 29/100, Loss: 15.4351, Validation Accuracy: 0.6221\n",
            "Epoch 30/100, Loss: 53.3809, Validation Accuracy: 0.3699\n",
            "Epoch 31/100, Loss: 110.9198, Validation Accuracy: 0.5713\n",
            "Epoch 32/100, Loss: 26.7125, Validation Accuracy: 0.6191\n",
            "Epoch 33/100, Loss: 27.9305, Validation Accuracy: 0.6221\n",
            "Epoch 34/100, Loss: 124.0835, Validation Accuracy: 0.6231\n",
            "Epoch 35/100, Loss: 63.6988, Validation Accuracy: 0.4606\n",
            "Epoch 36/100, Loss: 63.5641, Validation Accuracy: 0.6610\n",
            "Epoch 37/100, Loss: 35.6477, Validation Accuracy: 0.4467\n",
            "Epoch 38/100, Loss: 14.8931, Validation Accuracy: 0.6760\n",
            "Epoch 39/100, Loss: 28.9726, Validation Accuracy: 0.5543\n",
            "Epoch 40/100, Loss: 28.4384, Validation Accuracy: 0.5743\n",
            "Epoch 41/100, Loss: 97.9792, Validation Accuracy: 0.6610\n",
            "Epoch 42/100, Loss: 113.3525, Validation Accuracy: 0.5414\n",
            "Epoch 43/100, Loss: 26.6491, Validation Accuracy: 0.6600\n",
            "Epoch 44/100, Loss: 63.4266, Validation Accuracy: 0.6122\n",
            "Epoch 45/100, Loss: 43.6530, Validation Accuracy: 0.6590\n",
            "Epoch 46/100, Loss: 40.7166, Validation Accuracy: 0.5803\n",
            "Epoch 47/100, Loss: 32.6403, Validation Accuracy: 0.6540\n",
            "Epoch 48/100, Loss: 33.8439, Validation Accuracy: 0.6520\n",
            "Epoch 49/100, Loss: 143.1508, Validation Accuracy: 0.3759\n",
            "Epoch 50/100, Loss: 65.4552, Validation Accuracy: 0.5992\n",
            "Epoch 51/100, Loss: 179.7162, Validation Accuracy: 0.6750\n",
            "Epoch 52/100, Loss: 25.8967, Validation Accuracy: 0.6411\n",
            "Epoch 53/100, Loss: 12.3499, Validation Accuracy: 0.6271\n",
            "Epoch 54/100, Loss: 66.5861, Validation Accuracy: 0.4417\n",
            "Epoch 55/100, Loss: 136.9736, Validation Accuracy: 0.5254\n",
            "Epoch 56/100, Loss: 95.8553, Validation Accuracy: 0.6680\n",
            "Epoch 57/100, Loss: 283.7137, Validation Accuracy: 0.6092\n",
            "Epoch 58/100, Loss: 102.5962, Validation Accuracy: 0.6889\n",
            "Epoch 59/100, Loss: 51.0595, Validation Accuracy: 0.6341\n",
            "Epoch 60/100, Loss: 35.7734, Validation Accuracy: 0.3200\n",
            "Epoch 61/100, Loss: 64.1530, Validation Accuracy: 0.6580\n",
            "Epoch 62/100, Loss: 16.7734, Validation Accuracy: 0.5284\n",
            "Epoch 63/100, Loss: 93.7861, Validation Accuracy: 0.5075\n",
            "Epoch 64/100, Loss: 11.6174, Validation Accuracy: 0.6341\n",
            "Epoch 65/100, Loss: 42.3508, Validation Accuracy: 0.5543\n",
            "Epoch 66/100, Loss: 199.1149, Validation Accuracy: 0.5324\n",
            "Epoch 67/100, Loss: 26.1676, Validation Accuracy: 0.6839\n",
            "Epoch 68/100, Loss: 55.6189, Validation Accuracy: 0.4646\n",
            "Epoch 69/100, Loss: 23.2529, Validation Accuracy: 0.6740\n",
            "Epoch 70/100, Loss: 533.5201, Validation Accuracy: 0.3021\n",
            "Epoch 71/100, Loss: 31.3198, Validation Accuracy: 0.6301\n",
            "Epoch 72/100, Loss: 32.0448, Validation Accuracy: 0.6620\n",
            "Epoch 73/100, Loss: 22.9328, Validation Accuracy: 0.4158\n",
            "Epoch 74/100, Loss: 76.0715, Validation Accuracy: 0.5972\n",
            "Epoch 75/100, Loss: 16.7971, Validation Accuracy: 0.5454\n",
            "Epoch 76/100, Loss: 38.3219, Validation Accuracy: 0.6500\n",
            "Epoch 77/100, Loss: 244.8462, Validation Accuracy: 0.6800\n",
            "Epoch 78/100, Loss: 131.0591, Validation Accuracy: 0.5085\n",
            "Epoch 79/100, Loss: 35.5555, Validation Accuracy: 0.6072\n",
            "Epoch 80/100, Loss: 23.2812, Validation Accuracy: 0.6441\n",
            "Epoch 81/100, Loss: 24.2624, Validation Accuracy: 0.4865\n",
            "Epoch 82/100, Loss: 83.2161, Validation Accuracy: 0.2562\n",
            "Epoch 83/100, Loss: 54.2251, Validation Accuracy: 0.5145\n",
            "Epoch 84/100, Loss: 24.9414, Validation Accuracy: 0.6710\n",
            "Epoch 85/100, Loss: 69.3636, Validation Accuracy: 0.5045\n",
            "Epoch 86/100, Loss: 96.1252, Validation Accuracy: 0.6122\n",
            "Epoch 87/100, Loss: 26.9116, Validation Accuracy: 0.6341\n",
            "Epoch 88/100, Loss: 36.1328, Validation Accuracy: 0.5862\n",
            "Epoch 89/100, Loss: 178.3781, Validation Accuracy: 0.6700\n",
            "Epoch 90/100, Loss: 82.4585, Validation Accuracy: 0.5543\n",
            "Epoch 91/100, Loss: 105.3393, Validation Accuracy: 0.5952\n",
            "Epoch 92/100, Loss: 18.8460, Validation Accuracy: 0.6211\n",
            "Epoch 93/100, Loss: 29.9017, Validation Accuracy: 0.6810\n",
            "Epoch 94/100, Loss: 48.5616, Validation Accuracy: 0.4566\n",
            "Epoch 95/100, Loss: 41.5274, Validation Accuracy: 0.6062\n",
            "Epoch 96/100, Loss: 76.0113, Validation Accuracy: 0.5005\n",
            "Epoch 97/100, Loss: 48.1262, Validation Accuracy: 0.5643\n",
            "Epoch 98/100, Loss: 28.2384, Validation Accuracy: 0.6321\n",
            "Epoch 99/100, Loss: 123.2527, Validation Accuracy: 0.5932\n",
            "Epoch 100/100, Loss: 114.7731, Validation Accuracy: 0.6221\n",
            "Epoch 101/100, Loss: 85.6736, Validation Accuracy: 0.6152\n",
            "Epoch 102/100, Loss: 98.0193, Validation Accuracy: 0.5214\n",
            "Epoch 103/100, Loss: 1108.5623, Validation Accuracy: 0.4935\n",
            "Epoch 104/100, Loss: 24.0415, Validation Accuracy: 0.5573\n",
            "Epoch 105/100, Loss: 37.1434, Validation Accuracy: 0.6281\n",
            "Epoch 106/100, Loss: 21.4732, Validation Accuracy: 0.4576\n",
            "Epoch 107/100, Loss: 32.2083, Validation Accuracy: 0.6401\n",
            "Epoch 108/100, Loss: 20.7433, Validation Accuracy: 0.6391\n",
            "Epoch 109/100, Loss: 65.0975, Validation Accuracy: 0.6331\n",
            "Epoch 110/100, Loss: 39.7740, Validation Accuracy: 0.5573\n",
            "Epoch 111/100, Loss: 81.7748, Validation Accuracy: 0.6281\n",
            "Epoch 112/100, Loss: 124.7055, Validation Accuracy: 0.5384\n",
            "Epoch 113/100, Loss: 79.6401, Validation Accuracy: 0.5833\n",
            "Epoch 114/100, Loss: 85.2928, Validation Accuracy: 0.4506\n",
            "Epoch 115/100, Loss: 25.6582, Validation Accuracy: 0.6500\n",
            "Epoch 116/100, Loss: 43.9647, Validation Accuracy: 0.6191\n",
            "Epoch 117/100, Loss: 72.7909, Validation Accuracy: 0.6510\n",
            "Epoch 118/100, Loss: 108.0885, Validation Accuracy: 0.5214\n",
            "Epoch 119/100, Loss: 89.7226, Validation Accuracy: 0.5663\n",
            "Epoch 120/100, Loss: 88.1771, Validation Accuracy: 0.6261\n",
            "Epoch 121/100, Loss: 116.3885, Validation Accuracy: 0.5274\n",
            "Epoch 122/100, Loss: 27.1002, Validation Accuracy: 0.5872\n",
            "Epoch 123/100, Loss: 78.1237, Validation Accuracy: 0.6461\n",
            "Epoch 124/100, Loss: 28.1314, Validation Accuracy: 0.6770\n",
            "Epoch 125/100, Loss: 185.6805, Validation Accuracy: 0.4267\n",
            "Epoch 126/100, Loss: 85.0388, Validation Accuracy: 0.5952\n",
            "Epoch 127/100, Loss: 36.8326, Validation Accuracy: 0.5713\n",
            "Epoch 128/100, Loss: 143.9567, Validation Accuracy: 0.5444\n",
            "Epoch 129/100, Loss: 49.1266, Validation Accuracy: 0.6580\n",
            "Epoch 130/100, Loss: 23.0072, Validation Accuracy: 0.5553\n",
            "Epoch 131/100, Loss: 53.8068, Validation Accuracy: 0.6201\n",
            "Epoch 132/100, Loss: 377.0620, Validation Accuracy: 0.6600\n",
            "Epoch 133/100, Loss: 65.1256, Validation Accuracy: 0.5773\n",
            "Epoch 134/100, Loss: 34.4089, Validation Accuracy: 0.6441\n",
            "Epoch 135/100, Loss: 17.3851, Validation Accuracy: 0.6660\n",
            "Epoch 136/100, Loss: 25.4923, Validation Accuracy: 0.6002\n",
            "Epoch 137/100, Loss: 42.4501, Validation Accuracy: 0.5773\n",
            "Epoch 138/100, Loss: 61.3634, Validation Accuracy: 0.6720\n",
            "Epoch 139/100, Loss: 164.4546, Validation Accuracy: 0.6181\n",
            "Epoch 140/100, Loss: 65.9520, Validation Accuracy: 0.5573\n",
            "Epoch 141/100, Loss: 48.9387, Validation Accuracy: 0.6122\n",
            "Epoch 142/100, Loss: 27.1952, Validation Accuracy: 0.6530\n",
            "Epoch 143/100, Loss: 76.5686, Validation Accuracy: 0.5404\n",
            "Epoch 144/100, Loss: 111.5354, Validation Accuracy: 0.5284\n",
            "Epoch 145/100, Loss: 53.7696, Validation Accuracy: 0.6780\n",
            "Epoch 146/100, Loss: 65.1307, Validation Accuracy: 0.6221\n",
            "Epoch 147/100, Loss: 165.3094, Validation Accuracy: 0.6132\n",
            "Epoch 148/100, Loss: 45.8096, Validation Accuracy: 0.6231\n",
            "Epoch 149/100, Loss: 28.3221, Validation Accuracy: 0.5583\n",
            "Epoch 150/100, Loss: 50.9101, Validation Accuracy: 0.6042\n",
            "Epoch 151/100, Loss: 54.4209, Validation Accuracy: 0.5454\n",
            "Epoch 152/100, Loss: 30.4685, Validation Accuracy: 0.6351\n",
            "Epoch 153/100, Loss: 67.5219, Validation Accuracy: 0.6301\n",
            "Epoch 154/100, Loss: 125.9162, Validation Accuracy: 0.6600\n",
            "Epoch 155/100, Loss: 145.5020, Validation Accuracy: 0.6750\n",
            "Epoch 156/100, Loss: 37.8285, Validation Accuracy: 0.4247\n",
            "Epoch 157/100, Loss: 114.8118, Validation Accuracy: 0.6550\n",
            "Epoch 158/100, Loss: 39.1016, Validation Accuracy: 0.5204\n",
            "Epoch 159/100, Loss: 53.1240, Validation Accuracy: 0.4915\n",
            "Epoch 160/100, Loss: 38.3408, Validation Accuracy: 0.6441\n",
            "Epoch 161/100, Loss: 140.0679, Validation Accuracy: 0.6062\n",
            "Epoch 162/100, Loss: 63.9135, Validation Accuracy: 0.6700\n",
            "Epoch 163/100, Loss: 104.5140, Validation Accuracy: 0.5623\n",
            "Epoch 164/100, Loss: 66.1565, Validation Accuracy: 0.6481\n",
            "Epoch 165/100, Loss: 24.5173, Validation Accuracy: 0.6540\n",
            "Epoch 166/100, Loss: 25.0385, Validation Accuracy: 0.6461\n",
            "Epoch 167/100, Loss: 136.6570, Validation Accuracy: 0.6740\n",
            "Epoch 168/100, Loss: 127.6292, Validation Accuracy: 0.5673\n",
            "Epoch 169/100, Loss: 125.2453, Validation Accuracy: 0.5872\n",
            "Epoch 170/100, Loss: 91.1984, Validation Accuracy: 0.5852\n",
            "Epoch 171/100, Loss: 19.3177, Validation Accuracy: 0.6461\n",
            "Epoch 172/100, Loss: 54.2320, Validation Accuracy: 0.6790\n",
            "Epoch 173/100, Loss: 28.2019, Validation Accuracy: 0.5234\n",
            "Epoch 174/100, Loss: 74.0164, Validation Accuracy: 0.6540\n",
            "Epoch 175/100, Loss: 54.7735, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 148.1716, Validation Accuracy: 0.6142\n",
            "Epoch 177/100, Loss: 87.2463, Validation Accuracy: 0.6471\n",
            "Epoch 178/100, Loss: 79.3580, Validation Accuracy: 0.4766\n",
            "Epoch 179/100, Loss: 136.4451, Validation Accuracy: 0.6371\n",
            "Epoch 180/100, Loss: 65.1105, Validation Accuracy: 0.6122\n",
            "Epoch 181/100, Loss: 79.7498, Validation Accuracy: 0.5334\n",
            "Epoch 182/100, Loss: 13.7786, Validation Accuracy: 0.6710\n",
            "Epoch 183/100, Loss: 78.9634, Validation Accuracy: 0.5603\n",
            "Epoch 184/100, Loss: 100.5248, Validation Accuracy: 0.5414\n",
            "Epoch 185/100, Loss: 137.3385, Validation Accuracy: 0.5773\n",
            "Epoch 186/100, Loss: 59.8359, Validation Accuracy: 0.5813\n",
            "Epoch 187/100, Loss: 30.8557, Validation Accuracy: 0.5484\n",
            "Epoch 188/100, Loss: 44.2387, Validation Accuracy: 0.5813\n",
            "Epoch 189/100, Loss: 69.8325, Validation Accuracy: 0.5623\n",
            "Epoch 190/100, Loss: 102.0809, Validation Accuracy: 0.6570\n",
            "Epoch 191/100, Loss: 40.3725, Validation Accuracy: 0.5633\n",
            "Epoch 192/100, Loss: 33.0761, Validation Accuracy: 0.5105\n",
            "Epoch 193/100, Loss: 158.0800, Validation Accuracy: 0.6810\n",
            "Epoch 194/100, Loss: 173.8775, Validation Accuracy: 0.6481\n",
            "Epoch 195/100, Loss: 114.8271, Validation Accuracy: 0.6052\n",
            "Epoch 196/100, Loss: 25.6103, Validation Accuracy: 0.6341\n",
            "Epoch 197/100, Loss: 104.0973, Validation Accuracy: 0.6371\n",
            "Epoch 198/100, Loss: 30.4759, Validation Accuracy: 0.6431\n",
            "Epoch 199/100, Loss: 24.9956, Validation Accuracy: 0.3799\n",
            "Epoch 200/100, Loss: 14.3225, Validation Accuracy: 0.6650\n",
            "Reward for Child Model: 0.294086238583974\n",
            "Child_89:  {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, [0, 0, 0, 2, 1, 3, 3, 3, 3, 0, 3, 0, 2, 0, 2], 0.294086238583974\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(128, 48, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(240, 48, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(352, 48, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=236544, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 24, 28]           1,024\n",
            "       BatchNorm2d-2           [-1, 64, 24, 28]             128\n",
            "            Conv2d-3           [-1, 64, 24, 28]           4,160\n",
            "       BatchNorm2d-4           [-1, 64, 24, 28]             128\n",
            "              ReLU-5           [-1, 64, 24, 28]               0\n",
            "            Conv2d-6           [-1, 48, 22, 28]          18,480\n",
            "       BatchNorm2d-7           [-1, 48, 22, 28]              96\n",
            "              ReLU-8           [-1, 48, 22, 28]               0\n",
            "            Conv2d-9           [-1, 48, 18, 28]          80,688\n",
            "      BatchNorm2d-10           [-1, 48, 18, 28]              96\n",
            "             ReLU-11           [-1, 48, 18, 28]               0\n",
            "           Conv2d-12           [-1, 48, 20, 24]         422,448\n",
            "      BatchNorm2d-13           [-1, 48, 20, 24]              96\n",
            "             ReLU-14           [-1, 48, 20, 24]               0\n",
            "           Linear-15                    [-1, 7]       1,655,815\n",
            "================================================================\n",
            "Total params: 2,183,159\n",
            "Trainable params: 2,183,159\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.40\n",
            "Params size (MB): 8.33\n",
            "Estimated Total Size (MB): 11.74\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 54.3966, Validation Accuracy: 0.6191\n",
            "Epoch 2/100, Loss: 225.5327, Validation Accuracy: 0.2353\n",
            "Epoch 3/100, Loss: 75.2091, Validation Accuracy: 0.4995\n",
            "Epoch 4/100, Loss: 37.5248, Validation Accuracy: 0.6371\n",
            "Epoch 5/100, Loss: 107.0028, Validation Accuracy: 0.5294\n",
            "Epoch 6/100, Loss: 100.5150, Validation Accuracy: 0.6839\n",
            "Epoch 7/100, Loss: 246.9450, Validation Accuracy: 0.6102\n",
            "Epoch 8/100, Loss: 315.9009, Validation Accuracy: 0.5743\n",
            "Epoch 9/100, Loss: 69.7317, Validation Accuracy: 0.7009\n",
            "Epoch 10/100, Loss: 55.7787, Validation Accuracy: 0.4885\n",
            "Epoch 11/100, Loss: 100.4758, Validation Accuracy: 0.6560\n",
            "Epoch 12/100, Loss: 101.3093, Validation Accuracy: 0.5653\n",
            "Epoch 13/100, Loss: 120.6196, Validation Accuracy: 0.5683\n",
            "Epoch 14/100, Loss: 90.4300, Validation Accuracy: 0.4766\n",
            "Epoch 15/100, Loss: 176.2756, Validation Accuracy: 0.5643\n",
            "Epoch 16/100, Loss: 231.6265, Validation Accuracy: 0.5872\n",
            "Epoch 17/100, Loss: 253.9303, Validation Accuracy: 0.6730\n",
            "Epoch 18/100, Loss: 213.9695, Validation Accuracy: 0.5394\n",
            "Epoch 19/100, Loss: 183.5720, Validation Accuracy: 0.6381\n",
            "Epoch 20/100, Loss: 192.9634, Validation Accuracy: 0.6251\n",
            "Epoch 21/100, Loss: 237.1216, Validation Accuracy: 0.6580\n",
            "Epoch 22/100, Loss: 160.0944, Validation Accuracy: 0.3659\n",
            "Epoch 23/100, Loss: 77.7056, Validation Accuracy: 0.4756\n",
            "Epoch 24/100, Loss: 136.5909, Validation Accuracy: 0.6520\n",
            "Epoch 25/100, Loss: 70.2571, Validation Accuracy: 0.6650\n",
            "Epoch 26/100, Loss: 185.1786, Validation Accuracy: 0.6491\n",
            "Epoch 27/100, Loss: 163.2316, Validation Accuracy: 0.5593\n",
            "Epoch 28/100, Loss: 320.5499, Validation Accuracy: 0.5274\n",
            "Epoch 29/100, Loss: 225.5929, Validation Accuracy: 0.5513\n",
            "Epoch 30/100, Loss: 193.3790, Validation Accuracy: 0.6002\n",
            "Epoch 31/100, Loss: 367.4590, Validation Accuracy: 0.6421\n",
            "Epoch 32/100, Loss: 179.4306, Validation Accuracy: 0.6142\n",
            "Epoch 33/100, Loss: 709.5219, Validation Accuracy: 0.6142\n",
            "Epoch 34/100, Loss: 126.8301, Validation Accuracy: 0.5733\n",
            "Epoch 35/100, Loss: 105.0809, Validation Accuracy: 0.5673\n",
            "Epoch 36/100, Loss: 139.5176, Validation Accuracy: 0.5334\n",
            "Epoch 37/100, Loss: 161.6315, Validation Accuracy: 0.6760\n",
            "Epoch 38/100, Loss: 106.0871, Validation Accuracy: 0.5743\n",
            "Epoch 39/100, Loss: 420.7217, Validation Accuracy: 0.6530\n",
            "Epoch 40/100, Loss: 76.7293, Validation Accuracy: 0.6281\n",
            "Epoch 41/100, Loss: 182.0392, Validation Accuracy: 0.6590\n",
            "Epoch 42/100, Loss: 162.1078, Validation Accuracy: 0.6441\n",
            "Epoch 43/100, Loss: 252.7531, Validation Accuracy: 0.6760\n",
            "Epoch 44/100, Loss: 324.6236, Validation Accuracy: 0.6640\n",
            "Epoch 45/100, Loss: 189.0350, Validation Accuracy: 0.5474\n",
            "Epoch 46/100, Loss: 262.4364, Validation Accuracy: 0.6221\n",
            "Epoch 47/100, Loss: 170.0835, Validation Accuracy: 0.6899\n",
            "Epoch 48/100, Loss: 165.8869, Validation Accuracy: 0.5703\n",
            "Epoch 49/100, Loss: 91.7208, Validation Accuracy: 0.6760\n",
            "Epoch 50/100, Loss: 168.2091, Validation Accuracy: 0.6002\n",
            "Epoch 51/100, Loss: 64.8477, Validation Accuracy: 0.6760\n",
            "Epoch 52/100, Loss: 90.0535, Validation Accuracy: 0.6969\n",
            "Epoch 53/100, Loss: 295.0376, Validation Accuracy: 0.6820\n",
            "Epoch 54/100, Loss: 337.5371, Validation Accuracy: 0.6421\n",
            "Epoch 55/100, Loss: 163.8658, Validation Accuracy: 0.5882\n",
            "Epoch 56/100, Loss: 85.5698, Validation Accuracy: 0.6710\n",
            "Epoch 57/100, Loss: 44.2996, Validation Accuracy: 0.6072\n",
            "Epoch 58/100, Loss: 129.1335, Validation Accuracy: 0.6082\n",
            "Epoch 59/100, Loss: 149.8751, Validation Accuracy: 0.5474\n",
            "Epoch 60/100, Loss: 819.9864, Validation Accuracy: 0.6730\n",
            "Epoch 61/100, Loss: 190.8579, Validation Accuracy: 0.6929\n",
            "Epoch 62/100, Loss: 231.1162, Validation Accuracy: 0.6351\n",
            "Epoch 63/100, Loss: 241.6362, Validation Accuracy: 0.6650\n",
            "Epoch 64/100, Loss: 339.7783, Validation Accuracy: 0.6471\n",
            "Epoch 65/100, Loss: 267.9704, Validation Accuracy: 0.6411\n",
            "Epoch 66/100, Loss: 337.1266, Validation Accuracy: 0.5713\n",
            "Epoch 67/100, Loss: 34.5615, Validation Accuracy: 0.6122\n",
            "Epoch 68/100, Loss: 143.9030, Validation Accuracy: 0.6072\n",
            "Epoch 69/100, Loss: 158.8967, Validation Accuracy: 0.6700\n",
            "Epoch 70/100, Loss: 35.3812, Validation Accuracy: 0.6152\n",
            "Epoch 71/100, Loss: 216.1529, Validation Accuracy: 0.6849\n",
            "Epoch 72/100, Loss: 184.0521, Validation Accuracy: 0.6481\n",
            "Epoch 73/100, Loss: 74.1174, Validation Accuracy: 0.6820\n",
            "Epoch 74/100, Loss: 187.9248, Validation Accuracy: 0.6600\n",
            "Epoch 75/100, Loss: 226.7353, Validation Accuracy: 0.6201\n",
            "Epoch 76/100, Loss: 175.4826, Validation Accuracy: 0.5882\n",
            "Epoch 77/100, Loss: 575.0524, Validation Accuracy: 0.6790\n",
            "Epoch 78/100, Loss: 39.6018, Validation Accuracy: 0.6750\n",
            "Epoch 79/100, Loss: 136.5927, Validation Accuracy: 0.6590\n",
            "Epoch 80/100, Loss: 110.9750, Validation Accuracy: 0.6351\n",
            "Epoch 81/100, Loss: 223.6998, Validation Accuracy: 0.6341\n",
            "Epoch 82/100, Loss: 275.1756, Validation Accuracy: 0.5902\n",
            "Epoch 83/100, Loss: 217.7537, Validation Accuracy: 0.6022\n",
            "Epoch 84/100, Loss: 280.7544, Validation Accuracy: 0.6142\n",
            "Epoch 85/100, Loss: 246.0638, Validation Accuracy: 0.5922\n",
            "Epoch 86/100, Loss: 194.8423, Validation Accuracy: 0.6261\n",
            "Epoch 87/100, Loss: 61.2026, Validation Accuracy: 0.6142\n",
            "Epoch 88/100, Loss: 266.8168, Validation Accuracy: 0.6301\n",
            "Epoch 89/100, Loss: 258.4760, Validation Accuracy: 0.6032\n",
            "Epoch 90/100, Loss: 116.0994, Validation Accuracy: 0.6371\n",
            "Epoch 91/100, Loss: 410.5014, Validation Accuracy: 0.6620\n",
            "Epoch 92/100, Loss: 614.3886, Validation Accuracy: 0.6022\n",
            "Epoch 93/100, Loss: 106.4875, Validation Accuracy: 0.6650\n",
            "Epoch 94/100, Loss: 229.7758, Validation Accuracy: 0.5703\n",
            "Epoch 95/100, Loss: 193.4787, Validation Accuracy: 0.6730\n",
            "Epoch 96/100, Loss: 284.1582, Validation Accuracy: 0.6451\n",
            "Epoch 97/100, Loss: 142.5162, Validation Accuracy: 0.4786\n",
            "Epoch 98/100, Loss: 56.3219, Validation Accuracy: 0.6680\n",
            "Epoch 99/100, Loss: 203.8716, Validation Accuracy: 0.6171\n",
            "Epoch 100/100, Loss: 304.7536, Validation Accuracy: 0.6221\n",
            "Epoch 101/100, Loss: 269.5592, Validation Accuracy: 0.6022\n",
            "Epoch 102/100, Loss: 88.6164, Validation Accuracy: 0.6839\n",
            "Epoch 103/100, Loss: 3.7271, Validation Accuracy: 0.6381\n",
            "Epoch 104/100, Loss: 16.8954, Validation Accuracy: 0.6171\n",
            "Epoch 105/100, Loss: 154.4332, Validation Accuracy: 0.6800\n",
            "Epoch 106/100, Loss: 290.0148, Validation Accuracy: 0.6441\n",
            "Epoch 107/100, Loss: 109.8008, Validation Accuracy: 0.5653\n",
            "Epoch 108/100, Loss: 273.4129, Validation Accuracy: 0.6590\n",
            "Epoch 109/100, Loss: 154.5830, Validation Accuracy: 0.5384\n",
            "Epoch 110/100, Loss: 127.4475, Validation Accuracy: 0.5982\n",
            "Epoch 111/100, Loss: 161.7657, Validation Accuracy: 0.5962\n",
            "Epoch 112/100, Loss: 108.9018, Validation Accuracy: 0.5972\n",
            "Epoch 113/100, Loss: 243.8612, Validation Accuracy: 0.6670\n",
            "Epoch 114/100, Loss: 79.1979, Validation Accuracy: 0.6820\n",
            "Epoch 115/100, Loss: 502.3476, Validation Accuracy: 0.6530\n",
            "Epoch 116/100, Loss: 90.3205, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 147.9122, Validation Accuracy: 0.5394\n",
            "Epoch 118/100, Loss: 328.9044, Validation Accuracy: 0.6351\n",
            "Epoch 119/100, Loss: 77.7006, Validation Accuracy: 0.6491\n",
            "Epoch 120/100, Loss: 307.6194, Validation Accuracy: 0.6929\n",
            "Epoch 121/100, Loss: 279.0776, Validation Accuracy: 0.6201\n",
            "Epoch 122/100, Loss: 170.4827, Validation Accuracy: 0.6401\n",
            "Epoch 123/100, Loss: 202.6865, Validation Accuracy: 0.5892\n",
            "Epoch 124/100, Loss: 135.2696, Validation Accuracy: 0.6122\n",
            "Epoch 125/100, Loss: 53.4814, Validation Accuracy: 0.5523\n",
            "Epoch 126/100, Loss: 41.8516, Validation Accuracy: 0.5902\n",
            "Epoch 127/100, Loss: 216.8345, Validation Accuracy: 0.6570\n",
            "Epoch 128/100, Loss: 151.9707, Validation Accuracy: 0.6181\n",
            "Epoch 129/100, Loss: 352.4365, Validation Accuracy: 0.6750\n",
            "Epoch 130/100, Loss: 319.6072, Validation Accuracy: 0.6590\n",
            "Epoch 131/100, Loss: 100.9919, Validation Accuracy: 0.6261\n",
            "Epoch 132/100, Loss: 116.4422, Validation Accuracy: 0.6062\n",
            "Epoch 133/100, Loss: 274.6331, Validation Accuracy: 0.6291\n",
            "Epoch 134/100, Loss: 285.1465, Validation Accuracy: 0.6022\n",
            "Epoch 135/100, Loss: 46.9069, Validation Accuracy: 0.6730\n",
            "Epoch 136/100, Loss: 256.9947, Validation Accuracy: 0.5862\n",
            "Epoch 137/100, Loss: 237.8696, Validation Accuracy: 0.5992\n",
            "Epoch 138/100, Loss: 234.0014, Validation Accuracy: 0.6162\n",
            "Epoch 139/100, Loss: 189.1298, Validation Accuracy: 0.6102\n",
            "Epoch 140/100, Loss: 164.5480, Validation Accuracy: 0.6560\n",
            "Epoch 141/100, Loss: 171.4332, Validation Accuracy: 0.6022\n",
            "Epoch 142/100, Loss: 359.1962, Validation Accuracy: 0.5833\n",
            "Epoch 143/100, Loss: 39.7655, Validation Accuracy: 0.6451\n",
            "Epoch 144/100, Loss: 164.0806, Validation Accuracy: 0.5882\n",
            "Epoch 145/100, Loss: 121.9851, Validation Accuracy: 0.6022\n",
            "Epoch 146/100, Loss: 219.4553, Validation Accuracy: 0.5264\n",
            "Epoch 147/100, Loss: 292.5549, Validation Accuracy: 0.6491\n",
            "Epoch 148/100, Loss: 239.1798, Validation Accuracy: 0.6510\n",
            "Epoch 149/100, Loss: 272.1412, Validation Accuracy: 0.6122\n",
            "Epoch 150/100, Loss: 77.2272, Validation Accuracy: 0.6231\n",
            "Epoch 151/100, Loss: 137.2908, Validation Accuracy: 0.6481\n",
            "Epoch 152/100, Loss: 168.2829, Validation Accuracy: 0.5962\n",
            "Epoch 153/100, Loss: 98.8290, Validation Accuracy: 0.6132\n",
            "Epoch 154/100, Loss: 184.2652, Validation Accuracy: 0.6580\n",
            "Epoch 155/100, Loss: 212.6189, Validation Accuracy: 0.6381\n",
            "Epoch 156/100, Loss: 109.4152, Validation Accuracy: 0.6600\n",
            "Epoch 157/100, Loss: 132.1555, Validation Accuracy: 0.6351\n",
            "Epoch 158/100, Loss: 562.5688, Validation Accuracy: 0.5494\n",
            "Epoch 159/100, Loss: 99.1360, Validation Accuracy: 0.6670\n",
            "Epoch 160/100, Loss: 249.9688, Validation Accuracy: 0.6421\n",
            "Epoch 161/100, Loss: 395.8418, Validation Accuracy: 0.6321\n",
            "Epoch 162/100, Loss: 534.8257, Validation Accuracy: 0.5803\n",
            "Epoch 163/100, Loss: 123.3395, Validation Accuracy: 0.6700\n",
            "Epoch 164/100, Loss: 250.1441, Validation Accuracy: 0.5962\n",
            "Epoch 165/100, Loss: 80.0240, Validation Accuracy: 0.6381\n",
            "Epoch 166/100, Loss: 203.6270, Validation Accuracy: 0.6421\n",
            "Epoch 167/100, Loss: 170.2482, Validation Accuracy: 0.6162\n",
            "Epoch 168/100, Loss: 181.4923, Validation Accuracy: 0.6291\n",
            "Epoch 169/100, Loss: 130.9235, Validation Accuracy: 0.6102\n",
            "Epoch 170/100, Loss: 140.2615, Validation Accuracy: 0.6849\n",
            "Epoch 171/100, Loss: 58.0303, Validation Accuracy: 0.6780\n",
            "Epoch 172/100, Loss: 280.5474, Validation Accuracy: 0.6680\n",
            "Epoch 173/100, Loss: 115.4632, Validation Accuracy: 0.6042\n",
            "Epoch 174/100, Loss: 259.4339, Validation Accuracy: 0.5334\n",
            "Epoch 175/100, Loss: 770.1752, Validation Accuracy: 0.6181\n",
            "Epoch 176/100, Loss: 243.3714, Validation Accuracy: 0.6909\n",
            "Epoch 177/100, Loss: 69.1810, Validation Accuracy: 0.5872\n",
            "Epoch 178/100, Loss: 127.7373, Validation Accuracy: 0.6241\n",
            "Epoch 179/100, Loss: 272.9213, Validation Accuracy: 0.6191\n",
            "Epoch 180/100, Loss: 199.5675, Validation Accuracy: 0.5793\n",
            "Epoch 181/100, Loss: 69.9110, Validation Accuracy: 0.6221\n",
            "Epoch 182/100, Loss: 190.1890, Validation Accuracy: 0.6451\n",
            "Epoch 183/100, Loss: 219.2126, Validation Accuracy: 0.6810\n",
            "Epoch 184/100, Loss: 317.7747, Validation Accuracy: 0.5184\n",
            "Epoch 185/100, Loss: 330.7426, Validation Accuracy: 0.5783\n",
            "Epoch 186/100, Loss: 110.4710, Validation Accuracy: 0.6570\n",
            "Epoch 187/100, Loss: 1228.3048, Validation Accuracy: 0.6750\n",
            "Epoch 188/100, Loss: 326.5543, Validation Accuracy: 0.6072\n",
            "Epoch 189/100, Loss: 339.4009, Validation Accuracy: 0.6291\n",
            "Epoch 190/100, Loss: 110.3226, Validation Accuracy: 0.6560\n",
            "Epoch 191/100, Loss: 119.5653, Validation Accuracy: 0.5543\n",
            "Epoch 192/100, Loss: 129.4910, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 17.9558, Validation Accuracy: 0.6451\n",
            "Epoch 194/100, Loss: 98.0398, Validation Accuracy: 0.5852\n",
            "Epoch 195/100, Loss: 39.0658, Validation Accuracy: 0.5982\n",
            "Epoch 196/100, Loss: 350.2595, Validation Accuracy: 0.6491\n",
            "Epoch 197/100, Loss: 137.5966, Validation Accuracy: 0.5942\n",
            "Epoch 198/100, Loss: 137.4376, Validation Accuracy: 0.6680\n",
            "Epoch 199/100, Loss: 118.5491, Validation Accuracy: 0.6790\n",
            "Epoch 200/100, Loss: 269.2838, Validation Accuracy: 0.5972\n",
            "Reward for Child Model: 0.3129958192883965\n",
            "Child_90:  {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, [2, 0, 3, 0, 0, 3, 1, 0, 2, 3, 0, 2, 2, 2, 2], 0.3129958192883965\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(5, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 24, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(60, 24, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(84, 64, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(148, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=72576, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 24, 28]             576\n",
            "       BatchNorm2d-2           [-1, 36, 24, 28]              72\n",
            "            Conv2d-3           [-1, 24, 18, 28]           6,072\n",
            "       BatchNorm2d-4           [-1, 24, 18, 28]              48\n",
            "              ReLU-5           [-1, 24, 18, 28]               0\n",
            "            Conv2d-6           [-1, 24, 22, 26]          12,984\n",
            "       BatchNorm2d-7           [-1, 24, 22, 26]              48\n",
            "              ReLU-8           [-1, 24, 22, 26]               0\n",
            "            Conv2d-9           [-1, 64, 20, 22]         188,224\n",
            "      BatchNorm2d-10           [-1, 64, 20, 22]             128\n",
            "             ReLU-11           [-1, 64, 20, 22]               0\n",
            "           Conv2d-12           [-1, 48, 24, 24]          35,568\n",
            "      BatchNorm2d-13           [-1, 48, 24, 24]              96\n",
            "             ReLU-14           [-1, 48, 24, 24]               0\n",
            "           Linear-15                    [-1, 7]         508,039\n",
            "================================================================\n",
            "Total params: 751,855\n",
            "Trainable params: 751,855\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.24\n",
            "Params size (MB): 2.87\n",
            "Estimated Total Size (MB): 5.11\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 4.8404, Validation Accuracy: 0.5892\n",
            "Epoch 2/100, Loss: 11.4100, Validation Accuracy: 0.4227\n",
            "Epoch 3/100, Loss: 64.1462, Validation Accuracy: 0.6171\n",
            "Epoch 4/100, Loss: 14.4534, Validation Accuracy: 0.5862\n",
            "Epoch 5/100, Loss: 4.3188, Validation Accuracy: 0.5813\n",
            "Epoch 6/100, Loss: 4.4480, Validation Accuracy: 0.6750\n",
            "Epoch 7/100, Loss: 4.2266, Validation Accuracy: 0.5404\n",
            "Epoch 8/100, Loss: 2.8404, Validation Accuracy: 0.6072\n",
            "Epoch 9/100, Loss: 46.0307, Validation Accuracy: 0.4118\n",
            "Epoch 10/100, Loss: 72.5192, Validation Accuracy: 0.5404\n",
            "Epoch 11/100, Loss: 9.9161, Validation Accuracy: 0.6062\n",
            "Epoch 12/100, Loss: 11.1325, Validation Accuracy: 0.6590\n",
            "Epoch 13/100, Loss: 4.3101, Validation Accuracy: 0.6112\n",
            "Epoch 14/100, Loss: 6.7173, Validation Accuracy: 0.5234\n",
            "Epoch 15/100, Loss: 6.2847, Validation Accuracy: 0.4197\n",
            "Epoch 16/100, Loss: 17.2175, Validation Accuracy: 0.3918\n",
            "Epoch 17/100, Loss: 64.9252, Validation Accuracy: 0.3101\n",
            "Epoch 18/100, Loss: 11.4056, Validation Accuracy: 0.6391\n",
            "Epoch 19/100, Loss: 12.9832, Validation Accuracy: 0.6211\n",
            "Epoch 20/100, Loss: 37.2328, Validation Accuracy: 0.6740\n",
            "Epoch 21/100, Loss: 64.2317, Validation Accuracy: 0.6401\n",
            "Epoch 22/100, Loss: 15.6815, Validation Accuracy: 0.6660\n",
            "Epoch 23/100, Loss: 22.5676, Validation Accuracy: 0.5404\n",
            "Epoch 24/100, Loss: 19.8381, Validation Accuracy: 0.5872\n",
            "Epoch 25/100, Loss: 89.6093, Validation Accuracy: 0.5344\n",
            "Epoch 26/100, Loss: 28.2956, Validation Accuracy: 0.5364\n",
            "Epoch 27/100, Loss: 8.9992, Validation Accuracy: 0.5922\n",
            "Epoch 28/100, Loss: 14.9040, Validation Accuracy: 0.5304\n",
            "Epoch 29/100, Loss: 22.4631, Validation Accuracy: 0.5723\n",
            "Epoch 30/100, Loss: 32.8141, Validation Accuracy: 0.6451\n",
            "Epoch 31/100, Loss: 35.7907, Validation Accuracy: 0.6052\n",
            "Epoch 32/100, Loss: 12.7829, Validation Accuracy: 0.6371\n",
            "Epoch 33/100, Loss: 9.9043, Validation Accuracy: 0.5753\n",
            "Epoch 34/100, Loss: 10.9818, Validation Accuracy: 0.5294\n",
            "Epoch 35/100, Loss: 36.2705, Validation Accuracy: 0.6740\n",
            "Epoch 36/100, Loss: 64.8285, Validation Accuracy: 0.6760\n",
            "Epoch 37/100, Loss: 27.9034, Validation Accuracy: 0.5813\n",
            "Epoch 38/100, Loss: 28.4183, Validation Accuracy: 0.5404\n",
            "Epoch 39/100, Loss: 35.4657, Validation Accuracy: 0.6820\n",
            "Epoch 40/100, Loss: 22.8276, Validation Accuracy: 0.5284\n",
            "Epoch 41/100, Loss: 30.6135, Validation Accuracy: 0.6191\n",
            "Epoch 42/100, Loss: 49.0219, Validation Accuracy: 0.4706\n",
            "Epoch 43/100, Loss: 20.1157, Validation Accuracy: 0.6092\n",
            "Epoch 44/100, Loss: 16.4359, Validation Accuracy: 0.5703\n",
            "Epoch 45/100, Loss: 21.4380, Validation Accuracy: 0.5972\n",
            "Epoch 46/100, Loss: 59.9562, Validation Accuracy: 0.4855\n",
            "Epoch 47/100, Loss: 24.4065, Validation Accuracy: 0.5503\n",
            "Epoch 48/100, Loss: 21.9755, Validation Accuracy: 0.6550\n",
            "Epoch 49/100, Loss: 32.9570, Validation Accuracy: 0.3041\n",
            "Epoch 50/100, Loss: 15.9106, Validation Accuracy: 0.6520\n",
            "Epoch 51/100, Loss: 38.4557, Validation Accuracy: 0.5404\n",
            "Epoch 52/100, Loss: 13.8692, Validation Accuracy: 0.6241\n",
            "Epoch 53/100, Loss: 8.7627, Validation Accuracy: 0.6441\n",
            "Epoch 54/100, Loss: 14.6488, Validation Accuracy: 0.5673\n",
            "Epoch 55/100, Loss: 35.3673, Validation Accuracy: 0.5793\n",
            "Epoch 56/100, Loss: 23.3165, Validation Accuracy: 0.6002\n",
            "Epoch 57/100, Loss: 22.3113, Validation Accuracy: 0.5982\n",
            "Epoch 58/100, Loss: 64.3423, Validation Accuracy: 0.6500\n",
            "Epoch 59/100, Loss: 32.6086, Validation Accuracy: 0.5204\n",
            "Epoch 60/100, Loss: 13.4654, Validation Accuracy: 0.6042\n",
            "Epoch 61/100, Loss: 9.9055, Validation Accuracy: 0.5763\n",
            "Epoch 62/100, Loss: 25.3474, Validation Accuracy: 0.6500\n",
            "Epoch 63/100, Loss: 29.2346, Validation Accuracy: 0.5803\n",
            "Epoch 64/100, Loss: 58.6778, Validation Accuracy: 0.6181\n",
            "Epoch 65/100, Loss: 67.2843, Validation Accuracy: 0.6102\n",
            "Epoch 66/100, Loss: 17.9980, Validation Accuracy: 0.6122\n",
            "Epoch 67/100, Loss: 15.8126, Validation Accuracy: 0.5563\n",
            "Epoch 68/100, Loss: 59.2263, Validation Accuracy: 0.5264\n",
            "Epoch 69/100, Loss: 24.7270, Validation Accuracy: 0.5663\n",
            "Epoch 70/100, Loss: 19.0049, Validation Accuracy: 0.5653\n",
            "Epoch 71/100, Loss: 7.9000, Validation Accuracy: 0.5793\n",
            "Epoch 72/100, Loss: 14.1902, Validation Accuracy: 0.6560\n",
            "Epoch 73/100, Loss: 70.9380, Validation Accuracy: 0.5573\n",
            "Epoch 74/100, Loss: 154.8458, Validation Accuracy: 0.6261\n",
            "Epoch 75/100, Loss: 17.3335, Validation Accuracy: 0.5045\n",
            "Epoch 76/100, Loss: 14.7775, Validation Accuracy: 0.6271\n",
            "Epoch 77/100, Loss: 63.3283, Validation Accuracy: 0.5872\n",
            "Epoch 78/100, Loss: 18.4699, Validation Accuracy: 0.6082\n",
            "Epoch 79/100, Loss: 43.6920, Validation Accuracy: 0.6181\n",
            "Epoch 80/100, Loss: 21.0603, Validation Accuracy: 0.5932\n",
            "Epoch 81/100, Loss: 35.0729, Validation Accuracy: 0.4965\n",
            "Epoch 82/100, Loss: 7.4686, Validation Accuracy: 0.5354\n",
            "Epoch 83/100, Loss: 89.2686, Validation Accuracy: 0.6082\n",
            "Epoch 84/100, Loss: 33.1417, Validation Accuracy: 0.4885\n",
            "Epoch 85/100, Loss: 19.2291, Validation Accuracy: 0.5105\n",
            "Epoch 86/100, Loss: 44.4732, Validation Accuracy: 0.5354\n",
            "Epoch 87/100, Loss: 31.3343, Validation Accuracy: 0.5972\n",
            "Epoch 88/100, Loss: 10.9893, Validation Accuracy: 0.6162\n",
            "Epoch 89/100, Loss: 57.8446, Validation Accuracy: 0.5703\n",
            "Epoch 90/100, Loss: 29.1176, Validation Accuracy: 0.3878\n",
            "Epoch 91/100, Loss: 28.1961, Validation Accuracy: 0.5803\n",
            "Epoch 92/100, Loss: 19.7577, Validation Accuracy: 0.5823\n",
            "Epoch 93/100, Loss: 38.0534, Validation Accuracy: 0.6431\n",
            "Epoch 94/100, Loss: 25.9863, Validation Accuracy: 0.4855\n",
            "Epoch 95/100, Loss: 89.0125, Validation Accuracy: 0.5523\n",
            "Epoch 96/100, Loss: 82.6155, Validation Accuracy: 0.6341\n",
            "Epoch 97/100, Loss: 28.7166, Validation Accuracy: 0.5773\n",
            "Epoch 98/100, Loss: 25.2089, Validation Accuracy: 0.6710\n",
            "Epoch 99/100, Loss: 22.4944, Validation Accuracy: 0.6092\n",
            "Epoch 100/100, Loss: 9.9326, Validation Accuracy: 0.6630\n",
            "Epoch 101/100, Loss: 33.2148, Validation Accuracy: 0.6640\n",
            "Epoch 102/100, Loss: 29.3096, Validation Accuracy: 0.6301\n",
            "Epoch 103/100, Loss: 18.9606, Validation Accuracy: 0.6002\n",
            "Epoch 104/100, Loss: 34.0550, Validation Accuracy: 0.5982\n",
            "Epoch 105/100, Loss: 16.3086, Validation Accuracy: 0.6321\n",
            "Epoch 106/100, Loss: 33.7860, Validation Accuracy: 0.6361\n",
            "Epoch 107/100, Loss: 35.9974, Validation Accuracy: 0.5852\n",
            "Epoch 108/100, Loss: 88.0385, Validation Accuracy: 0.6670\n",
            "Epoch 109/100, Loss: 60.1076, Validation Accuracy: 0.5623\n",
            "Epoch 110/100, Loss: 21.8223, Validation Accuracy: 0.6471\n",
            "Epoch 111/100, Loss: 12.9654, Validation Accuracy: 0.6142\n",
            "Epoch 112/100, Loss: 7.7445, Validation Accuracy: 0.5125\n",
            "Epoch 113/100, Loss: 36.8289, Validation Accuracy: 0.4626\n",
            "Epoch 114/100, Loss: 61.2506, Validation Accuracy: 0.6810\n",
            "Epoch 115/100, Loss: 11.5860, Validation Accuracy: 0.6032\n",
            "Epoch 116/100, Loss: 18.4393, Validation Accuracy: 0.5593\n",
            "Epoch 117/100, Loss: 28.3016, Validation Accuracy: 0.6171\n",
            "Epoch 118/100, Loss: 17.1474, Validation Accuracy: 0.6331\n",
            "Epoch 119/100, Loss: 6.1677, Validation Accuracy: 0.5633\n",
            "Epoch 120/100, Loss: 30.1962, Validation Accuracy: 0.5155\n",
            "Epoch 121/100, Loss: 59.9301, Validation Accuracy: 0.5643\n",
            "Epoch 122/100, Loss: 16.1881, Validation Accuracy: 0.5862\n",
            "Epoch 123/100, Loss: 50.9699, Validation Accuracy: 0.6152\n",
            "Epoch 124/100, Loss: 88.7304, Validation Accuracy: 0.4337\n",
            "Epoch 125/100, Loss: 75.3956, Validation Accuracy: 0.6670\n",
            "Epoch 126/100, Loss: 17.2216, Validation Accuracy: 0.6520\n",
            "Epoch 127/100, Loss: 25.3856, Validation Accuracy: 0.5892\n",
            "Epoch 128/100, Loss: 13.1215, Validation Accuracy: 0.5384\n",
            "Epoch 129/100, Loss: 8.6251, Validation Accuracy: 0.5573\n",
            "Epoch 130/100, Loss: 26.6064, Validation Accuracy: 0.5643\n",
            "Epoch 131/100, Loss: 59.2097, Validation Accuracy: 0.5294\n",
            "Epoch 132/100, Loss: 15.5568, Validation Accuracy: 0.6271\n",
            "Epoch 133/100, Loss: 13.9493, Validation Accuracy: 0.3699\n",
            "Epoch 134/100, Loss: 10.0977, Validation Accuracy: 0.4885\n",
            "Epoch 135/100, Loss: 30.8616, Validation Accuracy: 0.6401\n",
            "Epoch 136/100, Loss: 51.8066, Validation Accuracy: 0.5314\n",
            "Epoch 137/100, Loss: 30.3538, Validation Accuracy: 0.6461\n",
            "Epoch 138/100, Loss: 36.3538, Validation Accuracy: 0.4945\n",
            "Epoch 139/100, Loss: 27.4891, Validation Accuracy: 0.5693\n",
            "Epoch 140/100, Loss: 35.5136, Validation Accuracy: 0.5823\n",
            "Epoch 141/100, Loss: 28.2886, Validation Accuracy: 0.5593\n",
            "Epoch 142/100, Loss: 42.0419, Validation Accuracy: 0.6371\n",
            "Epoch 143/100, Loss: 14.7735, Validation Accuracy: 0.6152\n",
            "Epoch 144/100, Loss: 103.0248, Validation Accuracy: 0.5494\n",
            "Epoch 145/100, Loss: 74.5171, Validation Accuracy: 0.6500\n",
            "Epoch 146/100, Loss: 30.0185, Validation Accuracy: 0.5972\n",
            "Epoch 147/100, Loss: 7.4333, Validation Accuracy: 0.5813\n",
            "Epoch 148/100, Loss: 5.1191, Validation Accuracy: 0.5842\n",
            "Epoch 149/100, Loss: 17.4752, Validation Accuracy: 0.5783\n",
            "Epoch 150/100, Loss: 68.4424, Validation Accuracy: 0.4855\n",
            "Epoch 151/100, Loss: 24.2261, Validation Accuracy: 0.5743\n",
            "Epoch 152/100, Loss: 17.6532, Validation Accuracy: 0.6052\n",
            "Epoch 153/100, Loss: 28.1113, Validation Accuracy: 0.6371\n",
            "Epoch 154/100, Loss: 9.1937, Validation Accuracy: 0.4108\n",
            "Epoch 155/100, Loss: 12.6723, Validation Accuracy: 0.6132\n",
            "Epoch 156/100, Loss: 18.4001, Validation Accuracy: 0.6401\n",
            "Epoch 157/100, Loss: 49.3012, Validation Accuracy: 0.6640\n",
            "Epoch 158/100, Loss: 37.4518, Validation Accuracy: 0.5603\n",
            "Epoch 159/100, Loss: 21.8100, Validation Accuracy: 0.4676\n",
            "Epoch 160/100, Loss: 17.0233, Validation Accuracy: 0.5763\n",
            "Epoch 161/100, Loss: 66.8928, Validation Accuracy: 0.6381\n",
            "Epoch 162/100, Loss: 28.9194, Validation Accuracy: 0.5703\n",
            "Epoch 163/100, Loss: 22.0597, Validation Accuracy: 0.5284\n",
            "Epoch 164/100, Loss: 26.4822, Validation Accuracy: 0.4885\n",
            "Epoch 165/100, Loss: 39.6790, Validation Accuracy: 0.4646\n",
            "Epoch 166/100, Loss: 38.2576, Validation Accuracy: 0.5852\n",
            "Epoch 167/100, Loss: 17.0259, Validation Accuracy: 0.6620\n",
            "Epoch 168/100, Loss: 34.4868, Validation Accuracy: 0.4746\n",
            "Epoch 169/100, Loss: 29.6833, Validation Accuracy: 0.6790\n",
            "Epoch 170/100, Loss: 42.8551, Validation Accuracy: 0.5294\n",
            "Epoch 171/100, Loss: 76.3672, Validation Accuracy: 0.4736\n",
            "Epoch 172/100, Loss: 7.4907, Validation Accuracy: 0.6201\n",
            "Epoch 173/100, Loss: 17.1553, Validation Accuracy: 0.3968\n",
            "Epoch 174/100, Loss: 26.1811, Validation Accuracy: 0.6072\n",
            "Epoch 175/100, Loss: 26.9627, Validation Accuracy: 0.5842\n",
            "Epoch 176/100, Loss: 36.7766, Validation Accuracy: 0.6461\n",
            "Epoch 177/100, Loss: 28.4620, Validation Accuracy: 0.6231\n",
            "Epoch 178/100, Loss: 61.2710, Validation Accuracy: 0.5194\n",
            "Epoch 179/100, Loss: 85.6806, Validation Accuracy: 0.6291\n",
            "Epoch 180/100, Loss: 90.0346, Validation Accuracy: 0.5194\n",
            "Epoch 181/100, Loss: 54.8082, Validation Accuracy: 0.6112\n",
            "Epoch 182/100, Loss: 30.8071, Validation Accuracy: 0.5982\n",
            "Epoch 183/100, Loss: 47.8073, Validation Accuracy: 0.6730\n",
            "Epoch 184/100, Loss: 38.8484, Validation Accuracy: 0.5972\n",
            "Epoch 185/100, Loss: 15.8102, Validation Accuracy: 0.6800\n",
            "Epoch 186/100, Loss: 21.3019, Validation Accuracy: 0.6630\n",
            "Epoch 187/100, Loss: 17.0921, Validation Accuracy: 0.6590\n",
            "Epoch 188/100, Loss: 25.4220, Validation Accuracy: 0.5902\n",
            "Epoch 189/100, Loss: 39.5262, Validation Accuracy: 0.6331\n",
            "Epoch 190/100, Loss: 26.5145, Validation Accuracy: 0.6241\n",
            "Epoch 191/100, Loss: 45.2925, Validation Accuracy: 0.6361\n",
            "Epoch 192/100, Loss: 58.4048, Validation Accuracy: 0.4686\n",
            "Epoch 193/100, Loss: 69.6360, Validation Accuracy: 0.3659\n",
            "Epoch 194/100, Loss: 20.3996, Validation Accuracy: 0.5823\n",
            "Epoch 195/100, Loss: 39.6021, Validation Accuracy: 0.5862\n",
            "Epoch 196/100, Loss: 42.4597, Validation Accuracy: 0.4656\n",
            "Epoch 197/100, Loss: 32.2217, Validation Accuracy: 0.6301\n",
            "Epoch 198/100, Loss: 14.7312, Validation Accuracy: 0.5912\n",
            "Epoch 199/100, Loss: 138.6963, Validation Accuracy: 0.6590\n",
            "Epoch 200/100, Loss: 15.0446, Validation Accuracy: 0.6331\n",
            "Reward for Child Model: 0.2862210558013131\n",
            "Child_91:  {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, [2, 0, 1, 3, 0, 0, 1, 1, 0, 2, 3, 3, 0, 2, 2], 0.2862210558013131\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 48, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(48, 64, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(100, 24, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(172, 36, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=56448, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 36, 28, 28]             144\n",
            "       BatchNorm2d-2           [-1, 36, 28, 28]              72\n",
            "            Conv2d-3           [-1, 48, 24, 22]          60,528\n",
            "       BatchNorm2d-4           [-1, 48, 24, 22]              96\n",
            "              ReLU-5           [-1, 48, 24, 22]               0\n",
            "            Conv2d-6           [-1, 64, 24, 20]           9,280\n",
            "       BatchNorm2d-7           [-1, 64, 24, 20]             128\n",
            "              ReLU-8           [-1, 64, 24, 20]               0\n",
            "            Conv2d-9           [-1, 24, 22, 28]          16,824\n",
            "      BatchNorm2d-10           [-1, 24, 22, 28]              48\n",
            "             ReLU-11           [-1, 24, 22, 28]               0\n",
            "           Conv2d-12           [-1, 36, 22, 26]         130,068\n",
            "      BatchNorm2d-13           [-1, 36, 22, 26]              72\n",
            "             ReLU-14           [-1, 36, 22, 26]               0\n",
            "           Linear-15                    [-1, 7]         395,143\n",
            "================================================================\n",
            "Total params: 612,403\n",
            "Trainable params: 612,403\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.52\n",
            "Params size (MB): 2.34\n",
            "Estimated Total Size (MB): 4.87\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 3.3125, Validation Accuracy: 0.0937\n",
            "Epoch 2/100, Loss: 20.1337, Validation Accuracy: 0.5793\n",
            "Epoch 3/100, Loss: 20.6836, Validation Accuracy: 0.1854\n",
            "Epoch 4/100, Loss: 27.4401, Validation Accuracy: 0.6122\n",
            "Epoch 5/100, Loss: 17.8723, Validation Accuracy: 0.6510\n",
            "Epoch 6/100, Loss: 131.9798, Validation Accuracy: 0.4526\n",
            "Epoch 7/100, Loss: 29.7603, Validation Accuracy: 0.6590\n",
            "Epoch 8/100, Loss: 12.6357, Validation Accuracy: 0.6351\n",
            "Epoch 9/100, Loss: 8.3252, Validation Accuracy: 0.6590\n",
            "Epoch 10/100, Loss: 38.4018, Validation Accuracy: 0.3878\n",
            "Epoch 11/100, Loss: 33.1009, Validation Accuracy: 0.6690\n",
            "Epoch 12/100, Loss: 47.2907, Validation Accuracy: 0.4915\n",
            "Epoch 13/100, Loss: 24.8653, Validation Accuracy: 0.5224\n",
            "Epoch 14/100, Loss: 44.5656, Validation Accuracy: 0.5434\n",
            "Epoch 15/100, Loss: 28.2569, Validation Accuracy: 0.5633\n",
            "Epoch 16/100, Loss: 171.6294, Validation Accuracy: 0.6421\n",
            "Epoch 17/100, Loss: 9.8412, Validation Accuracy: 0.6301\n",
            "Epoch 18/100, Loss: 23.5528, Validation Accuracy: 0.5912\n",
            "Epoch 19/100, Loss: 20.4169, Validation Accuracy: 0.6341\n",
            "Epoch 20/100, Loss: 14.5133, Validation Accuracy: 0.6361\n",
            "Epoch 21/100, Loss: 67.3444, Validation Accuracy: 0.6600\n",
            "Epoch 22/100, Loss: 31.9194, Validation Accuracy: 0.4227\n",
            "Epoch 23/100, Loss: 57.8760, Validation Accuracy: 0.5813\n",
            "Epoch 24/100, Loss: 71.6697, Validation Accuracy: 0.5464\n",
            "Epoch 25/100, Loss: 29.9795, Validation Accuracy: 0.5085\n",
            "Epoch 26/100, Loss: 56.9474, Validation Accuracy: 0.6441\n",
            "Epoch 27/100, Loss: 49.0801, Validation Accuracy: 0.6530\n",
            "Epoch 28/100, Loss: 46.8648, Validation Accuracy: 0.5354\n",
            "Epoch 29/100, Loss: 10.8834, Validation Accuracy: 0.6092\n",
            "Epoch 30/100, Loss: 10.9214, Validation Accuracy: 0.6251\n",
            "Epoch 31/100, Loss: 115.0216, Validation Accuracy: 0.6351\n",
            "Epoch 32/100, Loss: 21.2693, Validation Accuracy: 0.3529\n",
            "Epoch 33/100, Loss: 40.1485, Validation Accuracy: 0.5224\n",
            "Epoch 34/100, Loss: 21.1844, Validation Accuracy: 0.5922\n",
            "Epoch 35/100, Loss: 28.9346, Validation Accuracy: 0.6461\n",
            "Epoch 36/100, Loss: 18.6962, Validation Accuracy: 0.6162\n",
            "Epoch 37/100, Loss: 66.3939, Validation Accuracy: 0.5753\n",
            "Epoch 38/100, Loss: 22.7877, Validation Accuracy: 0.4148\n",
            "Epoch 39/100, Loss: 19.3589, Validation Accuracy: 0.6620\n",
            "Epoch 40/100, Loss: 126.0023, Validation Accuracy: 0.6481\n",
            "Epoch 41/100, Loss: 18.5919, Validation Accuracy: 0.6122\n",
            "Epoch 42/100, Loss: 10.8993, Validation Accuracy: 0.5204\n",
            "Epoch 43/100, Loss: 27.7563, Validation Accuracy: 0.6421\n",
            "Epoch 44/100, Loss: 18.8661, Validation Accuracy: 0.6800\n",
            "Epoch 45/100, Loss: 39.6943, Validation Accuracy: 0.6510\n",
            "Epoch 46/100, Loss: 17.4103, Validation Accuracy: 0.6341\n",
            "Epoch 47/100, Loss: 35.4558, Validation Accuracy: 0.6770\n",
            "Epoch 48/100, Loss: 103.3533, Validation Accuracy: 0.5683\n",
            "Epoch 49/100, Loss: 48.6350, Validation Accuracy: 0.6241\n",
            "Epoch 50/100, Loss: 15.6345, Validation Accuracy: 0.6062\n",
            "Epoch 51/100, Loss: 11.0202, Validation Accuracy: 0.6201\n",
            "Epoch 52/100, Loss: 12.2805, Validation Accuracy: 0.6810\n",
            "Epoch 53/100, Loss: 22.1684, Validation Accuracy: 0.5623\n",
            "Epoch 54/100, Loss: 24.2983, Validation Accuracy: 0.5394\n",
            "Epoch 55/100, Loss: 59.3262, Validation Accuracy: 0.5683\n",
            "Epoch 56/100, Loss: 29.2508, Validation Accuracy: 0.6211\n",
            "Epoch 57/100, Loss: 20.1021, Validation Accuracy: 0.5683\n",
            "Epoch 58/100, Loss: 11.6416, Validation Accuracy: 0.6530\n",
            "Epoch 59/100, Loss: 22.9561, Validation Accuracy: 0.3729\n",
            "Epoch 60/100, Loss: 19.0224, Validation Accuracy: 0.6341\n",
            "Epoch 61/100, Loss: 25.6987, Validation Accuracy: 0.4955\n",
            "Epoch 62/100, Loss: 29.2798, Validation Accuracy: 0.6560\n",
            "Epoch 63/100, Loss: 64.4103, Validation Accuracy: 0.6630\n",
            "Epoch 64/100, Loss: 57.7738, Validation Accuracy: 0.4516\n",
            "Epoch 65/100, Loss: 38.8537, Validation Accuracy: 0.5892\n",
            "Epoch 66/100, Loss: 37.8997, Validation Accuracy: 0.4646\n",
            "Epoch 67/100, Loss: 24.7015, Validation Accuracy: 0.6750\n",
            "Epoch 68/100, Loss: 37.0147, Validation Accuracy: 0.6720\n",
            "Epoch 69/100, Loss: 38.2953, Validation Accuracy: 0.6471\n",
            "Epoch 70/100, Loss: 23.5492, Validation Accuracy: 0.4975\n",
            "Epoch 71/100, Loss: 56.8145, Validation Accuracy: 0.5932\n",
            "Epoch 72/100, Loss: 26.6570, Validation Accuracy: 0.6481\n",
            "Epoch 73/100, Loss: 129.2484, Validation Accuracy: 0.6122\n",
            "Epoch 74/100, Loss: 23.5812, Validation Accuracy: 0.5693\n",
            "Epoch 75/100, Loss: 19.6101, Validation Accuracy: 0.6341\n",
            "Epoch 76/100, Loss: 22.7319, Validation Accuracy: 0.6241\n",
            "Epoch 77/100, Loss: 35.0844, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 22.5492, Validation Accuracy: 0.6361\n",
            "Epoch 79/100, Loss: 35.2650, Validation Accuracy: 0.6251\n",
            "Epoch 80/100, Loss: 11.8990, Validation Accuracy: 0.5244\n",
            "Epoch 81/100, Loss: 25.3320, Validation Accuracy: 0.6600\n",
            "Epoch 82/100, Loss: 42.5734, Validation Accuracy: 0.4905\n",
            "Epoch 83/100, Loss: 28.1906, Validation Accuracy: 0.5374\n",
            "Epoch 84/100, Loss: 44.0470, Validation Accuracy: 0.5563\n",
            "Epoch 85/100, Loss: 77.7423, Validation Accuracy: 0.6730\n",
            "Epoch 86/100, Loss: 40.7619, Validation Accuracy: 0.6341\n",
            "Epoch 87/100, Loss: 52.8508, Validation Accuracy: 0.5593\n",
            "Epoch 88/100, Loss: 8.7275, Validation Accuracy: 0.5813\n",
            "Epoch 89/100, Loss: 17.7322, Validation Accuracy: 0.6869\n",
            "Epoch 90/100, Loss: 8.5773, Validation Accuracy: 0.6481\n",
            "Epoch 91/100, Loss: 22.5352, Validation Accuracy: 0.6670\n",
            "Epoch 92/100, Loss: 97.5996, Validation Accuracy: 0.5763\n",
            "Epoch 93/100, Loss: 32.9413, Validation Accuracy: 0.6859\n",
            "Epoch 94/100, Loss: 14.3999, Validation Accuracy: 0.5653\n",
            "Epoch 95/100, Loss: 17.0938, Validation Accuracy: 0.5872\n",
            "Epoch 96/100, Loss: 67.1995, Validation Accuracy: 0.6181\n",
            "Epoch 97/100, Loss: 34.2462, Validation Accuracy: 0.5155\n",
            "Epoch 98/100, Loss: 26.9581, Validation Accuracy: 0.3280\n",
            "Epoch 99/100, Loss: 90.3622, Validation Accuracy: 0.5414\n",
            "Epoch 100/100, Loss: 16.4404, Validation Accuracy: 0.6570\n",
            "Epoch 101/100, Loss: 18.6055, Validation Accuracy: 0.6700\n",
            "Epoch 102/100, Loss: 19.4420, Validation Accuracy: 0.6510\n",
            "Epoch 103/100, Loss: 35.7026, Validation Accuracy: 0.5593\n",
            "Epoch 104/100, Loss: 9.7477, Validation Accuracy: 0.5952\n",
            "Epoch 105/100, Loss: 18.3534, Validation Accuracy: 0.6500\n",
            "Epoch 106/100, Loss: 32.2055, Validation Accuracy: 0.6072\n",
            "Epoch 107/100, Loss: 21.5931, Validation Accuracy: 0.6481\n",
            "Epoch 108/100, Loss: 110.1256, Validation Accuracy: 0.2552\n",
            "Epoch 109/100, Loss: 38.3784, Validation Accuracy: 0.6760\n",
            "Epoch 110/100, Loss: 23.9742, Validation Accuracy: 0.6411\n",
            "Epoch 111/100, Loss: 26.7378, Validation Accuracy: 0.6032\n",
            "Epoch 112/100, Loss: 17.8359, Validation Accuracy: 0.5922\n",
            "Epoch 113/100, Loss: 28.2341, Validation Accuracy: 0.5533\n",
            "Epoch 114/100, Loss: 25.0309, Validation Accuracy: 0.5474\n",
            "Epoch 115/100, Loss: 25.8697, Validation Accuracy: 0.6640\n",
            "Epoch 116/100, Loss: 66.5686, Validation Accuracy: 0.5633\n",
            "Epoch 117/100, Loss: 30.0802, Validation Accuracy: 0.5972\n",
            "Epoch 118/100, Loss: 14.2798, Validation Accuracy: 0.6341\n",
            "Epoch 119/100, Loss: 25.5907, Validation Accuracy: 0.5324\n",
            "Epoch 120/100, Loss: 33.7896, Validation Accuracy: 0.5743\n",
            "Epoch 121/100, Loss: 41.3675, Validation Accuracy: 0.5633\n",
            "Epoch 122/100, Loss: 54.3711, Validation Accuracy: 0.6760\n",
            "Epoch 123/100, Loss: 26.1206, Validation Accuracy: 0.6331\n",
            "Epoch 124/100, Loss: 20.1442, Validation Accuracy: 0.5912\n",
            "Epoch 125/100, Loss: 33.4893, Validation Accuracy: 0.6760\n",
            "Epoch 126/100, Loss: 32.8216, Validation Accuracy: 0.5424\n",
            "Epoch 127/100, Loss: 11.2136, Validation Accuracy: 0.5434\n",
            "Epoch 128/100, Loss: 17.2912, Validation Accuracy: 0.6640\n",
            "Epoch 129/100, Loss: 50.2001, Validation Accuracy: 0.6032\n",
            "Epoch 130/100, Loss: 63.9968, Validation Accuracy: 0.6720\n",
            "Epoch 131/100, Loss: 82.9410, Validation Accuracy: 0.4766\n",
            "Epoch 132/100, Loss: 56.3684, Validation Accuracy: 0.5962\n",
            "Epoch 133/100, Loss: 22.6777, Validation Accuracy: 0.5932\n",
            "Epoch 134/100, Loss: 36.4615, Validation Accuracy: 0.6411\n",
            "Epoch 135/100, Loss: 15.0849, Validation Accuracy: 0.6191\n",
            "Epoch 136/100, Loss: 28.4873, Validation Accuracy: 0.6471\n",
            "Epoch 137/100, Loss: 64.0419, Validation Accuracy: 0.4028\n",
            "Epoch 138/100, Loss: 35.1411, Validation Accuracy: 0.6162\n",
            "Epoch 139/100, Loss: 20.7107, Validation Accuracy: 0.6211\n",
            "Epoch 140/100, Loss: 19.0234, Validation Accuracy: 0.6640\n",
            "Epoch 141/100, Loss: 42.2271, Validation Accuracy: 0.6451\n",
            "Epoch 142/100, Loss: 33.1892, Validation Accuracy: 0.5713\n",
            "Epoch 143/100, Loss: 44.2914, Validation Accuracy: 0.6122\n",
            "Epoch 144/100, Loss: 63.3041, Validation Accuracy: 0.4915\n",
            "Epoch 145/100, Loss: 162.0949, Validation Accuracy: 0.6112\n",
            "Epoch 146/100, Loss: 23.2279, Validation Accuracy: 0.6660\n",
            "Epoch 147/100, Loss: 47.2755, Validation Accuracy: 0.5174\n",
            "Epoch 148/100, Loss: 31.3456, Validation Accuracy: 0.5942\n",
            "Epoch 149/100, Loss: 60.0690, Validation Accuracy: 0.5892\n",
            "Epoch 150/100, Loss: 65.8975, Validation Accuracy: 0.5075\n",
            "Epoch 151/100, Loss: 44.7317, Validation Accuracy: 0.6849\n",
            "Epoch 152/100, Loss: 25.6536, Validation Accuracy: 0.6481\n",
            "Epoch 153/100, Loss: 35.6691, Validation Accuracy: 0.4915\n",
            "Epoch 154/100, Loss: 54.6461, Validation Accuracy: 0.5244\n",
            "Epoch 155/100, Loss: 12.7789, Validation Accuracy: 0.6441\n",
            "Epoch 156/100, Loss: 46.8025, Validation Accuracy: 0.6530\n",
            "Epoch 157/100, Loss: 102.4448, Validation Accuracy: 0.6301\n",
            "Epoch 158/100, Loss: 8.1464, Validation Accuracy: 0.6391\n",
            "Epoch 159/100, Loss: 24.5815, Validation Accuracy: 0.6142\n",
            "Epoch 160/100, Loss: 16.4951, Validation Accuracy: 0.5882\n",
            "Epoch 161/100, Loss: 10.4153, Validation Accuracy: 0.5503\n",
            "Epoch 162/100, Loss: 202.2845, Validation Accuracy: 0.4636\n",
            "Epoch 163/100, Loss: 51.4035, Validation Accuracy: 0.6431\n",
            "Epoch 164/100, Loss: 27.1746, Validation Accuracy: 0.5603\n",
            "Epoch 165/100, Loss: 41.0301, Validation Accuracy: 0.6520\n",
            "Epoch 166/100, Loss: 25.6324, Validation Accuracy: 0.3360\n",
            "Epoch 167/100, Loss: 95.0662, Validation Accuracy: 0.6431\n",
            "Epoch 168/100, Loss: 42.3106, Validation Accuracy: 0.5982\n",
            "Epoch 169/100, Loss: 198.4784, Validation Accuracy: 0.4826\n",
            "Epoch 170/100, Loss: 17.4068, Validation Accuracy: 0.6481\n",
            "Epoch 171/100, Loss: 39.3909, Validation Accuracy: 0.5842\n",
            "Epoch 172/100, Loss: 4.9403, Validation Accuracy: 0.6750\n",
            "Epoch 173/100, Loss: 27.6299, Validation Accuracy: 0.6152\n",
            "Epoch 174/100, Loss: 58.0084, Validation Accuracy: 0.3111\n",
            "Epoch 175/100, Loss: 38.9225, Validation Accuracy: 0.6211\n",
            "Epoch 176/100, Loss: 81.0360, Validation Accuracy: 0.4267\n",
            "Epoch 177/100, Loss: 11.9089, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 16.4304, Validation Accuracy: 0.6281\n",
            "Epoch 179/100, Loss: 36.0458, Validation Accuracy: 0.6241\n",
            "Epoch 180/100, Loss: 127.9841, Validation Accuracy: 0.6590\n",
            "Epoch 181/100, Loss: 35.4261, Validation Accuracy: 0.6411\n",
            "Epoch 182/100, Loss: 15.8171, Validation Accuracy: 0.6341\n",
            "Epoch 183/100, Loss: 22.0736, Validation Accuracy: 0.5663\n",
            "Epoch 184/100, Loss: 41.1678, Validation Accuracy: 0.5513\n",
            "Epoch 185/100, Loss: 59.1677, Validation Accuracy: 0.6092\n",
            "Epoch 186/100, Loss: 29.9948, Validation Accuracy: 0.4417\n",
            "Epoch 187/100, Loss: 25.0601, Validation Accuracy: 0.6231\n",
            "Epoch 188/100, Loss: 77.8838, Validation Accuracy: 0.2832\n",
            "Epoch 189/100, Loss: 44.8482, Validation Accuracy: 0.5573\n",
            "Epoch 190/100, Loss: 72.6010, Validation Accuracy: 0.6461\n",
            "Epoch 191/100, Loss: 36.0171, Validation Accuracy: 0.6510\n",
            "Epoch 192/100, Loss: 18.1306, Validation Accuracy: 0.5743\n",
            "Epoch 193/100, Loss: 20.5629, Validation Accuracy: 0.6700\n",
            "Epoch 194/100, Loss: 20.6931, Validation Accuracy: 0.3639\n",
            "Epoch 195/100, Loss: 71.7851, Validation Accuracy: 0.6530\n",
            "Epoch 196/100, Loss: 42.5658, Validation Accuracy: 0.6291\n",
            "Epoch 197/100, Loss: 12.0146, Validation Accuracy: 0.6221\n",
            "Epoch 198/100, Loss: 11.5072, Validation Accuracy: 0.4766\n",
            "Epoch 199/100, Loss: 46.9683, Validation Accuracy: 0.6381\n",
            "Epoch 200/100, Loss: 59.6264, Validation Accuracy: 0.6281\n",
            "Reward for Child Model: 0.25979878931429257\n",
            "Child_92:  {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, [0, 0, 1, 2, 3, 2, 0, 1, 3, 3, 0, 0, 3, 1, 1], 0.25979878931429257\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 36, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 48, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(108, 64, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(124, 36, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=221312, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 28, 26]             240\n",
            "       BatchNorm2d-2           [-1, 24, 28, 26]              48\n",
            "            Conv2d-3           [-1, 36, 22, 26]           6,084\n",
            "       BatchNorm2d-4           [-1, 36, 22, 26]              72\n",
            "              ReLU-5           [-1, 36, 22, 26]               0\n",
            "            Conv2d-6           [-1, 48, 18, 20]          60,528\n",
            "       BatchNorm2d-7           [-1, 48, 18, 20]              96\n",
            "              ReLU-8           [-1, 48, 18, 20]               0\n",
            "            Conv2d-9           [-1, 64, 26, 20]         145,216\n",
            "      BatchNorm2d-10           [-1, 64, 26, 20]             128\n",
            "             ReLU-11           [-1, 64, 26, 20]               0\n",
            "           Conv2d-12           [-1, 36, 22, 24]          93,780\n",
            "      BatchNorm2d-13           [-1, 36, 22, 24]              72\n",
            "             ReLU-14           [-1, 36, 22, 24]               0\n",
            "           Linear-15                    [-1, 7]       1,549,191\n",
            "================================================================\n",
            "Total params: 1,855,455\n",
            "Trainable params: 1,855,455\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.33\n",
            "Params size (MB): 7.08\n",
            "Estimated Total Size (MB): 9.42\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 26.3848, Validation Accuracy: 0.4377\n",
            "Epoch 2/100, Loss: 126.3843, Validation Accuracy: 0.6431\n",
            "Epoch 3/100, Loss: 207.0473, Validation Accuracy: 0.6221\n",
            "Epoch 4/100, Loss: 98.4355, Validation Accuracy: 0.3061\n",
            "Epoch 5/100, Loss: 153.0103, Validation Accuracy: 0.3180\n",
            "Epoch 6/100, Loss: 22.9594, Validation Accuracy: 0.3091\n",
            "Epoch 7/100, Loss: 4.5198, Validation Accuracy: 0.4845\n",
            "Epoch 8/100, Loss: 107.0585, Validation Accuracy: 0.5194\n",
            "Epoch 9/100, Loss: 311.5330, Validation Accuracy: 0.5553\n",
            "Epoch 10/100, Loss: 37.9882, Validation Accuracy: 0.2692\n",
            "Epoch 11/100, Loss: 79.1786, Validation Accuracy: 0.5922\n",
            "Epoch 12/100, Loss: 20.4085, Validation Accuracy: 0.5823\n",
            "Epoch 13/100, Loss: 37.3925, Validation Accuracy: 0.6570\n",
            "Epoch 14/100, Loss: 8.5711, Validation Accuracy: 0.6171\n",
            "Epoch 15/100, Loss: 86.1833, Validation Accuracy: 0.6630\n",
            "Epoch 16/100, Loss: 19.2378, Validation Accuracy: 0.5603\n",
            "Epoch 17/100, Loss: 70.4754, Validation Accuracy: 0.5484\n",
            "Epoch 18/100, Loss: 74.8953, Validation Accuracy: 0.4885\n",
            "Epoch 19/100, Loss: 9.2058, Validation Accuracy: 0.6770\n",
            "Epoch 20/100, Loss: 9.7837, Validation Accuracy: 0.5763\n",
            "Epoch 21/100, Loss: 11.5411, Validation Accuracy: 0.6461\n",
            "Epoch 22/100, Loss: 160.9257, Validation Accuracy: 0.4895\n",
            "Epoch 23/100, Loss: 11.1180, Validation Accuracy: 0.6471\n",
            "Epoch 24/100, Loss: 51.6494, Validation Accuracy: 0.5165\n",
            "Epoch 25/100, Loss: 183.9197, Validation Accuracy: 0.5354\n",
            "Epoch 26/100, Loss: 22.4334, Validation Accuracy: 0.5374\n",
            "Epoch 27/100, Loss: 7.8189, Validation Accuracy: 0.4756\n",
            "Epoch 28/100, Loss: 371.3285, Validation Accuracy: 0.6042\n",
            "Epoch 29/100, Loss: 559.1194, Validation Accuracy: 0.6102\n",
            "Epoch 30/100, Loss: 34.9013, Validation Accuracy: 0.6062\n",
            "Epoch 31/100, Loss: 12.3857, Validation Accuracy: 0.5842\n",
            "Epoch 32/100, Loss: 48.7644, Validation Accuracy: 0.6630\n",
            "Epoch 33/100, Loss: 27.9916, Validation Accuracy: 0.6421\n",
            "Epoch 34/100, Loss: 10.9261, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 11.1576, Validation Accuracy: 0.6162\n",
            "Epoch 36/100, Loss: 12.9282, Validation Accuracy: 0.6261\n",
            "Epoch 37/100, Loss: 114.2269, Validation Accuracy: 0.6461\n",
            "Epoch 38/100, Loss: 218.5876, Validation Accuracy: 0.5474\n",
            "Epoch 39/100, Loss: 42.5781, Validation Accuracy: 0.6251\n",
            "Epoch 40/100, Loss: 31.2249, Validation Accuracy: 0.6261\n",
            "Epoch 41/100, Loss: 60.6526, Validation Accuracy: 0.5972\n",
            "Epoch 42/100, Loss: 20.1572, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 7.8356, Validation Accuracy: 0.5394\n",
            "Epoch 44/100, Loss: 2.6690, Validation Accuracy: 0.6251\n",
            "Epoch 45/100, Loss: 12.1669, Validation Accuracy: 0.4626\n",
            "Epoch 46/100, Loss: 26.1570, Validation Accuracy: 0.6800\n",
            "Epoch 47/100, Loss: 13.3105, Validation Accuracy: 0.5553\n",
            "Epoch 48/100, Loss: 25.0944, Validation Accuracy: 0.6032\n",
            "Epoch 49/100, Loss: 31.1177, Validation Accuracy: 0.6540\n",
            "Epoch 50/100, Loss: 67.2007, Validation Accuracy: 0.5823\n",
            "Epoch 51/100, Loss: 247.2719, Validation Accuracy: 0.4506\n",
            "Epoch 52/100, Loss: 18.3439, Validation Accuracy: 0.6471\n",
            "Epoch 53/100, Loss: 17.5626, Validation Accuracy: 0.6142\n",
            "Epoch 54/100, Loss: 8.3544, Validation Accuracy: 0.6082\n",
            "Epoch 55/100, Loss: 836.6159, Validation Accuracy: 0.5803\n",
            "Epoch 56/100, Loss: 71.0105, Validation Accuracy: 0.5474\n",
            "Epoch 57/100, Loss: 67.4067, Validation Accuracy: 0.5783\n",
            "Epoch 58/100, Loss: 14.5604, Validation Accuracy: 0.3051\n",
            "Epoch 59/100, Loss: 89.0089, Validation Accuracy: 0.5803\n",
            "Epoch 60/100, Loss: 3.7037, Validation Accuracy: 0.5513\n",
            "Epoch 61/100, Loss: 6846.7056, Validation Accuracy: 0.1107\n",
            "Epoch 62/100, Loss: 636.1033, Validation Accuracy: 0.6241\n",
            "Epoch 63/100, Loss: 354.1590, Validation Accuracy: 0.5713\n",
            "Epoch 64/100, Loss: 120.7147, Validation Accuracy: 0.6580\n",
            "Epoch 65/100, Loss: 65.3858, Validation Accuracy: 0.5713\n",
            "Epoch 66/100, Loss: 25.4120, Validation Accuracy: 0.6042\n",
            "Epoch 67/100, Loss: 16.9351, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 11.7293, Validation Accuracy: 0.6391\n",
            "Epoch 69/100, Loss: 6.6421, Validation Accuracy: 0.6530\n",
            "Epoch 70/100, Loss: 10.5121, Validation Accuracy: 0.6491\n",
            "Epoch 71/100, Loss: 6.9814, Validation Accuracy: 0.6630\n",
            "Epoch 72/100, Loss: 8.5112, Validation Accuracy: 0.6919\n",
            "Epoch 73/100, Loss: 10.1981, Validation Accuracy: 0.5623\n",
            "Epoch 74/100, Loss: 8.4633, Validation Accuracy: 0.5733\n",
            "Epoch 75/100, Loss: 56.1595, Validation Accuracy: 0.5912\n",
            "Epoch 76/100, Loss: 10.3404, Validation Accuracy: 0.6929\n",
            "Epoch 77/100, Loss: 12.3854, Validation Accuracy: 0.6740\n",
            "Epoch 78/100, Loss: 35.2031, Validation Accuracy: 0.6620\n",
            "Epoch 79/100, Loss: 9.0633, Validation Accuracy: 0.6221\n",
            "Epoch 80/100, Loss: 205.7762, Validation Accuracy: 0.4666\n",
            "Epoch 81/100, Loss: 15.9540, Validation Accuracy: 0.6281\n",
            "Epoch 82/100, Loss: 15.6438, Validation Accuracy: 0.6441\n",
            "Epoch 83/100, Loss: 18.1900, Validation Accuracy: 0.6251\n",
            "Epoch 84/100, Loss: 9.4513, Validation Accuracy: 0.5563\n",
            "Epoch 85/100, Loss: 11.9494, Validation Accuracy: 0.5404\n",
            "Epoch 86/100, Loss: 83.4486, Validation Accuracy: 0.6351\n",
            "Epoch 87/100, Loss: 36.2587, Validation Accuracy: 0.4397\n",
            "Epoch 88/100, Loss: 43.9109, Validation Accuracy: 0.6620\n",
            "Epoch 89/100, Loss: 19.1828, Validation Accuracy: 0.4437\n",
            "Epoch 90/100, Loss: 11.8012, Validation Accuracy: 0.5613\n",
            "Epoch 91/100, Loss: 31.7362, Validation Accuracy: 0.5803\n",
            "Epoch 92/100, Loss: 73.8650, Validation Accuracy: 0.6730\n",
            "Epoch 93/100, Loss: 37.3685, Validation Accuracy: 0.6790\n",
            "Epoch 94/100, Loss: 30.9666, Validation Accuracy: 0.6550\n",
            "Epoch 95/100, Loss: 22.2872, Validation Accuracy: 0.5693\n",
            "Epoch 96/100, Loss: 11.9566, Validation Accuracy: 0.5105\n",
            "Epoch 97/100, Loss: 41.7480, Validation Accuracy: 0.6610\n",
            "Epoch 98/100, Loss: 85.6589, Validation Accuracy: 0.6301\n",
            "Epoch 99/100, Loss: 19.7466, Validation Accuracy: 0.5992\n",
            "Epoch 100/100, Loss: 13.9888, Validation Accuracy: 0.6471\n",
            "Epoch 101/100, Loss: 24.9515, Validation Accuracy: 0.6530\n",
            "Epoch 102/100, Loss: 9.1554, Validation Accuracy: 0.6082\n",
            "Epoch 103/100, Loss: 75.4501, Validation Accuracy: 0.5414\n",
            "Epoch 104/100, Loss: 13.2122, Validation Accuracy: 0.6211\n",
            "Epoch 105/100, Loss: 26.2224, Validation Accuracy: 0.6002\n",
            "Epoch 106/100, Loss: 53.4935, Validation Accuracy: 0.6540\n",
            "Epoch 107/100, Loss: 57.6336, Validation Accuracy: 0.5743\n",
            "Epoch 108/100, Loss: 36.2399, Validation Accuracy: 0.6849\n",
            "Epoch 109/100, Loss: 36.0415, Validation Accuracy: 0.5882\n",
            "Epoch 110/100, Loss: 28.0919, Validation Accuracy: 0.6820\n",
            "Epoch 111/100, Loss: 52.7077, Validation Accuracy: 0.5474\n",
            "Epoch 112/100, Loss: 21.5109, Validation Accuracy: 0.6650\n",
            "Epoch 113/100, Loss: 31.1326, Validation Accuracy: 0.1954\n",
            "Epoch 114/100, Loss: 51.8796, Validation Accuracy: 0.5603\n",
            "Epoch 115/100, Loss: 31.2831, Validation Accuracy: 0.6122\n",
            "Epoch 116/100, Loss: 340.1867, Validation Accuracy: 0.6700\n",
            "Epoch 117/100, Loss: 60.8535, Validation Accuracy: 0.5583\n",
            "Epoch 118/100, Loss: 47.3712, Validation Accuracy: 0.5932\n",
            "Epoch 119/100, Loss: 44.6438, Validation Accuracy: 0.6471\n",
            "Epoch 120/100, Loss: 10.4951, Validation Accuracy: 0.6869\n",
            "Epoch 121/100, Loss: 26.3294, Validation Accuracy: 0.5444\n",
            "Epoch 122/100, Loss: 27.4087, Validation Accuracy: 0.5942\n",
            "Epoch 123/100, Loss: 165.7481, Validation Accuracy: 0.5384\n",
            "Epoch 124/100, Loss: 14.4231, Validation Accuracy: 0.6152\n",
            "Epoch 125/100, Loss: 7.1039, Validation Accuracy: 0.6879\n",
            "Epoch 126/100, Loss: 38.1645, Validation Accuracy: 0.5254\n",
            "Epoch 127/100, Loss: 16.7818, Validation Accuracy: 0.6979\n",
            "Epoch 128/100, Loss: 18.2161, Validation Accuracy: 0.4905\n",
            "Epoch 129/100, Loss: 5.7702, Validation Accuracy: 0.6790\n",
            "Epoch 130/100, Loss: 8.9055, Validation Accuracy: 0.6600\n",
            "Epoch 131/100, Loss: 18.4512, Validation Accuracy: 0.4885\n",
            "Epoch 132/100, Loss: 2752.0703, Validation Accuracy: 0.6361\n",
            "Epoch 133/100, Loss: 1153.6189, Validation Accuracy: 0.5523\n",
            "Epoch 134/100, Loss: 559.9602, Validation Accuracy: 0.6311\n",
            "Epoch 135/100, Loss: 646.0068, Validation Accuracy: 0.5523\n",
            "Epoch 136/100, Loss: 199.9351, Validation Accuracy: 0.6461\n",
            "Epoch 137/100, Loss: 291.4755, Validation Accuracy: 0.5573\n",
            "Epoch 138/100, Loss: 225.2643, Validation Accuracy: 0.6750\n",
            "Epoch 139/100, Loss: 96.9581, Validation Accuracy: 0.6311\n",
            "Epoch 140/100, Loss: 113.3306, Validation Accuracy: 0.5773\n",
            "Epoch 141/100, Loss: 37.3092, Validation Accuracy: 0.6381\n",
            "Epoch 142/100, Loss: 27.2654, Validation Accuracy: 0.6590\n",
            "Epoch 143/100, Loss: 16.5679, Validation Accuracy: 0.5444\n",
            "Epoch 144/100, Loss: 24.4906, Validation Accuracy: 0.5464\n",
            "Epoch 145/100, Loss: 14.8751, Validation Accuracy: 0.5813\n",
            "Epoch 146/100, Loss: 19.7285, Validation Accuracy: 0.5902\n",
            "Epoch 147/100, Loss: 15.5683, Validation Accuracy: 0.6082\n",
            "Epoch 148/100, Loss: 21.3653, Validation Accuracy: 0.6570\n",
            "Epoch 149/100, Loss: 18.1216, Validation Accuracy: 0.6321\n",
            "Epoch 150/100, Loss: 12.2329, Validation Accuracy: 0.6241\n",
            "Epoch 151/100, Loss: 18.4978, Validation Accuracy: 0.5703\n",
            "Epoch 152/100, Loss: 53.7833, Validation Accuracy: 0.6092\n",
            "Epoch 153/100, Loss: 6.8973, Validation Accuracy: 0.6471\n",
            "Epoch 154/100, Loss: 183.9614, Validation Accuracy: 0.6491\n",
            "Epoch 155/100, Loss: 30.7151, Validation Accuracy: 0.6002\n",
            "Epoch 156/100, Loss: 18.2742, Validation Accuracy: 0.5394\n",
            "Epoch 157/100, Loss: 14.7067, Validation Accuracy: 0.5045\n",
            "Epoch 158/100, Loss: 11.4321, Validation Accuracy: 0.6082\n",
            "Epoch 159/100, Loss: 7.2644, Validation Accuracy: 0.5304\n",
            "Epoch 160/100, Loss: 20.3730, Validation Accuracy: 0.6331\n",
            "Epoch 161/100, Loss: 4.8107, Validation Accuracy: 0.6650\n",
            "Epoch 162/100, Loss: 48.9180, Validation Accuracy: 0.5593\n",
            "Epoch 163/100, Loss: 47.3948, Validation Accuracy: 0.5942\n",
            "Epoch 164/100, Loss: 22.1253, Validation Accuracy: 0.6780\n",
            "Epoch 165/100, Loss: 23.7729, Validation Accuracy: 0.4636\n",
            "Epoch 166/100, Loss: 85.1299, Validation Accuracy: 0.6411\n",
            "Epoch 167/100, Loss: 15.2244, Validation Accuracy: 0.5414\n",
            "Epoch 168/100, Loss: 12.5797, Validation Accuracy: 0.6311\n",
            "Epoch 169/100, Loss: 39.8695, Validation Accuracy: 0.4457\n",
            "Epoch 170/100, Loss: 46.9851, Validation Accuracy: 0.4835\n",
            "Epoch 171/100, Loss: 197.9622, Validation Accuracy: 0.4397\n",
            "Epoch 172/100, Loss: 50.4707, Validation Accuracy: 0.5753\n",
            "Epoch 173/100, Loss: 29.0880, Validation Accuracy: 0.5872\n",
            "Epoch 174/100, Loss: 32.8879, Validation Accuracy: 0.5842\n",
            "Epoch 175/100, Loss: 10.6080, Validation Accuracy: 0.6361\n",
            "Epoch 176/100, Loss: 63.7430, Validation Accuracy: 0.6760\n",
            "Epoch 177/100, Loss: 172.0120, Validation Accuracy: 0.5962\n",
            "Epoch 178/100, Loss: 16.1635, Validation Accuracy: 0.5155\n",
            "Epoch 179/100, Loss: 45.8697, Validation Accuracy: 0.4377\n",
            "Epoch 180/100, Loss: 129.3165, Validation Accuracy: 0.6740\n",
            "Epoch 181/100, Loss: 39.0645, Validation Accuracy: 0.5444\n",
            "Epoch 182/100, Loss: 18.7795, Validation Accuracy: 0.5703\n",
            "Epoch 183/100, Loss: 36.2266, Validation Accuracy: 0.6181\n",
            "Epoch 184/100, Loss: 21.1865, Validation Accuracy: 0.6082\n",
            "Epoch 185/100, Loss: 53.8288, Validation Accuracy: 0.5324\n",
            "Epoch 186/100, Loss: 71.6624, Validation Accuracy: 0.6181\n",
            "Epoch 187/100, Loss: 20.9985, Validation Accuracy: 0.5922\n",
            "Epoch 188/100, Loss: 25.9155, Validation Accuracy: 0.6251\n",
            "Epoch 189/100, Loss: 14.9122, Validation Accuracy: 0.6281\n",
            "Epoch 190/100, Loss: 15.7080, Validation Accuracy: 0.6142\n",
            "Epoch 191/100, Loss: 17.1518, Validation Accuracy: 0.4118\n",
            "Epoch 192/100, Loss: 54.6658, Validation Accuracy: 0.6261\n",
            "Epoch 193/100, Loss: 90.2818, Validation Accuracy: 0.4666\n",
            "Epoch 194/100, Loss: 32.0309, Validation Accuracy: 0.6491\n",
            "Epoch 195/100, Loss: 26.2288, Validation Accuracy: 0.3998\n",
            "Epoch 196/100, Loss: 19.7530, Validation Accuracy: 0.5962\n",
            "Epoch 197/100, Loss: 179.4617, Validation Accuracy: 0.6889\n",
            "Epoch 198/100, Loss: 35.7386, Validation Accuracy: 0.5155\n",
            "Epoch 199/100, Loss: 17.2901, Validation Accuracy: 0.5055\n",
            "Epoch 200/100, Loss: 8.2907, Validation Accuracy: 0.6451\n",
            "Reward for Child Model: 0.32698764470260316\n",
            "Child_93:  {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, [0, 1, 0, 3, 0, 1, 2, 3, 2, 1, 3, 3, 3, 1, 1], 0.32698764470260316\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 64, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(128, 24, kernel_size=(3, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(88, 36, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(316, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=78848, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 22, 28]           1,408\n",
            "       BatchNorm2d-2           [-1, 64, 22, 28]             128\n",
            "            Conv2d-3           [-1, 64, 16, 26]          86,080\n",
            "       BatchNorm2d-4           [-1, 64, 16, 26]             128\n",
            "              ReLU-5           [-1, 64, 16, 26]               0\n",
            "            Conv2d-6           [-1, 24, 20, 22]          64,536\n",
            "       BatchNorm2d-7           [-1, 24, 20, 22]              48\n",
            "              ReLU-8           [-1, 24, 20, 22]               0\n",
            "            Conv2d-9           [-1, 36, 16, 26]          66,564\n",
            "      BatchNorm2d-10           [-1, 36, 16, 26]              72\n",
            "             ReLU-11           [-1, 36, 16, 26]               0\n",
            "           Conv2d-12           [-1, 64, 20, 26]         182,080\n",
            "      BatchNorm2d-13           [-1, 64, 20, 26]             128\n",
            "             ReLU-14           [-1, 64, 20, 26]               0\n",
            "           Linear-15                    [-1, 7]         551,943\n",
            "================================================================\n",
            "Total params: 953,115\n",
            "Trainable params: 953,115\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.56\n",
            "Params size (MB): 3.64\n",
            "Estimated Total Size (MB): 6.20\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 19.4784, Validation Accuracy: 0.6510\n",
            "Epoch 2/100, Loss: 20.9211, Validation Accuracy: 0.6700\n",
            "Epoch 3/100, Loss: 19.2247, Validation Accuracy: 0.6191\n",
            "Epoch 4/100, Loss: 29.9769, Validation Accuracy: 0.5194\n",
            "Epoch 5/100, Loss: 135.9857, Validation Accuracy: 0.6421\n",
            "Epoch 6/100, Loss: 35.3598, Validation Accuracy: 0.2203\n",
            "Epoch 7/100, Loss: 32.8318, Validation Accuracy: 0.6002\n",
            "Epoch 8/100, Loss: 89.7515, Validation Accuracy: 0.6620\n",
            "Epoch 9/100, Loss: 57.7313, Validation Accuracy: 0.6610\n",
            "Epoch 10/100, Loss: 26.5150, Validation Accuracy: 0.5484\n",
            "Epoch 11/100, Loss: 277.8553, Validation Accuracy: 0.5932\n",
            "Epoch 12/100, Loss: 81.4446, Validation Accuracy: 0.6670\n",
            "Epoch 13/100, Loss: 38.8597, Validation Accuracy: 0.5484\n",
            "Epoch 14/100, Loss: 46.6903, Validation Accuracy: 0.4865\n",
            "Epoch 15/100, Loss: 15.5357, Validation Accuracy: 0.6740\n",
            "Epoch 16/100, Loss: 44.6946, Validation Accuracy: 0.5773\n",
            "Epoch 17/100, Loss: 68.1705, Validation Accuracy: 0.4656\n",
            "Epoch 18/100, Loss: 29.0578, Validation Accuracy: 0.6082\n",
            "Epoch 19/100, Loss: 33.8767, Validation Accuracy: 0.6810\n",
            "Epoch 20/100, Loss: 37.3595, Validation Accuracy: 0.4646\n",
            "Epoch 21/100, Loss: 25.1317, Validation Accuracy: 0.6800\n",
            "Epoch 22/100, Loss: 74.4517, Validation Accuracy: 0.6022\n",
            "Epoch 23/100, Loss: 21.3604, Validation Accuracy: 0.5833\n",
            "Epoch 24/100, Loss: 37.0108, Validation Accuracy: 0.5264\n",
            "Epoch 25/100, Loss: 51.1591, Validation Accuracy: 0.6839\n",
            "Epoch 26/100, Loss: 28.3402, Validation Accuracy: 0.6441\n",
            "Epoch 27/100, Loss: 182.7165, Validation Accuracy: 0.6700\n",
            "Epoch 28/100, Loss: 114.3376, Validation Accuracy: 0.5773\n",
            "Epoch 29/100, Loss: 42.5199, Validation Accuracy: 0.6820\n",
            "Epoch 30/100, Loss: 152.2994, Validation Accuracy: 0.6471\n",
            "Epoch 31/100, Loss: 62.0309, Validation Accuracy: 0.6740\n",
            "Epoch 32/100, Loss: 128.0428, Validation Accuracy: 0.7059\n",
            "Epoch 33/100, Loss: 46.6938, Validation Accuracy: 0.6052\n",
            "Epoch 34/100, Loss: 86.9664, Validation Accuracy: 0.6640\n",
            "Epoch 35/100, Loss: 69.8808, Validation Accuracy: 0.5603\n",
            "Epoch 36/100, Loss: 50.5898, Validation Accuracy: 0.6451\n",
            "Epoch 37/100, Loss: 43.5702, Validation Accuracy: 0.5623\n",
            "Epoch 38/100, Loss: 18.0936, Validation Accuracy: 0.6830\n",
            "Epoch 39/100, Loss: 68.6889, Validation Accuracy: 0.5992\n",
            "Epoch 40/100, Loss: 23.8421, Validation Accuracy: 0.4905\n",
            "Epoch 41/100, Loss: 64.9158, Validation Accuracy: 0.5304\n",
            "Epoch 42/100, Loss: 40.6431, Validation Accuracy: 0.6780\n",
            "Epoch 43/100, Loss: 83.9172, Validation Accuracy: 0.5414\n",
            "Epoch 44/100, Loss: 53.7126, Validation Accuracy: 0.5693\n",
            "Epoch 45/100, Loss: 71.6806, Validation Accuracy: 0.6082\n",
            "Epoch 46/100, Loss: 48.7369, Validation Accuracy: 0.6002\n",
            "Epoch 47/100, Loss: 89.3221, Validation Accuracy: 0.6869\n",
            "Epoch 48/100, Loss: 40.9506, Validation Accuracy: 0.6311\n",
            "Epoch 49/100, Loss: 36.4165, Validation Accuracy: 0.6750\n",
            "Epoch 50/100, Loss: 75.2862, Validation Accuracy: 0.6540\n",
            "Epoch 51/100, Loss: 113.0831, Validation Accuracy: 0.5962\n",
            "Epoch 52/100, Loss: 39.9545, Validation Accuracy: 0.6560\n",
            "Epoch 53/100, Loss: 48.7385, Validation Accuracy: 0.6580\n",
            "Epoch 54/100, Loss: 47.8867, Validation Accuracy: 0.5015\n",
            "Epoch 55/100, Loss: 29.7034, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 54.6263, Validation Accuracy: 0.5952\n",
            "Epoch 57/100, Loss: 59.9757, Validation Accuracy: 0.6381\n",
            "Epoch 58/100, Loss: 64.1264, Validation Accuracy: 0.5434\n",
            "Epoch 59/100, Loss: 75.2079, Validation Accuracy: 0.6481\n",
            "Epoch 60/100, Loss: 52.5410, Validation Accuracy: 0.6710\n",
            "Epoch 61/100, Loss: 64.4369, Validation Accuracy: 0.6371\n",
            "Epoch 62/100, Loss: 61.6612, Validation Accuracy: 0.6790\n",
            "Epoch 63/100, Loss: 91.5294, Validation Accuracy: 0.6092\n",
            "Epoch 64/100, Loss: 43.0154, Validation Accuracy: 0.6590\n",
            "Epoch 65/100, Loss: 46.5290, Validation Accuracy: 0.6221\n",
            "Epoch 66/100, Loss: 72.6312, Validation Accuracy: 0.6421\n",
            "Epoch 67/100, Loss: 38.7814, Validation Accuracy: 0.6012\n",
            "Epoch 68/100, Loss: 45.3475, Validation Accuracy: 0.6181\n",
            "Epoch 69/100, Loss: 34.7939, Validation Accuracy: 0.6879\n",
            "Epoch 70/100, Loss: 42.2811, Validation Accuracy: 0.6879\n",
            "Epoch 71/100, Loss: 51.8754, Validation Accuracy: 0.6321\n",
            "Epoch 72/100, Loss: 19.7031, Validation Accuracy: 0.6082\n",
            "Epoch 73/100, Loss: 30.9259, Validation Accuracy: 0.6919\n",
            "Epoch 74/100, Loss: 105.0799, Validation Accuracy: 0.6142\n",
            "Epoch 75/100, Loss: 80.8507, Validation Accuracy: 0.5882\n",
            "Epoch 76/100, Loss: 12.2902, Validation Accuracy: 0.6630\n",
            "Epoch 77/100, Loss: 66.5499, Validation Accuracy: 0.5733\n",
            "Epoch 78/100, Loss: 28.5563, Validation Accuracy: 0.6879\n",
            "Epoch 79/100, Loss: 33.5995, Validation Accuracy: 0.6481\n",
            "Epoch 80/100, Loss: 69.7657, Validation Accuracy: 0.5723\n",
            "Epoch 81/100, Loss: 72.9599, Validation Accuracy: 0.6919\n",
            "Epoch 82/100, Loss: 48.1135, Validation Accuracy: 0.6042\n",
            "Epoch 83/100, Loss: 52.9569, Validation Accuracy: 0.5613\n",
            "Epoch 84/100, Loss: 70.8615, Validation Accuracy: 0.6481\n",
            "Epoch 85/100, Loss: 37.6356, Validation Accuracy: 0.6869\n",
            "Epoch 86/100, Loss: 148.1163, Validation Accuracy: 0.6321\n",
            "Epoch 87/100, Loss: 131.3152, Validation Accuracy: 0.6022\n",
            "Epoch 88/100, Loss: 38.7999, Validation Accuracy: 0.4277\n",
            "Epoch 89/100, Loss: 23.9765, Validation Accuracy: 0.6820\n",
            "Epoch 90/100, Loss: 53.6833, Validation Accuracy: 0.6471\n",
            "Epoch 91/100, Loss: 18.5866, Validation Accuracy: 0.6889\n",
            "Epoch 92/100, Loss: 75.4647, Validation Accuracy: 0.6640\n",
            "Epoch 93/100, Loss: 47.3456, Validation Accuracy: 0.5434\n",
            "Epoch 94/100, Loss: 82.6481, Validation Accuracy: 0.6879\n",
            "Epoch 95/100, Loss: 68.2662, Validation Accuracy: 0.6839\n",
            "Epoch 96/100, Loss: 32.7398, Validation Accuracy: 0.6770\n",
            "Epoch 97/100, Loss: 41.2725, Validation Accuracy: 0.5364\n",
            "Epoch 98/100, Loss: 104.2127, Validation Accuracy: 0.6580\n",
            "Epoch 99/100, Loss: 67.4351, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 165.3536, Validation Accuracy: 0.5852\n",
            "Epoch 101/100, Loss: 72.9465, Validation Accuracy: 0.6959\n",
            "Epoch 102/100, Loss: 112.8684, Validation Accuracy: 0.5833\n",
            "Epoch 103/100, Loss: 35.4104, Validation Accuracy: 0.6171\n",
            "Epoch 104/100, Loss: 35.0945, Validation Accuracy: 0.6351\n",
            "Epoch 105/100, Loss: 35.3933, Validation Accuracy: 0.6790\n",
            "Epoch 106/100, Loss: 57.9995, Validation Accuracy: 0.5404\n",
            "Epoch 107/100, Loss: 65.0639, Validation Accuracy: 0.4855\n",
            "Epoch 108/100, Loss: 56.4849, Validation Accuracy: 0.6381\n",
            "Epoch 109/100, Loss: 28.2410, Validation Accuracy: 0.5952\n",
            "Epoch 110/100, Loss: 52.5217, Validation Accuracy: 0.6949\n",
            "Epoch 111/100, Loss: 100.1922, Validation Accuracy: 0.6999\n",
            "Epoch 112/100, Loss: 34.4338, Validation Accuracy: 0.4437\n",
            "Epoch 113/100, Loss: 108.2367, Validation Accuracy: 0.6640\n",
            "Epoch 114/100, Loss: 45.4018, Validation Accuracy: 0.6072\n",
            "Epoch 115/100, Loss: 33.1422, Validation Accuracy: 0.6122\n",
            "Epoch 116/100, Loss: 50.7960, Validation Accuracy: 0.6730\n",
            "Epoch 117/100, Loss: 59.8008, Validation Accuracy: 0.6800\n",
            "Epoch 118/100, Loss: 101.8661, Validation Accuracy: 0.6241\n",
            "Epoch 119/100, Loss: 32.0721, Validation Accuracy: 0.6401\n",
            "Epoch 120/100, Loss: 30.0246, Validation Accuracy: 0.6839\n",
            "Epoch 121/100, Loss: 25.8189, Validation Accuracy: 0.6301\n",
            "Epoch 122/100, Loss: 48.0317, Validation Accuracy: 0.6411\n",
            "Epoch 123/100, Loss: 37.4675, Validation Accuracy: 0.5623\n",
            "Epoch 124/100, Loss: 48.5936, Validation Accuracy: 0.5693\n",
            "Epoch 125/100, Loss: 45.9064, Validation Accuracy: 0.6331\n",
            "Epoch 126/100, Loss: 138.6912, Validation Accuracy: 0.6790\n",
            "Epoch 127/100, Loss: 110.8485, Validation Accuracy: 0.6271\n",
            "Epoch 128/100, Loss: 35.9635, Validation Accuracy: 0.6162\n",
            "Epoch 129/100, Loss: 39.2856, Validation Accuracy: 0.7019\n",
            "Epoch 130/100, Loss: 42.3740, Validation Accuracy: 0.5713\n",
            "Epoch 131/100, Loss: 46.4393, Validation Accuracy: 0.5733\n",
            "Epoch 132/100, Loss: 47.9458, Validation Accuracy: 0.6102\n",
            "Epoch 133/100, Loss: 100.2924, Validation Accuracy: 0.5882\n",
            "Epoch 134/100, Loss: 74.4063, Validation Accuracy: 0.6331\n",
            "Epoch 135/100, Loss: 48.4105, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 91.4928, Validation Accuracy: 0.6032\n",
            "Epoch 137/100, Loss: 49.0733, Validation Accuracy: 0.6999\n",
            "Epoch 138/100, Loss: 75.0881, Validation Accuracy: 0.6560\n",
            "Epoch 139/100, Loss: 29.4601, Validation Accuracy: 0.6321\n",
            "Epoch 140/100, Loss: 118.7470, Validation Accuracy: 0.6211\n",
            "Epoch 141/100, Loss: 43.1262, Validation Accuracy: 0.6879\n",
            "Epoch 142/100, Loss: 79.4107, Validation Accuracy: 0.6152\n",
            "Epoch 143/100, Loss: 85.0336, Validation Accuracy: 0.6351\n",
            "Epoch 144/100, Loss: 118.3252, Validation Accuracy: 0.5932\n",
            "Epoch 145/100, Loss: 52.4591, Validation Accuracy: 0.5623\n",
            "Epoch 146/100, Loss: 24.9158, Validation Accuracy: 0.7049\n",
            "Epoch 147/100, Loss: 89.9056, Validation Accuracy: 0.6032\n",
            "Epoch 148/100, Loss: 112.9540, Validation Accuracy: 0.6181\n",
            "Epoch 149/100, Loss: 23.8409, Validation Accuracy: 0.6211\n",
            "Epoch 150/100, Loss: 56.5984, Validation Accuracy: 0.6351\n",
            "Epoch 151/100, Loss: 78.6036, Validation Accuracy: 0.6191\n",
            "Epoch 152/100, Loss: 116.6252, Validation Accuracy: 0.6889\n",
            "Epoch 153/100, Loss: 46.0368, Validation Accuracy: 0.5852\n",
            "Epoch 154/100, Loss: 33.0880, Validation Accuracy: 0.6899\n",
            "Epoch 155/100, Loss: 28.3559, Validation Accuracy: 0.6361\n",
            "Epoch 156/100, Loss: 52.4088, Validation Accuracy: 0.6411\n",
            "Epoch 157/100, Loss: 50.4709, Validation Accuracy: 0.6421\n",
            "Epoch 158/100, Loss: 15.5396, Validation Accuracy: 0.6351\n",
            "Epoch 159/100, Loss: 76.7752, Validation Accuracy: 0.6570\n",
            "Epoch 160/100, Loss: 8.9562, Validation Accuracy: 0.6600\n",
            "Epoch 161/100, Loss: 56.3577, Validation Accuracy: 0.6969\n",
            "Epoch 162/100, Loss: 38.1593, Validation Accuracy: 0.6570\n",
            "Epoch 163/100, Loss: 21.7186, Validation Accuracy: 0.6610\n",
            "Epoch 164/100, Loss: 76.3589, Validation Accuracy: 0.6271\n",
            "Epoch 165/100, Loss: 41.0098, Validation Accuracy: 0.6510\n",
            "Epoch 166/100, Loss: 41.0577, Validation Accuracy: 0.6720\n",
            "Epoch 167/100, Loss: 43.5207, Validation Accuracy: 0.6032\n",
            "Epoch 168/100, Loss: 39.0727, Validation Accuracy: 0.6371\n",
            "Epoch 169/100, Loss: 69.5219, Validation Accuracy: 0.6072\n",
            "Epoch 170/100, Loss: 16.9231, Validation Accuracy: 0.6191\n",
            "Epoch 171/100, Loss: 84.9974, Validation Accuracy: 0.6082\n",
            "Epoch 172/100, Loss: 50.0982, Validation Accuracy: 0.6481\n",
            "Epoch 173/100, Loss: 63.1213, Validation Accuracy: 0.5543\n",
            "Epoch 174/100, Loss: 41.0678, Validation Accuracy: 0.6471\n",
            "Epoch 175/100, Loss: 35.4821, Validation Accuracy: 0.6500\n",
            "Epoch 176/100, Loss: 104.4233, Validation Accuracy: 0.6411\n",
            "Epoch 177/100, Loss: 53.2973, Validation Accuracy: 0.6580\n",
            "Epoch 178/100, Loss: 65.9253, Validation Accuracy: 0.6401\n",
            "Epoch 179/100, Loss: 25.4573, Validation Accuracy: 0.5603\n",
            "Epoch 180/100, Loss: 9.6269, Validation Accuracy: 0.6211\n",
            "Epoch 181/100, Loss: 64.9600, Validation Accuracy: 0.5962\n",
            "Epoch 182/100, Loss: 18.6177, Validation Accuracy: 0.6640\n",
            "Epoch 183/100, Loss: 100.1293, Validation Accuracy: 0.6321\n",
            "Epoch 184/100, Loss: 48.6257, Validation Accuracy: 0.6261\n",
            "Epoch 185/100, Loss: 53.3460, Validation Accuracy: 0.6889\n",
            "Epoch 186/100, Loss: 43.9007, Validation Accuracy: 0.6052\n",
            "Epoch 187/100, Loss: 32.4039, Validation Accuracy: 0.6830\n",
            "Epoch 188/100, Loss: 29.4491, Validation Accuracy: 0.6231\n",
            "Epoch 189/100, Loss: 75.6195, Validation Accuracy: 0.5833\n",
            "Epoch 190/100, Loss: 61.4615, Validation Accuracy: 0.6241\n",
            "Epoch 191/100, Loss: 21.5543, Validation Accuracy: 0.6241\n",
            "Epoch 192/100, Loss: 88.4006, Validation Accuracy: 0.5882\n",
            "Epoch 193/100, Loss: 52.1800, Validation Accuracy: 0.6391\n",
            "Epoch 194/100, Loss: 110.3225, Validation Accuracy: 0.6162\n",
            "Epoch 195/100, Loss: 65.4919, Validation Accuracy: 0.6092\n",
            "Epoch 196/100, Loss: 54.9148, Validation Accuracy: 0.6022\n",
            "Epoch 197/100, Loss: 40.5060, Validation Accuracy: 0.6550\n",
            "Epoch 198/100, Loss: 25.7001, Validation Accuracy: 0.5613\n",
            "Epoch 199/100, Loss: 66.8201, Validation Accuracy: 0.7159\n",
            "Epoch 200/100, Loss: 82.2660, Validation Accuracy: 0.6939\n",
            "Reward for Child Model: 0.36683480431689164\n",
            "Child_94:  {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, [3, 0, 3, 3, 1, 3, 1, 3, 0, 3, 1, 1, 1, 1, 3], 0.36683480431689164\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 48, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(48, 48, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(96, 24, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(120, 48, kernel_size=(3, 5), stride=(1, 1))\n",
            "  (12): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(144, 64, kernel_size=(1, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=144768, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 48, 24, 26]           2,208\n",
            "       BatchNorm2d-2           [-1, 48, 24, 26]              96\n",
            "            Conv2d-3           [-1, 48, 24, 24]           6,960\n",
            "       BatchNorm2d-4           [-1, 48, 24, 24]              96\n",
            "              ReLU-5           [-1, 48, 24, 24]               0\n",
            "            Conv2d-6           [-1, 24, 24, 20]          16,152\n",
            "       BatchNorm2d-7           [-1, 24, 24, 20]              48\n",
            "              ReLU-8           [-1, 24, 24, 20]               0\n",
            "            Conv2d-9           [-1, 48, 22, 22]          86,448\n",
            "      BatchNorm2d-10           [-1, 48, 22, 22]              96\n",
            "             ReLU-11           [-1, 48, 22, 22]               0\n",
            "           Conv2d-12           [-1, 64, 24, 24]          27,712\n",
            "      BatchNorm2d-13           [-1, 64, 24, 24]             128\n",
            "             ReLU-14           [-1, 64, 24, 24]               0\n",
            "           Linear-15                    [-1, 7]       1,013,383\n",
            "================================================================\n",
            "Total params: 1,153,327\n",
            "Trainable params: 1,153,327\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.73\n",
            "Params size (MB): 4.40\n",
            "Estimated Total Size (MB): 7.14\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 28.0264, Validation Accuracy: 0.5513\n",
            "Epoch 2/100, Loss: 77.0182, Validation Accuracy: 0.4516\n",
            "Epoch 3/100, Loss: 27.8440, Validation Accuracy: 0.6211\n",
            "Epoch 4/100, Loss: 10.0011, Validation Accuracy: 0.4885\n",
            "Epoch 5/100, Loss: 13.0592, Validation Accuracy: 0.6381\n",
            "Epoch 6/100, Loss: 134.1440, Validation Accuracy: 0.6600\n",
            "Epoch 7/100, Loss: 79.3951, Validation Accuracy: 0.6201\n",
            "Epoch 8/100, Loss: 67.8447, Validation Accuracy: 0.4088\n",
            "Epoch 9/100, Loss: 132.0115, Validation Accuracy: 0.5803\n",
            "Epoch 10/100, Loss: 38.5711, Validation Accuracy: 0.5852\n",
            "Epoch 11/100, Loss: 50.5519, Validation Accuracy: 0.5314\n",
            "Epoch 12/100, Loss: 22.9805, Validation Accuracy: 0.6072\n",
            "Epoch 13/100, Loss: 114.4919, Validation Accuracy: 0.6142\n",
            "Epoch 14/100, Loss: 111.2446, Validation Accuracy: 0.1924\n",
            "Epoch 15/100, Loss: 66.9755, Validation Accuracy: 0.5852\n",
            "Epoch 16/100, Loss: 55.2309, Validation Accuracy: 0.6790\n",
            "Epoch 17/100, Loss: 42.5330, Validation Accuracy: 0.5374\n",
            "Epoch 18/100, Loss: 32.5040, Validation Accuracy: 0.4875\n",
            "Epoch 19/100, Loss: 66.7133, Validation Accuracy: 0.5613\n",
            "Epoch 20/100, Loss: 40.1324, Validation Accuracy: 0.6670\n",
            "Epoch 21/100, Loss: 124.8582, Validation Accuracy: 0.5543\n",
            "Epoch 22/100, Loss: 117.4337, Validation Accuracy: 0.6839\n",
            "Epoch 23/100, Loss: 123.9395, Validation Accuracy: 0.5334\n",
            "Epoch 24/100, Loss: 48.7997, Validation Accuracy: 0.3430\n",
            "Epoch 25/100, Loss: 47.9195, Validation Accuracy: 0.4826\n",
            "Epoch 26/100, Loss: 67.3557, Validation Accuracy: 0.6231\n",
            "Epoch 27/100, Loss: 161.2679, Validation Accuracy: 0.6690\n",
            "Epoch 28/100, Loss: 108.9874, Validation Accuracy: 0.4835\n",
            "Epoch 29/100, Loss: 56.4069, Validation Accuracy: 0.6660\n",
            "Epoch 30/100, Loss: 87.0986, Validation Accuracy: 0.5314\n",
            "Epoch 31/100, Loss: 59.1230, Validation Accuracy: 0.1715\n",
            "Epoch 32/100, Loss: 186.1341, Validation Accuracy: 0.2851\n",
            "Epoch 33/100, Loss: 41.9080, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 62.4556, Validation Accuracy: 0.5414\n",
            "Epoch 35/100, Loss: 37.9097, Validation Accuracy: 0.6800\n",
            "Epoch 36/100, Loss: 118.9077, Validation Accuracy: 0.5364\n",
            "Epoch 37/100, Loss: 53.9726, Validation Accuracy: 0.6221\n",
            "Epoch 38/100, Loss: 101.8018, Validation Accuracy: 0.6471\n",
            "Epoch 39/100, Loss: 70.0907, Validation Accuracy: 0.6251\n",
            "Epoch 40/100, Loss: 59.6116, Validation Accuracy: 0.5942\n",
            "Epoch 41/100, Loss: 34.6702, Validation Accuracy: 0.6012\n",
            "Epoch 42/100, Loss: 101.8911, Validation Accuracy: 0.5842\n",
            "Epoch 43/100, Loss: 54.9287, Validation Accuracy: 0.6710\n",
            "Epoch 44/100, Loss: 68.5914, Validation Accuracy: 0.6590\n",
            "Epoch 45/100, Loss: 157.2368, Validation Accuracy: 0.4915\n",
            "Epoch 46/100, Loss: 67.5590, Validation Accuracy: 0.2313\n",
            "Epoch 47/100, Loss: 107.8530, Validation Accuracy: 0.6251\n",
            "Epoch 48/100, Loss: 58.0659, Validation Accuracy: 0.6381\n",
            "Epoch 49/100, Loss: 60.2134, Validation Accuracy: 0.5763\n",
            "Epoch 50/100, Loss: 113.8623, Validation Accuracy: 0.4766\n",
            "Epoch 51/100, Loss: 109.8861, Validation Accuracy: 0.5115\n",
            "Epoch 52/100, Loss: 27.5499, Validation Accuracy: 0.5274\n",
            "Epoch 53/100, Loss: 228.7246, Validation Accuracy: 0.6381\n",
            "Epoch 54/100, Loss: 72.8698, Validation Accuracy: 0.6281\n",
            "Epoch 55/100, Loss: 116.6036, Validation Accuracy: 0.5494\n",
            "Epoch 56/100, Loss: 100.0682, Validation Accuracy: 0.3809\n",
            "Epoch 57/100, Loss: 56.2372, Validation Accuracy: 0.4247\n",
            "Epoch 58/100, Loss: 133.1794, Validation Accuracy: 0.3729\n",
            "Epoch 59/100, Loss: 98.3775, Validation Accuracy: 0.6181\n",
            "Epoch 60/100, Loss: 21.9152, Validation Accuracy: 0.6451\n",
            "Epoch 61/100, Loss: 96.2501, Validation Accuracy: 0.3988\n",
            "Epoch 62/100, Loss: 71.0059, Validation Accuracy: 0.6670\n",
            "Epoch 63/100, Loss: 142.8990, Validation Accuracy: 0.6510\n",
            "Epoch 64/100, Loss: 74.8368, Validation Accuracy: 0.5553\n",
            "Epoch 65/100, Loss: 44.6909, Validation Accuracy: 0.6201\n",
            "Epoch 66/100, Loss: 118.6505, Validation Accuracy: 0.5304\n",
            "Epoch 67/100, Loss: 32.9074, Validation Accuracy: 0.6162\n",
            "Epoch 68/100, Loss: 55.2622, Validation Accuracy: 0.3420\n",
            "Epoch 69/100, Loss: 37.4800, Validation Accuracy: 0.6650\n",
            "Epoch 70/100, Loss: 161.8567, Validation Accuracy: 0.6590\n",
            "Epoch 71/100, Loss: 125.8465, Validation Accuracy: 0.6790\n",
            "Epoch 72/100, Loss: 15.4260, Validation Accuracy: 0.6560\n",
            "Epoch 73/100, Loss: 155.6317, Validation Accuracy: 0.6401\n",
            "Epoch 74/100, Loss: 42.7329, Validation Accuracy: 0.5793\n",
            "Epoch 75/100, Loss: 44.0823, Validation Accuracy: 0.6122\n",
            "Epoch 76/100, Loss: 137.4012, Validation Accuracy: 0.4487\n",
            "Epoch 77/100, Loss: 45.7333, Validation Accuracy: 0.5174\n",
            "Epoch 78/100, Loss: 93.7594, Validation Accuracy: 0.6421\n",
            "Epoch 79/100, Loss: 62.5437, Validation Accuracy: 0.5354\n",
            "Epoch 80/100, Loss: 69.1129, Validation Accuracy: 0.5384\n",
            "Epoch 81/100, Loss: 117.9419, Validation Accuracy: 0.6271\n",
            "Epoch 82/100, Loss: 60.3083, Validation Accuracy: 0.5842\n",
            "Epoch 83/100, Loss: 63.9223, Validation Accuracy: 0.5872\n",
            "Epoch 84/100, Loss: 97.9353, Validation Accuracy: 0.6211\n",
            "Epoch 85/100, Loss: 51.3716, Validation Accuracy: 0.6082\n",
            "Epoch 86/100, Loss: 237.9622, Validation Accuracy: 0.4955\n",
            "Epoch 87/100, Loss: 49.4268, Validation Accuracy: 0.6431\n",
            "Epoch 88/100, Loss: 38.4966, Validation Accuracy: 0.6281\n",
            "Epoch 89/100, Loss: 40.2837, Validation Accuracy: 0.6830\n",
            "Epoch 90/100, Loss: 94.5345, Validation Accuracy: 0.5703\n",
            "Epoch 91/100, Loss: 93.2860, Validation Accuracy: 0.6341\n",
            "Epoch 92/100, Loss: 36.1116, Validation Accuracy: 0.6839\n",
            "Epoch 93/100, Loss: 168.8592, Validation Accuracy: 0.6022\n",
            "Epoch 94/100, Loss: 128.2263, Validation Accuracy: 0.6431\n",
            "Epoch 95/100, Loss: 94.4336, Validation Accuracy: 0.4327\n",
            "Epoch 96/100, Loss: 71.7920, Validation Accuracy: 0.6122\n",
            "Epoch 97/100, Loss: 117.5721, Validation Accuracy: 0.5882\n",
            "Epoch 98/100, Loss: 43.5363, Validation Accuracy: 0.6391\n",
            "Epoch 99/100, Loss: 131.3168, Validation Accuracy: 0.6351\n",
            "Epoch 100/100, Loss: 184.7759, Validation Accuracy: 0.5424\n",
            "Epoch 101/100, Loss: 88.8400, Validation Accuracy: 0.6610\n",
            "Epoch 102/100, Loss: 135.2104, Validation Accuracy: 0.6231\n",
            "Epoch 103/100, Loss: 56.3863, Validation Accuracy: 0.5583\n",
            "Epoch 104/100, Loss: 114.4253, Validation Accuracy: 0.6301\n",
            "Epoch 105/100, Loss: 116.5705, Validation Accuracy: 0.5803\n",
            "Epoch 106/100, Loss: 84.6550, Validation Accuracy: 0.5862\n",
            "Epoch 107/100, Loss: 154.5717, Validation Accuracy: 0.5444\n",
            "Epoch 108/100, Loss: 96.3737, Validation Accuracy: 0.1416\n",
            "Epoch 109/100, Loss: 65.0004, Validation Accuracy: 0.4786\n",
            "Epoch 110/100, Loss: 95.8910, Validation Accuracy: 0.6441\n",
            "Epoch 111/100, Loss: 123.8511, Validation Accuracy: 0.3769\n",
            "Epoch 112/100, Loss: 105.1778, Validation Accuracy: 0.4227\n",
            "Epoch 113/100, Loss: 90.1428, Validation Accuracy: 0.6770\n",
            "Epoch 114/100, Loss: 77.4100, Validation Accuracy: 0.5803\n",
            "Epoch 115/100, Loss: 109.3770, Validation Accuracy: 0.6241\n",
            "Epoch 116/100, Loss: 177.0374, Validation Accuracy: 0.6371\n",
            "Epoch 117/100, Loss: 45.4624, Validation Accuracy: 0.6341\n",
            "Epoch 118/100, Loss: 56.3718, Validation Accuracy: 0.5623\n",
            "Epoch 119/100, Loss: 90.1931, Validation Accuracy: 0.5892\n",
            "Epoch 120/100, Loss: 83.0626, Validation Accuracy: 0.6132\n",
            "Epoch 121/100, Loss: 150.5674, Validation Accuracy: 0.5533\n",
            "Epoch 122/100, Loss: 87.9923, Validation Accuracy: 0.6351\n",
            "Epoch 123/100, Loss: 28.6137, Validation Accuracy: 0.6461\n",
            "Epoch 124/100, Loss: 150.4971, Validation Accuracy: 0.5374\n",
            "Epoch 125/100, Loss: 28.3042, Validation Accuracy: 0.6381\n",
            "Epoch 126/100, Loss: 99.8765, Validation Accuracy: 0.4008\n",
            "Epoch 127/100, Loss: 78.3945, Validation Accuracy: 0.4676\n",
            "Epoch 128/100, Loss: 127.3105, Validation Accuracy: 0.5543\n",
            "Epoch 129/100, Loss: 54.9729, Validation Accuracy: 0.6181\n",
            "Epoch 130/100, Loss: 28.7059, Validation Accuracy: 0.6411\n",
            "Epoch 131/100, Loss: 185.6931, Validation Accuracy: 0.5723\n",
            "Epoch 132/100, Loss: 247.8062, Validation Accuracy: 0.5633\n",
            "Epoch 133/100, Loss: 70.3396, Validation Accuracy: 0.5952\n",
            "Epoch 134/100, Loss: 153.6499, Validation Accuracy: 0.4586\n",
            "Epoch 135/100, Loss: 63.9337, Validation Accuracy: 0.6132\n",
            "Epoch 136/100, Loss: 54.9784, Validation Accuracy: 0.5334\n",
            "Epoch 137/100, Loss: 188.0288, Validation Accuracy: 0.6351\n",
            "Epoch 138/100, Loss: 62.2361, Validation Accuracy: 0.5643\n",
            "Epoch 139/100, Loss: 344.5691, Validation Accuracy: 0.5633\n",
            "Epoch 140/100, Loss: 148.3261, Validation Accuracy: 0.5673\n",
            "Epoch 141/100, Loss: 54.8764, Validation Accuracy: 0.6221\n",
            "Epoch 142/100, Loss: 75.2726, Validation Accuracy: 0.5892\n",
            "Epoch 143/100, Loss: 76.7071, Validation Accuracy: 0.5633\n",
            "Epoch 144/100, Loss: 264.9134, Validation Accuracy: 0.5852\n",
            "Epoch 145/100, Loss: 174.0580, Validation Accuracy: 0.6291\n",
            "Epoch 146/100, Loss: 147.8038, Validation Accuracy: 0.6351\n",
            "Epoch 147/100, Loss: 41.3190, Validation Accuracy: 0.5962\n",
            "Epoch 148/100, Loss: 151.4720, Validation Accuracy: 0.5723\n",
            "Epoch 149/100, Loss: 79.6794, Validation Accuracy: 0.5743\n",
            "Epoch 150/100, Loss: 187.6907, Validation Accuracy: 0.4347\n",
            "Epoch 151/100, Loss: 69.7688, Validation Accuracy: 0.5663\n",
            "Epoch 152/100, Loss: 47.2908, Validation Accuracy: 0.5703\n",
            "Epoch 153/100, Loss: 142.6332, Validation Accuracy: 0.4865\n",
            "Epoch 154/100, Loss: 59.9370, Validation Accuracy: 0.6002\n",
            "Epoch 155/100, Loss: 228.7235, Validation Accuracy: 0.6321\n",
            "Epoch 156/100, Loss: 245.7260, Validation Accuracy: 0.5952\n",
            "Epoch 157/100, Loss: 105.7301, Validation Accuracy: 0.4985\n",
            "Epoch 158/100, Loss: 69.4888, Validation Accuracy: 0.6361\n",
            "Epoch 159/100, Loss: 71.9676, Validation Accuracy: 0.5803\n",
            "Epoch 160/100, Loss: 110.7871, Validation Accuracy: 0.4616\n",
            "Epoch 161/100, Loss: 69.7510, Validation Accuracy: 0.6072\n",
            "Epoch 162/100, Loss: 135.1918, Validation Accuracy: 0.6311\n",
            "Epoch 163/100, Loss: 97.2348, Validation Accuracy: 0.6291\n",
            "Epoch 164/100, Loss: 99.4781, Validation Accuracy: 0.6321\n",
            "Epoch 165/100, Loss: 90.2185, Validation Accuracy: 0.6032\n",
            "Epoch 166/100, Loss: 132.2154, Validation Accuracy: 0.6062\n",
            "Epoch 167/100, Loss: 125.0874, Validation Accuracy: 0.5244\n",
            "Epoch 168/100, Loss: 25.8031, Validation Accuracy: 0.6530\n",
            "Epoch 169/100, Loss: 153.5641, Validation Accuracy: 0.4207\n",
            "Epoch 170/100, Loss: 17.7240, Validation Accuracy: 0.6142\n",
            "Epoch 171/100, Loss: 169.9350, Validation Accuracy: 0.6251\n",
            "Epoch 172/100, Loss: 81.7680, Validation Accuracy: 0.2682\n",
            "Epoch 173/100, Loss: 97.9459, Validation Accuracy: 0.6042\n",
            "Epoch 174/100, Loss: 132.3830, Validation Accuracy: 0.6371\n",
            "Epoch 175/100, Loss: 99.3646, Validation Accuracy: 0.6072\n",
            "Epoch 176/100, Loss: 63.4613, Validation Accuracy: 0.5962\n",
            "Epoch 177/100, Loss: 83.8545, Validation Accuracy: 0.4766\n",
            "Epoch 178/100, Loss: 74.9189, Validation Accuracy: 0.5503\n",
            "Epoch 179/100, Loss: 191.1068, Validation Accuracy: 0.6231\n",
            "Epoch 180/100, Loss: 65.9412, Validation Accuracy: 0.5833\n",
            "Epoch 181/100, Loss: 132.4335, Validation Accuracy: 0.5952\n",
            "Epoch 182/100, Loss: 112.8540, Validation Accuracy: 0.6201\n",
            "Epoch 183/100, Loss: 114.4084, Validation Accuracy: 0.3629\n",
            "Epoch 184/100, Loss: 107.0064, Validation Accuracy: 0.5743\n",
            "Epoch 185/100, Loss: 34.1628, Validation Accuracy: 0.6481\n",
            "Epoch 186/100, Loss: 277.3888, Validation Accuracy: 0.5394\n",
            "Epoch 187/100, Loss: 216.3817, Validation Accuracy: 0.6441\n",
            "Epoch 188/100, Loss: 28.2237, Validation Accuracy: 0.5932\n",
            "Epoch 189/100, Loss: 107.6800, Validation Accuracy: 0.6062\n",
            "Epoch 190/100, Loss: 30.1073, Validation Accuracy: 0.6281\n",
            "Epoch 191/100, Loss: 26.2579, Validation Accuracy: 0.6610\n",
            "Epoch 192/100, Loss: 132.0000, Validation Accuracy: 0.6401\n",
            "Epoch 193/100, Loss: 99.2251, Validation Accuracy: 0.6171\n",
            "Epoch 194/100, Loss: 74.3074, Validation Accuracy: 0.4237\n",
            "Epoch 195/100, Loss: 79.9323, Validation Accuracy: 0.6341\n",
            "Epoch 196/100, Loss: 326.3322, Validation Accuracy: 0.6550\n",
            "Epoch 197/100, Loss: 155.1518, Validation Accuracy: 0.5523\n",
            "Epoch 198/100, Loss: 143.1944, Validation Accuracy: 0.6301\n",
            "Epoch 199/100, Loss: 308.5403, Validation Accuracy: 0.6421\n",
            "Epoch 200/100, Loss: 82.0662, Validation Accuracy: 0.6002\n",
            "Reward for Child Model: 0.28105629027913037\n",
            "Child_95:  {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, [2, 1, 2, 0, 1, 2, 0, 3, 0, 1, 2, 2, 0, 1, 3], 0.28105629027913037\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 48, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(112, 64, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(176, 64, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(240, 48, kernel_size=(5, 3), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=206976, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 28, 22]           1,408\n",
            "       BatchNorm2d-2           [-1, 64, 28, 22]             128\n",
            "            Conv2d-3           [-1, 48, 24, 18]          76,848\n",
            "       BatchNorm2d-4           [-1, 48, 24, 18]              96\n",
            "              ReLU-5           [-1, 48, 24, 18]               0\n",
            "            Conv2d-6           [-1, 64, 26, 22]          21,568\n",
            "       BatchNorm2d-7           [-1, 64, 26, 22]             128\n",
            "              ReLU-8           [-1, 64, 26, 22]               0\n",
            "            Conv2d-9           [-1, 64, 26, 22]          33,856\n",
            "      BatchNorm2d-10           [-1, 64, 26, 22]             128\n",
            "             ReLU-11           [-1, 64, 26, 22]               0\n",
            "           Conv2d-12           [-1, 48, 24, 20]         172,848\n",
            "      BatchNorm2d-13           [-1, 48, 24, 20]              96\n",
            "             ReLU-14           [-1, 48, 24, 20]               0\n",
            "           Linear-15                    [-1, 7]       1,448,839\n",
            "================================================================\n",
            "Total params: 1,755,943\n",
            "Trainable params: 1,755,943\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 3.28\n",
            "Params size (MB): 6.70\n",
            "Estimated Total Size (MB): 9.99\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 39.7113, Validation Accuracy: 0.6710\n",
            "Epoch 2/100, Loss: 24.3752, Validation Accuracy: 0.6331\n",
            "Epoch 3/100, Loss: 32.2967, Validation Accuracy: 0.5813\n",
            "Epoch 4/100, Loss: 27.7762, Validation Accuracy: 0.6251\n",
            "Epoch 5/100, Loss: 31.4310, Validation Accuracy: 0.5982\n",
            "Epoch 6/100, Loss: 20.9413, Validation Accuracy: 0.5773\n",
            "Epoch 7/100, Loss: 19.1263, Validation Accuracy: 0.3968\n",
            "Epoch 8/100, Loss: 167.5883, Validation Accuracy: 0.5434\n",
            "Epoch 9/100, Loss: 64.9583, Validation Accuracy: 0.6042\n",
            "Epoch 10/100, Loss: 32.8689, Validation Accuracy: 0.5613\n",
            "Epoch 11/100, Loss: 18.0219, Validation Accuracy: 0.6550\n",
            "Epoch 12/100, Loss: 98.1721, Validation Accuracy: 0.5224\n",
            "Epoch 13/100, Loss: 234.3546, Validation Accuracy: 0.5892\n",
            "Epoch 14/100, Loss: 74.3663, Validation Accuracy: 0.6680\n",
            "Epoch 15/100, Loss: 77.8677, Validation Accuracy: 0.4776\n",
            "Epoch 16/100, Loss: 84.1192, Validation Accuracy: 0.6171\n",
            "Epoch 17/100, Loss: 78.1594, Validation Accuracy: 0.6560\n",
            "Epoch 18/100, Loss: 129.7931, Validation Accuracy: 0.5713\n",
            "Epoch 19/100, Loss: 204.5585, Validation Accuracy: 0.5593\n",
            "Epoch 20/100, Loss: 159.0440, Validation Accuracy: 0.6112\n",
            "Epoch 21/100, Loss: 92.5416, Validation Accuracy: 0.5065\n",
            "Epoch 22/100, Loss: 58.3538, Validation Accuracy: 0.5982\n",
            "Epoch 23/100, Loss: 29.1031, Validation Accuracy: 0.6301\n",
            "Epoch 24/100, Loss: 86.1272, Validation Accuracy: 0.2871\n",
            "Epoch 25/100, Loss: 222.0481, Validation Accuracy: 0.6191\n",
            "Epoch 26/100, Loss: 96.0895, Validation Accuracy: 0.6162\n",
            "Epoch 27/100, Loss: 63.8138, Validation Accuracy: 0.5384\n",
            "Epoch 28/100, Loss: 45.9263, Validation Accuracy: 0.5743\n",
            "Epoch 29/100, Loss: 261.0784, Validation Accuracy: 0.6500\n",
            "Epoch 30/100, Loss: 111.7951, Validation Accuracy: 0.4138\n",
            "Epoch 31/100, Loss: 202.5627, Validation Accuracy: 0.5523\n",
            "Epoch 32/100, Loss: 76.6827, Validation Accuracy: 0.4397\n",
            "Epoch 33/100, Loss: 41.9308, Validation Accuracy: 0.5214\n",
            "Epoch 34/100, Loss: 67.2015, Validation Accuracy: 0.6052\n",
            "Epoch 35/100, Loss: 80.0172, Validation Accuracy: 0.6750\n",
            "Epoch 36/100, Loss: 179.4003, Validation Accuracy: 0.5165\n",
            "Epoch 37/100, Loss: 144.1951, Validation Accuracy: 0.5733\n",
            "Epoch 38/100, Loss: 107.3908, Validation Accuracy: 0.6062\n",
            "Epoch 39/100, Loss: 51.3466, Validation Accuracy: 0.6491\n",
            "Epoch 40/100, Loss: 64.5084, Validation Accuracy: 0.6720\n",
            "Epoch 41/100, Loss: 332.6378, Validation Accuracy: 0.5783\n",
            "Epoch 42/100, Loss: 94.6039, Validation Accuracy: 0.6162\n",
            "Epoch 43/100, Loss: 83.7369, Validation Accuracy: 0.5872\n",
            "Epoch 44/100, Loss: 75.7387, Validation Accuracy: 0.5194\n",
            "Epoch 45/100, Loss: 153.9398, Validation Accuracy: 0.5513\n",
            "Epoch 46/100, Loss: 76.2746, Validation Accuracy: 0.5354\n",
            "Epoch 47/100, Loss: 35.2128, Validation Accuracy: 0.4845\n",
            "Epoch 48/100, Loss: 249.3009, Validation Accuracy: 0.5783\n",
            "Epoch 49/100, Loss: 91.5365, Validation Accuracy: 0.6770\n",
            "Epoch 50/100, Loss: 211.5309, Validation Accuracy: 0.5115\n",
            "Epoch 51/100, Loss: 132.7765, Validation Accuracy: 0.6112\n",
            "Epoch 52/100, Loss: 26.9986, Validation Accuracy: 0.6251\n",
            "Epoch 53/100, Loss: 63.0992, Validation Accuracy: 0.6630\n",
            "Epoch 54/100, Loss: 85.4355, Validation Accuracy: 0.5793\n",
            "Epoch 55/100, Loss: 306.9819, Validation Accuracy: 0.4158\n",
            "Epoch 56/100, Loss: 90.4543, Validation Accuracy: 0.5992\n",
            "Epoch 57/100, Loss: 60.0440, Validation Accuracy: 0.6142\n",
            "Epoch 58/100, Loss: 30.3211, Validation Accuracy: 0.6361\n",
            "Epoch 59/100, Loss: 60.7539, Validation Accuracy: 0.6181\n",
            "Epoch 60/100, Loss: 57.4434, Validation Accuracy: 0.5324\n",
            "Epoch 61/100, Loss: 96.8528, Validation Accuracy: 0.5633\n",
            "Epoch 62/100, Loss: 151.3853, Validation Accuracy: 0.4706\n",
            "Epoch 63/100, Loss: 116.3567, Validation Accuracy: 0.6142\n",
            "Epoch 64/100, Loss: 102.2260, Validation Accuracy: 0.5484\n",
            "Epoch 65/100, Loss: 68.1970, Validation Accuracy: 0.5912\n",
            "Epoch 66/100, Loss: 162.7205, Validation Accuracy: 0.5892\n",
            "Epoch 67/100, Loss: 75.8490, Validation Accuracy: 0.6421\n",
            "Epoch 68/100, Loss: 73.8917, Validation Accuracy: 0.5683\n",
            "Epoch 69/100, Loss: 66.0142, Validation Accuracy: 0.6820\n",
            "Epoch 70/100, Loss: 318.5148, Validation Accuracy: 0.3739\n",
            "Epoch 71/100, Loss: 94.7114, Validation Accuracy: 0.6132\n",
            "Epoch 72/100, Loss: 55.6433, Validation Accuracy: 0.5813\n",
            "Epoch 73/100, Loss: 71.0544, Validation Accuracy: 0.5842\n",
            "Epoch 74/100, Loss: 84.8935, Validation Accuracy: 0.5095\n",
            "Epoch 75/100, Loss: 33.6502, Validation Accuracy: 0.6361\n",
            "Epoch 76/100, Loss: 84.6517, Validation Accuracy: 0.6760\n",
            "Epoch 77/100, Loss: 131.2638, Validation Accuracy: 0.4187\n",
            "Epoch 78/100, Loss: 76.4565, Validation Accuracy: 0.4686\n",
            "Epoch 79/100, Loss: 86.8136, Validation Accuracy: 0.5643\n",
            "Epoch 80/100, Loss: 132.0072, Validation Accuracy: 0.6421\n",
            "Epoch 81/100, Loss: 73.0707, Validation Accuracy: 0.4616\n",
            "Epoch 82/100, Loss: 58.3864, Validation Accuracy: 0.4447\n",
            "Epoch 83/100, Loss: 53.2787, Validation Accuracy: 0.5135\n",
            "Epoch 84/100, Loss: 76.2877, Validation Accuracy: 0.5115\n",
            "Epoch 85/100, Loss: 75.6790, Validation Accuracy: 0.6142\n",
            "Epoch 86/100, Loss: 154.9236, Validation Accuracy: 0.6650\n",
            "Epoch 87/100, Loss: 140.4013, Validation Accuracy: 0.6162\n",
            "Epoch 88/100, Loss: 51.7609, Validation Accuracy: 0.5444\n",
            "Epoch 89/100, Loss: 54.0886, Validation Accuracy: 0.6580\n",
            "Epoch 90/100, Loss: 107.3684, Validation Accuracy: 0.6331\n",
            "Epoch 91/100, Loss: 117.7279, Validation Accuracy: 0.5354\n",
            "Epoch 92/100, Loss: 58.7780, Validation Accuracy: 0.5842\n",
            "Epoch 93/100, Loss: 210.0391, Validation Accuracy: 0.6191\n",
            "Epoch 94/100, Loss: 105.9576, Validation Accuracy: 0.6421\n",
            "Epoch 95/100, Loss: 106.2001, Validation Accuracy: 0.6650\n",
            "Epoch 96/100, Loss: 127.3822, Validation Accuracy: 0.6381\n",
            "Epoch 97/100, Loss: 279.4636, Validation Accuracy: 0.5603\n",
            "Epoch 98/100, Loss: 140.4082, Validation Accuracy: 0.5513\n",
            "Epoch 99/100, Loss: 90.8987, Validation Accuracy: 0.5583\n",
            "Epoch 100/100, Loss: 51.5304, Validation Accuracy: 0.6221\n",
            "Epoch 101/100, Loss: 57.2811, Validation Accuracy: 0.4806\n",
            "Epoch 102/100, Loss: 116.6658, Validation Accuracy: 0.5733\n",
            "Epoch 103/100, Loss: 186.7932, Validation Accuracy: 0.5304\n",
            "Epoch 104/100, Loss: 49.4410, Validation Accuracy: 0.6291\n",
            "Epoch 105/100, Loss: 70.6122, Validation Accuracy: 0.6780\n",
            "Epoch 106/100, Loss: 85.7251, Validation Accuracy: 0.6720\n",
            "Epoch 107/100, Loss: 86.6594, Validation Accuracy: 0.6471\n",
            "Epoch 108/100, Loss: 150.1616, Validation Accuracy: 0.6361\n",
            "Epoch 109/100, Loss: 166.5261, Validation Accuracy: 0.4377\n",
            "Epoch 110/100, Loss: 131.2462, Validation Accuracy: 0.5982\n",
            "Epoch 111/100, Loss: 123.7614, Validation Accuracy: 0.6231\n",
            "Epoch 112/100, Loss: 166.6574, Validation Accuracy: 0.6211\n",
            "Epoch 113/100, Loss: 70.9677, Validation Accuracy: 0.5713\n",
            "Epoch 114/100, Loss: 50.5816, Validation Accuracy: 0.6371\n",
            "Epoch 115/100, Loss: 119.5401, Validation Accuracy: 0.6600\n",
            "Epoch 116/100, Loss: 99.8006, Validation Accuracy: 0.6421\n",
            "Epoch 117/100, Loss: 305.1327, Validation Accuracy: 0.4935\n",
            "Epoch 118/100, Loss: 116.6841, Validation Accuracy: 0.4427\n",
            "Epoch 119/100, Loss: 84.6996, Validation Accuracy: 0.6251\n",
            "Epoch 120/100, Loss: 72.7416, Validation Accuracy: 0.6251\n",
            "Epoch 121/100, Loss: 31.2493, Validation Accuracy: 0.6600\n",
            "Epoch 122/100, Loss: 65.1515, Validation Accuracy: 0.6261\n",
            "Epoch 123/100, Loss: 125.8144, Validation Accuracy: 0.4526\n",
            "Epoch 124/100, Loss: 94.4338, Validation Accuracy: 0.6600\n",
            "Epoch 125/100, Loss: 110.0315, Validation Accuracy: 0.5972\n",
            "Epoch 126/100, Loss: 139.0359, Validation Accuracy: 0.4915\n",
            "Epoch 127/100, Loss: 60.9678, Validation Accuracy: 0.5324\n",
            "Epoch 128/100, Loss: 112.1149, Validation Accuracy: 0.6371\n",
            "Epoch 129/100, Loss: 151.2839, Validation Accuracy: 0.5204\n",
            "Epoch 130/100, Loss: 140.2662, Validation Accuracy: 0.6291\n",
            "Epoch 131/100, Loss: 116.2197, Validation Accuracy: 0.6411\n",
            "Epoch 132/100, Loss: 318.8371, Validation Accuracy: 0.5823\n",
            "Epoch 133/100, Loss: 104.9361, Validation Accuracy: 0.6780\n",
            "Epoch 134/100, Loss: 123.2471, Validation Accuracy: 0.6112\n",
            "Epoch 135/100, Loss: 92.1495, Validation Accuracy: 0.5414\n",
            "Epoch 136/100, Loss: 126.0722, Validation Accuracy: 0.5105\n",
            "Epoch 137/100, Loss: 211.1527, Validation Accuracy: 0.3998\n",
            "Epoch 138/100, Loss: 54.2711, Validation Accuracy: 0.6381\n",
            "Epoch 139/100, Loss: 25.0268, Validation Accuracy: 0.5603\n",
            "Epoch 140/100, Loss: 149.0308, Validation Accuracy: 0.5743\n",
            "Epoch 141/100, Loss: 373.4576, Validation Accuracy: 0.6181\n",
            "Epoch 142/100, Loss: 68.5134, Validation Accuracy: 0.5513\n",
            "Epoch 143/100, Loss: 147.5825, Validation Accuracy: 0.5892\n",
            "Epoch 144/100, Loss: 132.4437, Validation Accuracy: 0.6191\n",
            "Epoch 145/100, Loss: 110.1114, Validation Accuracy: 0.6560\n",
            "Epoch 146/100, Loss: 103.0611, Validation Accuracy: 0.6620\n",
            "Epoch 147/100, Loss: 176.0474, Validation Accuracy: 0.5264\n",
            "Epoch 148/100, Loss: 211.7806, Validation Accuracy: 0.5623\n",
            "Epoch 149/100, Loss: 52.6692, Validation Accuracy: 0.6700\n",
            "Epoch 150/100, Loss: 88.4402, Validation Accuracy: 0.4088\n",
            "Epoch 151/100, Loss: 120.1489, Validation Accuracy: 0.6790\n",
            "Epoch 152/100, Loss: 87.2089, Validation Accuracy: 0.5454\n",
            "Epoch 153/100, Loss: 182.8434, Validation Accuracy: 0.6321\n",
            "Epoch 154/100, Loss: 120.1327, Validation Accuracy: 0.6281\n",
            "Epoch 155/100, Loss: 92.6105, Validation Accuracy: 0.6201\n",
            "Epoch 156/100, Loss: 166.0762, Validation Accuracy: 0.6132\n",
            "Epoch 157/100, Loss: 131.2279, Validation Accuracy: 0.5563\n",
            "Epoch 158/100, Loss: 61.5028, Validation Accuracy: 0.6760\n",
            "Epoch 159/100, Loss: 56.0920, Validation Accuracy: 0.6201\n",
            "Epoch 160/100, Loss: 192.8820, Validation Accuracy: 0.6142\n",
            "Epoch 161/100, Loss: 49.8219, Validation Accuracy: 0.6152\n",
            "Epoch 162/100, Loss: 101.6139, Validation Accuracy: 0.5244\n",
            "Epoch 163/100, Loss: 61.2125, Validation Accuracy: 0.5464\n",
            "Epoch 164/100, Loss: 128.9841, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 147.9413, Validation Accuracy: 0.5902\n",
            "Epoch 166/100, Loss: 86.5704, Validation Accuracy: 0.6780\n",
            "Epoch 167/100, Loss: 158.2233, Validation Accuracy: 0.6650\n",
            "Epoch 168/100, Loss: 218.8484, Validation Accuracy: 0.5673\n",
            "Epoch 169/100, Loss: 90.2443, Validation Accuracy: 0.5633\n",
            "Epoch 170/100, Loss: 147.6759, Validation Accuracy: 0.6201\n",
            "Epoch 171/100, Loss: 92.5489, Validation Accuracy: 0.6491\n",
            "Epoch 172/100, Loss: 119.6735, Validation Accuracy: 0.5902\n",
            "Epoch 173/100, Loss: 59.1743, Validation Accuracy: 0.5713\n",
            "Epoch 174/100, Loss: 272.1790, Validation Accuracy: 0.5484\n",
            "Epoch 175/100, Loss: 177.6671, Validation Accuracy: 0.5922\n",
            "Epoch 176/100, Loss: 107.4567, Validation Accuracy: 0.6321\n",
            "Epoch 177/100, Loss: 179.8385, Validation Accuracy: 0.5773\n",
            "Epoch 178/100, Loss: 100.1582, Validation Accuracy: 0.5384\n",
            "Epoch 179/100, Loss: 86.3239, Validation Accuracy: 0.5763\n",
            "Epoch 180/100, Loss: 37.8735, Validation Accuracy: 0.5394\n",
            "Epoch 181/100, Loss: 323.3304, Validation Accuracy: 0.6560\n",
            "Epoch 182/100, Loss: 52.6258, Validation Accuracy: 0.6191\n",
            "Epoch 183/100, Loss: 78.5553, Validation Accuracy: 0.5753\n",
            "Epoch 184/100, Loss: 249.7461, Validation Accuracy: 0.5942\n",
            "Epoch 185/100, Loss: 55.2762, Validation Accuracy: 0.4806\n",
            "Epoch 186/100, Loss: 100.1950, Validation Accuracy: 0.6491\n",
            "Epoch 187/100, Loss: 72.1872, Validation Accuracy: 0.6301\n",
            "Epoch 188/100, Loss: 207.2219, Validation Accuracy: 0.6640\n",
            "Epoch 189/100, Loss: 236.5381, Validation Accuracy: 0.6510\n",
            "Epoch 190/100, Loss: 184.0232, Validation Accuracy: 0.5533\n",
            "Epoch 191/100, Loss: 104.0185, Validation Accuracy: 0.5374\n",
            "Epoch 192/100, Loss: 103.2327, Validation Accuracy: 0.5713\n",
            "Epoch 193/100, Loss: 151.1218, Validation Accuracy: 0.6550\n",
            "Epoch 194/100, Loss: 24.4589, Validation Accuracy: 0.5842\n",
            "Epoch 195/100, Loss: 180.9259, Validation Accuracy: 0.6321\n",
            "Epoch 196/100, Loss: 144.4355, Validation Accuracy: 0.5623\n",
            "Epoch 197/100, Loss: 203.2627, Validation Accuracy: 0.5344\n",
            "Epoch 198/100, Loss: 262.1185, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 163.1029, Validation Accuracy: 0.5982\n",
            "Epoch 200/100, Loss: 223.1051, Validation Accuracy: 0.6500\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_96:  {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, [0, 3, 3, 2, 2, 2, 1, 0, 3, 1, 0, 3, 2, 1, 2], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 64, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(64, 36, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 36, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(100, 36, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(136, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (16): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=116480, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 26, 28]             640\n",
            "       BatchNorm2d-2           [-1, 64, 26, 28]             128\n",
            "            Conv2d-3           [-1, 36, 26, 28]           2,340\n",
            "       BatchNorm2d-4           [-1, 36, 26, 28]              72\n",
            "              ReLU-5           [-1, 36, 26, 28]               0\n",
            "            Conv2d-6           [-1, 36, 20, 28]           9,108\n",
            "       BatchNorm2d-7           [-1, 36, 20, 28]              72\n",
            "              ReLU-8           [-1, 36, 20, 28]               0\n",
            "            Conv2d-9           [-1, 36, 20, 28]          25,236\n",
            "      BatchNorm2d-10           [-1, 36, 20, 28]              72\n",
            "             ReLU-11           [-1, 36, 20, 28]               0\n",
            "           Conv2d-12           [-1, 24, 26, 28]           3,288\n",
            "      BatchNorm2d-13           [-1, 24, 26, 28]              48\n",
            "             ReLU-14           [-1, 24, 26, 28]               0\n",
            "           Linear-15                    [-1, 7]         815,367\n",
            "================================================================\n",
            "Total params: 856,371\n",
            "Trainable params: 856,371\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.63\n",
            "Params size (MB): 3.27\n",
            "Estimated Total Size (MB): 5.91\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 7.2930, Validation Accuracy: 0.5214\n",
            "Epoch 2/100, Loss: 20.1757, Validation Accuracy: 0.4955\n",
            "Epoch 3/100, Loss: 98.3790, Validation Accuracy: 0.3609\n",
            "Epoch 4/100, Loss: 103.8333, Validation Accuracy: 0.6730\n",
            "Epoch 5/100, Loss: 34.2724, Validation Accuracy: 0.6530\n",
            "Epoch 6/100, Loss: 63.9266, Validation Accuracy: 0.5055\n",
            "Epoch 7/100, Loss: 3010.5315, Validation Accuracy: 0.5533\n",
            "Epoch 8/100, Loss: 40.8468, Validation Accuracy: 0.6550\n",
            "Epoch 9/100, Loss: 14.4513, Validation Accuracy: 0.6441\n",
            "Epoch 10/100, Loss: 31.8478, Validation Accuracy: 0.2483\n",
            "Epoch 11/100, Loss: 17.1289, Validation Accuracy: 0.6281\n",
            "Epoch 12/100, Loss: 12.6909, Validation Accuracy: 0.4776\n",
            "Epoch 13/100, Loss: 87.2882, Validation Accuracy: 0.6371\n",
            "Epoch 14/100, Loss: 59.5369, Validation Accuracy: 0.6939\n",
            "Epoch 15/100, Loss: 116.2784, Validation Accuracy: 0.6012\n",
            "Epoch 16/100, Loss: 109.1183, Validation Accuracy: 0.3838\n",
            "Epoch 17/100, Loss: 18.1117, Validation Accuracy: 0.6660\n",
            "Epoch 18/100, Loss: 28.3746, Validation Accuracy: 0.6092\n",
            "Epoch 19/100, Loss: 43.0413, Validation Accuracy: 0.5892\n",
            "Epoch 20/100, Loss: 45.5104, Validation Accuracy: 0.5035\n",
            "Epoch 21/100, Loss: 138.9444, Validation Accuracy: 0.6780\n",
            "Epoch 22/100, Loss: 15.2272, Validation Accuracy: 0.4766\n",
            "Epoch 23/100, Loss: 34.0122, Validation Accuracy: 0.6122\n",
            "Epoch 24/100, Loss: 95.8104, Validation Accuracy: 0.5055\n",
            "Epoch 25/100, Loss: 45.4355, Validation Accuracy: 0.6740\n",
            "Epoch 26/100, Loss: 682.0910, Validation Accuracy: 0.6451\n",
            "Epoch 27/100, Loss: 123.0132, Validation Accuracy: 0.4636\n",
            "Epoch 28/100, Loss: 24.8703, Validation Accuracy: 0.6491\n",
            "Epoch 29/100, Loss: 67.3807, Validation Accuracy: 0.4885\n",
            "Epoch 30/100, Loss: 14.0477, Validation Accuracy: 0.5543\n",
            "Epoch 31/100, Loss: 21.8883, Validation Accuracy: 0.6491\n",
            "Epoch 32/100, Loss: 14.1821, Validation Accuracy: 0.6750\n",
            "Epoch 33/100, Loss: 69.0499, Validation Accuracy: 0.6331\n",
            "Epoch 34/100, Loss: 144.6998, Validation Accuracy: 0.4546\n",
            "Epoch 35/100, Loss: 77.3635, Validation Accuracy: 0.6530\n",
            "Epoch 36/100, Loss: 88.7862, Validation Accuracy: 0.6780\n",
            "Epoch 37/100, Loss: 68.9147, Validation Accuracy: 0.6142\n",
            "Epoch 38/100, Loss: 64.3528, Validation Accuracy: 0.6201\n",
            "Epoch 39/100, Loss: 16.4501, Validation Accuracy: 0.6780\n",
            "Epoch 40/100, Loss: 45.5357, Validation Accuracy: 0.5314\n",
            "Epoch 41/100, Loss: 40.5597, Validation Accuracy: 0.6431\n",
            "Epoch 42/100, Loss: 68.3648, Validation Accuracy: 0.6630\n",
            "Epoch 43/100, Loss: 191.5956, Validation Accuracy: 0.4207\n",
            "Epoch 44/100, Loss: 45.4107, Validation Accuracy: 0.5663\n",
            "Epoch 45/100, Loss: 50.3276, Validation Accuracy: 0.5583\n",
            "Epoch 46/100, Loss: 71.4656, Validation Accuracy: 0.6102\n",
            "Epoch 47/100, Loss: 45.2637, Validation Accuracy: 0.5633\n",
            "Epoch 48/100, Loss: 59.4916, Validation Accuracy: 0.6760\n",
            "Epoch 49/100, Loss: 62.7982, Validation Accuracy: 0.4945\n",
            "Epoch 50/100, Loss: 28.7286, Validation Accuracy: 0.6770\n",
            "Epoch 51/100, Loss: 93.5234, Validation Accuracy: 0.6002\n",
            "Epoch 52/100, Loss: 59.0553, Validation Accuracy: 0.5872\n",
            "Epoch 53/100, Loss: 99.1454, Validation Accuracy: 0.5982\n",
            "Epoch 54/100, Loss: 21.4621, Validation Accuracy: 0.3729\n",
            "Epoch 55/100, Loss: 19.3239, Validation Accuracy: 0.6291\n",
            "Epoch 56/100, Loss: 69.2331, Validation Accuracy: 0.6570\n",
            "Epoch 57/100, Loss: 91.4035, Validation Accuracy: 0.6142\n",
            "Epoch 58/100, Loss: 46.2032, Validation Accuracy: 0.5733\n",
            "Epoch 59/100, Loss: 68.2291, Validation Accuracy: 0.6750\n",
            "Epoch 60/100, Loss: 100.4969, Validation Accuracy: 0.4696\n",
            "Epoch 61/100, Loss: 114.3886, Validation Accuracy: 0.5902\n",
            "Epoch 62/100, Loss: 251.9030, Validation Accuracy: 0.6102\n",
            "Epoch 63/100, Loss: 94.9909, Validation Accuracy: 0.6132\n",
            "Epoch 64/100, Loss: 38.3407, Validation Accuracy: 0.3619\n",
            "Epoch 65/100, Loss: 10.9200, Validation Accuracy: 0.5533\n",
            "Epoch 66/100, Loss: 130.4399, Validation Accuracy: 0.5952\n",
            "Epoch 67/100, Loss: 78.1608, Validation Accuracy: 0.5872\n",
            "Epoch 68/100, Loss: 44.2785, Validation Accuracy: 0.4048\n",
            "Epoch 69/100, Loss: 89.5010, Validation Accuracy: 0.6610\n",
            "Epoch 70/100, Loss: 52.8722, Validation Accuracy: 0.6630\n",
            "Epoch 71/100, Loss: 12.4360, Validation Accuracy: 0.6630\n",
            "Epoch 72/100, Loss: 68.2535, Validation Accuracy: 0.6162\n",
            "Epoch 73/100, Loss: 32.4858, Validation Accuracy: 0.6421\n",
            "Epoch 74/100, Loss: 60.6075, Validation Accuracy: 0.3240\n",
            "Epoch 75/100, Loss: 64.6779, Validation Accuracy: 0.5643\n",
            "Epoch 76/100, Loss: 67.2884, Validation Accuracy: 0.6451\n",
            "Epoch 77/100, Loss: 140.9594, Validation Accuracy: 0.4138\n",
            "Epoch 78/100, Loss: 54.9284, Validation Accuracy: 0.6052\n",
            "Epoch 79/100, Loss: 63.6202, Validation Accuracy: 0.6530\n",
            "Epoch 80/100, Loss: 59.5605, Validation Accuracy: 0.6181\n",
            "Epoch 81/100, Loss: 23.1141, Validation Accuracy: 0.6680\n",
            "Epoch 82/100, Loss: 54.5543, Validation Accuracy: 0.5334\n",
            "Epoch 83/100, Loss: 47.3690, Validation Accuracy: 0.4138\n",
            "Epoch 84/100, Loss: 46.5788, Validation Accuracy: 0.4377\n",
            "Epoch 85/100, Loss: 35.3191, Validation Accuracy: 0.6720\n",
            "Epoch 86/100, Loss: 49.9475, Validation Accuracy: 0.5982\n",
            "Epoch 87/100, Loss: 101.4279, Validation Accuracy: 0.5533\n",
            "Epoch 88/100, Loss: 40.3425, Validation Accuracy: 0.4457\n",
            "Epoch 89/100, Loss: 73.4077, Validation Accuracy: 0.5823\n",
            "Epoch 90/100, Loss: 88.5652, Validation Accuracy: 0.6002\n",
            "Epoch 91/100, Loss: 172.0973, Validation Accuracy: 0.6241\n",
            "Epoch 92/100, Loss: 59.4090, Validation Accuracy: 0.5434\n",
            "Epoch 93/100, Loss: 51.9782, Validation Accuracy: 0.6700\n",
            "Epoch 94/100, Loss: 104.2074, Validation Accuracy: 0.5194\n",
            "Epoch 95/100, Loss: 185.9266, Validation Accuracy: 0.6650\n",
            "Epoch 96/100, Loss: 30.7310, Validation Accuracy: 0.6002\n",
            "Epoch 97/100, Loss: 63.6840, Validation Accuracy: 0.6311\n",
            "Epoch 98/100, Loss: 92.7606, Validation Accuracy: 0.6590\n",
            "Epoch 99/100, Loss: 37.9162, Validation Accuracy: 0.5444\n",
            "Epoch 100/100, Loss: 69.1826, Validation Accuracy: 0.6790\n",
            "Epoch 101/100, Loss: 47.6868, Validation Accuracy: 0.6261\n",
            "Epoch 102/100, Loss: 270.6818, Validation Accuracy: 0.6500\n",
            "Epoch 103/100, Loss: 64.9101, Validation Accuracy: 0.6311\n",
            "Epoch 104/100, Loss: 18.9660, Validation Accuracy: 0.6560\n",
            "Epoch 105/100, Loss: 60.9327, Validation Accuracy: 0.6251\n",
            "Epoch 106/100, Loss: 149.5762, Validation Accuracy: 0.4576\n",
            "Epoch 107/100, Loss: 51.2517, Validation Accuracy: 0.6241\n",
            "Epoch 108/100, Loss: 54.8010, Validation Accuracy: 0.5783\n",
            "Epoch 109/100, Loss: 43.9890, Validation Accuracy: 0.4835\n",
            "Epoch 110/100, Loss: 95.5513, Validation Accuracy: 0.5533\n",
            "Epoch 111/100, Loss: 106.3058, Validation Accuracy: 0.5693\n",
            "Epoch 112/100, Loss: 112.2176, Validation Accuracy: 0.4307\n",
            "Epoch 113/100, Loss: 49.5532, Validation Accuracy: 0.6112\n",
            "Epoch 114/100, Loss: 158.5656, Validation Accuracy: 0.4556\n",
            "Epoch 115/100, Loss: 38.3490, Validation Accuracy: 0.6231\n",
            "Epoch 116/100, Loss: 69.1916, Validation Accuracy: 0.6122\n",
            "Epoch 117/100, Loss: 9.7892, Validation Accuracy: 0.5593\n",
            "Epoch 118/100, Loss: 7.3101, Validation Accuracy: 0.5344\n",
            "Epoch 119/100, Loss: 247.9953, Validation Accuracy: 0.5563\n",
            "Epoch 120/100, Loss: 96.7070, Validation Accuracy: 0.6281\n",
            "Epoch 121/100, Loss: 63.9448, Validation Accuracy: 0.5145\n",
            "Epoch 122/100, Loss: 57.3956, Validation Accuracy: 0.6540\n",
            "Epoch 123/100, Loss: 70.0065, Validation Accuracy: 0.4925\n",
            "Epoch 124/100, Loss: 25.3295, Validation Accuracy: 0.4616\n",
            "Epoch 125/100, Loss: 104.7111, Validation Accuracy: 0.5623\n",
            "Epoch 126/100, Loss: 28.9098, Validation Accuracy: 0.6261\n",
            "Epoch 127/100, Loss: 38.9795, Validation Accuracy: 0.6321\n",
            "Epoch 128/100, Loss: 127.4247, Validation Accuracy: 0.5653\n",
            "Epoch 129/100, Loss: 16.6524, Validation Accuracy: 0.6620\n",
            "Epoch 130/100, Loss: 75.5183, Validation Accuracy: 0.5663\n",
            "Epoch 131/100, Loss: 55.9788, Validation Accuracy: 0.5932\n",
            "Epoch 132/100, Loss: 82.1867, Validation Accuracy: 0.5444\n",
            "Epoch 133/100, Loss: 166.9014, Validation Accuracy: 0.5952\n",
            "Epoch 134/100, Loss: 61.9793, Validation Accuracy: 0.6201\n",
            "Epoch 135/100, Loss: 127.8978, Validation Accuracy: 0.5623\n",
            "Epoch 136/100, Loss: 150.9317, Validation Accuracy: 0.6311\n",
            "Epoch 137/100, Loss: 103.2666, Validation Accuracy: 0.6620\n",
            "Epoch 138/100, Loss: 97.9672, Validation Accuracy: 0.5982\n",
            "Epoch 139/100, Loss: 50.3108, Validation Accuracy: 0.6311\n",
            "Epoch 140/100, Loss: 48.9209, Validation Accuracy: 0.6550\n",
            "Epoch 141/100, Loss: 53.2949, Validation Accuracy: 0.5533\n",
            "Epoch 142/100, Loss: 89.1216, Validation Accuracy: 0.6231\n",
            "Epoch 143/100, Loss: 48.7565, Validation Accuracy: 0.4855\n",
            "Epoch 144/100, Loss: 144.3075, Validation Accuracy: 0.5793\n",
            "Epoch 145/100, Loss: 14.2637, Validation Accuracy: 0.5862\n",
            "Epoch 146/100, Loss: 83.9396, Validation Accuracy: 0.6660\n",
            "Epoch 147/100, Loss: 90.9402, Validation Accuracy: 0.6042\n",
            "Epoch 148/100, Loss: 61.6452, Validation Accuracy: 0.6341\n",
            "Epoch 149/100, Loss: 84.5914, Validation Accuracy: 0.6520\n",
            "Epoch 150/100, Loss: 28.1495, Validation Accuracy: 0.6181\n",
            "Epoch 151/100, Loss: 62.8392, Validation Accuracy: 0.6670\n",
            "Epoch 152/100, Loss: 90.6851, Validation Accuracy: 0.5623\n",
            "Epoch 153/100, Loss: 50.0418, Validation Accuracy: 0.5982\n",
            "Epoch 154/100, Loss: 48.6719, Validation Accuracy: 0.6341\n",
            "Epoch 155/100, Loss: 91.7450, Validation Accuracy: 0.6331\n",
            "Epoch 156/100, Loss: 66.6484, Validation Accuracy: 0.5703\n",
            "Epoch 157/100, Loss: 123.4730, Validation Accuracy: 0.3310\n",
            "Epoch 158/100, Loss: 79.9630, Validation Accuracy: 0.5972\n",
            "Epoch 159/100, Loss: 165.7818, Validation Accuracy: 0.6391\n",
            "Epoch 160/100, Loss: 72.7858, Validation Accuracy: 0.6231\n",
            "Epoch 161/100, Loss: 95.9075, Validation Accuracy: 0.5962\n",
            "Epoch 162/100, Loss: 99.7673, Validation Accuracy: 0.5962\n",
            "Epoch 163/100, Loss: 221.1664, Validation Accuracy: 0.6620\n",
            "Epoch 164/100, Loss: 45.1043, Validation Accuracy: 0.5633\n",
            "Epoch 165/100, Loss: 75.1091, Validation Accuracy: 0.6271\n",
            "Epoch 166/100, Loss: 89.3819, Validation Accuracy: 0.6590\n",
            "Epoch 167/100, Loss: 28.6697, Validation Accuracy: 0.6351\n",
            "Epoch 168/100, Loss: 128.8630, Validation Accuracy: 0.6072\n",
            "Epoch 169/100, Loss: 48.5275, Validation Accuracy: 0.6391\n",
            "Epoch 170/100, Loss: 59.4974, Validation Accuracy: 0.4875\n",
            "Epoch 171/100, Loss: 85.0442, Validation Accuracy: 0.5743\n",
            "Epoch 172/100, Loss: 52.0679, Validation Accuracy: 0.6371\n",
            "Epoch 173/100, Loss: 73.3732, Validation Accuracy: 0.6461\n",
            "Epoch 174/100, Loss: 71.7128, Validation Accuracy: 0.6680\n",
            "Epoch 175/100, Loss: 98.3609, Validation Accuracy: 0.6271\n",
            "Epoch 176/100, Loss: 118.4080, Validation Accuracy: 0.6231\n",
            "Epoch 177/100, Loss: 40.6183, Validation Accuracy: 0.6002\n",
            "Epoch 178/100, Loss: 155.2146, Validation Accuracy: 0.6281\n",
            "Epoch 179/100, Loss: 51.0516, Validation Accuracy: 0.6231\n",
            "Epoch 180/100, Loss: 76.3140, Validation Accuracy: 0.5603\n",
            "Epoch 181/100, Loss: 47.1900, Validation Accuracy: 0.6600\n",
            "Epoch 182/100, Loss: 100.9407, Validation Accuracy: 0.6002\n",
            "Epoch 183/100, Loss: 120.3831, Validation Accuracy: 0.6610\n",
            "Epoch 184/100, Loss: 83.1593, Validation Accuracy: 0.6760\n",
            "Epoch 185/100, Loss: 175.8922, Validation Accuracy: 0.4696\n",
            "Epoch 186/100, Loss: 70.1367, Validation Accuracy: 0.6820\n",
            "Epoch 187/100, Loss: 24.1057, Validation Accuracy: 0.6012\n",
            "Epoch 188/100, Loss: 148.2924, Validation Accuracy: 0.5902\n",
            "Epoch 189/100, Loss: 74.1104, Validation Accuracy: 0.6371\n",
            "Epoch 190/100, Loss: 48.1715, Validation Accuracy: 0.6271\n",
            "Epoch 191/100, Loss: 135.1318, Validation Accuracy: 0.5424\n",
            "Epoch 192/100, Loss: 33.1398, Validation Accuracy: 0.5523\n",
            "Epoch 193/100, Loss: 75.0956, Validation Accuracy: 0.5753\n",
            "Epoch 194/100, Loss: 53.1977, Validation Accuracy: 0.6171\n",
            "Epoch 195/100, Loss: 31.0652, Validation Accuracy: 0.6461\n",
            "Epoch 196/100, Loss: 83.8642, Validation Accuracy: 0.6640\n",
            "Epoch 197/100, Loss: 61.0314, Validation Accuracy: 0.5823\n",
            "Epoch 198/100, Loss: 87.5829, Validation Accuracy: 0.5773\n",
            "Epoch 199/100, Loss: 130.4141, Validation Accuracy: 0.6221\n",
            "Epoch 200/100, Loss: 125.3304, Validation Accuracy: 0.6570\n",
            "Reward for Child Model: 0.2927654939811637\n",
            "Child_97:  {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, [1, 0, 3, 0, 0, 1, 3, 0, 1, 3, 0, 1, 0, 0, 0], 0.2927654939811637\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 48, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(72, 64, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(88, 64, kernel_size=(7, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(64, 48, kernel_size=(1, 5), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=32256, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 22, 24]           2,544\n",
            "       BatchNorm2d-2           [-1, 24, 22, 24]              48\n",
            "            Conv2d-3           [-1, 48, 22, 18]           8,112\n",
            "       BatchNorm2d-4           [-1, 48, 22, 18]              96\n",
            "              ReLU-5           [-1, 48, 22, 18]               0\n",
            "            Conv2d-6           [-1, 64, 16, 22]          96,832\n",
            "       BatchNorm2d-7           [-1, 64, 16, 22]             128\n",
            "              ReLU-8           [-1, 64, 16, 22]               0\n",
            "            Conv2d-9           [-1, 64, 16, 18]         276,032\n",
            "      BatchNorm2d-10           [-1, 64, 16, 18]             128\n",
            "             ReLU-11           [-1, 64, 16, 18]               0\n",
            "           Conv2d-12           [-1, 48, 16, 14]          15,408\n",
            "      BatchNorm2d-13           [-1, 48, 16, 14]              96\n",
            "             ReLU-14           [-1, 48, 16, 14]               0\n",
            "           Linear-15                    [-1, 7]         225,799\n",
            "================================================================\n",
            "Total params: 625,223\n",
            "Trainable params: 625,223\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.81\n",
            "Params size (MB): 2.39\n",
            "Estimated Total Size (MB): 4.21\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 1.3181, Validation Accuracy: 0.6690\n",
            "Epoch 2/100, Loss: 1.1631, Validation Accuracy: 0.6690\n",
            "Epoch 3/100, Loss: 4.6027, Validation Accuracy: 0.6341\n",
            "Epoch 4/100, Loss: 1.2360, Validation Accuracy: 0.6690\n",
            "Epoch 5/100, Loss: 1.2286, Validation Accuracy: 0.6690\n",
            "Epoch 6/100, Loss: 1.1361, Validation Accuracy: 0.6690\n",
            "Epoch 7/100, Loss: 1.2226, Validation Accuracy: 0.6690\n",
            "Epoch 8/100, Loss: 1.6795, Validation Accuracy: 0.6690\n",
            "Epoch 9/100, Loss: 1.3025, Validation Accuracy: 0.6690\n",
            "Epoch 10/100, Loss: 1.0316, Validation Accuracy: 0.6690\n",
            "Epoch 11/100, Loss: 1.2236, Validation Accuracy: 0.6560\n",
            "Epoch 12/100, Loss: 1.7622, Validation Accuracy: 0.6690\n",
            "Epoch 13/100, Loss: 0.8804, Validation Accuracy: 0.6680\n",
            "Epoch 14/100, Loss: 1.9106, Validation Accuracy: 0.6690\n",
            "Epoch 15/100, Loss: 1.1439, Validation Accuracy: 0.6690\n",
            "Epoch 16/100, Loss: 1.0014, Validation Accuracy: 0.6690\n",
            "Epoch 17/100, Loss: 9.5619, Validation Accuracy: 0.2054\n",
            "Epoch 18/100, Loss: 1.1241, Validation Accuracy: 0.6680\n",
            "Epoch 19/100, Loss: 0.8297, Validation Accuracy: 0.6630\n",
            "Epoch 20/100, Loss: 0.8923, Validation Accuracy: 0.6680\n",
            "Epoch 21/100, Loss: 1.0662, Validation Accuracy: 0.6610\n",
            "Epoch 22/100, Loss: 0.7451, Validation Accuracy: 0.6690\n",
            "Epoch 23/100, Loss: 1.5067, Validation Accuracy: 0.6650\n",
            "Epoch 24/100, Loss: 1.4823, Validation Accuracy: 0.6690\n",
            "Epoch 25/100, Loss: 1.0592, Validation Accuracy: 0.6670\n",
            "Epoch 26/100, Loss: 1.0541, Validation Accuracy: 0.6690\n",
            "Epoch 27/100, Loss: 0.9468, Validation Accuracy: 0.6690\n",
            "Epoch 28/100, Loss: 1.1312, Validation Accuracy: 0.6690\n",
            "Epoch 29/100, Loss: 0.8915, Validation Accuracy: 0.6690\n",
            "Epoch 30/100, Loss: 1.0296, Validation Accuracy: 0.6690\n",
            "Epoch 31/100, Loss: 1.3229, Validation Accuracy: 0.6690\n",
            "Epoch 32/100, Loss: 1.1174, Validation Accuracy: 0.6690\n",
            "Epoch 33/100, Loss: 0.9397, Validation Accuracy: 0.6690\n",
            "Epoch 34/100, Loss: 0.8982, Validation Accuracy: 0.6690\n",
            "Epoch 35/100, Loss: 1.3914, Validation Accuracy: 0.6690\n",
            "Epoch 36/100, Loss: 1.5870, Validation Accuracy: 0.6690\n",
            "Epoch 37/100, Loss: 1.4136, Validation Accuracy: 0.6690\n",
            "Epoch 38/100, Loss: 1.0156, Validation Accuracy: 0.6690\n",
            "Epoch 39/100, Loss: 1.9838, Validation Accuracy: 0.6690\n",
            "Epoch 40/100, Loss: 1.0898, Validation Accuracy: 0.6690\n",
            "Epoch 41/100, Loss: 1.2186, Validation Accuracy: 0.6690\n",
            "Epoch 42/100, Loss: 1.0455, Validation Accuracy: 0.6690\n",
            "Epoch 43/100, Loss: 0.8290, Validation Accuracy: 0.6690\n",
            "Epoch 44/100, Loss: 1.3149, Validation Accuracy: 0.6690\n",
            "Epoch 45/100, Loss: 1.0321, Validation Accuracy: 0.6690\n",
            "Epoch 46/100, Loss: 1.0386, Validation Accuracy: 0.6690\n",
            "Epoch 47/100, Loss: 1.1240, Validation Accuracy: 0.6690\n",
            "Epoch 48/100, Loss: 1.0875, Validation Accuracy: 0.6690\n",
            "Epoch 49/100, Loss: 0.8171, Validation Accuracy: 0.6690\n",
            "Epoch 50/100, Loss: 1.3789, Validation Accuracy: 0.6690\n",
            "Epoch 51/100, Loss: 0.8855, Validation Accuracy: 0.6690\n",
            "Epoch 52/100, Loss: 1.1357, Validation Accuracy: 0.6690\n",
            "Epoch 53/100, Loss: 1.2857, Validation Accuracy: 0.6690\n",
            "Epoch 54/100, Loss: 1.2067, Validation Accuracy: 0.6690\n",
            "Epoch 55/100, Loss: 1.2346, Validation Accuracy: 0.6690\n",
            "Epoch 56/100, Loss: 1.1165, Validation Accuracy: 0.6690\n",
            "Epoch 57/100, Loss: 1.1326, Validation Accuracy: 0.6690\n",
            "Epoch 58/100, Loss: 1.1948, Validation Accuracy: 0.6690\n",
            "Epoch 59/100, Loss: 1.2305, Validation Accuracy: 0.6690\n",
            "Epoch 60/100, Loss: 1.1448, Validation Accuracy: 0.6690\n",
            "Epoch 61/100, Loss: 0.9519, Validation Accuracy: 0.6690\n",
            "Epoch 62/100, Loss: 1.4130, Validation Accuracy: 0.6690\n",
            "Epoch 63/100, Loss: 1.2083, Validation Accuracy: 0.6690\n",
            "Epoch 64/100, Loss: 0.9397, Validation Accuracy: 0.6690\n",
            "Epoch 65/100, Loss: 1.0455, Validation Accuracy: 0.6690\n",
            "Epoch 66/100, Loss: 1.2944, Validation Accuracy: 0.6690\n",
            "Epoch 67/100, Loss: 0.8516, Validation Accuracy: 0.6690\n",
            "Epoch 68/100, Loss: 1.2816, Validation Accuracy: 0.6690\n",
            "Epoch 69/100, Loss: 1.2387, Validation Accuracy: 0.6690\n",
            "Epoch 70/100, Loss: 0.8020, Validation Accuracy: 0.6690\n",
            "Epoch 71/100, Loss: 1.0886, Validation Accuracy: 0.6690\n",
            "Epoch 72/100, Loss: 1.2911, Validation Accuracy: 0.6690\n",
            "Epoch 73/100, Loss: 0.9159, Validation Accuracy: 0.6690\n",
            "Epoch 74/100, Loss: 1.0689, Validation Accuracy: 0.6690\n",
            "Epoch 75/100, Loss: 1.2544, Validation Accuracy: 0.6690\n",
            "Epoch 76/100, Loss: 1.0810, Validation Accuracy: 0.6690\n",
            "Epoch 77/100, Loss: 1.0987, Validation Accuracy: 0.6690\n",
            "Epoch 78/100, Loss: 1.0757, Validation Accuracy: 0.6690\n",
            "Epoch 79/100, Loss: 1.3655, Validation Accuracy: 0.6690\n",
            "Epoch 80/100, Loss: 1.0970, Validation Accuracy: 0.6690\n",
            "Epoch 81/100, Loss: 1.2138, Validation Accuracy: 0.6690\n",
            "Epoch 82/100, Loss: 1.0810, Validation Accuracy: 0.6690\n",
            "Epoch 83/100, Loss: 0.8485, Validation Accuracy: 0.6690\n",
            "Epoch 84/100, Loss: 0.9464, Validation Accuracy: 0.6690\n",
            "Epoch 85/100, Loss: 1.0345, Validation Accuracy: 0.6690\n",
            "Epoch 86/100, Loss: 0.9685, Validation Accuracy: 0.6690\n",
            "Epoch 87/100, Loss: 1.2024, Validation Accuracy: 0.6690\n",
            "Epoch 88/100, Loss: 1.1401, Validation Accuracy: 0.6690\n",
            "Epoch 89/100, Loss: 1.2842, Validation Accuracy: 0.6690\n",
            "Epoch 90/100, Loss: 1.3348, Validation Accuracy: 0.6690\n",
            "Epoch 91/100, Loss: 1.0877, Validation Accuracy: 0.6690\n",
            "Epoch 92/100, Loss: 1.1083, Validation Accuracy: 0.6690\n",
            "Epoch 93/100, Loss: 1.0155, Validation Accuracy: 0.6690\n",
            "Epoch 94/100, Loss: 1.1278, Validation Accuracy: 0.6690\n",
            "Epoch 95/100, Loss: 1.2623, Validation Accuracy: 0.6690\n",
            "Epoch 96/100, Loss: 1.2394, Validation Accuracy: 0.6690\n",
            "Epoch 97/100, Loss: 0.9362, Validation Accuracy: 0.6690\n",
            "Epoch 98/100, Loss: 1.1468, Validation Accuracy: 0.6690\n",
            "Epoch 99/100, Loss: 1.3679, Validation Accuracy: 0.6690\n",
            "Epoch 100/100, Loss: 1.1912, Validation Accuracy: 0.6690\n",
            "Epoch 101/100, Loss: 0.7086, Validation Accuracy: 0.6690\n",
            "Epoch 102/100, Loss: 1.3740, Validation Accuracy: 0.6690\n",
            "Epoch 103/100, Loss: 1.2538, Validation Accuracy: 0.6690\n",
            "Epoch 104/100, Loss: 0.9107, Validation Accuracy: 0.6690\n",
            "Epoch 105/100, Loss: 1.2590, Validation Accuracy: 0.6690\n",
            "Epoch 106/100, Loss: 1.1200, Validation Accuracy: 0.6690\n",
            "Epoch 107/100, Loss: 1.0435, Validation Accuracy: 0.6690\n",
            "Epoch 108/100, Loss: 1.1727, Validation Accuracy: 0.6690\n",
            "Epoch 109/100, Loss: 1.3195, Validation Accuracy: 0.6690\n",
            "Epoch 110/100, Loss: 1.0852, Validation Accuracy: 0.6690\n",
            "Epoch 111/100, Loss: 1.2219, Validation Accuracy: 0.6690\n",
            "Epoch 112/100, Loss: 1.1236, Validation Accuracy: 0.6690\n",
            "Epoch 113/100, Loss: 1.1744, Validation Accuracy: 0.6690\n",
            "Epoch 114/100, Loss: 1.0678, Validation Accuracy: 0.6690\n",
            "Epoch 115/100, Loss: 0.9697, Validation Accuracy: 0.6690\n",
            "Epoch 116/100, Loss: 0.9746, Validation Accuracy: 0.6690\n",
            "Epoch 117/100, Loss: 1.3405, Validation Accuracy: 0.6690\n",
            "Epoch 118/100, Loss: 1.2003, Validation Accuracy: 0.6690\n",
            "Epoch 119/100, Loss: 1.3049, Validation Accuracy: 0.6690\n",
            "Epoch 120/100, Loss: 0.9381, Validation Accuracy: 0.6690\n",
            "Epoch 121/100, Loss: 1.1172, Validation Accuracy: 0.6690\n",
            "Epoch 122/100, Loss: 1.4763, Validation Accuracy: 0.6690\n",
            "Epoch 123/100, Loss: 1.0121, Validation Accuracy: 0.6690\n",
            "Epoch 124/100, Loss: 1.0522, Validation Accuracy: 0.6690\n",
            "Epoch 125/100, Loss: 1.5275, Validation Accuracy: 0.6690\n",
            "Epoch 126/100, Loss: 1.1870, Validation Accuracy: 0.6690\n",
            "Epoch 127/100, Loss: 1.7872, Validation Accuracy: 0.6690\n",
            "Epoch 128/100, Loss: 1.3649, Validation Accuracy: 0.6690\n",
            "Epoch 129/100, Loss: 1.1457, Validation Accuracy: 0.6690\n",
            "Epoch 130/100, Loss: 0.8948, Validation Accuracy: 0.6690\n",
            "Epoch 131/100, Loss: 1.5407, Validation Accuracy: 0.6690\n",
            "Epoch 132/100, Loss: 0.8890, Validation Accuracy: 0.6690\n",
            "Epoch 133/100, Loss: 1.1982, Validation Accuracy: 0.6690\n",
            "Epoch 134/100, Loss: 1.2451, Validation Accuracy: 0.6690\n",
            "Epoch 135/100, Loss: 1.0504, Validation Accuracy: 0.6690\n",
            "Epoch 136/100, Loss: 1.1976, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 1.0792, Validation Accuracy: 0.6690\n",
            "Epoch 138/100, Loss: 1.4893, Validation Accuracy: 0.6690\n",
            "Epoch 139/100, Loss: 1.0737, Validation Accuracy: 0.6690\n",
            "Epoch 140/100, Loss: 0.8863, Validation Accuracy: 0.6690\n",
            "Epoch 141/100, Loss: 1.1905, Validation Accuracy: 0.6690\n",
            "Epoch 142/100, Loss: 1.0912, Validation Accuracy: 0.6690\n",
            "Epoch 143/100, Loss: 1.1130, Validation Accuracy: 0.6690\n",
            "Epoch 144/100, Loss: 1.3621, Validation Accuracy: 0.6690\n",
            "Epoch 145/100, Loss: 0.9184, Validation Accuracy: 0.6690\n",
            "Epoch 146/100, Loss: 0.8718, Validation Accuracy: 0.6690\n",
            "Epoch 147/100, Loss: 1.2078, Validation Accuracy: 0.6690\n",
            "Epoch 148/100, Loss: 0.9389, Validation Accuracy: 0.6690\n",
            "Epoch 149/100, Loss: 1.0685, Validation Accuracy: 0.6690\n",
            "Epoch 150/100, Loss: 1.1204, Validation Accuracy: 0.6690\n",
            "Epoch 151/100, Loss: 1.0687, Validation Accuracy: 0.6690\n",
            "Epoch 152/100, Loss: 1.0588, Validation Accuracy: 0.6690\n",
            "Epoch 153/100, Loss: 1.1161, Validation Accuracy: 0.6690\n",
            "Epoch 154/100, Loss: 1.1678, Validation Accuracy: 0.6690\n",
            "Epoch 155/100, Loss: 0.8312, Validation Accuracy: 0.6690\n",
            "Epoch 156/100, Loss: 1.0609, Validation Accuracy: 0.6690\n",
            "Epoch 157/100, Loss: 1.1261, Validation Accuracy: 0.6690\n",
            "Epoch 158/100, Loss: 1.0480, Validation Accuracy: 0.6690\n",
            "Epoch 159/100, Loss: 0.8684, Validation Accuracy: 0.6690\n",
            "Epoch 160/100, Loss: 1.1063, Validation Accuracy: 0.6690\n",
            "Epoch 161/100, Loss: 1.0135, Validation Accuracy: 0.6690\n",
            "Epoch 162/100, Loss: 1.0796, Validation Accuracy: 0.6690\n",
            "Epoch 163/100, Loss: 0.9767, Validation Accuracy: 0.6690\n",
            "Epoch 164/100, Loss: 1.3777, Validation Accuracy: 0.6690\n",
            "Epoch 165/100, Loss: 1.1673, Validation Accuracy: 0.6690\n",
            "Epoch 166/100, Loss: 1.0273, Validation Accuracy: 0.6690\n",
            "Epoch 167/100, Loss: 1.0943, Validation Accuracy: 0.6690\n",
            "Epoch 168/100, Loss: 1.2298, Validation Accuracy: 0.6690\n",
            "Epoch 169/100, Loss: 1.2049, Validation Accuracy: 0.6690\n",
            "Epoch 170/100, Loss: 1.5379, Validation Accuracy: 0.6690\n",
            "Epoch 171/100, Loss: 1.2616, Validation Accuracy: 0.6690\n",
            "Epoch 172/100, Loss: 0.9937, Validation Accuracy: 0.6690\n",
            "Epoch 173/100, Loss: 0.9477, Validation Accuracy: 0.6690\n",
            "Epoch 174/100, Loss: 1.3096, Validation Accuracy: 0.6690\n",
            "Epoch 175/100, Loss: 1.3040, Validation Accuracy: 0.6690\n",
            "Epoch 176/100, Loss: 1.3062, Validation Accuracy: 0.6690\n",
            "Epoch 177/100, Loss: 1.0779, Validation Accuracy: 0.6690\n",
            "Epoch 178/100, Loss: 1.4038, Validation Accuracy: 0.6690\n",
            "Epoch 179/100, Loss: 0.8262, Validation Accuracy: 0.6690\n",
            "Epoch 180/100, Loss: 0.8647, Validation Accuracy: 0.6690\n",
            "Epoch 181/100, Loss: 1.5164, Validation Accuracy: 0.6690\n",
            "Epoch 182/100, Loss: 1.1384, Validation Accuracy: 0.6690\n",
            "Epoch 183/100, Loss: 1.1564, Validation Accuracy: 0.6690\n",
            "Epoch 184/100, Loss: 0.8422, Validation Accuracy: 0.6690\n",
            "Epoch 185/100, Loss: 1.2259, Validation Accuracy: 0.6690\n",
            "Epoch 186/100, Loss: 0.9919, Validation Accuracy: 0.6690\n",
            "Epoch 187/100, Loss: 0.8779, Validation Accuracy: 0.6690\n",
            "Epoch 188/100, Loss: 0.9572, Validation Accuracy: 0.6690\n",
            "Epoch 189/100, Loss: 1.0314, Validation Accuracy: 0.6690\n",
            "Epoch 190/100, Loss: 1.2904, Validation Accuracy: 0.6690\n",
            "Epoch 191/100, Loss: 1.6681, Validation Accuracy: 0.6690\n",
            "Epoch 192/100, Loss: 1.1049, Validation Accuracy: 0.6690\n",
            "Epoch 193/100, Loss: 1.5590, Validation Accuracy: 0.6690\n",
            "Epoch 194/100, Loss: 1.0209, Validation Accuracy: 0.6690\n",
            "Epoch 195/100, Loss: 1.1133, Validation Accuracy: 0.6690\n",
            "Epoch 196/100, Loss: 1.3465, Validation Accuracy: 0.6690\n",
            "Epoch 197/100, Loss: 1.2800, Validation Accuracy: 0.6690\n",
            "Epoch 198/100, Loss: 0.9924, Validation Accuracy: 0.6690\n",
            "Epoch 199/100, Loss: 1.0681, Validation Accuracy: 0.6690\n",
            "Epoch 200/100, Loss: 0.9198, Validation Accuracy: 0.6690\n",
            "Reward for Child Model: 0.2994089384287623\n",
            "Child_98:  {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, [3, 2, 0, 0, 3, 2, 3, 1, 3, 3, 3, 3, 0, 2, 2], 0.2994089384287623\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 24, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(64, 24, kernel_size=(7, 5), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(112, 64, kernel_size=(7, 1), stride=(1, 1))\n",
            "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(64, 48, kernel_size=(5, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=164736, out_features=7, bias=True)\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 24, 22, 24]           2,544\n",
            "       BatchNorm2d-2           [-1, 24, 22, 24]              48\n",
            "            Conv2d-3           [-1, 64, 20, 22]          13,888\n",
            "       BatchNorm2d-4           [-1, 64, 20, 22]             128\n",
            "              ReLU-5           [-1, 64, 20, 22]               0\n",
            "            Conv2d-6           [-1, 24, 14, 18]          53,784\n",
            "       BatchNorm2d-7           [-1, 24, 14, 18]              48\n",
            "              ReLU-8           [-1, 24, 14, 18]               0\n",
            "            Conv2d-9           [-1, 64, 16, 24]          50,240\n",
            "      BatchNorm2d-10           [-1, 64, 16, 24]             128\n",
            "             ReLU-11           [-1, 64, 16, 24]               0\n",
            "           Conv2d-12           [-1, 48, 12, 18]         107,568\n",
            "      BatchNorm2d-13           [-1, 48, 12, 18]              96\n",
            "             ReLU-14           [-1, 48, 12, 18]               0\n",
            "           Linear-15                    [-1, 7]       1,153,159\n",
            "================================================================\n",
            "Total params: 1,381,631\n",
            "Trainable params: 1,381,631\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.78\n",
            "Params size (MB): 5.27\n",
            "Estimated Total Size (MB): 7.06\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/100, Loss: 81.0649, Validation Accuracy: 0.6122\n",
            "Epoch 2/100, Loss: 24.2627, Validation Accuracy: 0.2343\n",
            "Epoch 3/100, Loss: 12.2854, Validation Accuracy: 0.5294\n",
            "Epoch 4/100, Loss: 198.4742, Validation Accuracy: 0.5284\n",
            "Epoch 5/100, Loss: 13.3420, Validation Accuracy: 0.6251\n",
            "Epoch 6/100, Loss: 209.4342, Validation Accuracy: 0.5852\n",
            "Epoch 7/100, Loss: 35.6575, Validation Accuracy: 0.6032\n",
            "Epoch 8/100, Loss: 79.8929, Validation Accuracy: 0.6311\n",
            "Epoch 9/100, Loss: 7.4177, Validation Accuracy: 0.6491\n",
            "Epoch 10/100, Loss: 81.5608, Validation Accuracy: 0.5384\n",
            "Epoch 11/100, Loss: 5.6833, Validation Accuracy: 0.6321\n",
            "Epoch 12/100, Loss: 104.5646, Validation Accuracy: 0.4347\n",
            "Epoch 13/100, Loss: 58.6443, Validation Accuracy: 0.5882\n",
            "Epoch 14/100, Loss: 4.3065, Validation Accuracy: 0.6461\n",
            "Epoch 15/100, Loss: 6.6579, Validation Accuracy: 0.5264\n",
            "Epoch 16/100, Loss: 26.8135, Validation Accuracy: 0.4885\n",
            "Epoch 17/100, Loss: 156.9488, Validation Accuracy: 0.6022\n",
            "Epoch 18/100, Loss: 12.4795, Validation Accuracy: 0.5254\n",
            "Epoch 19/100, Loss: 4.2551, Validation Accuracy: 0.6600\n",
            "Epoch 20/100, Loss: 2.7924, Validation Accuracy: 0.3779\n",
            "Epoch 21/100, Loss: 9.9039, Validation Accuracy: 0.5494\n",
            "Epoch 22/100, Loss: 12.1001, Validation Accuracy: 0.5882\n",
            "Epoch 23/100, Loss: 3.6745, Validation Accuracy: 0.5155\n",
            "Epoch 24/100, Loss: 3.3063, Validation Accuracy: 0.6471\n",
            "Epoch 25/100, Loss: 164.8338, Validation Accuracy: 0.6690\n",
            "Epoch 26/100, Loss: 7.1025, Validation Accuracy: 0.6291\n",
            "Epoch 27/100, Loss: 9.9881, Validation Accuracy: 0.5683\n",
            "Epoch 28/100, Loss: 225.4201, Validation Accuracy: 0.6849\n",
            "Epoch 29/100, Loss: 17.6784, Validation Accuracy: 0.6461\n",
            "Epoch 30/100, Loss: 7.7093, Validation Accuracy: 0.6421\n",
            "Epoch 31/100, Loss: 16.1826, Validation Accuracy: 0.5583\n",
            "Epoch 32/100, Loss: 17.8640, Validation Accuracy: 0.6491\n",
            "Epoch 33/100, Loss: 6.9731, Validation Accuracy: 0.5892\n",
            "Epoch 34/100, Loss: 16.8122, Validation Accuracy: 0.5593\n",
            "Epoch 35/100, Loss: 22.4101, Validation Accuracy: 0.6261\n",
            "Epoch 36/100, Loss: 17.9950, Validation Accuracy: 0.5663\n",
            "Epoch 37/100, Loss: 64.3165, Validation Accuracy: 0.6361\n",
            "Epoch 38/100, Loss: 8.4561, Validation Accuracy: 0.5942\n",
            "Epoch 39/100, Loss: 74.8519, Validation Accuracy: 0.4666\n",
            "Epoch 40/100, Loss: 6.8022, Validation Accuracy: 0.6201\n",
            "Epoch 41/100, Loss: 19.1180, Validation Accuracy: 0.5075\n",
            "Epoch 42/100, Loss: 5.5329, Validation Accuracy: 0.5942\n",
            "Epoch 43/100, Loss: 16.1910, Validation Accuracy: 0.6590\n",
            "Epoch 44/100, Loss: 3.7976, Validation Accuracy: 0.6042\n",
            "Epoch 45/100, Loss: 5.6342, Validation Accuracy: 0.5663\n",
            "Epoch 46/100, Loss: 28.4600, Validation Accuracy: 0.5314\n",
            "Epoch 47/100, Loss: 228.8440, Validation Accuracy: 0.5474\n",
            "Epoch 48/100, Loss: 11.7218, Validation Accuracy: 0.6281\n",
            "Epoch 49/100, Loss: 4.7724, Validation Accuracy: 0.6640\n",
            "Epoch 50/100, Loss: 14.4302, Validation Accuracy: 0.6640\n",
            "Epoch 51/100, Loss: 110.3444, Validation Accuracy: 0.6331\n",
            "Epoch 52/100, Loss: 10.4641, Validation Accuracy: 0.5533\n",
            "Epoch 53/100, Loss: 11.4954, Validation Accuracy: 0.6750\n",
            "Epoch 54/100, Loss: 7.7062, Validation Accuracy: 0.5254\n",
            "Epoch 55/100, Loss: 9.1040, Validation Accuracy: 0.4227\n",
            "Epoch 56/100, Loss: 1960.7339, Validation Accuracy: 0.5783\n",
            "Epoch 57/100, Loss: 225.3392, Validation Accuracy: 0.6162\n",
            "Epoch 58/100, Loss: 167.4666, Validation Accuracy: 0.5364\n",
            "Epoch 59/100, Loss: 27.1972, Validation Accuracy: 0.6361\n",
            "Epoch 60/100, Loss: 39.8645, Validation Accuracy: 0.5683\n",
            "Epoch 61/100, Loss: 70.2099, Validation Accuracy: 0.0140\n",
            "Epoch 62/100, Loss: 11.0660, Validation Accuracy: 0.5184\n",
            "Epoch 63/100, Loss: 4.3133, Validation Accuracy: 0.6600\n",
            "Epoch 64/100, Loss: 246.7678, Validation Accuracy: 0.6570\n",
            "Epoch 65/100, Loss: 6.1629, Validation Accuracy: 0.5683\n",
            "Epoch 66/100, Loss: 4.9268, Validation Accuracy: 0.6650\n",
            "Epoch 67/100, Loss: 46.0849, Validation Accuracy: 0.5284\n",
            "Epoch 68/100, Loss: 339.7170, Validation Accuracy: 0.4337\n",
            "Epoch 69/100, Loss: 204.0595, Validation Accuracy: 0.5075\n",
            "Epoch 70/100, Loss: 45.3089, Validation Accuracy: 0.5783\n",
            "Epoch 71/100, Loss: 141.8965, Validation Accuracy: 0.5833\n",
            "Epoch 72/100, Loss: 2732.4980, Validation Accuracy: 0.5244\n",
            "Epoch 73/100, Loss: 265.0917, Validation Accuracy: 0.5892\n",
            "Epoch 74/100, Loss: 197.3184, Validation Accuracy: 0.6381\n",
            "Epoch 75/100, Loss: 301.4246, Validation Accuracy: 0.5962\n",
            "Epoch 76/100, Loss: 144.7822, Validation Accuracy: 0.5573\n",
            "Epoch 77/100, Loss: 195.0643, Validation Accuracy: 0.6540\n",
            "Epoch 78/100, Loss: 28.8342, Validation Accuracy: 0.3928\n",
            "Epoch 79/100, Loss: 70.1786, Validation Accuracy: 0.5494\n",
            "Epoch 80/100, Loss: 35.9742, Validation Accuracy: 0.6311\n",
            "Epoch 81/100, Loss: 27.4622, Validation Accuracy: 0.5823\n",
            "Epoch 82/100, Loss: 75.6302, Validation Accuracy: 0.6780\n",
            "Epoch 83/100, Loss: 10.4756, Validation Accuracy: 0.6461\n",
            "Epoch 84/100, Loss: 35.0695, Validation Accuracy: 0.4267\n",
            "Epoch 85/100, Loss: 20.2051, Validation Accuracy: 0.6092\n",
            "Epoch 86/100, Loss: 12.8497, Validation Accuracy: 0.6461\n",
            "Epoch 87/100, Loss: 10.9904, Validation Accuracy: 0.6620\n",
            "Epoch 88/100, Loss: 5.0356, Validation Accuracy: 0.6740\n",
            "Epoch 89/100, Loss: 7.2455, Validation Accuracy: 0.5643\n",
            "Epoch 90/100, Loss: 6.4374, Validation Accuracy: 0.6929\n",
            "Epoch 91/100, Loss: 60.3109, Validation Accuracy: 0.6550\n",
            "Epoch 92/100, Loss: 15.0105, Validation Accuracy: 0.5613\n",
            "Epoch 93/100, Loss: 9.3537, Validation Accuracy: 0.6650\n",
            "Epoch 94/100, Loss: 9.0807, Validation Accuracy: 0.6022\n",
            "Epoch 95/100, Loss: 55.4052, Validation Accuracy: 0.6231\n",
            "Epoch 96/100, Loss: 11.8064, Validation Accuracy: 0.5952\n",
            "Epoch 97/100, Loss: 3.4053, Validation Accuracy: 0.5942\n",
            "Epoch 98/100, Loss: 65.1966, Validation Accuracy: 0.4945\n",
            "Epoch 99/100, Loss: 4.1717, Validation Accuracy: 0.5852\n",
            "Epoch 100/100, Loss: 9.5447, Validation Accuracy: 0.6311\n",
            "Epoch 101/100, Loss: 4.1953, Validation Accuracy: 0.4766\n",
            "Epoch 102/100, Loss: 4.4642, Validation Accuracy: 0.5663\n",
            "Epoch 103/100, Loss: 16.1687, Validation Accuracy: 0.3529\n",
            "Epoch 104/100, Loss: 59.4461, Validation Accuracy: 0.5593\n",
            "Epoch 105/100, Loss: 18.5548, Validation Accuracy: 0.5862\n",
            "Epoch 106/100, Loss: 5.0013, Validation Accuracy: 0.6361\n",
            "Epoch 107/100, Loss: 5.2863, Validation Accuracy: 0.5962\n",
            "Epoch 108/100, Loss: 54.5300, Validation Accuracy: 0.5783\n",
            "Epoch 109/100, Loss: 38.8852, Validation Accuracy: 0.5324\n",
            "Epoch 110/100, Loss: 14.3008, Validation Accuracy: 0.6461\n",
            "Epoch 111/100, Loss: 19.4993, Validation Accuracy: 0.4267\n",
            "Epoch 112/100, Loss: 5.8195, Validation Accuracy: 0.6142\n",
            "Epoch 113/100, Loss: 36.9129, Validation Accuracy: 0.5862\n",
            "Epoch 114/100, Loss: 6.4383, Validation Accuracy: 0.4138\n",
            "Epoch 115/100, Loss: 230.3118, Validation Accuracy: 0.5464\n",
            "Epoch 116/100, Loss: 397.7807, Validation Accuracy: 0.6002\n",
            "Epoch 117/100, Loss: 31.7396, Validation Accuracy: 0.6102\n",
            "Epoch 118/100, Loss: 26.0374, Validation Accuracy: 0.6461\n",
            "Epoch 119/100, Loss: 247.3455, Validation Accuracy: 0.5673\n",
            "Epoch 120/100, Loss: 41.1924, Validation Accuracy: 0.5324\n",
            "Epoch 121/100, Loss: 5.7614, Validation Accuracy: 0.6560\n",
            "Epoch 122/100, Loss: 24.0013, Validation Accuracy: 0.5194\n",
            "Epoch 123/100, Loss: 4.9971, Validation Accuracy: 0.5833\n",
            "Epoch 124/100, Loss: 5.9316, Validation Accuracy: 0.6471\n",
            "Epoch 125/100, Loss: 4.8575, Validation Accuracy: 0.6451\n",
            "Epoch 126/100, Loss: 4.0965, Validation Accuracy: 0.5613\n",
            "Epoch 127/100, Loss: 7.3625, Validation Accuracy: 0.5244\n",
            "Epoch 128/100, Loss: 3.4968, Validation Accuracy: 0.5882\n",
            "Epoch 129/100, Loss: 12.6065, Validation Accuracy: 0.5444\n",
            "Epoch 130/100, Loss: 2.9531, Validation Accuracy: 0.6271\n",
            "Epoch 131/100, Loss: 13.5188, Validation Accuracy: 0.5304\n",
            "Epoch 132/100, Loss: 11.9357, Validation Accuracy: 0.5174\n",
            "Epoch 133/100, Loss: 22.0569, Validation Accuracy: 0.5224\n",
            "Epoch 134/100, Loss: 18.3119, Validation Accuracy: 0.4377\n",
            "Epoch 135/100, Loss: 28.9077, Validation Accuracy: 0.6520\n",
            "Epoch 136/100, Loss: 12.0200, Validation Accuracy: 0.6690\n",
            "Epoch 137/100, Loss: 23.2297, Validation Accuracy: 0.6411\n",
            "Epoch 138/100, Loss: 13.0941, Validation Accuracy: 0.5344\n",
            "Epoch 139/100, Loss: 86.9127, Validation Accuracy: 0.6441\n",
            "Epoch 140/100, Loss: 23.9211, Validation Accuracy: 0.5474\n",
            "Epoch 141/100, Loss: 11.1998, Validation Accuracy: 0.6570\n",
            "Epoch 142/100, Loss: 25.1226, Validation Accuracy: 0.6670\n",
            "Epoch 143/100, Loss: 12.6631, Validation Accuracy: 0.5922\n",
            "Epoch 144/100, Loss: 4.9112, Validation Accuracy: 0.6859\n",
            "Epoch 145/100, Loss: 11.5405, Validation Accuracy: 0.5374\n",
            "Epoch 146/100, Loss: 33.4989, Validation Accuracy: 0.6002\n",
            "Epoch 147/100, Loss: 143.8475, Validation Accuracy: 0.4586\n",
            "Epoch 148/100, Loss: 19.0074, Validation Accuracy: 0.6331\n",
            "Epoch 149/100, Loss: 7.8842, Validation Accuracy: 0.5982\n",
            "Epoch 150/100, Loss: 11.9353, Validation Accuracy: 0.5703\n",
            "Epoch 151/100, Loss: 12.5717, Validation Accuracy: 0.6002\n",
            "Epoch 152/100, Loss: 20.6261, Validation Accuracy: 0.3509\n",
            "Epoch 153/100, Loss: 25.4936, Validation Accuracy: 0.6122\n",
            "Epoch 154/100, Loss: 148.0232, Validation Accuracy: 0.4546\n",
            "Epoch 155/100, Loss: 41.3728, Validation Accuracy: 0.6221\n",
            "Epoch 156/100, Loss: 19.1489, Validation Accuracy: 0.5912\n",
            "Epoch 157/100, Loss: 18.7794, Validation Accuracy: 0.5982\n",
            "Epoch 158/100, Loss: 5.4640, Validation Accuracy: 0.6481\n",
            "Epoch 159/100, Loss: 138.2587, Validation Accuracy: 0.4816\n",
            "Epoch 160/100, Loss: 36.1418, Validation Accuracy: 0.5214\n",
            "Epoch 161/100, Loss: 20.0322, Validation Accuracy: 0.5374\n",
            "Epoch 162/100, Loss: 7.2923, Validation Accuracy: 0.6042\n",
            "Epoch 163/100, Loss: 9.9975, Validation Accuracy: 0.6092\n",
            "Epoch 164/100, Loss: 30.9259, Validation Accuracy: 0.5753\n",
            "Epoch 165/100, Loss: 70.0102, Validation Accuracy: 0.6062\n",
            "Epoch 166/100, Loss: 5.4708, Validation Accuracy: 0.5803\n",
            "Epoch 167/100, Loss: 35.0274, Validation Accuracy: 0.6530\n",
            "Epoch 168/100, Loss: 12.3815, Validation Accuracy: 0.6820\n",
            "Epoch 169/100, Loss: 24.3913, Validation Accuracy: 0.3819\n",
            "Epoch 170/100, Loss: 33.5706, Validation Accuracy: 0.6411\n",
            "Epoch 171/100, Loss: 46.3116, Validation Accuracy: 0.5733\n",
            "Epoch 172/100, Loss: 20.8604, Validation Accuracy: 0.6072\n",
            "Epoch 173/100, Loss: 11.7529, Validation Accuracy: 0.5583\n",
            "Epoch 174/100, Loss: 17.3084, Validation Accuracy: 0.6002\n",
            "Epoch 175/100, Loss: 49.9567, Validation Accuracy: 0.5344\n",
            "Epoch 176/100, Loss: 90.1598, Validation Accuracy: 0.5872\n",
            "Epoch 177/100, Loss: 17.3355, Validation Accuracy: 0.5454\n",
            "Epoch 178/100, Loss: 16.5385, Validation Accuracy: 0.6052\n",
            "Epoch 179/100, Loss: 3.4734, Validation Accuracy: 0.6321\n",
            "Epoch 180/100, Loss: 20.1690, Validation Accuracy: 0.1795\n",
            "Epoch 181/100, Loss: 24.1200, Validation Accuracy: 0.6331\n",
            "Epoch 182/100, Loss: 18.9066, Validation Accuracy: 0.6570\n",
            "Epoch 183/100, Loss: 20.7077, Validation Accuracy: 0.4058\n",
            "Epoch 184/100, Loss: 13.6123, Validation Accuracy: 0.6311\n",
            "Epoch 185/100, Loss: 8.1098, Validation Accuracy: 0.5364\n",
            "Epoch 186/100, Loss: 4.5947, Validation Accuracy: 0.5563\n",
            "Epoch 187/100, Loss: 7.9126, Validation Accuracy: 0.6042\n",
            "Epoch 188/100, Loss: 15.6659, Validation Accuracy: 0.5543\n",
            "Epoch 189/100, Loss: 7.4931, Validation Accuracy: 0.5723\n",
            "Epoch 190/100, Loss: 20.1649, Validation Accuracy: 0.4955\n",
            "Epoch 191/100, Loss: 23.6229, Validation Accuracy: 0.5503\n",
            "Epoch 192/100, Loss: 46.5252, Validation Accuracy: 0.6590\n",
            "Epoch 193/100, Loss: 108.8232, Validation Accuracy: 0.6012\n",
            "Epoch 194/100, Loss: 11.9057, Validation Accuracy: 0.6102\n",
            "Epoch 195/100, Loss: 11.8012, Validation Accuracy: 0.5394\n",
            "Epoch 196/100, Loss: 11.4626, Validation Accuracy: 0.6560\n",
            "Epoch 197/100, Loss: 12.3916, Validation Accuracy: 0.5334\n",
            "Epoch 198/100, Loss: 29.0343, Validation Accuracy: 0.6680\n",
            "Epoch 199/100, Loss: 37.7586, Validation Accuracy: 0.6620\n",
            "Epoch 200/100, Loss: 18.3228, Validation Accuracy: 0.5882\n",
            "Reward for Child Model: 0.2980722933598883\n",
            "Child_99:  {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, [3, 2, 0, 1, 1, 3, 3, 2, 0, 3, 0, 3, 2, 3, 2], 0.2980722933598883\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "def To_saveR(id, skips, labels, rewards):     # convert to a saveable format for unique architecture\n",
        "  data=[]\n",
        "  data.append({\"id\": id, \"label\": labels, \"skips\": skips, \"rewards\": rewards})\n",
        "  df = pd.DataFrame(data)\n",
        "  return df\n",
        "\n",
        "def Train_random_models(R_labels, R_skips, num_epochs, learning_rate = 0.1):\n",
        "    child_model = child_network([1,3,28,28],7,vocab,R_labels, R_skips)\n",
        "    # model_parameters = child_model.parameters()\n",
        "    # print(model_parameters)\n",
        "    \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    child_model = child_model.to(device)\n",
        "    \n",
        "    \n",
        "    summary(child_model,(3,28,28), device= \"cuda\")\n",
        "    optimizer = Adam(child_model.parameters(), lr=learning_rate)\n",
        "    validation_accuracies = []\n",
        "    reward_per_20 = []\n",
        "    # start_time = time.time()\n",
        "    id = 0\n",
        "    for epoch in range(200):\n",
        "        child_model.train()\n",
        "        for inputs, targets in Mtrain_loader:\n",
        "            inputs = inputs.float().to(device)\n",
        "            # F.dropout(inputs, p=0.2, training=True, inplace=False)\n",
        "            targets = targets.float().to(device)\n",
        "            # print(type(inputs))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = child_model(inputs)\n",
        "            # print(\"training_output\",outputs)\n",
        "            targets = targets.squeeze().long()\n",
        "            # print(\"target shap is \", targets)\n",
        "            loss = F.cross_entropy(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        # print(\"training endtime: \")\n",
        "        \n",
        "        child_model.eval()\n",
        "        correct = 0\n",
        "        total =0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in Mtrain_loader_at_eval:\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device)\n",
        "                outputs = child_model(inputs)\n",
        "                targets =targets.flatten()\n",
        "                targets = targets.squeeze().long()\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                \n",
        "                outputs=outputs.argmax(dim=-1)\n",
        "                # print(\"output for processing at neural network output is\", outputs)\n",
        "                # targets = targets.float().resize_(len(targets), 1)\n",
        "                # print(\"ground truth label is \", targets)\n",
        "                correct += (outputs == targets).sum().item()\n",
        "                total += len(targets)\n",
        "                # print(\"correct predictsions are:\",correct)\n",
        "                # print(\"total predictions are \", total)\n",
        "                # _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy = correct/total\n",
        "        validation_accuracies.append(accuracy)\n",
        "        if(epoch%20 == 0):\n",
        "            id += 1\n",
        "            reward_per_20.append(max(validation_accuracies[-5:]) ** 3)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Validation Accuracy: {accuracy:.4f}')\n",
        "    reward = max(validation_accuracies[-5:]) ** 3\n",
        "    print(f'Reward for Child Model: {reward}')\n",
        "    return reward, reward_per_20, id\n",
        "\n",
        "def generate_child_models(num_childs, num_layers, size_predict, vocab):\n",
        "    for num_child in range(num_childs):\n",
        "        skip_child = {}\n",
        "        labels_num_child = []\n",
        "        for num_layer in range(num_layers):\n",
        "            labels_num_layer = []\n",
        "            for predict in range(size_predict):\n",
        "                    labels_num_layer.append(random.randrange(len(vocab[predict])))\n",
        "            labels_num_child.append(labels_num_layer)\n",
        "            labels = np.concatenate(np.array(labels_num_child))\n",
        "            labels = labels.tolist()\n",
        "            # print(type(labels))\n",
        "        for num_layer in range(num_layers-1):\n",
        "            label_num_layer = []\n",
        "            for predict in range(num_layer+1):\n",
        "                label_num_layer.append(random.randrange(2))\n",
        "            skip_child[num_layer]=label_num_layer\n",
        "        start_time= time.time()\n",
        "        I_reward, reward_per_epoch, r_Id= Train_random_models(labels, skip_child, 100)\n",
        "        end_trainingtime = (time.time()) - start_time\n",
        "        randomM = To_saveR( r_Id, skip_child, labels, reward_per_epoch)\n",
        "        if not os.path.exists(\"Randomchilds.csv\") or os.path.getsize(\"Randomchilds.csv\") == 0:\n",
        "            # If the file doesn't exist or is empty, write the DataFrame with the header\n",
        "            try:\n",
        "                randomM.to_csv(\"Randomchilds.csv\", index=False)\n",
        "            finally:\n",
        "                del randomM\n",
        "                gc.collect()\n",
        "        else:\n",
        "            try:\n",
        "                randomM.to_csv(\"Randomchilds.csv\", mode='a', header=False, index=False)\n",
        "            finally:\n",
        "                del randomM\n",
        "                gc.collect()\n",
        "        print (\"Child_{0}:  {1}, {2}, {3}\".format(num_child, skip_child, labels,I_reward))\n",
        "\n",
        "generate_child_models(100,conv_layers_num , len(vocab), vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "483a7e73e3bc48ec831563ee70c3ab1d",
            "25ed5e067bbc46cbaddd5528cfa986ea",
            "c34b4c045d184044b8336a04fec81ffe",
            "eb02dd05a3f840b79e08b24a05cdad9d",
            "9ec3de546846451793ae9d28181482c3",
            "7692b7723ecf40fe9deacf00163e0ed3",
            "1b9da4f211b84267bbf3ea264927321f",
            "c7389f3b0fdc4d7da3fe0bbd23e99098",
            "c3d61e4d269c47e3aded2a75ec9123fa",
            "25313e6a7b5c40479fb3c6d3c981140e",
            "eb367ce15f6a4a738bd09af2235ef0d2",
            "6845a97ed9234f16babf40c633c9e5fd",
            "49709487ea0e42ee8b4317fff54f250b",
            "396172b2a8984d6ca3ae8bcd60aeec43",
            "dfee6af47a1d434f9329212841dabf9f",
            "5b8637b35f434425a8b9696fdc0412e4",
            "b7328629d61240f28b2ab70e5753e51f",
            "5c2e2d223c8648dd90a02c54cd83b7ae",
            "d380f50b78c44b128534c3e704e3a611",
            "874bc9197d4342aeba30550926bd1b6f",
            "98d78a894337485f866d486340ab5db6",
            "976b8cf9b6864777bd5600e672525f3c"
          ]
        },
        "id": "EuNqBhIOK8Pg",
        "outputId": "2738071f-af59-4deb-f47d-83ce195ffd6d"
      },
      "outputs": [],
      "source": [
        "# class child_Model:\n",
        "#     def __init__(self,output_classes,vocab,child_labels,child_skips):\n",
        "#         \"\"\"\n",
        "#         randomly generated child_models are appended in child_models list.\n",
        "#         \"\"\"\n",
        "#         self.rewards=[]\n",
        "#         self.child_models = []\n",
        "#         for i in range(len(child_labels)):\n",
        "#             child_model = child_network([1,3,32,32],10,vocab,child_labels[i], child_skips[i])\n",
        "#             self.child_models.append(child_model)\n",
        "#             print(\"Child Model\", i, \":\", child_model)\n",
        "#             # print(\"Summary : \")\n",
        "#             # summary(child_model, (3,32,32))\n",
        "\n",
        "#     def train_child_models(self, train_loader, val_loader, num_epochs, learning_rate=0.1):\n",
        "#         \"\"\"\n",
        "#         Trains each child model in the collection.\n",
        "\n",
        "#         Args:\n",
        "#             train_loader (torch.utils.data.DataLoader): Training data loader.\n",
        "#             val_loader (torch.utils.data.DataLoader): Validation data loader.\n",
        "#             num_epochs (int, optional): Number of training epochs. Defaults to 5.\n",
        "#             learning_rate (float, optional): Learning rate for the optimizer. Defaults to 0.1.\n",
        "#             use_cuda (bool, optional): Whether to use GPU for training. Defaults to False.\n",
        "#         \"\"\"\n",
        "\n",
        "#         for i, child_model in tqdm(enumerate(self.child_models)):\n",
        "#             print(f\"\\nTraining Child Model {i + 1}:\")\n",
        "\n",
        "#             # Set device (CPU or GPU)\n",
        "#             device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#             child_model.to(device)\n",
        "\n",
        "#             optimizer = Adam(child_model.parameters(), lr=learning_rate)\n",
        "#             validation_accuracies = []\n",
        "#             start = time.time()\n",
        "#             for epoch in tqdm(range(num_epochs)):\n",
        "#                 child_model.train()\n",
        "#                 for inputs, targets in train_loader:\n",
        "#                     inputs = inputs.to(device)\n",
        "#                     targets = targets.to(device)\n",
        "                    \n",
        "\n",
        "#                     optimizer.zero_grad()\n",
        "                    \n",
        "#                     outputs = child_model(inputs)\n",
        "#                     print(outputs.shape)\n",
        "#                     print(\"target shape: {}\".format(targets.shape))\n",
        "#                     loss = F.cross_entropy(outputs, targets)\n",
        "#                     loss.backward()\n",
        "#                     optimizer.step()\n",
        "\n",
        "#                 # Validation\n",
        "#                 child_model.eval()\n",
        "#                 correct = 0\n",
        "#                 total = 0\n",
        "#                 with torch.no_grad():\n",
        "#                     for inputs, targets in val_loader:\n",
        "#                         inputs = inputs.to(device)\n",
        "#                         targets = targets.to(device)\n",
        "#                         outputs = child_model(inputs)\n",
        "#                         print(outputs)\n",
        "#                         _, predicted = torch.max(outputs.data, 1)\n",
        "#                         targets = targets.float().resize_(len(targets), 1)\n",
        "#                         correct += (outputs == targets).sum().item()\n",
        "#                         total += targets.size(0)\n",
        "#                         correct += (predicted == targets).sum().item()\n",
        "\n",
        "#                 accuracy = correct / total\n",
        "#                 validation_accuracies.append(accuracy)\n",
        "#                 print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Validation Accuracy: {accuracy:.4f}')\n",
        "\n",
        "#             # Calculate and print the reward\n",
        "#             reward = max(validation_accuracies[-5:]) ** 3\n",
        "#             endtime = (time.time())- start\n",
        "#             print(f'Reward for Child Model {i + 1}: {reward} time: {endtime}')\n",
        "#             self.rewards.append(reward)\n",
        "#         return self.rewards\n",
        "\n",
        "# child_model_instance = child_Model(output_classes,vocab,child_labels,child_skips)\n",
        "\n",
        "# # # Train all child models using Adam optimizer\n",
        "# rewards=child_model_instance.train_child_models(train_loader, val_loader,num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VZtfFb7BE4S"
      },
      "source": [
        "### **Train exlpoited child labels*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# function to train the cifar dataset on the  exploited child model \n",
        "\n",
        "def Train_exploited_child_Mod(exploited_child, T_train_loader, T_val_loader, T_num_epochs, learning_rate=0.1):\n",
        "    \"\"\"\n",
        "        Trains  child model in the collection.\n",
        "\n",
        "        Args:\n",
        "            exploited_child(Class child_network(nn.module)):  exploited child from the controller \n",
        "            T_train_loader (torch.utils.data.DataLoader): Training data loader.\n",
        "            T_val_loader (torch.utils.data.DataLoader): Validation data loader.\n",
        "            T_num_epochs (int, optional): Number of training epochs. Defaults to 5.\n",
        "            learning_rate (float, optional): Learning rate for the optimizer. Defaults to 0.1.\n",
        "            use_cuda (bool, optional): Whether to use GPU for training. Defaults to False.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    exploited_child.to(device)\n",
        "    optimizer = Adam(exploited_child.parameters(), lr=learning_rate)\n",
        "    validation_accuracies = []\n",
        "    for epoch in tqdm(range(T_num_epochs)):\n",
        "        exploited_child.train()\n",
        "        for inputs, targets in T_train_loader:\n",
        "            inputs = inputs.float().to(device)\n",
        "            targets = targets.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = exploited_child(inputs)\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = F.cross_entropy(outputs,targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        exploited_child.eval()\n",
        "        correct =0\n",
        "        total = 0 \n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in T_val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device)\n",
        "                outputs = exploited_child(inputs)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "                # outputs = outputs.softmax(dim=-1)\n",
        "                outputs=outputs.argmax(dim=-1)\n",
        "                correct += (outputs == targets).sum().item()\n",
        "                # # _, predicted = torch.max(outputs.data,1)\n",
        "                # print(len(targets))\n",
        "                # print(targets.size(0))\n",
        "\n",
        "                total += len(targets)\n",
        "                # correct += (predicted == targets).sum().item()\n",
        "        accuracy = correct / total\n",
        "        validation_accuracies.append(accuracy)\n",
        "        print(f'Epoch {epoch + 1}/{T_num_epochs}, Loss: {loss.item():.4f}, Validation Accuracy: {accuracy:.4f}')\n",
        "        reward = max(validation_accuracies[-5:])**3\n",
        "    return reward\n",
        "\n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eHACUP_2Ie_-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'child_0': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_1': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_2': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_3': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_4': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_5': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_6': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_7': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_8': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_9': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_10': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_11': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_12': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_13': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_14': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_15': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_16': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_17': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_18': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_19': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_20': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_21': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_22': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_23': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_24': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_25': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_26': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_27': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_28': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_29': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_30': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_31': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_32': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_33': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_34': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_35': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_36': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_37': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_38': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_39': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_40': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_41': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_42': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_43': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_44': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_45': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_46': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_47': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_48': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_49': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_50': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_51': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_52': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_53': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_54': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_55': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_56': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_57': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_58': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_59': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_60': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_61': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_62': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_63': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_64': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_65': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_66': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_67': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_68': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_69': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_70': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_71': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_72': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_73': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_74': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_75': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_76': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_77': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_78': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_79': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_80': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_81': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_82': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_83': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_84': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_85': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_86': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_87': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_88': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_89': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_90': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_91': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_92': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_93': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_94': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_95': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_96': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_97': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_98': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_99': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_100': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_101': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_102': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_103': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_104': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_105': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_106': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_107': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_108': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_109': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_110': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_111': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_112': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_113': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_114': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_115': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_116': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_117': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_118': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_119': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_120': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_121': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_122': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_123': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_124': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_125': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_126': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_127': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_128': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_129': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_130': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_131': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_132': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_133': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_134': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_135': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_136': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_137': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_138': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_139': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_140': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_141': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_142': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_143': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_144': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_145': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_146': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_147': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_148': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_149': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_150': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_151': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_152': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_153': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_154': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_155': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_156': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_157': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_158': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_159': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_160': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_161': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_162': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_163': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_164': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_165': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_166': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_167': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_168': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_169': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_170': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_171': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_172': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_173': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_174': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_175': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_176': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_177': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_178': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_179': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_180': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_181': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_182': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_183': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_184': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_185': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_186': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_187': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_188': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_189': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_190': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_191': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_192': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_193': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_194': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_195': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_196': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_197': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_198': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_199': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_200': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_201': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_202': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_203': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_204': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_205': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_206': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_207': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_208': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_209': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_210': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_211': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_212': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_213': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_214': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_215': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_216': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_217': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_218': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_219': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_220': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_221': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_222': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_223': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_224': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_225': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_226': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_227': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_228': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_229': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_230': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_231': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_232': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_233': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_234': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_235': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_236': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_237': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_238': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_239': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_240': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_241': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_242': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_243': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_244': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_245': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_246': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_247': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_248': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_249': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_250': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_251': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_252': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_253': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_254': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_255': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_256': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_257': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_258': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_259': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_260': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_261': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_262': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_263': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_264': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_265': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_266': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_267': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_268': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_269': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_270': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_271': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_272': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_273': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_274': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_275': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_276': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_277': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_278': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_279': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_280': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_281': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_282': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_283': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_284': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_285': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_286': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_287': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_288': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_289': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_290': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_291': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_292': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_293': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_294': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_295': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_296': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_297': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_298': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_299': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_300': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_301': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_302': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_303': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_304': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_305': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_306': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_307': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_308': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_309': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_310': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_311': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_312': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_313': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_314': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_315': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_316': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_317': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_318': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_319': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_320': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_321': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_322': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_323': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_324': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_325': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_326': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_327': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_328': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_329': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_330': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_331': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_332': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_333': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_334': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_335': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_336': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_337': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_338': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_339': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_340': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_341': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_342': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_343': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_344': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_345': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_346': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_347': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_348': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_349': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_350': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_351': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_352': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_353': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_354': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_355': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_356': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_357': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_358': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_359': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_360': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_361': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_362': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_363': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_364': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_365': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_366': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_367': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_368': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_369': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_370': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_371': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_372': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_373': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_374': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_375': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_376': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_377': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_378': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_379': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_380': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_381': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_382': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_383': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_384': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_385': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_386': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_387': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_388': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_389': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_390': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_391': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_392': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_393': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_394': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_395': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_396': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_397': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_398': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_399': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_400': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_401': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_402': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_403': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_404': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_405': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_406': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_407': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_408': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_409': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_410': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_411': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_412': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_413': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_414': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_415': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_416': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_417': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_418': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_419': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_420': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_421': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_422': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_423': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_424': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_425': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_426': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_427': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_428': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_429': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_430': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_431': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_432': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_433': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_434': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_435': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_436': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_437': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_438': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_439': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_440': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_441': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_442': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_443': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_444': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_445': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_446': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_447': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_448': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_449': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_450': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_451': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_452': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_453': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_454': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_455': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_456': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_457': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_458': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_459': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_460': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_461': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_462': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_463': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_464': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_465': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_466': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_467': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_468': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_469': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_470': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_471': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_472': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_473': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_474': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_475': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_476': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_477': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_478': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_479': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_480': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_481': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_482': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_483': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_484': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_485': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_486': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_487': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_488': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_489': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_490': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_491': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_492': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_493': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_494': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_495': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_496': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_497': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_498': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_499': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_500': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_501': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_502': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_503': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_504': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_505': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_506': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_507': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_508': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_509': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_510': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_511': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_512': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_513': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_514': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_515': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_516': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_517': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_518': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_519': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_520': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_521': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_522': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_523': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_524': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_525': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_526': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_527': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_528': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_529': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_530': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_531': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_532': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_533': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_534': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_535': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_536': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_537': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_538': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_539': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_540': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_541': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_542': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_543': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_544': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_545': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_546': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_547': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_548': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_549': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_550': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_551': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_552': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_553': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_554': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_555': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_556': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_557': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_558': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_559': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_560': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_561': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_562': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_563': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_564': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_565': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_566': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_567': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_568': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_569': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_570': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_571': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_572': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_573': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_574': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_575': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_576': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_577': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_578': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_579': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_580': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_581': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_582': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_583': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_584': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_585': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_586': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_587': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_588': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_589': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_590': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_591': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_592': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_593': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_594': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_595': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_596': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_597': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_598': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_599': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_600': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_601': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_602': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_603': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_604': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_605': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_606': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_607': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_608': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_609': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_610': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_611': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_612': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_613': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_614': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_615': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_616': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_617': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_618': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_619': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_620': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_621': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_622': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_623': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_624': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_625': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_626': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_627': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_628': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_629': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_630': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_631': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_632': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_633': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_634': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_635': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_636': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_637': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_638': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_639': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_640': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_641': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_642': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_643': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_644': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_645': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_646': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_647': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_648': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_649': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_650': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_651': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_652': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_653': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_654': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_655': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_656': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_657': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_658': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_659': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_660': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_661': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_662': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_663': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_664': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_665': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_666': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_667': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_668': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_669': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_670': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_671': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_672': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_673': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_674': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_675': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_676': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_677': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_678': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_679': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_680': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_681': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_682': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_683': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_684': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_685': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_686': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_687': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_688': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_689': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_690': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_691': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_692': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_693': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_694': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_695': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_696': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_697': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_698': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_699': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_700': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_701': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_702': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_703': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_704': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_705': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_706': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_707': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_708': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_709': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_710': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_711': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_712': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_713': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_714': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_715': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_716': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_717': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_718': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_719': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_720': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_721': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_722': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_723': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_724': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_725': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_726': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_727': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_728': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_729': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_730': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_731': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_732': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_733': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_734': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_735': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_736': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_737': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_738': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_739': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_740': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_741': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_742': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_743': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_744': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_745': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_746': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_747': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_748': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_749': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_750': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_751': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_752': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_753': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_754': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_755': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_756': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_757': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_758': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_759': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_760': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_761': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_762': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_763': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_764': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_765': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_766': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_767': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_768': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_769': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_770': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_771': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_772': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_773': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_774': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_775': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_776': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_777': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_778': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_779': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_780': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_781': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_782': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_783': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_784': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_785': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_786': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_787': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_788': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_789': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_790': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_791': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_792': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_793': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_794': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_795': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_796': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_797': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_798': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_799': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_800': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_801': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_802': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_803': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_804': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_805': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_806': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_807': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_808': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_809': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_810': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_811': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_812': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_813': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_814': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_815': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_816': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_817': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_818': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_819': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_820': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_821': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_822': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_823': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_824': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_825': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_826': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_827': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_828': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_829': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_830': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_831': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_832': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_833': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_834': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_835': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_836': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_837': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_838': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_839': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_840': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_841': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_842': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_843': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_844': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_845': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_846': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_847': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_848': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_849': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_850': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_851': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_852': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_853': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_854': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_855': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_856': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_857': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_858': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_859': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_860': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_861': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_862': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_863': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_864': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_865': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_866': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_867': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_868': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_869': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_870': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_871': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_872': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_873': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_874': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_875': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_876': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_877': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_878': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_879': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_880': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_881': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_882': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_883': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_884': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_885': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_886': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_887': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_888': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_889': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_890': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_891': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_892': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_893': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_894': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_895': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_896': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_897': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_898': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_899': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_900': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_901': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_902': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_903': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_904': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_905': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_906': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_907': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_908': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_909': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_910': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_911': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_912': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_913': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_914': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_915': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_916': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_917': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_918': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_919': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_920': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_921': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_922': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_923': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_924': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_925': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_926': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_927': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_928': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_929': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_930': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_931': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_932': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_933': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_934': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_935': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_936': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_937': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_938': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_939': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_940': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_941': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_942': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_943': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_944': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_945': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_946': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_947': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_948': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_949': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_950': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_951': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_952': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_953': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_954': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_955': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_956': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_957': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_958': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_959': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_960': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_961': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_962': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_963': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_964': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_965': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_966': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_967': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_968': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_969': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_970': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_971': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_972': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_973': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_974': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_975': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_976': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_977': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_978': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_979': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_980': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_981': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_982': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_983': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_984': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_985': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_986': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_987': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_988': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_989': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_990': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_991': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_992': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_993': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_994': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_995': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_996': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_997': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_998': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_999': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_1000': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_1001': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_1002': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_1003': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_1004': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_1005': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_1006': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_1007': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_1008': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1009': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_1010': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_1011': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_1012': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_1013': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_1014': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1015': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_1016': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_1017': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_1018': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_1019': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_1020': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_1021': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_1022': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_1023': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_1024': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_1025': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_1026': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_1027': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_1028': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_1029': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_1030': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_1031': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_1032': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_1033': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_1034': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_1035': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_1036': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_1037': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_1038': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_1039': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_1040': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_1041': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_1042': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_1043': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1044': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_1045': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_1046': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_1047': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_1048': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_1049': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_1050': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_1051': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_1052': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_1053': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_1054': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_1055': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_1056': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_1057': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_1058': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_1059': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1060': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_1061': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_1062': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_1063': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_1064': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_1065': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_1066': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_1067': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_1068': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_1069': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_1070': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_1071': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_1072': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_1073': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_1074': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_1075': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_1076': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_1077': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_1078': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_1079': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_1080': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_1081': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_1082': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_1083': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_1084': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_1085': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_1086': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_1087': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_1088': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1089': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_1090': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_1091': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_1092': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_1093': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1094': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_1095': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_1096': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_1097': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_1098': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_1099': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_1100': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_1101': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_1102': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_1103': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_1104': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_1105': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_1106': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_1107': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_1108': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_1109': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_1110': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_1111': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_1112': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_1113': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_1114': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_1115': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_1116': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_1117': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_1118': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_1119': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1120': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_1121': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_1122': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_1123': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_1124': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_1125': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_1126': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_1127': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_1128': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_1129': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1130': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_1131': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_1132': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_1133': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_1134': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_1135': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_1136': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_1137': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_1138': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_1139': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_1140': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_1141': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_1142': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_1143': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_1144': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_1145': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_1146': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_1147': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_1148': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_1149': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_1150': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_1151': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_1152': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_1153': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_1154': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1155': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_1156': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_1157': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_1158': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_1159': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_1160': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_1161': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_1162': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_1163': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_1164': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_1165': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_1166': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_1167': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_1168': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_1169': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_1170': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_1171': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_1172': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_1173': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_1174': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_1175': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_1176': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1177': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_1178': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_1179': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_1180': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_1181': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_1182': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_1183': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_1184': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_1185': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_1186': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_1187': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_1188': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_1189': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_1190': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_1191': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_1192': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_1193': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_1194': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1195': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_1196': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_1197': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_1198': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_1199': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_1200': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_1201': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_1202': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_1203': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_1204': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1205': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_1206': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_1207': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_1208': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_1209': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_1210': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1211': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_1212': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_1213': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_1214': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_1215': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_1216': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_1217': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_1218': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_1219': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_1220': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_1221': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_1222': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_1223': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_1224': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_1225': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_1226': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_1227': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_1228': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_1229': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_1230': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1231': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_1232': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_1233': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_1234': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_1235': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_1236': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_1237': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_1238': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_1239': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_1240': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_1241': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_1242': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_1243': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_1244': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_1245': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_1246': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_1247': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1248': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_1249': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_1250': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_1251': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_1252': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_1253': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_1254': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_1255': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_1256': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_1257': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_1258': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_1259': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_1260': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_1261': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_1262': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_1263': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_1264': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_1265': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_1266': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_1267': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_1268': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_1269': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_1270': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_1271': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_1272': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_1273': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_1274': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_1275': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_1276': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1277': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_1278': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_1279': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_1280': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_1281': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_1282': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_1283': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_1284': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_1285': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_1286': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_1287': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_1288': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_1289': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_1290': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_1291': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1292': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_1293': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_1294': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_1295': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_1296': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_1297': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_1298': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_1299': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_1300': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_1301': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_1302': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_1303': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_1304': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_1305': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_1306': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_1307': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_1308': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_1309': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_1310': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_1311': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_1312': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_1313': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1314': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_1315': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_1316': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_1317': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_1318': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_1319': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_1320': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_1321': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_1322': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_1323': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_1324': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_1325': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_1326': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_1327': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_1328': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_1329': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_1330': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1331': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_1332': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1333': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_1334': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_1335': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_1336': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_1337': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1338': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_1339': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_1340': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_1341': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_1342': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_1343': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_1344': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_1345': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1346': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_1347': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_1348': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_1349': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_1350': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_1351': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_1352': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_1353': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_1354': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_1355': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_1356': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1357': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1358': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_1359': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_1360': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_1361': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_1362': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_1363': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1364': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1365': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_1366': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_1367': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_1368': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1369': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_1370': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_1371': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_1372': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_1373': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_1374': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_1375': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_1376': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_1377': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_1378': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_1379': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1380': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_1381': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1382': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_1383': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_1384': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_1385': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_1386': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_1387': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_1388': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1389': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_1390': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_1391': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_1392': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_1393': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_1394': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_1395': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1396': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_1397': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_1398': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_1399': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_1400': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_1401': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_1402': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_1403': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1404': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_1405': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_1406': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_1407': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1408': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_1409': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_1410': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_1411': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_1412': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_1413': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_1414': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_1415': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_1416': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_1417': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_1418': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_1419': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_1420': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_1421': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1422': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_1423': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_1424': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_1425': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_1426': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_1427': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_1428': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1429': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_1430': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_1431': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_1432': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_1433': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_1434': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_1435': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_1436': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_1437': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_1438': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_1439': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_1440': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_1441': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_1442': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_1443': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_1444': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_1445': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_1446': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_1447': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_1448': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_1449': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_1450': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_1451': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_1452': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_1453': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_1454': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_1455': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_1456': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_1457': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_1458': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_1459': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_1460': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_1461': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_1462': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_1463': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_1464': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_1465': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_1466': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_1467': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_1468': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_1469': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_1470': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_1471': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_1472': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_1473': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_1474': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_1475': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1476': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_1477': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_1478': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_1479': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_1480': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_1481': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_1482': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_1483': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_1484': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_1485': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_1486': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_1487': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_1488': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_1489': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_1490': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_1491': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_1492': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_1493': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_1494': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_1495': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1496': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_1497': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_1498': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_1499': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_1500': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1501': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_1502': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_1503': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_1504': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_1505': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_1506': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_1507': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_1508': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_1509': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_1510': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1511': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1512': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_1513': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_1514': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_1515': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_1516': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_1517': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_1518': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_1519': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_1520': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_1521': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_1522': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_1523': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_1524': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1525': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_1526': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_1527': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_1528': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_1529': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1530': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_1531': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_1532': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_1533': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_1534': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_1535': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_1536': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_1537': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_1538': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1539': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_1540': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_1541': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_1542': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_1543': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_1544': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_1545': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_1546': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_1547': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_1548': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_1549': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_1550': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_1551': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_1552': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_1553': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1554': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_1555': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1556': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_1557': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_1558': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_1559': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_1560': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_1561': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_1562': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_1563': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_1564': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_1565': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_1566': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_1567': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1568': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_1569': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_1570': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_1571': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_1572': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1573': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_1574': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_1575': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_1576': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_1577': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1578': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_1579': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_1580': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_1581': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_1582': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_1583': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_1584': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_1585': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_1586': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_1587': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_1588': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1589': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_1590': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_1591': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_1592': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_1593': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_1594': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_1595': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_1596': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1597': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_1598': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_1599': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_1600': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_1601': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_1602': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_1603': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_1604': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_1605': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_1606': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_1607': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1608': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_1609': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_1610': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_1611': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_1612': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_1613': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_1614': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_1615': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1616': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_1617': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_1618': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_1619': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_1620': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_1621': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_1622': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1623': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_1624': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_1625': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1626': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_1627': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_1628': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_1629': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_1630': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_1631': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_1632': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_1633': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_1634': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_1635': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_1636': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_1637': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_1638': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_1639': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_1640': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1641': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_1642': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_1643': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1644': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_1645': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_1646': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1647': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_1648': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_1649': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_1650': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_1651': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_1652': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_1653': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_1654': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1655': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_1656': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_1657': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_1658': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_1659': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_1660': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_1661': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_1662': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_1663': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_1664': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_1665': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_1666': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_1667': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_1668': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_1669': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_1670': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_1671': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_1672': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_1673': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_1674': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_1675': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_1676': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_1677': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_1678': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_1679': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_1680': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_1681': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_1682': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1683': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_1684': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_1685': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_1686': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_1687': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_1688': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_1689': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_1690': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_1691': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_1692': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_1693': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_1694': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1695': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_1696': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_1697': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_1698': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_1699': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_1700': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_1701': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1702': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_1703': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_1704': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_1705': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_1706': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_1707': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_1708': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_1709': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_1710': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_1711': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_1712': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_1713': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_1714': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_1715': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_1716': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_1717': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_1718': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_1719': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_1720': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_1721': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_1722': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_1723': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_1724': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_1725': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_1726': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_1727': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_1728': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1729': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_1730': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_1731': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_1732': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_1733': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_1734': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_1735': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1736': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1737': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_1738': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_1739': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_1740': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_1741': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_1742': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_1743': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_1744': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_1745': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_1746': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_1747': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_1748': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_1749': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_1750': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_1751': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_1752': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_1753': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_1754': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_1755': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_1756': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_1757': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1758': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_1759': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_1760': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_1761': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_1762': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_1763': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_1764': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_1765': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_1766': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_1767': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_1768': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_1769': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_1770': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_1771': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_1772': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_1773': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_1774': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_1775': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_1776': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_1777': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_1778': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_1779': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_1780': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_1781': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_1782': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_1783': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_1784': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_1785': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_1786': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_1787': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_1788': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1789': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_1790': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_1791': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_1792': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_1793': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_1794': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_1795': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1796': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_1797': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_1798': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_1799': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_1800': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_1801': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_1802': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_1803': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_1804': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_1805': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_1806': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_1807': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_1808': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_1809': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_1810': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_1811': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_1812': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_1813': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_1814': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_1815': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_1816': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_1817': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_1818': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_1819': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_1820': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_1821': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_1822': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_1823': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_1824': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_1825': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_1826': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_1827': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_1828': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_1829': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_1830': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_1831': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_1832': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_1833': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_1834': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_1835': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_1836': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_1837': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_1838': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_1839': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_1840': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_1841': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_1842': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_1843': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_1844': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1845': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_1846': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_1847': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_1848': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_1849': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_1850': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_1851': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_1852': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_1853': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1854': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_1855': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_1856': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_1857': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_1858': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_1859': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_1860': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_1861': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_1862': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_1863': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_1864': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_1865': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_1866': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_1867': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_1868': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_1869': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_1870': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_1871': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_1872': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_1873': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_1874': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_1875': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_1876': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_1877': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_1878': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_1879': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_1880': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_1881': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_1882': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_1883': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1884': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_1885': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_1886': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_1887': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_1888': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_1889': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_1890': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_1891': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1892': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_1893': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_1894': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_1895': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_1896': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_1897': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_1898': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_1899': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_1900': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1901': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_1902': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_1903': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_1904': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_1905': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_1906': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_1907': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1908': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_1909': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_1910': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_1911': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_1912': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_1913': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_1914': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_1915': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_1916': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_1917': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_1918': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_1919': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_1920': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_1921': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_1922': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_1923': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_1924': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_1925': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_1926': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_1927': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_1928': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_1929': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_1930': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_1931': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_1932': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_1933': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_1934': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_1935': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_1936': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_1937': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_1938': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_1939': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_1940': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_1941': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_1942': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_1943': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1944': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_1945': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_1946': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_1947': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_1948': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_1949': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_1950': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_1951': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_1952': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_1953': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_1954': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_1955': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_1956': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_1957': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_1958': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_1959': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_1960': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_1961': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_1962': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_1963': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_1964': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_1965': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_1966': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_1967': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1968': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_1969': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_1970': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_1971': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_1972': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_1973': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_1974': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_1975': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_1976': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_1977': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_1978': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_1979': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_1980': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_1981': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_1982': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_1983': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_1984': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_1985': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_1986': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1987': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_1988': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_1989': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_1990': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_1991': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_1992': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_1993': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_1994': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_1995': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_1996': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_1997': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_1998': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_1999': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_2000': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2001': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_2002': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_2003': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_2004': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_2005': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_2006': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_2007': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_2008': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_2009': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_2010': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_2011': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_2012': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_2013': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_2014': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_2015': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2016': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_2017': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_2018': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_2019': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_2020': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_2021': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_2022': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_2023': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_2024': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_2025': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_2026': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_2027': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_2028': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_2029': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_2030': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_2031': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_2032': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_2033': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_2034': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2035': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_2036': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_2037': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_2038': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_2039': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_2040': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_2041': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_2042': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_2043': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_2044': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_2045': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_2046': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2047': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_2048': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_2049': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_2050': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_2051': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_2052': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_2053': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2054': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_2055': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_2056': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_2057': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_2058': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_2059': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_2060': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_2061': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_2062': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_2063': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_2064': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_2065': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_2066': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2067': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_2068': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_2069': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_2070': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_2071': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_2072': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_2073': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_2074': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_2075': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_2076': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_2077': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_2078': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_2079': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_2080': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_2081': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_2082': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_2083': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_2084': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_2085': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_2086': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_2087': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_2088': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_2089': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_2090': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_2091': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_2092': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_2093': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2094': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_2095': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_2096': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_2097': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2098': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_2099': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_2100': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_2101': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2102': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_2103': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_2104': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_2105': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_2106': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_2107': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_2108': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_2109': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_2110': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_2111': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_2112': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_2113': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_2114': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_2115': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_2116': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2117': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_2118': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_2119': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_2120': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_2121': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_2122': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_2123': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_2124': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_2125': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_2126': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_2127': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_2128': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_2129': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_2130': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_2131': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_2132': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_2133': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_2134': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_2135': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_2136': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_2137': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2138': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_2139': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_2140': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_2141': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_2142': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2143': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_2144': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_2145': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_2146': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_2147': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_2148': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_2149': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_2150': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_2151': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_2152': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_2153': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_2154': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_2155': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_2156': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_2157': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2158': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_2159': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_2160': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2161': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_2162': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_2163': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_2164': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_2165': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2166': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_2167': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_2168': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_2169': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_2170': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_2171': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_2172': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_2173': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_2174': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_2175': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_2176': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2177': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_2178': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_2179': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_2180': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_2181': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_2182': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_2183': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_2184': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_2185': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_2186': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_2187': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_2188': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_2189': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2190': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_2191': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_2192': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2193': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_2194': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_2195': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_2196': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_2197': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_2198': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2199': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_2200': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_2201': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_2202': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_2203': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_2204': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_2205': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_2206': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_2207': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_2208': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_2209': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_2210': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_2211': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_2212': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_2213': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_2214': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2215': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_2216': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_2217': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_2218': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_2219': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_2220': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_2221': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_2222': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_2223': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_2224': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_2225': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_2226': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_2227': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_2228': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_2229': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_2230': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_2231': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_2232': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_2233': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_2234': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_2235': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_2236': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2237': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_2238': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2239': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_2240': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_2241': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_2242': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_2243': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_2244': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2245': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_2246': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_2247': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_2248': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_2249': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_2250': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_2251': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_2252': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_2253': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_2254': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_2255': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_2256': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_2257': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_2258': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_2259': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_2260': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2261': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_2262': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_2263': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_2264': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_2265': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_2266': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_2267': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_2268': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2269': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_2270': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_2271': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_2272': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_2273': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_2274': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_2275': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_2276': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_2277': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_2278': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_2279': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_2280': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_2281': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_2282': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_2283': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_2284': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_2285': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_2286': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_2287': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_2288': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_2289': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_2290': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2291': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_2292': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_2293': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_2294': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_2295': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_2296': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_2297': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_2298': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2299': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_2300': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_2301': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_2302': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_2303': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_2304': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_2305': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_2306': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_2307': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2308': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_2309': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_2310': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_2311': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2312': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_2313': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_2314': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_2315': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_2316': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_2317': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2318': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_2319': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_2320': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_2321': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_2322': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_2323': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2324': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_2325': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_2326': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2327': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_2328': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_2329': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_2330': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_2331': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_2332': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2333': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_2334': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_2335': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_2336': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2337': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_2338': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_2339': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_2340': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_2341': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_2342': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_2343': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_2344': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_2345': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_2346': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_2347': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_2348': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_2349': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_2350': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_2351': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2352': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_2353': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_2354': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_2355': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_2356': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_2357': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_2358': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_2359': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_2360': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2361': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2362': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_2363': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_2364': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_2365': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_2366': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_2367': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_2368': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_2369': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_2370': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_2371': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_2372': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_2373': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_2374': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_2375': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_2376': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_2377': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_2378': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_2379': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_2380': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_2381': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_2382': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_2383': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_2384': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_2385': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_2386': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2387': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_2388': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_2389': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_2390': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_2391': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2392': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_2393': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_2394': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_2395': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2396': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_2397': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_2398': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_2399': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_2400': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_2401': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_2402': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_2403': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_2404': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2405': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2406': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2407': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_2408': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_2409': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_2410': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_2411': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_2412': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_2413': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_2414': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_2415': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_2416': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_2417': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_2418': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_2419': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_2420': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_2421': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_2422': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_2423': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_2424': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_2425': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_2426': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_2427': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_2428': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_2429': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_2430': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2431': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_2432': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_2433': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_2434': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_2435': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_2436': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_2437': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_2438': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_2439': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_2440': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2441': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_2442': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_2443': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_2444': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2445': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_2446': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_2447': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2448': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2449': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2450': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_2451': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_2452': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_2453': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_2454': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_2455': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_2456': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_2457': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_2458': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_2459': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_2460': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_2461': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_2462': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_2463': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_2464': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2465': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_2466': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_2467': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_2468': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2469': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_2470': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_2471': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_2472': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_2473': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_2474': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2475': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_2476': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_2477': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_2478': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_2479': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_2480': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_2481': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_2482': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_2483': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_2484': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2485': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_2486': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_2487': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_2488': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_2489': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_2490': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_2491': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_2492': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_2493': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_2494': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_2495': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_2496': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_2497': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_2498': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_2499': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_2500': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_2501': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_2502': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_2503': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_2504': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_2505': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_2506': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_2507': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_2508': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2509': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_2510': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_2511': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2512': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_2513': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_2514': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_2515': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_2516': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_2517': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_2518': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_2519': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_2520': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_2521': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_2522': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_2523': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_2524': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_2525': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_2526': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_2527': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_2528': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_2529': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_2530': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_2531': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_2532': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_2533': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_2534': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_2535': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_2536': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_2537': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_2538': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_2539': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_2540': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_2541': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_2542': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2543': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_2544': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_2545': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_2546': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_2547': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_2548': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_2549': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_2550': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_2551': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_2552': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_2553': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_2554': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_2555': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_2556': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_2557': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_2558': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_2559': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_2560': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_2561': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_2562': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2563': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_2564': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_2565': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_2566': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_2567': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_2568': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_2569': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_2570': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2571': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2572': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_2573': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2574': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_2575': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_2576': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_2577': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_2578': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_2579': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_2580': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_2581': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_2582': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_2583': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_2584': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_2585': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_2586': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_2587': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2588': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_2589': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_2590': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_2591': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_2592': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_2593': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_2594': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_2595': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_2596': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_2597': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_2598': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_2599': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_2600': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_2601': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_2602': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_2603': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_2604': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_2605': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_2606': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_2607': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_2608': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_2609': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_2610': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2611': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_2612': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_2613': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_2614': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_2615': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_2616': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2617': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_2618': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_2619': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_2620': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_2621': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_2622': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_2623': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2624': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_2625': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_2626': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2627': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_2628': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2629': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_2630': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_2631': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_2632': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_2633': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_2634': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_2635': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_2636': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_2637': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_2638': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_2639': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_2640': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_2641': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_2642': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_2643': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_2644': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_2645': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_2646': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_2647': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_2648': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2649': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_2650': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_2651': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_2652': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_2653': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_2654': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_2655': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_2656': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_2657': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_2658': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_2659': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2660': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_2661': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_2662': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2663': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_2664': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_2665': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_2666': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_2667': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2668': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_2669': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_2670': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_2671': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_2672': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_2673': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_2674': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_2675': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_2676': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_2677': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_2678': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_2679': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_2680': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2681': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_2682': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_2683': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_2684': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2685': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_2686': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_2687': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2688': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_2689': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2690': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_2691': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_2692': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_2693': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2694': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_2695': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_2696': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_2697': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_2698': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_2699': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_2700': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_2701': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_2702': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_2703': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_2704': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_2705': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_2706': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_2707': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_2708': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_2709': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_2710': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_2711': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_2712': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_2713': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_2714': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_2715': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2716': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_2717': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_2718': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_2719': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_2720': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_2721': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_2722': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_2723': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_2724': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2725': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_2726': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_2727': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_2728': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_2729': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_2730': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_2731': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_2732': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_2733': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_2734': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_2735': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_2736': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_2737': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_2738': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_2739': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_2740': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_2741': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2742': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2743': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_2744': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_2745': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_2746': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_2747': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_2748': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_2749': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_2750': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_2751': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_2752': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_2753': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_2754': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_2755': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_2756': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_2757': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_2758': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_2759': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_2760': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_2761': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_2762': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_2763': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_2764': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2765': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_2766': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_2767': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_2768': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_2769': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_2770': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_2771': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_2772': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_2773': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_2774': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_2775': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_2776': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_2777': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_2778': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_2779': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_2780': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_2781': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_2782': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_2783': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_2784': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_2785': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_2786': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_2787': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_2788': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_2789': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_2790': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_2791': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_2792': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_2793': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_2794': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_2795': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2796': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_2797': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_2798': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_2799': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_2800': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2801': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_2802': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_2803': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_2804': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_2805': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_2806': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_2807': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_2808': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_2809': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_2810': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_2811': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_2812': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_2813': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_2814': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_2815': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_2816': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2817': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_2818': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_2819': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_2820': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_2821': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_2822': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_2823': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_2824': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_2825': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2826': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_2827': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_2828': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_2829': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_2830': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_2831': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_2832': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_2833': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_2834': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_2835': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_2836': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_2837': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_2838': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_2839': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_2840': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_2841': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_2842': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2843': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_2844': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_2845': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_2846': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_2847': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_2848': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_2849': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_2850': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_2851': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_2852': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2853': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_2854': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_2855': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_2856': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_2857': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_2858': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_2859': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_2860': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_2861': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2862': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_2863': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_2864': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_2865': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_2866': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_2867': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_2868': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_2869': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2870': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_2871': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_2872': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_2873': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_2874': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_2875': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_2876': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_2877': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_2878': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_2879': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_2880': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_2881': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_2882': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2883': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_2884': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_2885': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_2886': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_2887': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_2888': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_2889': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_2890': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_2891': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_2892': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_2893': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_2894': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_2895': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_2896': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_2897': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_2898': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_2899': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_2900': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_2901': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_2902': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_2903': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_2904': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_2905': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_2906': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_2907': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_2908': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_2909': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_2910': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2911': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_2912': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_2913': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_2914': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_2915': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_2916': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_2917': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_2918': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_2919': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_2920': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_2921': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2922': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_2923': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_2924': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_2925': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_2926': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_2927': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_2928': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_2929': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_2930': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_2931': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2932': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_2933': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_2934': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_2935': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_2936': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_2937': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_2938': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_2939': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_2940': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_2941': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_2942': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_2943': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_2944': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_2945': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_2946': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_2947': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_2948': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_2949': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_2950': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_2951': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_2952': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_2953': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_2954': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_2955': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_2956': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_2957': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_2958': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_2959': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_2960': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_2961': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_2962': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_2963': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_2964': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_2965': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_2966': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_2967': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2968': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_2969': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_2970': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_2971': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_2972': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_2973': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_2974': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_2975': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_2976': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_2977': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_2978': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_2979': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_2980': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_2981': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_2982': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_2983': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_2984': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_2985': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_2986': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_2987': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_2988': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_2989': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_2990': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_2991': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_2992': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_2993': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_2994': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_2995': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_2996': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_2997': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_2998': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_2999': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_3000': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_3001': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_3002': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_3003': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3004': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_3005': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_3006': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_3007': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_3008': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_3009': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_3010': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_3011': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_3012': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_3013': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_3014': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_3015': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_3016': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_3017': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_3018': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_3019': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_3020': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_3021': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_3022': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3023': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_3024': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_3025': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_3026': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_3027': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_3028': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_3029': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_3030': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_3031': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_3032': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3033': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_3034': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_3035': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_3036': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_3037': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_3038': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_3039': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_3040': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_3041': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_3042': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_3043': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_3044': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_3045': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_3046': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_3047': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_3048': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_3049': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_3050': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3051': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_3052': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_3053': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_3054': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3055': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_3056': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_3057': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_3058': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_3059': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_3060': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_3061': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3062': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_3063': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_3064': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3065': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_3066': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3067': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_3068': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_3069': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_3070': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_3071': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_3072': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_3073': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_3074': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_3075': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_3076': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_3077': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_3078': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_3079': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_3080': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_3081': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_3082': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_3083': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_3084': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_3085': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_3086': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_3087': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_3088': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_3089': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_3090': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_3091': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_3092': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_3093': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3094': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_3095': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_3096': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_3097': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_3098': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_3099': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_3100': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_3101': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_3102': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_3103': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_3104': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_3105': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_3106': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_3107': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_3108': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_3109': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_3110': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_3111': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_3112': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_3113': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_3114': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_3115': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_3116': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_3117': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3118': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3119': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_3120': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_3121': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_3122': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_3123': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_3124': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_3125': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_3126': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_3127': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_3128': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_3129': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_3130': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_3131': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_3132': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_3133': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_3134': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_3135': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_3136': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_3137': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_3138': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_3139': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_3140': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_3141': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_3142': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3143': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3144': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_3145': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_3146': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_3147': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_3148': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_3149': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_3150': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_3151': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_3152': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_3153': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_3154': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_3155': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_3156': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_3157': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_3158': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_3159': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_3160': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_3161': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_3162': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3163': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_3164': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_3165': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_3166': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_3167': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_3168': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_3169': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_3170': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_3171': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_3172': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_3173': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_3174': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_3175': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_3176': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_3177': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_3178': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_3179': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_3180': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_3181': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_3182': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_3183': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_3184': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_3185': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_3186': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_3187': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_3188': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_3189': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_3190': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_3191': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_3192': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_3193': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_3194': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_3195': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_3196': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_3197': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_3198': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_3199': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_3200': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_3201': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_3202': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_3203': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_3204': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_3205': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_3206': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_3207': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_3208': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_3209': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_3210': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_3211': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_3212': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_3213': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_3214': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_3215': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_3216': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_3217': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_3218': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_3219': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_3220': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_3221': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_3222': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_3223': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_3224': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3225': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_3226': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_3227': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_3228': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_3229': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_3230': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_3231': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_3232': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_3233': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_3234': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_3235': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_3236': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_3237': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_3238': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_3239': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_3240': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_3241': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_3242': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_3243': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_3244': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_3245': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_3246': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_3247': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_3248': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_3249': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_3250': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_3251': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3252': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_3253': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3254': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_3255': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_3256': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_3257': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_3258': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_3259': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_3260': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_3261': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_3262': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3263': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3264': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_3265': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_3266': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_3267': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_3268': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_3269': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_3270': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_3271': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_3272': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_3273': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_3274': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_3275': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_3276': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_3277': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_3278': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_3279': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_3280': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_3281': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3282': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_3283': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_3284': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_3285': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_3286': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_3287': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_3288': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_3289': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_3290': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_3291': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_3292': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_3293': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_3294': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_3295': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_3296': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_3297': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_3298': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_3299': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_3300': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_3301': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_3302': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_3303': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_3304': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3305': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_3306': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_3307': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_3308': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_3309': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_3310': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_3311': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_3312': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_3313': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_3314': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_3315': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_3316': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_3317': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_3318': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_3319': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_3320': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_3321': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3322': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_3323': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_3324': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_3325': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_3326': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_3327': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_3328': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_3329': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_3330': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_3331': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3332': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_3333': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_3334': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_3335': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_3336': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_3337': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_3338': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_3339': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_3340': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_3341': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_3342': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_3343': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_3344': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_3345': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_3346': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_3347': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_3348': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_3349': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_3350': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_3351': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_3352': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_3353': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_3354': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_3355': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_3356': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_3357': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_3358': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_3359': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_3360': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_3361': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_3362': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_3363': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_3364': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_3365': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_3366': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3367': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_3368': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_3369': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_3370': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_3371': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_3372': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_3373': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_3374': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_3375': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_3376': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_3377': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_3378': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_3379': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_3380': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3381': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3382': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3383': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_3384': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_3385': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_3386': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_3387': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_3388': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_3389': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_3390': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_3391': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_3392': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_3393': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_3394': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_3395': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_3396': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3397': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_3398': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_3399': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3400': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_3401': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_3402': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_3403': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_3404': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_3405': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_3406': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_3407': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_3408': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_3409': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_3410': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_3411': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_3412': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_3413': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_3414': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_3415': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_3416': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_3417': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_3418': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_3419': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3420': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_3421': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_3422': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_3423': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_3424': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_3425': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3426': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_3427': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3428': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_3429': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3430': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_3431': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_3432': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_3433': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_3434': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_3435': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_3436': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_3437': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_3438': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_3439': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_3440': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_3441': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_3442': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_3443': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_3444': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_3445': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_3446': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_3447': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_3448': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_3449': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_3450': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3451': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_3452': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_3453': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_3454': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_3455': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_3456': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_3457': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_3458': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_3459': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_3460': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_3461': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_3462': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_3463': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_3464': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_3465': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_3466': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_3467': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_3468': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_3469': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_3470': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_3471': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_3472': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_3473': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_3474': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_3475': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_3476': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_3477': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_3478': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_3479': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3480': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_3481': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_3482': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_3483': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_3484': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_3485': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_3486': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_3487': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_3488': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_3489': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_3490': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_3491': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_3492': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_3493': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_3494': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_3495': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_3496': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_3497': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_3498': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_3499': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_3500': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_3501': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_3502': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_3503': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_3504': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_3505': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_3506': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_3507': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3508': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_3509': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_3510': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_3511': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_3512': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_3513': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_3514': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_3515': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_3516': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_3517': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3518': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_3519': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_3520': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_3521': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_3522': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_3523': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_3524': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_3525': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3526': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_3527': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_3528': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_3529': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_3530': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_3531': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3532': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_3533': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_3534': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_3535': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_3536': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_3537': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3538': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_3539': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_3540': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_3541': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_3542': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_3543': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_3544': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_3545': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_3546': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_3547': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_3548': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_3549': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_3550': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_3551': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_3552': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_3553': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_3554': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_3555': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_3556': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_3557': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_3558': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_3559': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_3560': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_3561': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_3562': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_3563': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_3564': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_3565': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_3566': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_3567': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_3568': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_3569': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3570': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_3571': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_3572': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_3573': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_3574': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_3575': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_3576': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_3577': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_3578': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_3579': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_3580': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_3581': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_3582': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_3583': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3584': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3585': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3586': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_3587': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_3588': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_3589': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_3590': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_3591': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_3592': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_3593': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3594': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_3595': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_3596': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_3597': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_3598': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_3599': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_3600': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_3601': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_3602': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_3603': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3604': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_3605': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_3606': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3607': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_3608': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_3609': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_3610': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_3611': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_3612': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_3613': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3614': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_3615': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_3616': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_3617': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_3618': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_3619': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_3620': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_3621': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_3622': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_3623': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_3624': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_3625': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_3626': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_3627': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_3628': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_3629': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_3630': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_3631': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_3632': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_3633': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_3634': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_3635': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_3636': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_3637': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_3638': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_3639': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_3640': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_3641': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_3642': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_3643': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_3644': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3645': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_3646': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_3647': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_3648': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_3649': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3650': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_3651': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_3652': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3653': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_3654': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_3655': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_3656': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3657': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_3658': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_3659': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_3660': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3661': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_3662': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_3663': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_3664': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_3665': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_3666': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_3667': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_3668': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_3669': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_3670': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_3671': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_3672': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_3673': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_3674': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_3675': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_3676': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_3677': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_3678': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_3679': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_3680': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_3681': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_3682': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_3683': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_3684': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_3685': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_3686': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_3687': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_3688': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_3689': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_3690': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_3691': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_3692': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_3693': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_3694': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_3695': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_3696': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_3697': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3698': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_3699': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_3700': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_3701': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_3702': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_3703': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_3704': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_3705': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_3706': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_3707': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_3708': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_3709': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_3710': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_3711': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_3712': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_3713': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_3714': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_3715': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_3716': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_3717': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_3718': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_3719': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_3720': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_3721': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3722': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_3723': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_3724': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_3725': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_3726': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_3727': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_3728': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3729': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_3730': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_3731': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_3732': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_3733': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_3734': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_3735': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_3736': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_3737': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_3738': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3739': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_3740': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_3741': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_3742': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_3743': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_3744': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_3745': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_3746': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_3747': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_3748': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_3749': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_3750': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_3751': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_3752': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_3753': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_3754': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_3755': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_3756': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_3757': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3758': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_3759': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_3760': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_3761': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_3762': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_3763': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_3764': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_3765': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_3766': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_3767': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_3768': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_3769': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_3770': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_3771': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_3772': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3773': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_3774': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3775': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_3776': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_3777': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_3778': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3779': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_3780': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_3781': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_3782': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_3783': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_3784': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_3785': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_3786': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_3787': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3788': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_3789': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_3790': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_3791': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_3792': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3793': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_3794': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_3795': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_3796': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_3797': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_3798': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3799': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_3800': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_3801': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_3802': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3803': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_3804': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_3805': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_3806': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_3807': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_3808': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_3809': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_3810': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_3811': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_3812': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_3813': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_3814': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_3815': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3816': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_3817': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_3818': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3819': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_3820': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_3821': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_3822': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_3823': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_3824': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_3825': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3826': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_3827': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_3828': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_3829': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_3830': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_3831': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_3832': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_3833': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_3834': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_3835': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_3836': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_3837': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_3838': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_3839': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_3840': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_3841': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_3842': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_3843': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_3844': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_3845': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_3846': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_3847': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3848': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_3849': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_3850': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_3851': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_3852': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_3853': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_3854': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_3855': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_3856': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_3857': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_3858': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_3859': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_3860': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_3861': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_3862': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_3863': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_3864': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_3865': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_3866': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_3867': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3868': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_3869': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_3870': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_3871': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_3872': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_3873': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_3874': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_3875': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_3876': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_3877': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_3878': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_3879': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_3880': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_3881': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_3882': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_3883': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_3884': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_3885': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_3886': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_3887': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3888': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_3889': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_3890': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_3891': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_3892': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_3893': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_3894': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_3895': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_3896': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_3897': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_3898': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_3899': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_3900': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_3901': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_3902': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_3903': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_3904': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_3905': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_3906': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_3907': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_3908': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_3909': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_3910': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_3911': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_3912': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_3913': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_3914': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_3915': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_3916': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_3917': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_3918': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_3919': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_3920': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_3921': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_3922': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_3923': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_3924': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_3925': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_3926': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_3927': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_3928': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_3929': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_3930': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3931': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_3932': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_3933': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_3934': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_3935': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_3936': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3937': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_3938': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_3939': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_3940': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_3941': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_3942': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_3943': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_3944': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_3945': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_3946': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_3947': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_3948': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_3949': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_3950': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_3951': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_3952': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_3953': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_3954': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_3955': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_3956': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_3957': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_3958': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_3959': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3960': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_3961': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_3962': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_3963': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_3964': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_3965': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3966': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3967': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_3968': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_3969': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_3970': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_3971': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_3972': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_3973': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_3974': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_3975': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_3976': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_3977': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_3978': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_3979': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_3980': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_3981': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_3982': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_3983': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_3984': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_3985': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_3986': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_3987': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_3988': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_3989': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_3990': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_3991': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_3992': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_3993': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_3994': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_3995': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_3996': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_3997': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_3998': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_3999': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_4000': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_4001': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_4002': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_4003': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_4004': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_4005': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4006': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_4007': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_4008': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_4009': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_4010': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_4011': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4012': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4013': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_4014': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_4015': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_4016': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_4017': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_4018': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_4019': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_4020': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_4021': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_4022': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_4023': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_4024': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_4025': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_4026': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_4027': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_4028': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_4029': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_4030': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_4031': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_4032': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4033': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_4034': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4035': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_4036': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_4037': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_4038': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_4039': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_4040': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_4041': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4042': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_4043': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_4044': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_4045': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_4046': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_4047': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_4048': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_4049': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_4050': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_4051': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_4052': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_4053': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_4054': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_4055': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_4056': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_4057': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_4058': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_4059': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_4060': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4061': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_4062': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_4063': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_4064': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_4065': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_4066': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_4067': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_4068': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_4069': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_4070': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_4071': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_4072': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_4073': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_4074': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_4075': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_4076': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_4077': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_4078': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_4079': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_4080': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_4081': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_4082': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_4083': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_4084': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_4085': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_4086': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_4087': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_4088': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_4089': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_4090': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_4091': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_4092': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_4093': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_4094': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_4095': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4096': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_4097': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_4098': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_4099': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_4100': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_4101': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_4102': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_4103': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_4104': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_4105': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_4106': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_4107': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_4108': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_4109': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_4110': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_4111': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_4112': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_4113': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_4114': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_4115': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_4116': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_4117': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_4118': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_4119': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_4120': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_4121': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4122': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_4123': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_4124': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_4125': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_4126': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_4127': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_4128': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4129': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_4130': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_4131': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_4132': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_4133': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4134': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_4135': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_4136': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_4137': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4138': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_4139': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_4140': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_4141': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_4142': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_4143': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_4144': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_4145': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_4146': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_4147': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_4148': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_4149': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_4150': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4151': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_4152': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_4153': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_4154': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_4155': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_4156': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_4157': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4158': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_4159': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_4160': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4161': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_4162': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_4163': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_4164': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_4165': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_4166': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_4167': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_4168': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_4169': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_4170': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4171': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_4172': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_4173': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_4174': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_4175': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_4176': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_4177': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_4178': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_4179': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_4180': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_4181': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_4182': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_4183': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_4184': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_4185': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_4186': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_4187': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_4188': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_4189': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_4190': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_4191': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_4192': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_4193': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_4194': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_4195': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4196': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_4197': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_4198': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_4199': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_4200': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_4201': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_4202': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_4203': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_4204': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_4205': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_4206': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_4207': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_4208': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_4209': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_4210': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4211': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_4212': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4213': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_4214': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_4215': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_4216': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4217': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_4218': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_4219': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_4220': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_4221': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4222': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_4223': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_4224': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_4225': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_4226': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4227': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_4228': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_4229': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_4230': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_4231': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_4232': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_4233': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_4234': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4235': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_4236': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_4237': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_4238': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_4239': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_4240': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4241': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_4242': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_4243': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_4244': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_4245': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_4246': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 0]}, 'child_4247': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_4248': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_4249': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_4250': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_4251': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_4252': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_4253': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_4254': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_4255': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_4256': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_4257': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_4258': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4259': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4260': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_4261': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_4262': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_4263': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_4264': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4265': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_4266': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_4267': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4268': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_4269': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_4270': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_4271': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_4272': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_4273': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_4274': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_4275': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_4276': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_4277': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_4278': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_4279': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_4280': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4281': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_4282': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_4283': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_4284': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_4285': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_4286': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_4287': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_4288': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_4289': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_4290': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_4291': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_4292': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_4293': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_4294': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_4295': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_4296': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_4297': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_4298': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_4299': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_4300': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_4301': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_4302': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_4303': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_4304': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_4305': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_4306': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_4307': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_4308': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4309': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_4310': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_4311': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_4312': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_4313': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_4314': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_4315': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_4316': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_4317': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_4318': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_4319': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_4320': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_4321': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_4322': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_4323': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_4324': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_4325': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_4326': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_4327': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_4328': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_4329': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_4330': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_4331': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_4332': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_4333': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_4334': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_4335': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_4336': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_4337': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_4338': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_4339': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_4340': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4341': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_4342': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_4343': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4344': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_4345': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_4346': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_4347': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_4348': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_4349': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_4350': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_4351': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_4352': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4353': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_4354': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_4355': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_4356': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_4357': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4358': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_4359': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_4360': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_4361': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_4362': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_4363': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_4364': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4365': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_4366': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_4367': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_4368': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_4369': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_4370': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4371': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4372': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_4373': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_4374': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_4375': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_4376': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_4377': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_4378': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_4379': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_4380': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_4381': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_4382': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_4383': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_4384': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_4385': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_4386': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_4387': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_4388': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_4389': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_4390': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_4391': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_4392': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4393': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_4394': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_4395': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_4396': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4397': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_4398': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_4399': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_4400': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_4401': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_4402': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_4403': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_4404': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_4405': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_4406': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_4407': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_4408': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_4409': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_4410': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_4411': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4412': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_4413': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_4414': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_4415': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_4416': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_4417': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_4418': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_4419': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_4420': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_4421': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_4422': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_4423': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_4424': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_4425': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_4426': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_4427': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_4428': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_4429': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_4430': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_4431': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_4432': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_4433': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_4434': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_4435': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_4436': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_4437': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_4438': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_4439': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_4440': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_4441': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_4442': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4443': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_4444': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_4445': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_4446': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_4447': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_4448': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_4449': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_4450': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_4451': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_4452': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_4453': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_4454': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_4455': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_4456': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_4457': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_4458': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_4459': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_4460': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_4461': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_4462': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4463': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_4464': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4465': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_4466': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4467': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_4468': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_4469': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_4470': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_4471': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_4472': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_4473': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4474': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_4475': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_4476': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_4477': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_4478': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_4479': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_4480': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_4481': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_4482': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4483': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_4484': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_4485': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_4486': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_4487': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_4488': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4489': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_4490': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_4491': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_4492': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_4493': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_4494': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_4495': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_4496': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_4497': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_4498': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_4499': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_4500': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_4501': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_4502': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_4503': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_4504': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_4505': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_4506': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_4507': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4508': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_4509': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_4510': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_4511': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_4512': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_4513': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_4514': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_4515': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_4516': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_4517': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_4518': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_4519': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_4520': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_4521': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_4522': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_4523': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_4524': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_4525': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_4526': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_4527': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_4528': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_4529': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_4530': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_4531': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_4532': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4533': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_4534': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_4535': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 0, 1, 0]}, 'child_4536': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4537': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4538': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_4539': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 1, 1]}, 'child_4540': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_4541': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_4542': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_4543': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_4544': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_4545': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_4546': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4547': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_4548': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_4549': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4550': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_4551': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_4552': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_4553': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4554': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_4555': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_4556': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_4557': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_4558': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_4559': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_4560': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_4561': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_4562': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_4563': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_4564': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_4565': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_4566': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_4567': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_4568': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4569': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_4570': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_4571': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 0]}, 'child_4572': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_4573': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_4574': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_4575': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_4576': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_4577': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_4578': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_4579': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_4580': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4581': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_4582': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_4583': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_4584': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_4585': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_4586': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_4587': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_4588': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_4589': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_4590': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_4591': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_4592': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 0]}, 'child_4593': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_4594': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_4595': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_4596': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_4597': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_4598': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_4599': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_4600': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_4601': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_4602': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_4603': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_4604': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_4605': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4606': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_4607': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_4608': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_4609': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_4610': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_4611': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4612': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_4613': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_4614': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_4615': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_4616': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4617': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_4618': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_4619': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_4620': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_4621': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_4622': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_4623': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_4624': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_4625': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_4626': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_4627': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_4628': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_4629': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_4630': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4631': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4632': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_4633': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_4634': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4635': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_4636': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4637': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4638': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_4639': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_4640': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_4641': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_4642': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_4643': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_4644': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4645': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 1]}, 'child_4646': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 0]}, 'child_4647': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_4648': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_4649': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_4650': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_4651': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_4652': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_4653': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_4654': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_4655': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_4656': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_4657': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_4658': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_4659': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_4660': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_4661': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_4662': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_4663': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_4664': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_4665': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_4666': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_4667': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_4668': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_4669': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 0]}, 'child_4670': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_4671': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4672': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4673': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 1, 0]}, 'child_4674': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_4675': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_4676': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_4677': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_4678': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_4679': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4680': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 1]}, 'child_4681': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_4682': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_4683': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_4684': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_4685': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_4686': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_4687': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_4688': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 0, 1, 0]}, 'child_4689': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_4690': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_4691': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4692': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_4693': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4694': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_4695': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_4696': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_4697': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4698': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_4699': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_4700': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_4701': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_4702': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_4703': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_4704': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_4705': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4706': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_4707': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_4708': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_4709': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_4710': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_4711': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_4712': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_4713': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_4714': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_4715': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_4716': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_4717': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_4718': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 1]}, 'child_4719': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_4720': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_4721': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_4722': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_4723': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_4724': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 1]}, 'child_4725': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_4726': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 1]}, 'child_4727': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_4728': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_4729': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_4730': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_4731': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_4732': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_4733': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_4734': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 0, 0]}, 'child_4735': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_4736': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_4737': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_4738': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_4739': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_4740': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_4741': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4742': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_4743': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_4744': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_4745': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_4746': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 1, 1]}, 'child_4747': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_4748': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4749': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_4750': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_4751': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_4752': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_4753': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_4754': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_4755': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 0]}, 'child_4756': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_4757': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_4758': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_4759': {0: [1], 1: [0, 0], 2: [1, 0, 1], 3: [1, 1, 0, 1]}, 'child_4760': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_4761': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 1, 0]}, 'child_4762': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_4763': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_4764': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_4765': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 1]}, 'child_4766': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_4767': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [0, 0, 1, 0]}, 'child_4768': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_4769': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 1, 0]}, 'child_4770': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_4771': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_4772': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_4773': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_4774': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_4775': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_4776': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_4777': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_4778': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_4779': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_4780': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_4781': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_4782': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_4783': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_4784': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4785': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [1, 1, 0, 0]}, 'child_4786': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4787': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_4788': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_4789': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_4790': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_4791': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_4792': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_4793': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_4794': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 1, 1]}, 'child_4795': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4796': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4797': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_4798': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_4799': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_4800': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_4801': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 0]}, 'child_4802': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4803': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_4804': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_4805': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_4806': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_4807': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_4808': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_4809': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_4810': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 0, 1]}, 'child_4811': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_4812': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_4813': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 1, 0, 1]}, 'child_4814': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [1, 0, 1, 1]}, 'child_4815': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_4816': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_4817': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_4818': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 1]}, 'child_4819': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_4820': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4821': {0: [0], 1: [1, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4822': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_4823': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_4824': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 0, 0]}, 'child_4825': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_4826': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_4827': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_4828': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 1]}, 'child_4829': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [0, 1, 1, 0]}, 'child_4830': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 1]}, 'child_4831': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [1, 0, 1, 0]}, 'child_4832': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_4833': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 1, 0, 1]}, 'child_4834': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4835': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_4836': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 1, 0]}, 'child_4837': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 0, 0]}, 'child_4838': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_4839': {0: [1], 1: [1, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_4840': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_4841': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_4842': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_4843': {0: [1], 1: [0, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_4844': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_4845': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_4846': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_4847': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_4848': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_4849': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 1, 0]}, 'child_4850': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 0, 1]}, 'child_4851': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 1, 0]}, 'child_4852': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 1]}, 'child_4853': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_4854': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4855': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_4856': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 1, 0]}, 'child_4857': {0: [1], 1: [0, 1], 2: [0, 1, 1], 3: [1, 1, 1, 0]}, 'child_4858': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_4859': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4860': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_4861': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 0]}, 'child_4862': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_4863': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_4864': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_4865': {0: [0], 1: [0, 1], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_4866': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 1, 1]}, 'child_4867': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 0]}, 'child_4868': {0: [0], 1: [1, 0], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_4869': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 0]}, 'child_4870': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_4871': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 1, 1]}, 'child_4872': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_4873': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_4874': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_4875': {0: [1], 1: [1, 1], 2: [0, 0, 0], 3: [0, 1, 0, 1]}, 'child_4876': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_4877': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [1, 0, 1, 1]}, 'child_4878': {0: [1], 1: [1, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_4879': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 1]}, 'child_4880': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4881': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_4882': {0: [0], 1: [1, 1], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_4883': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_4884': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_4885': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_4886': {0: [1], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 1]}, 'child_4887': {0: [0], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_4888': {0: [1], 1: [0, 0], 2: [0, 0, 1], 3: [1, 0, 1, 0]}, 'child_4889': {0: [1], 1: [1, 1], 2: [1, 1, 0], 3: [1, 0, 0, 0]}, 'child_4890': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 1, 1]}, 'child_4891': {0: [1], 1: [1, 0], 2: [0, 0, 1], 3: [1, 1, 1, 1]}, 'child_4892': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_4893': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [1, 0, 0, 0]}, 'child_4894': {0: [1], 1: [0, 1], 2: [1, 0, 0], 3: [1, 1, 0, 1]}, 'child_4895': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4896': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [0, 0, 1, 1]}, 'child_4897': {0: [0], 1: [1, 0], 2: [1, 0, 0], 3: [1, 1, 0, 0]}, 'child_4898': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_4899': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [0, 0, 1, 1]}, 'child_4900': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [0, 0, 1, 0]}, 'child_4901': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_4902': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_4903': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 1, 1]}, 'child_4904': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_4905': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_4906': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 0, 1]}, 'child_4907': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 1, 0, 1]}, 'child_4908': {0: [0], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 0, 0]}, 'child_4909': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [1, 0, 1, 1]}, 'child_4910': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [0, 0, 0, 1]}, 'child_4911': {0: [0], 1: [1, 0], 2: [0, 0, 0], 3: [0, 0, 0, 1]}, 'child_4912': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_4913': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 1, 0]}, 'child_4914': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_4915': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_4916': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_4917': {0: [1], 1: [0, 0], 2: [0, 1, 0], 3: [1, 1, 1, 1]}, 'child_4918': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_4919': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4920': {0: [1], 1: [1, 0], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4921': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 0]}, 'child_4922': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_4923': {0: [1], 1: [1, 0], 2: [1, 0, 0], 3: [0, 0, 1, 1]}, 'child_4924': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [0, 1, 1, 1]}, 'child_4925': {0: [1], 1: [0, 1], 2: [0, 0, 1], 3: [1, 1, 0, 1]}, 'child_4926': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_4927': {0: [0], 1: [1, 0], 2: [0, 1, 0], 3: [0, 0, 0, 0]}, 'child_4928': {0: [0], 1: [0, 0], 2: [1, 0, 0], 3: [1, 0, 0, 0]}, 'child_4929': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_4930': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 1, 0, 0]}, 'child_4931': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 1, 1, 0]}, 'child_4932': {0: [1], 1: [1, 1], 2: [0, 0, 1], 3: [0, 1, 0, 1]}, 'child_4933': {0: [0], 1: [1, 1], 2: [1, 1, 0], 3: [1, 1, 1, 0]}, 'child_4934': {0: [0], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 0, 1]}, 'child_4935': {0: [0], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_4936': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 1, 0]}, 'child_4937': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_4938': {0: [1], 1: [0, 0], 2: [0, 0, 0], 3: [1, 1, 0, 0]}, 'child_4939': {0: [0], 1: [0, 0], 2: [1, 0, 1], 3: [1, 0, 0, 1]}, 'child_4940': {0: [1], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 0, 0]}, 'child_4941': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_4942': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 1, 0]}, 'child_4943': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_4944': {0: [0], 1: [1, 0], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_4945': {0: [1], 1: [0, 0], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_4946': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 1]}, 'child_4947': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 0]}, 'child_4948': {0: [1], 1: [1, 0], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_4949': {0: [1], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 0, 1]}, 'child_4950': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_4951': {0: [0], 1: [1, 0], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_4952': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 0, 0, 0]}, 'child_4953': {0: [1], 1: [1, 0], 2: [1, 1, 0], 3: [0, 1, 1, 1]}, 'child_4954': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_4955': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 0, 0]}, 'child_4956': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 1, 1]}, 'child_4957': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 0, 1, 1]}, 'child_4958': {0: [0], 1: [0, 1], 2: [0, 0, 1], 3: [1, 0, 0, 0]}, 'child_4959': {0: [1], 1: [1, 1], 2: [1, 0, 0], 3: [1, 1, 1, 1]}, 'child_4960': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 1]}, 'child_4961': {0: [0], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_4962': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_4963': {0: [1], 1: [1, 0], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_4964': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 1, 0, 0]}, 'child_4965': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 1]}, 'child_4966': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 0, 0]}, 'child_4967': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_4968': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 0, 1]}, 'child_4969': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_4970': {0: [1], 1: [0, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_4971': {0: [0], 1: [0, 1], 2: [1, 0, 0], 3: [0, 0, 0, 0]}, 'child_4972': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [1, 1, 1, 1]}, 'child_4973': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 1, 0]}, 'child_4974': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 1]}, 'child_4975': {0: [1], 1: [1, 1], 2: [0, 1, 1], 3: [1, 1, 0, 0]}, 'child_4976': {0: [0], 1: [1, 1], 2: [0, 0, 0], 3: [1, 1, 1, 0]}, 'child_4977': {0: [0], 1: [1, 1], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_4978': {0: [0], 1: [1, 1], 2: [0, 1, 0], 3: [1, 1, 1, 0]}, 'child_4979': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4980': {0: [1], 1: [1, 0], 2: [1, 0, 1], 3: [0, 1, 0, 1]}, 'child_4981': {0: [0], 1: [1, 1], 2: [1, 0, 0], 3: [0, 0, 0, 1]}, 'child_4982': {0: [0], 1: [0, 1], 2: [1, 1, 0], 3: [1, 1, 1, 1]}, 'child_4983': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [0, 1, 1, 0]}, 'child_4984': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 1, 1, 1]}, 'child_4985': {0: [0], 1: [1, 1], 2: [1, 1, 1], 3: [1, 1, 1, 0]}, 'child_4986': {0: [0], 1: [1, 0], 2: [0, 1, 1], 3: [0, 0, 0, 1]}, 'child_4987': {0: [0], 1: [0, 0], 2: [1, 1, 0], 3: [1, 0, 0, 1]}, 'child_4988': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [0, 1, 0, 0]}, 'child_4989': {0: [0], 1: [0, 0], 2: [0, 1, 1], 3: [0, 1, 1, 1]}, 'child_4990': {0: [1], 1: [0, 1], 2: [1, 0, 1], 3: [0, 0, 0, 0]}, 'child_4991': {0: [1], 1: [0, 1], 2: [1, 1, 0], 3: [0, 1, 0, 0]}, 'child_4992': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [0, 0, 1, 0]}, 'child_4993': {0: [0], 1: [0, 0], 2: [1, 1, 1], 3: [1, 0, 1, 1]}, 'child_4994': {0: [1], 1: [1, 1], 2: [0, 1, 0], 3: [1, 0, 0, 1]}, 'child_4995': {0: [1], 1: [0, 1], 2: [0, 1, 0], 3: [1, 0, 0, 0]}, 'child_4996': {0: [0], 1: [0, 0], 2: [0, 0, 1], 3: [0, 0, 0, 1]}, 'child_4997': {0: [1], 1: [0, 1], 2: [1, 1, 1], 3: [0, 0, 1, 0]}, 'child_4998': {0: [0], 1: [0, 0], 2: [0, 0, 0], 3: [0, 1, 0, 0]}, 'child_4999': {0: [0], 1: [0, 1], 2: [1, 0, 1], 3: [1, 0, 0, 1]}}\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'child_model_instance' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(prefixed_data1)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# rewards = [0.8555555,0.9555555]\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# # Create DataFrame from the list\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m df3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchild_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m: [val] \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(child_model_instance\u001b[38;5;241m.\u001b[39mrewards, start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)})\n\u001b[1;32m     18\u001b[0m df1\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchildskips.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m df2\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchildlabels.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'child_model_instance' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Prefix keys with 'child_'\n",
        "prefixed_data = {f'child_{key}': value for key, value in child_skips.items()}\n",
        "print(prefixed_data)\n",
        "\n",
        "# Convert dictionaries to DataFrames\n",
        "df1 = pd.DataFrame.from_dict(prefixed_data, orient='index').T\n",
        "# df1.head(9)\n",
        "# Prefix keys with 'child_'\n",
        "prefixed_data1 = {f'child_{key}': value for key, value in child_labels.items()}\n",
        "df2 = pd.DataFrame(prefixed_data1)\n",
        "\n",
        "# rewards = [0.8555555,0.9555555]\n",
        "# # Create DataFrame from the list\n",
        "df3 = pd.DataFrame({f'child_{i}': [val] for i, val in enumerate(child_model_instance.rewards, start=0)})\n",
        "\n",
        "df1.to_csv('childskips.csv', index=True)\n",
        "df2.to_csv('childlabels.csv', index=True)\n",
        "df3.to_csv('rewards.csv', index=True)\n",
        "# print(child_skips[0])\n",
        "# Save DataFrames to aseparate csv files \n",
        "# with pd.ExcelWriter('results.xlsx') as writer:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK0QuSFwqOjz"
      },
      "source": [
        "**Retrieve them from csv file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-Ap3F78zP8A-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (3, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (4, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (5, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (6, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (7, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (8, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (9, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (10, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (11, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (12, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (13, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (14, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (15, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (16, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (17, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (18, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (19, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (20, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (21, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (22, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (23, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (24, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (25, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (26, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (27, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (28, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (29, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (30, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (31, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (32, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (33, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (34, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (35, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (36, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (37, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (38, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (39, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (40, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (41, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (42, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (43, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (44, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (45, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (46, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (47, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (48, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (49, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (50, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (51, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (52, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (53, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (54, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (55, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (56, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (57, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (58, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (59, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (60, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (61, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (62, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (63, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (64, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (65, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (66, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (67, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (68, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (69, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (70, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (71, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (72, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (73, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (74, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (75, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (76, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (77, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (78, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (79, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (80, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (81, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (82, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (83, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (84, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (85, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (86, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (87, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (88, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (89, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (90, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (91, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (92, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (93, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (94, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (95, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (96, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (97, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (98, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (99, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (100, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (101, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (102, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (103, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (104, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (105, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (106, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (107, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (108, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (109, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (110, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (111, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (112, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (113, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (114, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (115, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (116, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (117, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (118, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (119, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (120, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (121, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (122, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (123, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (124, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (125, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (126, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (127, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (128, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (129, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (130, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (131, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (132, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (133, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (134, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (135, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (136, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (137, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (138, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (139, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (140, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (141, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (142, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (143, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (144, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (145, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (146, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (147, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (148, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (149, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (150, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (151, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (152, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (153, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (154, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (155, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (156, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (157, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (158, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (159, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (160, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (161, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (162, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (163, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (164, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (165, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (166, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (167, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (168, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (169, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (170, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (171, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (172, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (173, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (174, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (175, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (176, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (177, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (178, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (179, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (180, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (181, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (182, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (183, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (184, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (185, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (186, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (187, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (188, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (189, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (190, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (191, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (192, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (193, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (194, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (195, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (196, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (197, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (198, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (199, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (200, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (201, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (202, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (203, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (204, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (205, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (206, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (207, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (208, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (209, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (210, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (211, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (212, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (213, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (214, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (215, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (216, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (217, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (218, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (219, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (220, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (221, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (222, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (223, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (224, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (225, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (226, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (227, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (228, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (229, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (230, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (231, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (232, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (233, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (234, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (235, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (236, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (237, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (238, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (239, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (240, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (241, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (242, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (243, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (244, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (245, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (246, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (247, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (248, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (249, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (250, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (251, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (252, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (253, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (254, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (255, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (256, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (257, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (258, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (259, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (260, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (261, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (262, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (263, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (264, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (265, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (266, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (267, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (268, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (269, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (270, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (271, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (272, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (273, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (274, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (275, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (276, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (277, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (278, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (279, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (280, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (281, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (282, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (283, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (284, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (285, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (286, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (287, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (288, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (289, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (290, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (291, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (292, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (293, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (294, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (295, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (296, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (297, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (298, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (299, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (300, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (301, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (302, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (303, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (304, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (305, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (306, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (307, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (308, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (309, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (310, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (311, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (312, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (313, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (314, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (315, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (316, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (317, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (318, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (319, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (320, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (321, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (322, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (323, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (324, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (325, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (326, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (327, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (328, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (329, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (330, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (331, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (332, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (333, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (334, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (335, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (336, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (337, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (338, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (339, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (340, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (341, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (342, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (343, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (344, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (345, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (346, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (347, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (348, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (349, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (350, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (351, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (352, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (353, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (354, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (355, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (356, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (357, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (358, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (359, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (360, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (361, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (362, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (363, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (364, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (365, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (366, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (367, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (368, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (369, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (370, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (371, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (372, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (373, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (374, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (375, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (376, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (377, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (378, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (379, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (380, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (381, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (382, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (383, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (384, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (385, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (386, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (387, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (388, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (389, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (390, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (391, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (392, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (393, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (394, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (395, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (396, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (397, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (398, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (399, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (400, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (401, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (402, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (403, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (404, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (405, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (406, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (407, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (408, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (409, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (410, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (411, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (412, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (413, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (414, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (415, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (416, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (417, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (418, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (419, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (420, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (421, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (422, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (423, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (424, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (425, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (426, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (427, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (428, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (429, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (430, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (431, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (432, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (433, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (434, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (435, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (436, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (437, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (438, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (439, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (440, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (441, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (442, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (443, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (444, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (445, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (446, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (447, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (448, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (449, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (450, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (451, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (452, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (453, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (454, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (455, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (456, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (457, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (458, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (459, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (460, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (461, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (462, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (463, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (464, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (465, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (466, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (467, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (468, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (469, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (470, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (471, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (472, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (473, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (474, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (475, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (476, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (477, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (478, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (479, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (480, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (481, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (482, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (483, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (484, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (485, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (486, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (487, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (488, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (489, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (490, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (491, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (492, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (493, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (494, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (495, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (496, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (497, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (498, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (499, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (500, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (501, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (502, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (503, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (504, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (505, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (506, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (507, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (508, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (509, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (510, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (511, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (512, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (513, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (514, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (515, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (516, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (517, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (518, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (519, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (520, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (521, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (522, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (523, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (524, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (525, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (526, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (527, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (528, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (529, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (530, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (531, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (532, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (533, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (534, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (535, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (536, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (537, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (538, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (539, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (540, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (541, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (542, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (543, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (544, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (545, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (546, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (547, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (548, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (549, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (550, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (551, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (552, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (553, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (554, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (555, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (556, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (557, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (558, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (559, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (560, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (561, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (562, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (563, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (564, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (565, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (566, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (567, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (568, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (569, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (570, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (571, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (572, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (573, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (574, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (575, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (576, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (577, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (578, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (579, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (580, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (581, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (582, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (583, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (584, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (585, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (586, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (587, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (588, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (589, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (590, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (591, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (592, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (593, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (594, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (595, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (596, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (597, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (598, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (599, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (600, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (601, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (602, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (603, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (604, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (605, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (606, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (607, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (608, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (609, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (610, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (611, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (612, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (613, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (614, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (615, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (616, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (617, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (618, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (619, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (620, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (621, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (622, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (623, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (624, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (625, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (626, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (627, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (628, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (629, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (630, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (631, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (632, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (633, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (634, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (635, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (636, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (637, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (638, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (639, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (640, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (641, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (642, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (643, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (644, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (645, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (646, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (647, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (648, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (649, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (650, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (651, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (652, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (653, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (654, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (655, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (656, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (657, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (658, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (659, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (660, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (661, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (662, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (663, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (664, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (665, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (666, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (667, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (668, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (669, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (670, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (671, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (672, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (673, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (674, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (675, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (676, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (677, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (678, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (679, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (680, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (681, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (682, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (683, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (684, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (685, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (686, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (687, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (688, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (689, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (690, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (691, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (692, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (693, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (694, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (695, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (696, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (697, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (698, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (699, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (700, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (701, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (702, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (703, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (704, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (705, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (706, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (707, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (708, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (709, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (710, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (711, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (712, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (713, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (714, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (715, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (716, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (717, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (718, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (719, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (720, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (721, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (722, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (723, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (724, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (725, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (726, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (727, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (728, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (729, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (730, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (731, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (732, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (733, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (734, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (735, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (736, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (737, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (738, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (739, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (740, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (741, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (742, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (743, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (744, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (745, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (746, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (747, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (748, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (749, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (750, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (751, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (752, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (753, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (754, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (755, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (756, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (757, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (758, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (759, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (760, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (761, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (762, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (763, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (764, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (765, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (766, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (767, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (768, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (769, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (770, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (771, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (772, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (773, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (774, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (775, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (776, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (777, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (778, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (779, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (780, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (781, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (782, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (783, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (784, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (785, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (786, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (787, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (788, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (789, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (790, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (791, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (792, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (793, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (794, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (795, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (796, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (797, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (798, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (799, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (800, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (801, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (802, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (803, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (804, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (805, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (806, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (807, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (808, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (809, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (810, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (811, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (812, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (813, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (814, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (815, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (816, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (817, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (818, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (819, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (820, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (821, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (822, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (823, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (824, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (825, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (826, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (827, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (828, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (829, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (830, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (831, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (832, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (833, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (834, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (835, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (836, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (837, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (838, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (839, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (840, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (841, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (842, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (843, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (844, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (845, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (846, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (847, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (848, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (849, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (850, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (851, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (852, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (853, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (854, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (855, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (856, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (857, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (858, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (859, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (860, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (861, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (862, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (863, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (864, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (865, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (866, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (867, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (868, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (869, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (870, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (871, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (872, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (873, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (874, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (875, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (876, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (877, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (878, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (879, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (880, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (881, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (882, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (883, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (884, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (885, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (886, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (887, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (888, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (889, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (890, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (891, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (892, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (893, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (894, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (895, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (896, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (897, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (898, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (899, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (900, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (901, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (902, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (903, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (904, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (905, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (906, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (907, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (908, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (909, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (910, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (911, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (912, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (913, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (914, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (915, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (916, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (917, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (918, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (919, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (920, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (921, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (922, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (923, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (924, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (925, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (926, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (927, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (928, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (929, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (930, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (931, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (932, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (933, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (934, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (935, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (936, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (937, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (938, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (939, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (940, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (941, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (942, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (943, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (944, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (945, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (946, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (947, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (948, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (949, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (950, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (951, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (952, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (953, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (954, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (955, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (956, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (957, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (958, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (959, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (960, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (961, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (962, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (963, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (964, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (965, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (966, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (967, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (968, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (969, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (970, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (971, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (972, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (973, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (974, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (975, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (976, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (977, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (978, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (979, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (980, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (981, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (982, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (983, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (984, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (985, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (986, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (987, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (988, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (989, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (990, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (991, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (992, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (993, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (994, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (995, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (996, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (997, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (998, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (999, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (1000, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (1001, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (1002, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (1003, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (1004, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (1005, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (1006, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (1007, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (1008, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (1009, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (1010, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (1011, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (1012, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (1013, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (1014, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (1015, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (1016, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (1017, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (1018, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (1019, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (1020, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (1021, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (1022, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (1023, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (1024, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (1025, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (1026, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (1027, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (1028, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (1029, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (1030, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (1031, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (1032, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (1033, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (1034, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (1035, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (1036, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (1037, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (1038, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (1039, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (1040, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1041, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (1042, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (1043, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (1044, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (1045, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (1046, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (1047, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (1048, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (1049, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (1050, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (1051, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (1052, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (1053, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (1054, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (1055, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (1056, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (1057, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (1058, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (1059, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (1060, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (1061, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (1062, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (1063, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (1064, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (1065, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (1066, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (1067, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (1068, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (1069, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (1070, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (1071, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (1072, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (1073, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (1074, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (1075, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (1076, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (1077, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (1078, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (1079, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (1080, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (1081, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (1082, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (1083, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (1084, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (1085, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (1086, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (1087, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (1088, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (1089, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (1090, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (1091, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (1092, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (1093, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (1094, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (1095, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (1096, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (1097, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (1098, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (1099, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (1100, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (1101, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (1102, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (1103, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (1104, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (1105, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1106, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (1107, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (1108, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (1109, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (1110, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (1111, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (1112, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (1113, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (1114, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (1115, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (1116, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (1117, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (1118, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (1119, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (1120, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (1121, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (1122, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (1123, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (1124, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (1125, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (1126, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (1127, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (1128, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (1129, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (1130, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (1131, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (1132, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (1133, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (1134, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (1135, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (1136, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (1137, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (1138, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (1139, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (1140, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (1141, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (1142, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (1143, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (1144, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (1145, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (1146, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (1147, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (1148, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (1149, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (1150, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (1151, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (1152, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (1153, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (1154, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (1155, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (1156, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (1157, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (1158, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (1159, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (1160, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (1161, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (1162, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (1163, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (1164, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (1165, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (1166, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (1167, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (1168, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (1169, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (1170, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1171, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (1172, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (1173, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (1174, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (1175, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (1176, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (1177, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (1178, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (1179, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (1180, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (1181, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (1182, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (1183, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (1184, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (1185, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (1186, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (1187, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (1188, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (1189, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (1190, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (1191, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (1192, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (1193, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (1194, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (1195, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (1196, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (1197, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (1198, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (1199, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (1200, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (1201, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (1202, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (1203, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (1204, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (1205, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (1206, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (1207, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (1208, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (1209, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (1210, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (1211, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (1212, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (1213, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (1214, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (1215, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (1216, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (1217, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (1218, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (1219, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (1220, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (1221, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (1222, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (1223, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (1224, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (1225, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (1226, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (1227, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (1228, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (1229, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (1230, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (1231, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (1232, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (1233, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (1234, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (1235, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1236, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (1237, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (1238, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (1239, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (1240, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (1241, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (1242, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (1243, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (1244, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (1245, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (1246, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (1247, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (1248, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (1249, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (1250, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (1251, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (1252, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (1253, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (1254, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (1255, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (1256, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (1257, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (1258, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (1259, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (1260, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (1261, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (1262, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (1263, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (1264, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (1265, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (1266, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (1267, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (1268, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (1269, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (1270, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (1271, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (1272, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (1273, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (1274, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (1275, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (1276, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (1277, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (1278, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (1279, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (1280, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (1281, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (1282, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (1283, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (1284, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (1285, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (1286, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (1287, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (1288, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (1289, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (1290, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (1291, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (1292, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (1293, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (1294, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (1295, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (1296, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (1297, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (1298, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (1299, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (1300, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1301, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (1302, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (1303, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (1304, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (1305, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (1306, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (1307, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (1308, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (1309, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (1310, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (1311, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (1312, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (1313, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (1314, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (1315, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (1316, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (1317, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (1318, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (1319, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (1320, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (1321, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (1322, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (1323, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (1324, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (1325, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (1326, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (1327, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (1328, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (1329, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (1330, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (1331, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (1332, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (1333, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (1334, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (1335, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (1336, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (1337, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (1338, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (1339, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (1340, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (1341, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (1342, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (1343, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (1344, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (1345, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (1346, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (1347, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (1348, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (1349, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (1350, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (1351, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (1352, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (1353, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (1354, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (1355, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (1356, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (1357, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (1358, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (1359, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (1360, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (1361, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (1362, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (1363, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (1364, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (1365, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1366, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (1367, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (1368, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (1369, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (1370, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (1371, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (1372, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (1373, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (1374, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (1375, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (1376, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (1377, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (1378, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (1379, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (1380, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (1381, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (1382, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (1383, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (1384, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (1385, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (1386, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (1387, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (1388, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (1389, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (1390, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (1391, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (1392, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (1393, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (1394, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (1395, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (1396, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (1397, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (1398, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (1399, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (1400, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (1401, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (1402, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (1403, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (1404, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (1405, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (1406, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (1407, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (1408, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (1409, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (1410, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (1411, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (1412, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (1413, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (1414, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (1415, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (1416, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (1417, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (1418, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (1419, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (1420, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (1421, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (1422, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (1423, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (1424, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (1425, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (1426, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (1427, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (1428, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (1429, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (1430, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1431, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (1432, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (1433, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (1434, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (1435, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (1436, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (1437, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (1438, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (1439, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (1440, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (1441, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (1442, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (1443, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (1444, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (1445, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (1446, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (1447, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (1448, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (1449, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (1450, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (1451, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (1452, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (1453, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (1454, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (1455, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (1456, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (1457, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (1458, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (1459, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (1460, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (1461, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (1462, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (1463, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (1464, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (1465, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (1466, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (1467, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (1468, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (1469, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (1470, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (1471, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (1472, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (1473, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (1474, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (1475, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (1476, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (1477, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (1478, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (1479, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (1480, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (1481, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (1482, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (1483, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (1484, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (1485, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (1486, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (1487, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (1488, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (1489, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (1490, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (1491, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (1492, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (1493, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (1494, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (1495, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1496, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (1497, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (1498, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (1499, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (1500, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (1501, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (1502, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (1503, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (1504, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (1505, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (1506, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (1507, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (1508, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (1509, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (1510, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (1511, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (1512, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (1513, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (1514, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (1515, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (1516, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (1517, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (1518, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (1519, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (1520, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (1521, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (1522, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (1523, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (1524, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (1525, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (1526, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (1527, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (1528, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (1529, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (1530, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (1531, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (1532, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (1533, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (1534, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (1535, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (1536, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (1537, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (1538, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (1539, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (1540, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (1541, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (1542, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (1543, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (1544, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (1545, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (1546, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (1547, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (1548, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (1549, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (1550, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (1551, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (1552, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (1553, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (1554, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (1555, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (1556, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (1557, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (1558, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (1559, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (1560, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1561, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (1562, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (1563, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (1564, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (1565, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (1566, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (1567, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (1568, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (1569, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (1570, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (1571, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (1572, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (1573, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (1574, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (1575, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (1576, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (1577, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (1578, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (1579, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (1580, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (1581, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (1582, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (1583, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (1584, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (1585, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (1586, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (1587, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (1588, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (1589, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (1590, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (1591, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (1592, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (1593, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (1594, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (1595, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (1596, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (1597, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (1598, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (1599, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (1600, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (1601, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (1602, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (1603, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (1604, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (1605, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (1606, [3, 3, 3, 1, 2, 3, 2, 0, 2, 0, 1, 2, 1, 3, 0]), (1607, [2, 3, 1, 3, 0, 3, 1, 0, 2, 3, 3, 0, 1, 2, 1]), (1608, [2, 2, 1, 1, 1, 2, 3, 2, 3, 3, 2, 0, 2, 0, 2]), (1609, [1, 2, 2, 1, 2, 3, 0, 1, 1, 0, 2, 2, 2, 3, 3]), (1610, [2, 1, 3, 3, 0, 3, 2, 2, 2, 3, 0, 0, 2, 1, 1]), (1611, [0, 0, 3, 1, 2, 2, 2, 1, 1, 0, 3, 1, 0, 3, 0]), (1612, [3, 1, 1, 2, 0, 0, 3, 2, 3, 2, 1, 3, 1, 2, 1]), (1613, [2, 0, 2, 2, 0, 2, 1, 0, 0, 0, 1, 2, 1, 1, 0]), (1614, [0, 2, 3, 0, 0, 0, 3, 0, 2, 3, 1, 1, 0, 3, 0]), (1615, [0, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 3, 3]), (1616, [2, 0, 3, 3, 3, 0, 2, 2, 1, 1, 2, 2, 2, 2, 0]), (1617, [1, 2, 2, 0, 0, 2, 2, 0, 3, 0, 1, 0, 2, 3, 0]), (1618, [1, 3, 3, 0, 3, 2, 2, 1, 1, 0, 3, 1, 2, 1, 0]), (1619, [0, 3, 3, 3, 2, 2, 3, 0, 3, 2, 0, 1, 3, 1, 3]), (1620, [0, 0, 2, 0, 1, 0, 3, 0, 1, 2, 3, 1, 1, 0, 2]), (1621, [3, 2, 0, 1, 1, 0, 0, 2, 1, 1, 1, 2, 3, 3, 2]), (1622, [0, 3, 3, 2, 3, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2]), (1623, [0, 2, 1, 1, 1, 0, 3, 3, 1, 3, 2, 3, 1, 2, 0]), (1624, [1, 0, 2, 0, 2, 0, 0, 1, 0, 1, 0, 1, 0, 2, 2]), (1625, [3, 3, 0, 2, 3, 3, 0, 2, 2, 1, 3, 2, 1, 3, 2]), (1626, [3, 0, 3, 2, 3, 2, 3, 0, 3, 2, 2, 2, 2, 1, 1]), (1627, [1, 0, 0, 2, 0, 1, 2, 3, 3, 0, 3, 2, 3, 1, 2]), (1628, [0, 2, 0, 2, 3, 3, 0, 3, 3, 2, 2, 2, 1, 2, 2]), (1629, [0, 2, 0, 2, 3, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1]), (1630, [2, 3, 3, 0, 1, 3, 3, 3, 0, 3, 1, 3, 0, 1, 1]), (1631, [2, 1, 1, 0, 0, 3, 3, 3, 0, 3, 0, 2, 2, 1, 1]), (1632, [1, 2, 2, 3, 2, 2, 0, 2, 0, 1, 2, 3, 2, 1, 1]), (1633, [2, 3, 2, 0, 1, 2, 2, 3, 3, 0, 0, 0, 2, 3, 1]), (1634, [2, 2, 2, 0, 2, 0, 3, 0, 1, 0, 3, 2, 2, 3, 2]), (1635, [3, 1, 2, 2, 3, 2, 0, 0, 1, 0, 1, 1, 2, 0, 1]), (1636, [2, 2, 3, 2, 1, 0, 1, 0, 0, 0, 0, 1, 3, 2, 3]), (1637, [3, 0, 2, 0, 1, 2, 0, 2, 2, 2, 3, 0, 3, 3, 3]), (1638, [0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 3, 0, 3, 1, 3]), (1639, [0, 2, 2, 3, 3, 0, 0, 3, 2, 2, 1, 0, 3, 1, 3]), (1640, [1, 3, 3, 0, 3, 0, 0, 2, 1, 3, 2, 2, 3, 3, 3]), (1641, [0, 1, 2, 0, 3, 2, 3, 0, 2, 2, 0, 1, 0, 3, 0]), (1642, [2, 0, 0, 0, 0, 3, 0, 2, 3, 0, 3, 2, 2, 3, 3]), (1643, [1, 3, 2, 1, 1, 3, 0, 3, 1, 0, 3, 2, 3, 1, 1]), (1644, [1, 2, 1, 3, 1, 2, 1, 3, 2, 2, 1, 1, 0, 0, 1]), (1645, [1, 2, 2, 3, 2, 3, 2, 1, 1, 1, 2, 2, 1, 3, 3]), (1646, [3, 2, 2, 2, 1, 0, 1, 3, 1, 0, 3, 0, 2, 0, 0]), (1647, [2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 1, 3, 3, 3, 1]), (1648, [1, 2, 0, 2, 0, 1, 0, 1, 1, 1, 3, 1, 1, 0, 1]), (1649, [2, 1, 1, 0, 2, 1, 0, 0, 1, 1, 2, 3, 1, 2, 2]), (1650, [0, 3, 2, 3, 0, 3, 3, 0, 0, 0, 3, 1, 0, 3, 1]), (1651, [3, 0, 3, 3, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 3]), (1652, [2, 0, 1, 1, 0, 0, 2, 0, 2, 3, 2, 1, 3, 3, 2]), (1653, [0, 2, 3, 1, 0, 2, 3, 2, 0, 0, 0, 3, 1, 3, 0]), (1654, [3, 2, 1, 3, 2, 1, 3, 1, 1, 1, 0, 0, 0, 2, 0]), (1655, [0, 2, 3, 1, 1, 3, 0, 0, 2, 0, 2, 0, 0, 2, 0]), (1656, [3, 3, 3, 1, 2, 1, 3, 1, 0, 3, 1, 1, 0, 0, 0]), (1657, [1, 3, 0, 1, 3, 3, 2, 2, 3, 1, 2, 0, 2, 1, 0]), (1658, [2, 0, 2, 0, 2, 3, 3, 3, 2, 2, 0, 2, 0, 0, 2]), (1659, [0, 2, 3, 2, 3, 0, 2, 2, 1, 1, 1, 2, 1, 1, 0]), (1660, [0, 1, 0, 0, 0, 1, 1, 2, 3, 0, 2, 3, 1, 2, 2]), (1661, [3, 0, 0, 0, 2, 0, 0, 3, 2, 0, 2, 1, 2, 0, 2]), (1662, [2, 0, 0, 2, 2, 0, 3, 2, 0, 3, 3, 0, 1, 2, 0]), (1663, [3, 3, 2, 2, 1, 1, 0, 1, 1, 0, 1, 0, 1, 3, 3]), (1664, [1, 3, 2, 1, 2, 1, 0, 0, 3, 1, 2, 1, 1, 1, 0]), (1665, [2, 3, 2, 3, 3, 2, 1, 0, 1, 3, 3, 0, 0, 2, 3]), (1666, [0, 1, 3, 2, 0, 1, 1, 1, 3, 0, 3, 1, 3, 2, 2]), (1667, [1, 3, 1, 0, 0, 0, 0, 0, 2, 3, 2, 0, 2, 2, 2]), (1668, [0, 1, 1, 1, 2, 1, 0, 3, 0, 2, 3, 3, 1, 3, 3]), (1669, [3, 2, 1, 0, 0, 0, 1, 3, 1, 1, 2, 1, 2, 2, 0]), (1670, [0, 0, 3, 0, 3, 0, 1, 2, 3, 0, 3, 1, 3, 2, 1]), (1671, [0, 3, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0]), (1672, [2, 0, 1, 1, 1, 0, 1, 0, 1, 2, 2, 0, 3, 3, 3]), (1673, [1, 3, 1, 3, 2, 2, 3, 2, 1, 2, 1, 1, 0, 0, 0]), (1674, [0, 1, 2, 1, 3, 3, 1, 1, 0, 2, 1, 3, 3, 2, 1]), (1675, [3, 3, 3, 2, 0, 0, 0, 1, 2, 1, 0, 0, 3, 0, 2]), (1676, [1, 0, 3, 2, 3, 3, 3, 3, 3, 3, 1, 1, 2, 1, 0]), (1677, [0, 2, 3, 1, 2, 3, 2, 3, 1, 0, 1, 1, 1, 0, 2]), (1678, [2, 3, 2, 2, 1, 2, 3, 2, 2, 1, 2, 0, 3, 3, 1]), (1679, [3, 1, 1, 0, 1, 2, 0, 0, 3, 1, 3, 0, 3, 3, 3]), (1680, [2, 1, 2, 0, 0, 1, 3, 2, 3, 3, 1, 2, 2, 0, 1]), (1681, [1, 3, 3, 2, 0, 1, 3, 0, 3, 0, 1, 2, 3, 0, 3]), (1682, [2, 0, 0, 3, 3, 1, 3, 0, 1, 2, 0, 3, 3, 2, 3]), (1683, [2, 0, 2, 2, 0, 0, 3, 0, 1, 3, 0, 3, 1, 0, 0]), (1684, [2, 1, 2, 0, 0, 0, 0, 1, 1, 1, 2, 0, 0, 0, 3]), (1685, [2, 1, 3, 2, 2, 1, 0, 2, 1, 0, 1, 3, 1, 3, 1]), (1686, [3, 1, 3, 1, 1, 1, 2, 1, 0, 1, 0, 3, 2, 0, 2]), (1687, [2, 0, 2, 1, 2, 1, 3, 2, 1, 1, 3, 0, 3, 0, 0]), (1688, [2, 0, 0, 0, 0, 3, 3, 0, 0, 3, 1, 1, 2, 3, 2]), (1689, [0, 2, 2, 0, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 2]), (1690, [1, 0, 0, 0, 2, 0, 1, 0, 3, 2, 1, 0, 1, 1, 1]), (1691, [3, 1, 2, 3, 2, 2, 3, 1, 1, 0, 3, 3, 2, 0, 3]), (1692, [3, 0, 1, 0, 2, 2, 0, 1, 1, 2, 1, 2, 3, 2, 3]), (1693, [1, 1, 2, 0, 0, 2, 0, 1, 3, 0, 0, 1, 2, 2, 2]), (1694, [2, 2, 0, 3, 3, 3, 3, 2, 2, 1, 0, 1, 1, 1, 1]), (1695, [1, 0, 2, 0, 1, 0, 2, 2, 2, 0, 1, 3, 2, 3, 3]), (1696, [2, 3, 1, 0, 2, 2, 3, 3, 2, 1, 2, 3, 0, 2, 3]), (1697, [1, 2, 1, 3, 0, 1, 0, 2, 1, 0, 1, 1, 0, 0, 3]), (1698, [1, 3, 1, 3, 0, 3, 1, 2, 1, 2, 1, 2, 2, 2, 0]), (1699, [1, 3, 1, 2, 0, 1, 3, 2, 0, 3, 3, 3, 1, 0, 3]), (1700, [1, 1, 3, 3, 3, 3, 1, 1, 1, 2, 2, 3, 2, 3, 1]), (1701, [1, 2, 3, 0, 1, 0, 3, 3, 3, 1, 1, 0, 3, 2, 3]), (1702, [1, 3, 3, 3, 0, 0, 3, 3, 1, 1, 1, 2, 2, 3, 1]), (1703, [2, 2, 3, 0, 3, 2, 3, 3, 3, 0, 1, 3, 0, 2, 3]), (1704, [3, 0, 3, 2, 2, 3, 1, 3, 2, 1, 1, 2, 1, 1, 1]), (1705, [0, 1, 1, 0, 0, 2, 2, 2, 0, 1, 1, 2, 2, 3, 0]), (1706, [0, 2, 0, 2, 3, 0, 1, 3, 1, 0, 1, 1, 1, 2, 1]), (1707, [0, 0, 3, 2, 3, 2, 1, 2, 0, 1, 0, 0, 2, 0, 0]), (1708, [3, 0, 3, 3, 3, 0, 1, 2, 1, 2, 3, 1, 0, 3, 2]), (1709, [0, 2, 3, 2, 2, 3, 0, 2, 3, 0, 3, 0, 1, 0, 2]), (1710, [2, 1, 1, 1, 2, 3, 0, 2, 2, 0, 1, 2, 1, 2, 2]), (1711, [2, 0, 2, 0, 2, 3, 3, 1, 3, 2, 1, 2, 3, 0, 1]), (1712, [1, 0, 3, 0, 1, 1, 2, 2, 1, 1, 1, 1, 3, 1, 3]), (1713, [3, 3, 3, 2, 3, 0, 2, 1, 2, 3, 3, 1, 3, 0, 1]), (1714, [1, 1, 3, 1, 2, 3, 0, 2, 2, 1, 1, 1, 0, 0, 0]), (1715, [1, 3, 3, 1, 3, 0, 2, 3, 0, 1, 0, 3, 1, 3, 0]), (1716, [2, 1, 1, 0, 3, 0, 3, 1, 2, 3, 2, 0, 0, 3, 1]), (1717, [0, 1, 0, 1, 1, 1, 1, 1, 2, 3, 2, 0, 3, 0, 3]), (1718, [3, 2, 0, 1, 2, 3, 3, 2, 0, 3, 0, 2, 3, 0, 3]), (1719, [0, 3, 1, 1, 3, 1, 2, 0, 0, 1, 1, 2, 3, 0, 0]), (1720, [0, 1, 2, 3, 0, 3, 1, 2, 0, 1, 3, 2, 2, 3, 0]), (1721, [1, 0, 3, 1, 0, 0, 3, 0, 1, 1, 3, 0, 0, 3, 2]), (1722, [1, 1, 3, 1, 2, 0, 2, 0, 1, 2, 1, 1, 3, 2, 3]), (1723, [3, 3, 0, 0, 2, 2, 3, 2, 3, 0, 3, 1, 3, 1, 0]), (1724, [2, 3, 3, 2, 2, 1, 2, 3, 0, 2, 0, 3, 0, 3, 0]), (1725, [2, 3, 3, 0, 0, 1, 0, 3, 0, 0, 3, 3, 2, 2, 2]), (1726, [3, 3, 0, 3, 3, 3, 1, 2, 2, 1, 1, 2, 2, 1, 1]), (1727, [1, 1, 2, 0, 3, 2, 1, 0, 0, 3, 3, 1, 1, 2, 0]), (1728, [3, 2, 1, 1, 2, 0, 1, 0, 1, 2, 3, 2, 0, 1, 0]), (1729, [0, 2, 1, 3, 0, 1, 0, 3, 3, 2, 1, 0, 3, 1, 1]), (1730, [2, 0, 1, 2, 0, 3, 2, 2, 3, 2, 1, 0, 3, 0, 0]), (1731, [3, 1, 3, 1, 2, 0, 1, 2, 0, 3, 2, 2, 0, 3, 1]), (1732, [0, 0, 1, 3, 2, 0, 0, 2, 2, 1, 3, 0, 0, 3, 3]), (1733, [3, 3, 3, 1, 0, 1, 0, 2, 2, 2, 2, 2, 3, 0, 1]), (1734, [0, 2, 1, 2, 1, 1, 2, 0, 0, 1, 3, 1, 0, 1, 2]), (1735, [3, 2, 1, 2, 1, 2, 2, 0, 0, 0, 3, 3, 3, 3, 2]), (1736, [1, 2, 3, 3, 1, 0, 3, 1, 0, 3, 1, 3, 0, 3, 0]), (1737, [1, 3, 3, 1, 2, 0, 1, 1, 1, 1, 0, 3, 0, 2, 3]), (1738, [1, 3, 1, 3, 2, 2, 0, 3, 0, 3, 3, 2, 2, 2, 3]), (1739, [3, 1, 3, 1, 1, 1, 2, 1, 3, 3, 3, 1, 1, 2, 3]), (1740, [1, 0, 1, 0, 2, 0, 2, 0, 3, 3, 0, 1, 0, 3, 1]), (1741, [0, 0, 2, 3, 3, 3, 3, 0, 1, 2, 2, 2, 3, 3, 3]), (1742, [1, 1, 3, 2, 3, 3, 3, 0, 2, 2, 1, 1, 2, 2, 2]), (1743, [0, 1, 0, 3, 0, 0, 2, 3, 2, 1, 0, 2, 2, 3, 1]), (1744, [0, 3, 3, 0, 1, 2, 0, 0, 2, 0, 3, 0, 3, 3, 1]), (1745, [0, 1, 3, 2, 1, 2, 0, 0, 3, 0, 1, 0, 2, 3, 0]), (1746, [3, 3, 3, 1, 2, 3, 2, 0, 2, 0, 1, 2, 1, 3, 0]), (1747, [2, 3, 1, 3, 0, 3, 1, 0, 2, 3, 3, 0, 1, 2, 1]), (1748, [2, 2, 1, 1, 1, 2, 3, 2, 3, 3, 2, 0, 2, 0, 2]), (1749, [1, 2, 2, 1, 2, 3, 0, 1, 1, 0, 2, 2, 2, 3, 3]), (1750, [2, 1, 3, 3, 0, 3, 2, 2, 2, 3, 0, 0, 2, 1, 1]), (1751, [0, 0, 3, 1, 2, 2, 2, 1, 1, 0, 3, 1, 0, 3, 0]), (1752, [3, 1, 1, 2, 0, 0, 3, 2, 3, 2, 1, 3, 1, 2, 1]), (1753, [2, 0, 2, 2, 0, 2, 1, 0, 0, 0, 1, 2, 1, 1, 0]), (1754, [0, 2, 3, 0, 0, 0, 3, 0, 2, 3, 1, 1, 0, 3, 0]), (1755, [0, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 3, 3]), (1756, [2, 0, 3, 3, 3, 0, 2, 2, 1, 1, 2, 2, 2, 2, 0]), (1757, [1, 2, 2, 0, 0, 2, 2, 0, 3, 0, 1, 0, 2, 3, 0]), (1758, [1, 3, 3, 0, 3, 2, 2, 1, 1, 0, 3, 1, 2, 1, 0]), (1759, [0, 3, 3, 3, 2, 2, 3, 0, 3, 2, 0, 1, 3, 1, 3]), (1760, [0, 0, 2, 0, 1, 0, 3, 0, 1, 2, 3, 1, 1, 0, 2]), (1761, [3, 2, 0, 1, 1, 0, 0, 2, 1, 1, 1, 2, 3, 3, 2]), (1762, [0, 3, 3, 2, 3, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2]), (1763, [0, 2, 1, 1, 1, 0, 3, 3, 1, 3, 2, 3, 1, 2, 0]), (1764, [1, 0, 2, 0, 2, 0, 0, 1, 0, 1, 0, 1, 0, 2, 2]), (1765, [3, 3, 0, 2, 3, 3, 0, 2, 2, 1, 3, 2, 1, 3, 2]), (1766, [3, 0, 3, 2, 3, 2, 3, 0, 3, 2, 2, 2, 2, 1, 1]), (1767, [1, 0, 0, 2, 0, 1, 2, 3, 3, 0, 3, 2, 3, 1, 2]), (1768, [0, 2, 0, 2, 3, 3, 0, 3, 3, 2, 2, 2, 1, 2, 2]), (1769, [0, 2, 0, 2, 3, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1]), (1770, [2, 3, 3, 0, 1, 3, 3, 3, 0, 3, 1, 3, 0, 1, 1]), (1771, [2, 1, 1, 0, 0, 3, 3, 3, 0, 3, 0, 2, 2, 1, 1]), (1772, [1, 2, 2, 3, 2, 2, 0, 2, 0, 1, 2, 3, 2, 1, 1]), (1773, [2, 3, 2, 0, 1, 2, 2, 3, 3, 0, 0, 0, 2, 3, 1]), (1774, [2, 2, 2, 0, 2, 0, 3, 0, 1, 0, 3, 2, 2, 3, 2]), (1775, [3, 1, 2, 2, 3, 2, 0, 0, 1, 0, 1, 1, 2, 0, 1]), (1776, [2, 2, 3, 2, 1, 0, 1, 0, 0, 0, 0, 1, 3, 2, 3]), (1777, [3, 0, 2, 0, 1, 2, 0, 2, 2, 2, 3, 0, 3, 3, 3]), (1778, [0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 3, 0, 3, 1, 3]), (1779, [0, 2, 2, 3, 3, 0, 0, 3, 2, 2, 1, 0, 3, 1, 3]), (1780, [1, 3, 3, 0, 3, 0, 0, 2, 1, 3, 2, 2, 3, 3, 3]), (1781, [0, 1, 2, 0, 3, 2, 3, 0, 2, 2, 0, 1, 0, 3, 0]), (1782, [2, 0, 0, 0, 0, 3, 0, 2, 3, 0, 3, 2, 2, 3, 3]), (1783, [1, 3, 2, 1, 1, 3, 0, 3, 1, 0, 3, 2, 3, 1, 1]), (1784, [1, 2, 1, 3, 1, 2, 1, 3, 2, 2, 1, 1, 0, 0, 1]), (1785, [1, 2, 2, 3, 2, 3, 2, 1, 1, 1, 2, 2, 1, 3, 3]), (1786, [3, 2, 2, 2, 1, 0, 1, 3, 1, 0, 3, 0, 2, 0, 0]), (1787, [2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 1, 3, 3, 3, 1]), (1788, [1, 2, 0, 2, 0, 1, 0, 1, 1, 1, 3, 1, 1, 0, 1]), (1789, [2, 1, 1, 0, 2, 1, 0, 0, 1, 1, 2, 3, 1, 2, 2]), (1790, [0, 3, 2, 3, 0, 3, 3, 0, 0, 0, 3, 1, 0, 3, 1]), (1791, [3, 0, 3, 3, 0, 1, 1, 2, 2, 1, 2, 1, 1, 2, 3]), (1792, [2, 0, 1, 1, 0, 0, 2, 0, 2, 3, 2, 1, 3, 3, 2]), (1793, [0, 2, 3, 1, 0, 2, 3, 2, 0, 0, 0, 3, 1, 3, 0]), (1794, [3, 2, 1, 3, 2, 1, 3, 1, 1, 1, 0, 0, 0, 2, 0]), (1795, [0, 2, 3, 1, 1, 3, 0, 0, 2, 0, 2, 0, 0, 2, 0]), (1796, [3, 3, 3, 1, 2, 1, 3, 1, 0, 3, 1, 1, 0, 0, 0]), (1797, [1, 3, 0, 1, 3, 3, 2, 2, 3, 1, 2, 0, 2, 1, 0]), (1798, [2, 0, 2, 0, 2, 3, 3, 3, 2, 2, 0, 2, 0, 0, 2]), (1799, [0, 2, 3, 2, 3, 0, 2, 2, 1, 1, 1, 2, 1, 1, 0]), (1800, [0, 1, 0, 0, 0, 1, 1, 2, 3, 0, 2, 3, 1, 2, 2]), (1801, [3, 0, 0, 0, 2, 0, 0, 3, 2, 0, 2, 1, 2, 0, 2]), (1802, [2, 0, 0, 2, 2, 0, 3, 2, 0, 3, 3, 0, 1, 2, 0]), (1803, [3, 3, 2, 2, 1, 1, 0, 1, 1, 0, 1, 0, 1, 3, 3]), (1804, [1, 3, 2, 1, 2, 1, 0, 0, 3, 1, 2, 1, 1, 1, 0]), (1805, [2, 3, 2, 3, 3, 2, 1, 0, 1, 3, 3, 0, 0, 2, 3]), (1806, [0, 1, 3, 2, 0, 1, 1, 1, 3, 0, 3, 1, 3, 2, 2]), (1807, [1, 3, 1, 0, 0, 0, 0, 0, 2, 3, 2, 0, 2, 2, 2]), (1808, [0, 1, 1, 1, 2, 1, 0, 3, 0, 2, 3, 3, 1, 3, 3]), (1809, [3, 2, 1, 0, 0, 0, 1, 3, 1, 1, 2, 1, 2, 2, 0]), (1810, [0, 0, 3, 0, 3, 0, 1, 2, 3, 0, 3, 1, 3, 2, 1]), (1811, [0, 3, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0]), (1812, [2, 0, 1, 1, 1, 0, 1, 0, 1, 2, 2, 0, 3, 3, 3]), (1813, [1, 3, 1, 3, 2, 2, 3, 2, 1, 2, 1, 1, 0, 0, 0]), (1814, [0, 1, 2, 1, 3, 3, 1, 1, 0, 2, 1, 3, 3, 2, 1]), (1815, [3, 3, 3, 2, 0, 0, 0, 1, 2, 1, 0, 0, 3, 0, 2]), (1816, [1, 0, 3, 2, 3, 3, 3, 3, 3, 3, 1, 1, 2, 1, 0]), (1817, [0, 2, 3, 1, 2, 3, 2, 3, 1, 0, 1, 1, 1, 0, 2]), (1818, [2, 3, 2, 2, 1, 2, 3, 2, 2, 1, 2, 0, 3, 3, 1]), (1819, [3, 1, 1, 0, 1, 2, 0, 0, 3, 1, 3, 0, 3, 3, 3]), (1820, [2, 1, 2, 0, 0, 1, 3, 2, 3, 3, 1, 2, 2, 0, 1]), (1821, [1, 3, 3, 2, 0, 1, 3, 0, 3, 0, 1, 2, 3, 0, 3]), (1822, [2, 0, 0, 3, 3, 1, 3, 0, 1, 2, 0, 3, 3, 2, 3]), (1823, [2, 0, 2, 2, 0, 0, 3, 0, 1, 3, 0, 3, 1, 0, 0]), (1824, [2, 1, 2, 0, 0, 0, 0, 1, 1, 1, 2, 0, 0, 0, 3]), (1825, [2, 1, 3, 2, 2, 1, 0, 2, 1, 0, 1, 3, 1, 3, 1]), (1826, [3, 1, 3, 1, 1, 1, 2, 1, 0, 1, 0, 3, 2, 0, 2]), (1827, [2, 0, 2, 1, 2, 1, 3, 2, 1, 1, 3, 0, 3, 0, 0]), (1828, [2, 0, 0, 0, 0, 3, 3, 0, 0, 3, 1, 1, 2, 3, 2]), (1829, [0, 2, 2, 0, 3, 2, 1, 2, 0, 1, 2, 1, 2, 1, 2]), (1830, [1, 0, 0, 0, 2, 0, 1, 0, 3, 2, 1, 0, 1, 1, 1]), (1831, [3, 1, 2, 3, 2, 2, 3, 1, 1, 0, 3, 3, 2, 0, 3]), (1832, [3, 0, 1, 0, 2, 2, 0, 1, 1, 2, 1, 2, 3, 2, 3]), (1833, [1, 1, 2, 0, 0, 2, 0, 1, 3, 0, 0, 1, 2, 2, 2]), (1834, [2, 2, 0, 3, 3, 3, 3, 2, 2, 1, 0, 1, 1, 1, 1]), (1835, [1, 0, 2, 0, 1, 0, 2, 2, 2, 0, 1, 3, 2, 3, 3]), (1836, [2, 3, 1, 0, 2, 2, 3, 3, 2, 1, 2, 3, 0, 2, 3]), (1837, [1, 2, 1, 3, 0, 1, 0, 2, 1, 0, 1, 1, 0, 0, 3]), (1838, [1, 3, 1, 3, 0, 3, 1, 2, 1, 2, 1, 2, 2, 2, 0]), (1839, [1, 3, 1, 2, 0, 1, 3, 2, 0, 3, 3, 3, 1, 0, 3]), (1840, [1, 1, 3, 3, 3, 3, 1, 1, 1, 2, 2, 3, 2, 3, 1]), (1841, [1, 2, 3, 0, 1, 0, 3, 3, 3, 1, 1, 0, 3, 2, 3]), (1842, [1, 3, 3, 3, 0, 0, 3, 3, 1, 1, 1, 2, 2, 3, 1]), (1843, [2, 2, 3, 0, 3, 2, 3, 3, 3, 0, 1, 3, 0, 2, 3]), (1844, [3, 0, 3, 2, 2, 3, 1, 3, 2, 1, 1, 2, 1, 1, 1]), (1845, [0, 1, 1, 0, 0, 2, 2, 2, 0, 1, 1, 2, 2, 3, 0]), (1846, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1847, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (1848, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (1849, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (1850, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (1851, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (1852, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (1853, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (1854, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (1855, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (1856, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (1857, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (1858, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (1859, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (1860, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (1861, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (1862, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (1863, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (1864, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (1865, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (1866, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (1867, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (1868, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (1869, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (1870, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (1871, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (1872, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (1873, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (1874, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (1875, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (1876, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (1877, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (1878, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (1879, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (1880, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (1881, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (1882, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (1883, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (1884, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (1885, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (1886, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (1887, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (1888, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (1889, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (1890, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (1891, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (1892, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (1893, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (1894, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (1895, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (1896, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (1897, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (1898, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (1899, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (1900, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (1901, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (1902, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (1903, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (1904, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (1905, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (1906, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (1907, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (1908, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (1909, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (1910, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (1911, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1912, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (1913, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (1914, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (1915, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (1916, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (1917, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (1918, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (1919, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (1920, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (1921, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (1922, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (1923, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (1924, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (1925, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (1926, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (1927, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (1928, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (1929, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (1930, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (1931, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (1932, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (1933, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (1934, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (1935, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (1936, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (1937, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (1938, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (1939, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (1940, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (1941, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (1942, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (1943, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (1944, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (1945, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (1946, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (1947, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (1948, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (1949, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (1950, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (1951, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (1952, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (1953, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (1954, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (1955, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (1956, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (1957, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (1958, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (1959, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (1960, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (1961, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (1962, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (1963, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (1964, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (1965, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (1966, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (1967, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (1968, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (1969, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (1970, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (1971, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (1972, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (1973, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (1974, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (1975, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (1976, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (1977, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (1978, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (1979, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (1980, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (1981, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (1982, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (1983, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (1984, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (1985, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (1986, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (1987, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (1988, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (1989, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (1990, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (1991, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (1992, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (1993, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (1994, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (1995, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (1996, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (1997, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (1998, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (1999, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2000, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2001, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2002, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2003, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2004, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2005, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2006, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2007, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2008, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2009, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2010, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2011, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2012, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2013, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2014, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2015, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2016, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2017, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2018, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2019, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2020, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2021, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2022, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2023, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2024, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2025, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2026, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2027, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2028, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2029, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2030, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2031, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2032, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2033, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2034, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2035, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2036, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2037, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2038, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2039, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2040, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2041, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2042, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2043, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2044, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2045, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2046, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2047, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2048, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2049, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2050, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2051, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2052, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2053, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2054, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2055, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2056, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2057, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2058, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2059, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2060, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2061, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2062, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2063, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2064, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2065, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2066, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2067, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2068, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2069, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2070, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2071, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2072, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2073, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2074, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2075, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2076, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2077, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2078, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2079, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2080, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2081, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2082, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2083, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2084, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2085, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2086, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2087, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2088, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2089, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2090, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2091, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2092, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2093, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2094, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2095, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2096, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2097, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2098, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2099, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2100, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2101, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2102, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2103, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2104, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2105, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2106, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2107, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2108, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2109, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2110, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2111, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2112, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2113, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2114, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2115, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2116, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2117, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2118, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2119, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2120, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2121, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2122, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2123, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2124, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2125, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2126, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2127, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2128, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2129, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2130, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2131, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2132, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2133, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2134, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2135, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2136, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2137, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2138, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2139, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2140, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2141, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2142, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2143, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2144, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2145, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2146, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2147, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2148, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2149, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2150, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2151, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2152, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2153, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2154, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2155, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2156, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2157, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2158, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2159, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2160, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2161, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2162, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2163, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2164, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2165, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2166, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2167, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2168, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2169, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2170, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2171, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2172, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2173, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2174, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2175, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2176, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2177, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2178, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2179, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2180, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2181, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2182, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2183, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2184, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2185, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2186, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2187, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2188, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2189, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2190, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2191, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2192, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2193, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2194, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2195, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2196, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2197, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2198, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2199, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2200, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2201, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2202, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2203, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2204, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2205, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2206, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2207, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2208, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2209, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2210, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2211, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2212, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2213, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2214, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2215, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2216, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2217, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2218, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2219, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2220, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2221, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2222, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2223, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2224, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2225, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2226, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2227, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2228, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2229, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2230, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2231, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2232, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2233, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2234, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2235, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2236, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2237, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2238, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2239, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2240, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2241, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2242, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2243, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2244, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2245, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2246, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2247, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2248, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2249, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2250, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2251, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2252, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2253, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2254, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2255, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2256, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2257, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2258, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2259, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2260, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2261, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2262, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2263, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2264, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2265, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2266, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2267, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2268, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2269, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2270, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2271, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2272, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2273, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2274, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2275, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2276, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2277, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2278, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2279, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2280, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2281, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2282, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2283, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2284, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2285, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2286, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2287, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2288, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2289, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2290, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2291, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2292, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2293, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2294, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2295, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2296, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2297, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2298, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2299, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2300, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2301, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2302, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2303, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2304, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2305, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2306, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2307, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2308, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2309, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2310, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2311, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2312, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2313, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2314, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2315, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2316, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2317, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2318, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2319, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2320, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2321, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2322, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2323, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2324, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2325, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2326, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2327, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2328, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2329, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2330, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2331, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2332, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2333, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2334, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2335, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2336, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2337, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2338, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2339, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2340, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2341, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2342, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2343, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2344, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2345, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2346, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2347, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2348, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2349, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2350, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2351, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2352, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2353, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2354, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2355, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2356, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2357, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2358, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2359, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2360, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2361, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2362, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2363, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2364, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2365, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2366, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2367, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2368, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2369, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2370, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2371, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2372, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2373, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2374, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2375, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2376, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2377, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2378, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2379, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2380, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2381, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2382, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2383, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2384, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2385, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2386, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2387, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2388, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2389, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2390, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2391, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2392, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2393, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2394, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2395, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2396, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2397, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2398, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2399, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2400, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2401, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2402, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2403, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2404, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2405, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2406, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2407, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2408, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2409, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2410, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2411, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2412, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2413, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2414, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2415, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2416, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2417, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2418, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2419, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2420, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2421, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2422, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2423, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2424, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2425, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2426, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2427, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2428, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2429, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2430, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2431, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2432, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2433, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2434, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2435, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2436, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2437, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2438, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2439, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2440, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2441, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2442, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2443, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2444, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2445, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2446, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2447, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2448, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2449, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2450, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2451, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2452, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2453, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2454, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2455, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2456, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2457, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2458, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2459, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2460, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2461, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2462, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2463, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2464, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2465, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2466, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2467, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2468, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2469, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2470, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2471, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2472, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2473, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2474, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2475, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2476, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2477, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2478, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2479, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2480, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2481, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2482, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2483, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2484, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2485, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2486, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2487, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2488, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2489, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2490, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2491, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2492, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2493, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2494, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2495, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2496, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2497, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2498, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2499, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2500, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2501, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2502, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2503, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2504, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2505, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2506, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2507, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2508, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2509, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2510, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2511, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2512, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2513, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2514, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2515, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2516, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2517, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2518, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2519, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2520, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2521, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2522, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2523, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2524, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2525, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2526, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2527, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2528, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2529, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2530, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2531, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2532, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2533, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2534, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2535, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2536, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2537, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2538, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2539, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2540, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2541, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2542, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2543, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2544, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2545, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2546, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2547, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2548, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2549, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2550, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2551, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2552, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2553, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2554, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2555, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2556, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2557, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2558, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2559, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2560, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2561, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2562, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2563, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2564, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2565, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2566, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2567, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2568, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2569, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2570, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2571, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2572, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2573, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2574, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2575, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2576, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2577, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2578, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2579, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2580, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2581, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2582, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2583, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2584, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2585, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2586, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2587, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2588, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2589, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2590, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2591, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2592, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2593, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2594, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2595, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2596, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2597, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2598, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2599, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2600, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2601, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2602, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2603, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2604, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2605, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2606, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2607, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2608, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2609, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2610, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2611, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2612, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2613, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2614, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2615, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2616, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2617, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2618, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2619, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2620, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2621, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2622, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2623, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2624, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2625, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2626, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2627, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2628, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2629, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2630, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2631, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2632, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2633, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2634, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2635, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2636, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2637, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2638, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2639, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2640, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2641, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2642, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2643, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2644, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2645, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2646, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2647, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2648, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2649, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2650, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2651, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2652, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2653, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2654, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2655, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2656, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2657, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2658, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2659, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2660, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2661, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2662, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2663, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2664, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2665, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2666, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2667, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2668, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2669, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2670, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2671, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2672, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2673, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2674, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2675, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2676, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2677, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2678, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2679, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2680, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2681, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2682, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2683, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2684, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2685, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2686, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2687, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2688, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2689, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2690, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2691, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2692, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2693, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2694, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2695, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2696, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2697, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2698, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2699, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2700, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2701, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2702, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2703, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2704, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2705, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2706, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2707, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2708, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2709, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2710, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2711, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2712, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2713, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2714, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2715, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2716, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2717, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2718, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2719, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2720, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2721, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2722, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2723, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2724, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2725, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2726, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2727, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2728, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2729, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2730, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2731, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2732, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2733, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2734, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2735, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2736, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2737, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2738, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2739, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2740, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2741, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2742, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2743, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2744, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2745, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2746, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2747, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2748, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2749, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2750, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2751, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2752, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2753, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2754, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2755, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2756, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2757, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2758, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2759, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2760, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2761, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2762, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2763, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2764, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2765, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2766, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2767, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2768, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2769, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2770, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2771, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2772, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2773, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2774, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2775, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2776, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2777, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2778, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2779, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2780, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2781, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2782, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2783, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2784, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2785, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2786, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2787, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2788, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2789, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2790, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2791, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2792, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2793, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2794, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2795, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2796, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2797, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2798, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2799, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2800, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2801, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2802, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2803, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2804, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2805, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2806, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2807, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2808, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2809, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2810, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2811, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2812, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2813, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2814, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2815, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2816, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2817, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2818, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2819, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2820, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2821, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2822, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2823, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2824, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2825, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2826, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2827, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2828, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2829, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2830, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2831, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2832, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2833, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2834, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2835, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2836, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2837, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2838, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2839, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2840, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2841, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2842, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2843, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2844, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2845, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2846, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2847, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2848, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2849, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2850, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2851, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2852, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2853, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2854, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2855, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2856, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2857, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2858, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2859, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2860, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2861, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2862, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2863, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2864, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2865, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2866, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2867, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2868, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2869, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2870, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2871, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2872, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2873, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2874, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2875, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2876, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2877, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2878, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2879, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2880, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2881, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2882, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2883, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2884, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2885, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2886, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2887, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2888, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2889, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2890, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2891, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2892, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2893, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2894, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2895, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2896, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2897, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2898, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2899, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2900, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2901, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2902, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2903, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2904, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2905, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2906, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2907, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2908, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2909, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2910, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2911, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2912, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2913, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2914, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2915, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2916, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2917, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2918, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2919, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2920, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2921, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2922, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2923, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2924, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2925, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2926, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2927, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2928, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2929, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2930, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2931, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2932, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2933, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2934, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (2935, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (2936, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (2937, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (2938, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (2939, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (2940, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (2941, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (2942, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (2943, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (2944, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (2945, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (2946, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (2947, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (2948, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (2949, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (2950, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (2951, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (2952, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (2953, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (2954, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (2955, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (2956, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (2957, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (2958, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (2959, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (2960, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (2961, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (2962, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (2963, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (2964, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (2965, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (2966, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (2967, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (2968, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (2969, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (2970, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (2971, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (2972, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (2973, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (2974, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (2975, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (2976, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (2977, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (2978, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (2979, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (2980, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (2981, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (2982, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (2983, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (2984, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (2985, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (2986, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (2987, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (2988, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (2989, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (2990, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (2991, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (2992, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (2993, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (2994, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (2995, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (2996, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (2997, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (2998, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (2999, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (3000, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (3001, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (3002, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (3003, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (3004, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (3005, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (3006, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (3007, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (3008, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (3009, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (3010, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (3011, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (3012, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (3013, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (3014, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (3015, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (3016, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (3017, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (3018, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (3019, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (3020, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (3021, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (3022, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (3023, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (3024, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (3025, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (3026, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (3027, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (3028, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (3029, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (3030, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (3031, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (3032, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (3033, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (3034, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (3035, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (3036, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (3037, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (3038, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (3039, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (3040, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (3041, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (3042, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (3043, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (3044, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (3045, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (3046, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (3047, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (3048, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (3049, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (3050, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (3051, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (3052, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (3053, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (3054, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (3055, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (3056, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (3057, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (3058, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (3059, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (3060, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (3061, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (3062, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (3063, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (3064, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (3065, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (3066, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (3067, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (3068, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (3069, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (3070, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (3071, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (3072, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (3073, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (3074, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (3075, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (3076, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (3077, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (3078, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (3079, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (3080, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (3081, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (3082, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (3083, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (3084, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (3085, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (3086, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (3087, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (3088, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (3089, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (3090, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (3091, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (3092, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (3093, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (3094, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (3095, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (3096, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (3097, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (3098, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (3099, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (3100, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (3101, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (3102, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (3103, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (3104, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (3105, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (3106, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (3107, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (3108, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (3109, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (3110, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (3111, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (3112, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (3113, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (3114, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (3115, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (3116, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (3117, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (3118, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (3119, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (3120, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (3121, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (3122, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (3123, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (3124, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (3125, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (3126, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (3127, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (3128, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (3129, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (3130, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (3131, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (3132, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (3133, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (3134, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (3135, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (3136, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (3137, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (3138, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (3139, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (3140, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (3141, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (3142, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (3143, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (3144, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (3145, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (3146, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (3147, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (3148, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (3149, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (3150, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (3151, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (3152, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (3153, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (3154, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (3155, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (3156, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (3157, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (3158, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (3159, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (3160, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (3161, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (3162, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (3163, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (3164, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (3165, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (3166, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (3167, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (3168, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (3169, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (3170, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (3171, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (3172, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (3173, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (3174, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (3175, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (3176, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (3177, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (3178, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (3179, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (3180, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (3181, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (3182, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (3183, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (3184, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (3185, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (3186, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (3187, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (3188, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (3189, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (3190, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (3191, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (3192, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (3193, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (3194, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (3195, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (3196, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (3197, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (3198, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (3199, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (3200, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (3201, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (3202, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (3203, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (3204, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (3205, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (3206, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (3207, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (3208, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (3209, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (3210, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (3211, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (3212, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (3213, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (3214, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (3215, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (3216, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (3217, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (3218, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (3219, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (3220, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (3221, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (3222, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (3223, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (3224, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (3225, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (3226, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (3227, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (3228, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (3229, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (3230, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (3231, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (3232, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (3233, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (3234, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (3235, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (3236, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (3237, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (3238, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (3239, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (3240, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (3241, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (3242, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (3243, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (3244, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (3245, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (3246, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (3247, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (3248, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (3249, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (3250, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (3251, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (3252, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (3253, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (3254, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (3255, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (3256, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (3257, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (3258, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (3259, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (3260, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (3261, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (3262, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (3263, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (3264, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (3265, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (3266, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (3267, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (3268, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (3269, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (3270, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (3271, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (3272, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (3273, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (3274, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (3275, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (3276, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (3277, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (3278, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (3279, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (3280, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (3281, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (3282, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (3283, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (3284, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (3285, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (3286, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (3287, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (3288, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (3289, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (3290, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (3291, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (3292, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (3293, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (3294, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (3295, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (3296, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (3297, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (3298, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (3299, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (3300, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (3301, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (3302, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (3303, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (3304, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (3305, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (3306, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (3307, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (3308, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (3309, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (3310, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (3311, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (3312, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (3313, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (3314, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (3315, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (3316, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (3317, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (3318, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (3319, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (3320, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (3321, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (3322, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (3323, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (3324, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (3325, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (3326, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (3327, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (3328, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (3329, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (3330, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (3331, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (3332, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (3333, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (3334, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (3335, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (3336, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (3337, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (3338, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (3339, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (3340, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (3341, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (3342, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (3343, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (3344, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (3345, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (3346, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (3347, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (3348, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (3349, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (3350, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (3351, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (3352, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (3353, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (3354, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (3355, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (3356, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (3357, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (3358, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (3359, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (3360, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (3361, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (3362, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (3363, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (3364, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (3365, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (3366, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (3367, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (3368, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (3369, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (3370, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (3371, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (3372, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (3373, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (3374, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (3375, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (3376, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (3377, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (3378, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (3379, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (3380, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (3381, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (3382, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (3383, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (3384, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (3385, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (3386, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1]), (3387, [1, 1, 2, 0, 2, 0, 3, 2, 0, 2, 2, 2, 3, 0, 1]), (3388, [0, 1, 1, 3, 0, 2, 1, 3, 1, 1, 2, 2, 2, 2, 0]), (3389, [1, 0, 2, 2, 2, 3, 3, 1, 3, 2, 3, 1, 3, 3, 2]), (3390, [0, 0, 1, 1, 3, 3, 1, 1, 1, 0, 2, 0, 1, 0, 1]), (3391, [0, 2, 1, 3, 2, 2, 1, 3, 0, 2, 3, 1, 3, 2, 3]), (3392, [0, 0, 0, 2, 3, 3, 1, 1, 3, 3, 0, 1, 2, 2, 3]), (3393, [3, 1, 2, 1, 3, 3, 1, 1, 3, 0, 2, 2, 2, 1, 0]), (3394, [3, 1, 0, 0, 1, 0, 1, 0, 3, 2, 1, 1, 2, 1, 2]), (3395, [0, 0, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 0, 3, 3]), (3396, [2, 0, 1, 0, 0, 3, 1, 3, 3, 0, 1, 2, 0, 2, 0]), (3397, [2, 3, 0, 3, 0, 1, 1, 1, 1, 2, 0, 2, 2, 0, 2]), (3398, [1, 3, 1, 0, 2, 3, 0, 0, 3, 1, 3, 3, 2, 2, 0]), (3399, [3, 2, 1, 3, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0]), (3400, [1, 0, 2, 2, 1, 2, 0, 1, 2, 1, 3, 0, 3, 3, 1]), (3401, [0, 2, 2, 0, 1, 3, 0, 1, 3, 2, 1, 0, 0, 2, 1]), (3402, [1, 0, 3, 3, 2, 3, 1, 1, 0, 2, 1, 2, 2, 2, 3]), (3403, [0, 2, 0, 0, 3, 3, 3, 3, 2, 2, 1, 3, 3, 3, 1]), (3404, [0, 2, 0, 1, 3, 1, 3, 0, 2, 2, 3, 2, 3, 1, 3]), (3405, [2, 0, 0, 2, 0, 2, 3, 2, 3, 2, 0, 2, 3, 0, 2]), (3406, [0, 0, 0, 2, 2, 1, 2, 0, 3, 1, 0, 1, 0, 1, 1]), (3407, [1, 2, 1, 1, 3, 0, 3, 2, 3, 0, 3, 0, 0, 3, 1]), (3408, [2, 2, 1, 3, 2, 1, 1, 0, 2, 1, 1, 0, 0, 2, 2]), (3409, [3, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 1, 3, 0, 3]), (3410, [2, 2, 3, 2, 0, 0, 1, 0, 2, 3, 2, 1, 2, 1, 0]), (3411, [1, 3, 0, 0, 3, 1, 0, 2, 0, 2, 3, 0, 2, 3, 0]), (3412, [0, 2, 2, 0, 0, 3, 3, 1, 2, 1, 1, 0, 1, 1, 2]), (3413, [0, 0, 3, 2, 1, 3, 2, 2, 1, 1, 0, 0, 2, 1, 1]), (3414, [3, 3, 1, 2, 3, 0, 0, 0, 1, 3, 0, 0, 3, 3, 2]), (3415, [1, 0, 1, 0, 2, 0, 2, 2, 3, 0, 2, 2, 3, 1, 1]), (3416, [1, 3, 3, 2, 3, 1, 3, 1, 1, 3, 2, 1, 3, 0, 3]), (3417, [3, 0, 0, 0, 3, 2, 1, 2, 0, 3, 1, 1, 0, 0, 1]), (3418, [3, 3, 3, 3, 1, 2, 1, 3, 0, 1, 0, 0, 3, 2, 2]), (3419, [1, 0, 2, 3, 2, 0, 1, 2, 1, 0, 3, 0, 1, 1, 3]), (3420, [0, 3, 0, 2, 3, 0, 1, 3, 1, 3, 1, 2, 0, 3, 3]), (3421, [2, 0, 0, 0, 0, 0, 2, 3, 2, 1, 1, 2, 0, 3, 3]), (3422, [0, 1, 1, 3, 1, 0, 0, 0, 0, 0, 3, 2, 3, 1, 0]), (3423, [2, 3, 1, 2, 0, 1, 2, 3, 3, 3, 2, 0, 2, 0, 3]), (3424, [2, 1, 2, 0, 0, 1, 1, 2, 2, 1, 1, 0, 0, 2, 2]), (3425, [2, 1, 3, 0, 2, 0, 2, 3, 0, 2, 2, 0, 0, 3, 3]), (3426, [1, 1, 2, 1, 3, 2, 3, 2, 3, 3, 2, 2, 0, 1, 3]), (3427, [1, 2, 3, 0, 1, 2, 1, 3, 3, 1, 3, 0, 3, 2, 2]), (3428, [1, 2, 3, 0, 0, 3, 0, 3, 0, 1, 3, 3, 3, 3, 0]), (3429, [2, 2, 1, 0, 3, 0, 0, 1, 1, 3, 2, 2, 2, 3, 1]), (3430, [0, 2, 3, 1, 3, 2, 2, 1, 1, 3, 0, 2, 1, 1, 0]), (3431, [2, 2, 0, 3, 2, 2, 1, 3, 2, 1, 0, 0, 0, 1, 0]), (3432, [1, 3, 3, 1, 2, 2, 0, 0, 2, 1, 1, 0, 2, 0, 0]), (3433, [3, 0, 0, 1, 2, 2, 3, 2, 1, 2, 2, 1, 3, 0, 2]), (3434, [1, 2, 0, 2, 1, 0, 1, 0, 0, 3, 2, 3, 0, 3, 2]), (3435, [0, 0, 0, 0, 1, 3, 1, 0, 3, 2, 2, 3, 1, 0, 0]), (3436, [1, 3, 1, 3, 2, 1, 0, 2, 3, 0, 3, 2, 0, 2, 0]), (3437, [3, 1, 0, 3, 2, 1, 3, 2, 3, 2, 3, 3, 0, 2, 1]), (3438, [0, 2, 3, 0, 1, 0, 3, 3, 1, 3, 2, 1, 3, 1, 2]), (3439, [1, 0, 1, 3, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 1]), (3440, [3, 3, 3, 1, 2, 3, 2, 2, 1, 3, 2, 2, 2, 0, 3]), (3441, [0, 1, 3, 2, 2, 0, 0, 3, 3, 3, 3, 0, 2, 2, 2]), (3442, [0, 1, 1, 0, 2, 0, 3, 3, 1, 3, 1, 0, 3, 2, 2]), (3443, [3, 2, 2, 3, 3, 3, 1, 2, 0, 2, 3, 1, 2, 1, 1]), (3444, [3, 3, 3, 1, 0, 2, 1, 0, 0, 0, 2, 3, 2, 0, 2]), (3445, [0, 0, 3, 3, 2, 3, 0, 1, 0, 3, 2, 1, 0, 1, 0]), (3446, [0, 1, 1, 2, 0, 1, 0, 1, 3, 1, 0, 0, 0, 3, 1]), (3447, [0, 1, 3, 2, 1, 1, 1, 3, 1, 0, 1, 1, 0, 3, 2]), (3448, [2, 2, 1, 2, 2, 0, 3, 1, 1, 2, 3, 1, 0, 3, 3]), (3449, [2, 0, 2, 1, 0, 1, 3, 2, 0, 3, 1, 1, 1, 2, 3]), (3450, [1, 1, 1, 1, 0, 3, 3, 2, 0, 1, 1, 2, 1, 2, 2]), (3451, [0, 0, 0, 0, 2, 3, 3, 3, 0, 2, 1, 0, 3, 2, 1])]\n",
            "[0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2994089384287623, 0.2875220586137977, 0.2797748805989118, 0.2784973717061793, 0.23278376764431305, 0.28492398350792647, 0.2573707790286969, 0.2797748805989118, 0.2772237576546104, 0.245457401410121, 0.2772237576546104, 0.25979878931429257, 0.2901358795813504, 0.31161900681179666, 0.31161900681179666, 0.22164772301981162, 0.26966353201558, 0.26346936195595083, 0.23619585365179713, 0.3034428373146045, 0.23278376764431305, 0.24899193408820353, 0.20354162426216163, 0.2888269978917027, 0.32557007018603873, 0.2772237576546104, 0.2901358795813504, 0.2994089384287623, 0.27595403249788275, 0.300749573479958, 0.2954109493838166, 0.32134194062573906, 0.2954109493838166, 0.30209420445979795, 0.24899193408820353, 0.2994089384287623, 0.2384890013456497, 0.2709139018929371, 0.2537572018871206, 0.2466318367505928, 0.2994089384287623, 0.2537572018871206, 0.3034428373146045, 0.2875220586137977, 0.2994089384287623, 0.2709139018929371, 0.2513670399435197, 0.28492398350792647, 0.24195647734617126, 0.2671743459652642, 0.30479547799070006, 0.2994089384287623, 0.2888269978917027, 0.23734058116562218, 0.31576159852455576, 0.2549579437578336, 0.2836308357873154, 0.3326990913197809, 0.2994089384287623, 0.2994089384287623, 0.2573707790286969, 0.2994089384287623, 0.2875220586137977, 0.2927654939811637, 0.2888269978917027, 0.2994089384287623, 0.2525602359311233, 0.2537572018871206, 0.2537572018871206, 0.26101849995342097, 0.2647005252119971, 0.28492398350792647, 0.2927654939811637, 0.2914487096290633, 0.28234160669315744, 0.28492398350792647, 0.28234160669315744, 0.2573707790286969, 0.2537572018871206, 0.2888269978917027, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.28105629027913037, 0.2967396323270139, 0.2772237576546104, 0.2784973717061793, 0.2994089384287623, 0.2513670399435197, 0.22940470156504542, 0.3284093281279372, 0.25979878931429257, 0.2994089384287623, 0.23734058116562218, 0.2994089384287623, 0.31024623783442024, 0.2836308357873154, 0.2513670399435197, 0.2466318367505928, 0.28234160669315744, 0.30615213243440703, 0.2622420221851996, 0.2994089384287623, 0.2549579437578336, 0.2954109493838166, 0.2994089384287623, 0.2994089384287623, 0.2980722933598883, 0.3034428373146045, 0.23165375133207408, 0.2384890013456497, 0.26101849995342097, 0.2980722933598883, 0.2442867003601084, 0.0013553958054683501, 0.22717025596579984, 0.2994089384287623, 0.23052739795442567, 0.300749573479958, 0.20045251275514153, 0.258582884321492, 0.28105629027913037, 0.26593551789966074, 0.2994089384287623, 0.3088775064099447, 0.27595403249788275, 0.2994089384287623, 0.2784973717061793, 0.3075128065920478, 0.2709139018929371, 0.26346936195595083, 0.2994089384287623, 0.2994089384287623, 0.26346936195595083, 0.3088775064099447, 0.2671743459652642, 0.26101849995342097, 0.23964112013820227, 0.274688190289674, 0.2994089384287623, 0.2875220586137977, 0.2797748805989118, 0.2784973717061793, 0.23278376764431305, 0.28492398350792647, 0.2573707790286969, 0.2797748805989118, 0.2772237576546104, 0.245457401410121, 0.2772237576546104, 0.25979878931429257, 0.2901358795813504, 0.31161900681179666, 0.31161900681179666, 0.22164772301981162, 0.26966353201558, 0.26346936195595083, 0.23619585365179713, 0.3034428373146045, 0.23278376764431305, 0.24899193408820353, 0.20354162426216163, 0.2888269978917027, 0.32557007018603873, 0.2772237576546104, 0.2901358795813504, 0.2994089384287623, 0.27595403249788275, 0.300749573479958, 0.2954109493838166, 0.32134194062573906, 0.2954109493838166, 0.30209420445979795, 0.24899193408820353, 0.2994089384287623, 0.2384890013456497, 0.2709139018929371, 0.2537572018871206, 0.2466318367505928, 0.2994089384287623, 0.2537572018871206, 0.3034428373146045, 0.2875220586137977, 0.2994089384287623, 0.2709139018929371, 0.2513670399435197, 0.28492398350792647, 0.24195647734617126, 0.2671743459652642, 0.30479547799070006, 0.2994089384287623, 0.2888269978917027, 0.23734058116562218, 0.31576159852455576, 0.2549579437578336, 0.2836308357873154, 0.3326990913197809, 0.2994089384287623, 0.2994089384287623, 0.2573707790286969, 0.2994089384287623, 0.2875220586137977, 0.2927654939811637, 0.2888269978917027, 0.2994089384287623, 0.2525602359311233, 0.2537572018871206, 0.2537572018871206, 0.26101849995342097, 0.2647005252119971, 0.28492398350792647, 0.2927654939811637, 0.2914487096290633, 0.28234160669315744, 0.28492398350792647, 0.28234160669315744, 0.2573707790286969, 0.2537572018871206, 0.2888269978917027, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.28105629027913037, 0.2967396323270139, 0.2772237576546104, 0.2784973717061793, 0.2994089384287623, 0.2513670399435197, 0.22940470156504542, 0.3284093281279372, 0.25979878931429257, 0.2994089384287623, 0.23734058116562218, 0.2994089384287623, 0.31024623783442024, 0.2836308357873154, 0.2513670399435197, 0.2466318367505928, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703, 0.2466318367505928, 0.25616246748958493, 0.2994089384287623, 0.300749573479958, 0.3171505771767599, 0.28105629027913037, 0.3227472240939291, 0.2797748805989118, 0.2994089384287623, 0.33126504549020364, 0.3034428373146045, 0.22384586632088296, 0.2994089384287623, 0.300749573479958, 0.2573707790286969, 0.22717025596579984, 0.3171505771767599, 0.2927654939811637, 0.2797748805989118, 0.2901358795813504, 0.30209420445979795, 0.27595403249788275, 0.2875220586137977, 0.28105629027913037, 0.2671743459652642, 0.31437668121054196, 0.2914487096290633, 0.26966353201558, 0.2994089384287623, 0.23964112013820227, 0.23391745283746496, 0.274688190289674, 0.2862210558013131, 0.2994089384287623, 0.2994089384287623, 0.2994089384287623, 0.2384890013456497, 0.23505481285785218, 0.2772237576546104, 0.2513670399435197, 0.2901358795813504, 0.2980722933598883, 0.2994089384287623, 0.30479547799070006, 0.26593551789966074, 0.23505481285785218, 0.2994089384287623, 0.2836308357873154, 0.2994089384287623, 0.33413726984341724, 0.300749573479958, 0.2862210558013131, 0.2622420221851996, 0.2994089384287623, 0.21087262016421682, 0.2994089384287623, 0.2537572018871206, 0.3129958192883965, 0.2671743459652642, 0.2888269978917027, 0.2980722933598883, 0.2478100123278462, 0.2734262250836617, 0.30479547799070006, 0.30615213243440703]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import ast \n",
        "# xls = pd.ExcelFile('results.xlsx')\n",
        "# Parse the sheets into DataFrames\n",
        "# df_skips = pd.read_csv('childskips.csv')\n",
        "# df_labels = pd.read_csv('childlabels.csv')\n",
        "# df_rewards = pd.read_csv('rewards.csv')\n",
        "\n",
        "df_combined = pd.read_csv('Random_childs.csv')\n",
        "# df_combined.head(5)\n",
        "\n",
        "# Accessing values from DataFrames\n",
        "# to access values from 'child_skips' DataFrame:\n",
        "new_child_skips = df_combined['skips'].to_dict()\n",
        "# new_child_skips = [ast.literal_eval(new_child_skips[i]) for i in range(len(new_child_skips))\n",
        "for key in new_child_skips:\n",
        "    new_child_skips[key] = list(ast.literal_eval(new_child_skips[key]).values())\n",
        "new_child_skips = list(new_child_skips.items())\n",
        "# child_skips_values = df_skips.iloc[:, 1:].to_dict(orient='list')\n",
        "# for key in child_skips_values:\n",
        "#     child_skips_values[key] = [list(ast.literal_eval(item)) for item in child_skips_values[key]]\n",
        "# child_skips_values = list(child_skips_values.items())\n",
        "\n",
        "# child_labels_values = df_labels.iloc[:, 1:].to_dict(orient='list')\n",
        "child_labels_values = df_combined['label'].to_dict()\n",
        "for key in child_labels_values:\n",
        "    child_labels_values[key] = ast.literal_eval(child_labels_values[key])\n",
        "# child_labels_values = [ast.literal_eval(child_labels_values[i]) for i in range(len(child_labels_values))]\n",
        "child_labels_values = list(child_labels_values.items())\n",
        "# rewards_values=df_rewards.iloc[:, 1:].values.flatten().tolist()\n",
        "rewards_values = df_combined['rewards'].values.flatten().tolist()\n",
        "rewards_values = [ast.literal_eval(s) for s in rewards_values]\n",
        "rewards_values = [lst[-1] for lst in rewards_values ]\n",
        "\n",
        "print(child_labels_values)\n",
        "print(rewards_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels: {3193: [[1], [0, 1], [1, 1, 0], [1, 0, 1, 0]], 2716: [[0], [1, 0], [0, 0, 0], [1, 0, 0, 1]], 157: [[0], [0, 0], [0, 0, 0], [0, 1, 1, 0]], 628: [[1], [0, 1], [1, 0, 0], [1, 1, 0, 0]], 2359: [[0], [0, 0], [1, 1, 0], [1, 1, 0, 1]], 1946: [[1], [1, 0], [1, 1, 1], [0, 0, 1, 0]], 1208: [[0], [0, 1], [0, 1, 0], [1, 0, 0, 0]], 3390: [[0], [0, 1], [1, 1, 1], [0, 1, 1, 1]], 3374: [[0], [1, 1], [1, 0, 0], [1, 0, 1, 0]], 707: [[0], [0, 0], [0, 1, 1], [1, 0, 1, 1]], 1996: [[1], [0, 0], [1, 0, 0], [1, 0, 0, 0]], 284: [[1], [0, 1], [0, 0, 1], [1, 0, 1, 1]], 2009: [[0], [1, 1], [1, 0, 0], [1, 0, 1, 0]], 75: [[0], [1, 1], [0, 0, 1], [1, 1, 1, 0]], 903: [[0], [0, 0], [1, 1, 0], [1, 1, 0, 1]], 1045: [[0], [1, 1], [0, 0, 1], [1, 0, 0, 1]], 2773: [[0], [1, 0], [1, 1, 0], [1, 1, 0, 1]], 3295: [[1], [0, 0], [1, 1, 1], [0, 0, 0, 1]], 2093: [[1], [1, 1], [1, 1, 1], [1, 1, 1, 0]], 2943: [[0], [0, 0], [0, 1, 1], [1, 0, 1, 1]], 2859: [[0], [0, 1], [0, 1, 0], [1, 0, 0, 0]], 3299: [[1], [0, 1], [1, 0, 0], [0, 0, 0, 0]], 3199: [[0], [1, 0], [1, 0, 0], [1, 1, 0, 0]], 2261: [[0], [1, 0], [0, 0, 0], [1, 0, 0, 1]], 50: [[0], [1, 0], [0, 0, 0], [1, 1, 0, 1]], 1892: [[0], [0, 0], [1, 0, 0], [1, 0, 1, 1]], 2404: [[0], [0, 1], [0, 1, 0], [1, 0, 0, 0]], 1922: [[0], [1, 1], [1, 1, 1], [0, 0, 1, 0]], 2715: [[1], [0, 1], [0, 0, 1], [1, 0, 1, 1]], 2132: [[0], [1, 1], [0, 0, 1], [0, 1, 0, 1]], 387: [[0], [0, 1], [1, 0, 0], [1, 1, 1, 1]], 2556: [[0], [1, 0], [0, 0, 1], [0, 0, 1, 0]], 2172: [[1], [0, 1], [1, 0, 0], [0, 1, 1, 0]], 1267: [[1], [1, 0], [0, 1, 0], [1, 0, 0, 1]], 1577: [[0], [1, 0], [1, 1, 0], [1, 1, 0, 1]], 3244: [[0], [1, 1], [1, 0, 0], [1, 0, 1, 0]], 2312: [[0], [1, 1], [1, 1, 1], [0, 0, 1, 0]], 3396: [[1], [1, 1], [1, 1, 1], [1, 0, 1, 0]], 2777: [[0], [1, 1], [0, 1, 0], [1, 1, 1, 1]], 165: [[1], [1, 0], [1, 1, 1], [0, 0, 1, 0]], 2472: [[1], [0, 1], [0, 0, 1], [1, 1, 1, 0]], 600: [[0], [0, 0], [0, 1, 0], [0, 1, 1, 1]], 1726: [[0], [1, 0], [0, 1, 1], [0, 1, 1, 1]], 3407: [[1], [0, 1], [1, 0, 0], [0, 1, 1, 0]], 210: [[0], [0, 0], [0, 1, 0], [0, 1, 1, 1]], 3350: [[0], [0, 1], [1, 0, 1], [0, 0, 1, 0]], 1638: [[1], [0, 0], [0, 0, 0], [1, 1, 1, 1]], 1849: [[0], [0, 1], [0, 1, 1], [1, 1, 1, 0]], 2254: [[0], [0, 1], [1, 0, 1], [1, 1, 0, 1]], 2322: [[0], [1, 1], [0, 1, 0], [1, 1, 1, 1]], 2603: [[1], [1, 1], [1, 1, 1], [1, 1, 0, 0]], 2632: [[0], [0, 1], [1, 1, 0], [1, 1, 1, 0]], 3183: [[1], [0, 0], [1, 0, 1], [1, 1, 0, 1]], 3412: [[0], [0, 1], [1, 1, 0], [1, 1, 1, 0]], 1044: [[1], [1, 0], [1, 0, 1], [1, 0, 1, 0]], 1074: [[0], [0, 0], [0, 1, 1], [0, 1, 0, 0]], 1138: [[0], [1, 1], [1, 0, 0], [1, 0, 1, 0]], 287: [[0], [0, 0], [0, 0, 0], [0, 1, 1, 0]], 2277: [[1], [0, 1], [0, 0, 1], [1, 1, 1, 0]], 335: [[0], [1, 1], [0, 0, 1], [1, 1, 1, 0]], 2761: [[0], [1, 1], [0, 0, 1], [1, 0, 0, 1]], 175: [[0], [0, 1], [0, 1, 1], [1, 1, 0, 0]], 946: [[0], [1, 1], [1, 0, 1], [0, 0, 0, 0]], 2504: [[1], [1, 1], [1, 1, 0], [1, 0, 0, 1]]}\n",
            "Skips: [0.25616246748958493, 0.26593551789966074, 0.2994089384287623, 0.2734262250836617, 0.2994089384287623, 0.21087262016421682, 0.3129958192883965, 0.300749573479958, 0.2622420221851996, 0.22384586632088296, 0.2513670399435197, 0.30479547799070006, 0.2622420221851996, 0.23964112013820227, 0.2994089384287623, 0.2671743459652642, 0.2384890013456497, 0.2772237576546104, 0.3227472240939291, 0.22384586632088296, 0.3129958192883965, 0.2994089384287623, 0.2797748805989118, 0.26593551789966074, 0.3171505771767599, 0.2466318367505928, 0.3129958192883965, 0.23391745283746496, 0.30479547799070006, 0.23505481285785218, 0.3171505771767599, 0.2573707790286969, 0.30209420445979795, 0.2862210558013131, 0.2384890013456497, 0.2622420221851996, 0.23391745283746496, 0.33126504549020364, 0.2901358795813504, 0.21087262016421682, 0.2980722933598883, 0.2994089384287623, 0.20045251275514153, 0.30209420445979795, 0.2994089384287623, 0.2994089384287623, 0.2954109493838166, 0.2875220586137977, 0.23505481285785218, 0.2901358795813504, 0.2478100123278462, 0.31437668121054196, 0.2537572018871206, 0.31437668121054196, 0.28105629027913037, 0.2994089384287623, 0.2622420221851996, 0.2994089384287623, 0.2980722933598883, 0.23964112013820227, 0.2671743459652642, 0.30615213243440703, 0.2994089384287623, 0.26966353201558]\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "\n",
        "# **** #  Create a dataset of the skips and label in preparation for training the controller #******#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, skips_values, label_values, reward_values):\n",
        "        self.skips_values = skips_values\n",
        "        self.label_values = label_values\n",
        "        self.reward_values = reward_values\n",
        "        # self.children = list(skips_values.keys())  # Assuming all dictionaries have the same keys\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reward_values)  # Assuming rewards define the number of samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # For each child, fetch the corresponding skip and label by index\n",
        "        # This example assumes the length of skips and labels matches the length of rewards for simplicity\n",
        "        skips = self.skips_values[idx]\n",
        "        labels = self.label_values[idx]\n",
        "        rewards = self.reward_values[idx]\n",
        "        return skips, labels, rewards\n",
        "\n",
        "  \n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    # 'batch' is a list of tuples returned by CustomDataset.__getitem__\n",
        "    skips_batch, labels_batch, rewards_batch = [], [], []\n",
        "    for skips, labels, rewards in batch:\n",
        "        skips_batch.append(skips)\n",
        "        labels_batch.append(labels)\n",
        "        rewards_batch.append(rewards)\n",
        "    # Return a dictionary of batches\n",
        "    \n",
        "    return  dict(skips_batch), dict(labels_batch), rewards_batch #{\"skips\": skips_batch, \"labels\": labels_batch, \"rewards\": rewards_batch}\n",
        "\n",
        "dataset = CustomDataset(new_child_skips, child_labels_values, rewards_values)\n",
        "\n",
        "# Create the DataLoader with the custom collate function\n",
        "data_loader = DataLoader(dataset, batch_size=64, shuffle=True, collate_fn=custom_collate_fn)\n",
        "batch = next(iter(data_loader))\n",
        "skips, labels, rewards = batch\n",
        "print(\"Labels:\", skips)\n",
        "print(\"Skips:\", rewards)\n",
        "# print(\"Rewards:\", rewards)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqaYn1ZArVvz"
      },
      "source": [
        "## Controller training with REINFORCE: Loss Function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " the controller predicts to design an architecture for a child network. At convergence, this child network will achieve an accuracy R on a held-out dataset. We can use this accuracy R as the reward signal and use reinforcement learning to train the controller. More concretely, to find the optimal architecture, we ask our controller to maximize its expected reward, Policy gradient method.\n",
        "\n",
        " ### Loss function:\n",
        "  \n",
        " 1. **CrossEntropyLoss** is mainly used for calculating loss of Child Labels, child targets for multi- classification. [see more](https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html)\n",
        "\n",
        " [nll_loss](https://pytorch.org/docs/stable/generated/torch.nn.functional.nll_loss.html)\n",
        "\n",
        "\n",
        "$$ CE({y}, \\hat{y}) = - \\sum_{i=1}^{N_c} y_i \\log(\\hat{y}_i)$$\n",
        "\n",
        " where,\n",
        "\n",
        "  $y_i$ - is a one-hot encoded vector representing the true labels\n",
        "\n",
        "  $ \\hat{y}_i$​ - is a vector representing the predicted probabilities for each class.\n",
        "\n",
        "  $N_c$ - ​is the number of classes.\n",
        "\n",
        "  $i$ - is the index for iterating over each class.\n",
        "\n",
        "  In pytorch,\n",
        "  - **F.cross_entropy** is used for computing the cross-entropy loss between the predicted probabilities (**logits**) and the target labels.\n",
        "  - It combines torch.log_softmax and F.nll_loss (negative log likelihood loss) in a single function call.\n",
        "\n",
        "\n",
        "\n",
        " 2. **Binary Cross Entropy** and is used for calculating loss of Child skips, skip targets for binary classification.\n",
        "\n",
        " $$  BCE(y, \\hat{y}) = - [y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y})]$$\n",
        "\n",
        " where,\n",
        "\n",
        " $y_i$ - is the true label, either 0 or 1.\n",
        "\n",
        " $ \\hat{y}_i$​ - is the predicted probability for the positive class (typically denoted by 1).\n",
        "\n",
        "\n",
        "\n",
        "The above update is an unbiased estimate for our gradient, but has a very high variance. In order to reduce the variance of this estimate we employ a baseline function:\n",
        "  \n",
        "  $baseline(b) = \\alpha \\cdot \\text{torch.mean(rewards)} + (1 - \\alpha) \\cdot baseline $\n",
        "\n",
        "\n",
        "  $$\\therefore Loss=\\dfrac{1}{m}\\sum\\limits_{k=1}^m \\left\\{\\left[\\sum\\limits_{t=1}^T \\nabla_{\\theta_c}\\log\\left(P\\left(a_t|a_{(t-1):1}; \\theta_c\\right)\\right)\\right]\\left(R_k-b\\right)\\right\\}$$\n",
        "\n",
        "  where,\n",
        "\n",
        "  $R_k$ - is reward of $k_{th}$ child model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "FfRHBMpMi497"
      },
      "outputs": [],
      "source": [
        "def loss_nas(child_labels, child_targets, skip_labels, skip_targets, rewards, baseline, alpha = 0.5):\n",
        "  \"\"\"\n",
        "    Calculates the loss for neural architecture search (NAS) based on child and skip connections.\n",
        "    Args:\n",
        "        child_labels (list): List of child labels (predictions).\n",
        "        child_targets (list): List of child targets (ground truth).\n",
        "        skip_labels (list): List of skip connection labels.\n",
        "        skip_targets (list): List of skip connection targets.\n",
        "        rewards (list): List of rewards for each child network.\n",
        "        baseline (float, optional): Baseline value. Defaults to 0.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Calculated loss.\n",
        "  \"\"\"\n",
        "\n",
        "  loss = torch.zeros(1)\n",
        "  # baseline = 0\n",
        "  for child_net_ind in range(len(rewards)):\n",
        "    loss_temp=torch.zeros(1)\n",
        "    for pred_num_target in range(len(child_labels[child_net_ind])):\n",
        "      loss_temp += F.cross_entropy(child_targets[pred_num_target][child_net_ind].view(1,len(child_targets[pred_num_target][child_net_ind])), torch.LongTensor([child_labels[child_net_ind][pred_num_target]]))\n",
        "\n",
        "    for skip_num_target in range(len(skip_labels[child_net_ind])):\n",
        "      for skip_index in range(skip_num_target+1):\n",
        "        loss_temp +=F.binary_cross_entropy(skip_targets[skip_num_target][skip_index][child_net_ind] , torch.tensor([skip_labels[child_net_ind][skip_num_target][skip_index]]).float())\n",
        "\n",
        "    loss += (rewards[child_net_ind]-baseline)*loss_temp\n",
        "    baseline=alpha*torch.mean(torch.tensor(rewards))+(1-alpha)*baseline\n",
        "  return loss, baseline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "\n",
        "def To_save(id, skips, labels, rewards, numB):     # convert to a saveable format for sampled architecture \n",
        "  data=[]\n",
        "  for i in range(numB):\n",
        "    data.append({\"id\": id, \"label\": labels[i], \"skips\": skips[i], \"rewards\": rewards[i], })\n",
        "  df = pd.DataFrame(data)\n",
        "  return df\n",
        "\n",
        "def train_controller(num_batchs,child_test,child_skips,reward, batch_id, epoch_id,baseline):\n",
        "  optimizer = Adam(controller_check.parameters(), lr=0.01)\n",
        "  # batch_loss = \n",
        "  print (child_skips)\n",
        "  targets_false_inference,skip_targets_inference_false=controller_check(inference=False, child_network_labels=child_test,child_network_skips=child_skips)\n",
        "  print(\"baseline track:\",baseline)\n",
        "  total_loss, baseline = loss_nas(list(child_test.values()), targets_false_inference, list(child_skips.values()), skip_targets_inference_false, reward, baseline)\n",
        "  \n",
        "  id = \"Id_{}_{}\".format(batch_id, epoch_id)\n",
        "  \n",
        "  sampled = To_save(id, list(child_skips.values()), list(child_test.values()), reward, num_batchs)\n",
        "  \n",
        "  if not os.path.exists(\"archi.csv\") or os.path.getsize(\"archi.csv\") == 0:\n",
        "        # If the file doesn't exist or is empty, write the DataFrame with the header\n",
        "        sampled.to_csv(\"archi.csv\", index=False)\n",
        "  else:\n",
        "    sampled.to_csv(\"archi.csv\", mode='a', header=False, index=False)\n",
        "    \n",
        "  optimizer.zero_grad()\n",
        "  total_loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "\n",
        "  return total_loss, baseline\n",
        "\n",
        "    # exploit_label, exploit_csv = controller_check()\n",
        "    # check if gotten architecture\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "PzZE3M1rpDeL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1680: [[1], [1, 0], [0, 0, 1], [1, 0, 1, 0]], 899: [[0], [1, 1], [1, 1, 0], [0, 0, 0, 0]], 2399: [[0], [1, 1], [1, 0, 0], [1, 0, 1, 0]], 3364: [[1], [0, 1], [1, 0, 0], [0, 0, 0, 0]], 1421: [[1], [1, 0], [1, 0, 0], [0, 0, 0, 1]], 2591: [[0], [1, 0], [1, 0, 1], [0, 1, 1, 1]], 3148: [[0], [1, 0], [1, 1, 0], [1, 0, 0, 1]], 2604: [[1], [0, 1], [1, 0, 0], [1, 1, 0, 0]], 2275: [[0], [1, 0], [1, 0, 1], [0, 0, 0, 1]], 2080: [[0], [1, 0], [1, 0, 1], [0, 0, 0, 1]], 2432: [[1], [0, 1], [1, 0, 0], [0, 1, 1, 0]], 2706: [[0], [0, 0], [0, 1, 0], [0, 1, 1, 1]], 2833: [[0], [0, 1], [0, 1, 0], [1, 0, 1, 0]], 1425: [[0], [1, 0], [0, 0, 1], [0, 0, 1, 0]], 627: [[1], [1, 1], [1, 1, 1], [1, 1, 0, 0]], 303: [[1], [0, 1], [1, 0, 0], [1, 1, 0, 0]], 1573: [[0], [1, 0], [0, 1, 0], [0, 1, 1, 0]], 3310: [[0], [0, 0], [0, 1, 1], [0, 1, 0, 0]], 2786: [[0], [1, 0], [1, 0, 1], [0, 1, 1, 1]], 3020: [[1], [1, 0], [1, 0, 1], [1, 0, 1, 0]], 2503: [[0], [0, 1], [0, 1, 1], [1, 0, 1, 0]], 760: [[0], [0, 1], [0, 1, 1], [1, 1, 0, 0]], 1176: [[0], [0, 1], [1, 1, 0], [1, 1, 1, 0]], 494: [[0], [1, 0], [1, 0, 1], [0, 0, 0, 1]], 66: [[1], [0, 1], [1, 0, 0], [0, 1, 1, 0]], 381: [[1], [1, 0], [1, 0, 0], [0, 0, 0, 1]], 1209: [[0], [1, 0], [1, 0, 1], [0, 0, 0, 1]], 3018: [[0], [1, 0], [1, 1, 0], [1, 0, 0, 1]], 2982: [[0], [1, 1], [1, 0, 0], [0, 1, 0, 1]], 2351: [[0], [1, 0], [0, 0, 0], [1, 1, 0, 1]], 1143: [[0], [0, 1], [0, 1, 0], [1, 0, 0, 0]], 210: [[0], [0, 0], [0, 1, 0], [0, 1, 1, 1]], 1117: [[0], [0, 1], [0, 1, 0], [1, 0, 1, 0]], 847: [[0], [1, 0], [1, 1, 0], [1, 0, 0, 1]], 1131: [[0], [1, 1], [0, 0, 1], [0, 1, 0, 1]], 2499: [[0], [0, 1], [0, 1, 1], [1, 1, 1, 0]], 2416: [[0], [1, 0], [0, 0, 0], [1, 1, 0, 1]], 3340: [[0], [0, 0], [0, 0, 1], [1, 0, 1, 1]], 117: [[1], [1, 1], [1, 1, 1], [1, 1, 1, 0]], 2993: [[1], [1, 1], [1, 1, 1], [1, 1, 0, 0]], 351: [[0], [1, 1], [0, 0, 1], [0, 1, 0, 1]], 2938: [[1], [1, 1], [1, 1, 1], [1, 1, 1, 0]], 86: [[0], [1, 1], [0, 1, 0], [1, 1, 1, 1]], 335: [[0], [1, 1], [0, 0, 1], [1, 1, 1, 0]], 2852: [[0], [1, 1], [1, 0, 0], [0, 1, 0, 1]], 2893: [[0], [0, 1], [0, 1, 1], [1, 0, 1, 0]], 1153: [[0], [0, 0], [0, 0, 1], [0, 1, 0, 1]], 2900: [[1], [1, 1], [1, 0, 0], [0, 0, 0, 0]], 2066: [[0], [1, 0], [0, 0, 0], [1, 0, 0, 1]], 267: [[0], [0, 1], [0, 1, 1], [1, 0, 1, 0]], 2928: [[1], [1, 1], [1, 1, 1], [1, 1, 0, 0]], 1460: [[0], [1, 0], [1, 0, 1], [0, 1, 1, 1]], 3221: [[0], [1, 1], [0, 0, 1], [1, 1, 1, 0]], 583: [[0], [1, 1], [0, 1, 0], [0, 1, 1, 1]], 1656: [[1], [0, 0], [0, 0, 0], [1, 1, 0, 0]], 3017: [[1], [0, 1], [1, 0, 0], [0, 1, 1, 0]], 502: [[1], [0, 1], [1, 1, 0], [1, 0, 1, 0]], 3057: [[1], [0, 1], [0, 0, 1], [1, 1, 1, 0]], 2037: [[1], [0, 1], [0, 1, 1], [1, 0, 0, 1]], 686: [[0], [1, 1], [1, 0, 1], [0, 0, 0, 0]], 1964: [[0], [1, 0], [1, 0, 0], [1, 1, 0, 0]], 1499: [[1], [1, 0], [1, 0, 1], [1, 0, 1, 0]], 1989: [[0], [1, 0], [0, 1, 0], [0, 1, 1, 0]], 1662: [[1], [1, 1], [1, 0, 1], [0, 1, 1, 1]]}\n",
            "baseline track: 0\n",
            "loss: tensor([25.6316], grad_fn=<AddBackward0>)\n",
            "baseline: 0.28574806451797485\n",
            "<class 'list'>\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 24, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Linear(in_features=10560, out_features=7, bias=True)\n",
            ")\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 64, kernel_size=(3, 1), stride=(1, 1))\n",
            "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(64, 24, kernel_size=(7, 3), stride=(1, 1))\n",
            "  (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Linear(in_features=50336, out_features=7, bias=True)\n",
            ")\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(72, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Linear(in_features=110880, out_features=7, bias=True)\n",
            ")\n",
            "ModuleList(\n",
            "  (0): Conv2d(3, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): Conv2d(36, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (4): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (5): ReLU()\n",
            "  (6): Dropout(p=0.2, inplace=False)\n",
            "  (7): Conv2d(36, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (8): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): ReLU()\n",
            "  (10): Dropout(p=0.2, inplace=False)\n",
            "  (11): Conv2d(72, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (12): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (13): ReLU()\n",
            "  (14): Dropout(p=0.2, inplace=False)\n",
            "  (15): Conv2d(180, 36, kernel_size=(1, 7), stride=(1, 1))\n",
            "  (16): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (17): ReLU()\n",
            "  (18): Dropout(p=0.2, inplace=False)\n",
            "  (19): Linear(in_features=155232, out_features=7, bias=True)\n",
            ")\n",
            "exploit: [0, 3, 1, 0, 3, 1, 0, 3, 1, 0, 3, 1, 0, 3, 1]\n",
            "exploit_skips: [[0], [0, 1], [1, 1, 1], [0, 1, 0, 1]]\n",
            "False\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ed918f74ee746029e06408bb8102ed0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200, Loss: 13.5168, Validation Accuracy: 11.0618\n",
            "Epoch 2/200, Loss: 15.4867, Validation Accuracy: 13.4816\n",
            "Epoch 3/200, Loss: 68.2555, Validation Accuracy: 13.7886\n",
            "Epoch 4/200, Loss: 69.8933, Validation Accuracy: 3.5035\n",
            "Epoch 5/200, Loss: 269.5757, Validation Accuracy: 17.8833\n",
            "Epoch 6/200, Loss: 152.1921, Validation Accuracy: 11.7378\n",
            "Epoch 7/200, Loss: 60.1824, Validation Accuracy: 15.2193\n",
            "Epoch 8/200, Loss: 12.5154, Validation Accuracy: 17.6471\n",
            "Epoch 9/200, Loss: 15.3048, Validation Accuracy: 13.6949\n",
            "Epoch 10/200, Loss: 11.8070, Validation Accuracy: 14.3051\n",
            "Epoch 11/200, Loss: 44.1513, Validation Accuracy: 16.6072\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[61], line 110\u001b[0m\n\u001b[1;32m    107\u001b[0m     exploited\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexploited.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)    \u001b[38;5;66;03m#append archi to csv without headers if the file is not empty \u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m   \u001b[38;5;66;03m#evaluate label and get reward\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m   E_reward \u001b[38;5;241m=\u001b[39m Train_exploited_child_Mod(new_child_model, Mtrain_loader, Mtrain_loader_at_eval, \u001b[38;5;241m200\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)   \u001b[38;5;66;03m# train the cifar -10 dataset with the unique arrchitecture \u001b[39;00m\n\u001b[1;32m    111\u001b[0m   \u001b[38;5;28mprint\u001b[39m(E_reward)\n\u001b[1;32m    112\u001b[0m   exploit_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplot_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(batch_count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, epoch_count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# set id column\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[58], line 34\u001b[0m, in \u001b[0;36mTrain_exploited_child_Mod\u001b[0;34m(exploited_child, T_train_loader, T_val_loader, T_num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     32\u001b[0m     targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     33\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(outputs,targets)\n\u001b[0;32m---> 34\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     35\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     37\u001b[0m exploited_child\u001b[38;5;241m.\u001b[39meval()\n",
            "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
            "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#training the controller\n",
        "import os \n",
        "num_batchs=2\n",
        "controller_epochs= 100\n",
        "\n",
        "\n",
        "def getChild_models(P_labels, P_skips):    # get correct format for the child skips, child labels and generate child model \n",
        "  split_tensor=[]\n",
        "  controller_skips = {}\n",
        "  for tensor in P_labels:\n",
        "    split_tensor.append(torch.argmax(tensor.detach()))\n",
        "    values_list = [tensor.item() for tensor in split_tensor]\n",
        "  print(type(values_list))\n",
        "  for key, value_list in P_skips.items():\n",
        "    new_value_list =[]\n",
        "    for tensor in value_list:\n",
        "      tensor_no_grad = tensor.detach()\n",
        "      thresholded_value = 1 if tensor_no_grad >0.5 else 0\n",
        "      new_value_list.append(thresholded_value)\n",
        "    controller_skips[key] = new_value_list\n",
        "    e_child_model = child_network([1,3,28,28],n_classes, vocab, values_list, controller_skips)\n",
        "\n",
        "    # e_child_model = child_Model(output_classes, vocab, values_list, controller_skips)\n",
        "  \n",
        "  return e_child_model, list(controller_skips.values()), values_list\n",
        "\n",
        "def save_Model(network, epoch_label):\n",
        "  save_name = \"Mod_{0}.pth\".format(epoch_label)\n",
        "  save_path = os.path.join(\"./saved_models\", save_name)\n",
        "  torch.save(network.state_dict(), save_path)\n",
        "\n",
        "   \n",
        "   \n",
        "\n",
        "def isUnique(data, label_check, skip_check):  # check if generated architecture is unique\n",
        "  # print((data.iloc[0:,0]))\n",
        "\n",
        "  filtered_df =  mydata[(mydata.iloc[:, 0] == str(new_label)) & (mydata.iloc[:, 1] == str(new_skips))]\n",
        "\n",
        "  if not filtered_df.empty:\n",
        "    P_reward = filtered_df.iloc[0, 2]\n",
        "    return True, P_reward \n",
        "  else:\n",
        "    P_reward = \"\"\n",
        "    return False, P_reward\n",
        "  \n",
        "  \n",
        "def To_saveE(id, skips, labels, rewards):     # convert to a saveable format  for exploited architecture\n",
        "  data=[]\n",
        "  data.append({\"id\": id, \"label\": labels, \"skips\": skips, \"rewards\": rewards})\n",
        "  df = pd.DataFrame(data)\n",
        "  return df\n",
        "\n",
        "def To_saveU(skips, labels, rewards):     # convert to a saveable format for unique architecture\n",
        "  data=[]\n",
        "  data.append({\"label\": labels, \"skips\": skips, \"rewards\": rewards})\n",
        "  df = pd.DataFrame(data)\n",
        "  return df\n",
        "\n",
        "Train_from_Previous = False  # train flag true if we want to start training from where we stopped previously\n",
        "load_point = 0\n",
        "prev_epoch_count = 0    # get epoch count from our last training \n",
        "batch_count = 0\n",
        "\n",
        "if Train_from_Previous:\n",
        "  sampled_archi = pd.read_csv('loss.csv')\n",
        "  Prev_baseline = sampled_archi.iloc[-1,2]\n",
        "  prev_epoch_count = int(sampled_archi.iloc[-1,0][-1])\n",
        "  if( os.path.isfile(\"./saved_models/Mod_{}\".format(load_point))):\n",
        "    controller_check.load_state_dict(torch.load(\"./saved_models/Mod_{}\".format(load_point)))\n",
        "  else:\n",
        "    pass\n",
        "else:\n",
        "  epoch_count = 0\n",
        "  Prev_baseline = 0\n",
        "\n",
        "for epoch in range(controller_epochs):\n",
        "    archi_exists = False\n",
        "    epoch_count = prev_epoch_count + epoch + 1 \n",
        "    batch = next(iter(data_loader))\n",
        "    # skips, labels, rewards = batch\n",
        "    batch_skips, batch_labels, batch_rewards = batch\n",
        "    loss, baseline = train_controller(num_batchs,batch_labels,batch_skips,batch_rewards, batch_count+1, epoch_count,Prev_baseline )  # get loss and baseline from the train function\n",
        "    loss_data = {\"id\": \"sample_{}_{}\".format(batch_count+1, epoch_count), \"loss\": loss.detach(), \"baseline\": str(baseline.item())}\n",
        "    lossdf = pd.DataFrame(loss_data)\n",
        "    Prev_baseline = baseline\n",
        "    if not os.path.exists(\"loss.csv\") or os.path.getsize(\"loss.csv\") == 0: # check if the file exists or its not empty and save the loss and baseline per batch\n",
        "      lossdf.to_csv(\"loss.csv\", index = False)\n",
        "    else:\n",
        "      lossdf.to_csv(\"loss.csv\", mode = 'a', header = False, index = False)\n",
        "    print(\"loss: {}\".format(loss))\n",
        "    print(\"baseline: {}\".format(baseline))\n",
        "    exploit_label, exploit_skips = controller_check()   # exploit the controller to get a child model and child label\n",
        "    new_child_model, new_skips, new_label= getChild_models(exploit_label, exploit_skips)   # get the child model, modified label and modified skips from the child network class\n",
        "    print(\"exploit: {}\".format(new_label))\n",
        "    print(\"exploit_skips: {}\".format(new_skips))\n",
        "    #check if architecture already exist\n",
        "    mydata = pd.read_csv(\"uniqueArch.csv\")  # read the uniqueArch csv \n",
        "    archi_exists, E_reward = isUnique(mydata, new_label, new_skips)  # check if the architecture generated by the controller is unique and return its reward if true\n",
        "    print(archi_exists)\n",
        "    if archi_exists:\n",
        "      exploit_id = \"explot_{}_{}\".format(batch_count+1, epoch_count+1)\n",
        "      exploited = To_saveE(exploit_id, new_skips, new_label, E_reward)  # prepare to save the architecture in the exploited architeture\n",
        "      if not os.path.exists(\"exploited.csv\") or os.path.getsize(\"archi.csv\") == 0:\n",
        "        exploited.to_csv(\"exploited.csv\", index=False) #save csv with headers if the file is empty or not found\n",
        "      else:\n",
        "        exploited.to_csv(\"exploited.csv\", mode='a', header=False, index=False)    #append archi to csv without headers if the file is not empty \n",
        "    else:\n",
        "      #evaluate label and get reward\n",
        "      E_reward = Train_exploited_child_Mod(new_child_model, Mtrain_loader, Mtrain_loader_at_eval, 200, learning_rate=0.1)   # train the cifar -10 dataset with the unique arrchitecture \n",
        "      print(E_reward)\n",
        "      exploit_id = \"explot_{}_{}\".format(batch_count+1, epoch_count+1) # set id column\n",
        "      exploited = To_saveE(exploit_id, new_skips, new_label, E_reward) # prepare to save the architecture in the exploited architeture\n",
        "      unique = To_saveU(new_skips, new_label, E_reward)  # prepare to save the architecture in the unique architeture\n",
        "      unique.to_csv('uniqueArch.csv', mode = 'a', header=False, index=False)  #append archi to csv without headers \n",
        "      if not os.path.exists(\"exploited.csv\") or os.path.getsize(\"archi.csv\") == 0:\n",
        "        # If the file doesn't exist or is empty, write the DataFrame with the header\n",
        "        exploited.to_csv(\"exploited.csv\", index=False) \n",
        "      else:\n",
        "        exploited.to_csv(\"exploited.csv\", mode='a', header=False, index=False)\n",
        "    # for batch, data in enumerate(data_loader, 0):\n",
        "        # Unpack the batched data\n",
        "        # batch_skips, batch_labels, batch_rewards = data\n",
        "        # print(batch_labels)\n",
        "        # update the batch count \n",
        "        \n",
        "    save_Model(controller_check, epoch_count)\n",
        "    batch_count += 1\n",
        "    \n",
        "            \n",
        "        # loss_data = {\"id\": \"sample_{}_{}\".format(batch+1, epoch+1), \"loss\": loss.detach(), \"baseline\": baseline}\n",
        "        # \n",
        "\n",
        "            \n",
        "        \n",
        "\n",
        "\n",
        "# num_batchs=2\n",
        "# controller_epochs= 20\n",
        "# for i in controller_epochs:\n",
        "#   total_loss = 0\n",
        "#   train_controller(num_batchs,child_labels,child_skips,rewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#generating child model from the controller \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoCc6ATZZsS6"
      },
      "source": [
        "CONTROLLER_EPOCHS = 2000\n",
        "\n",
        "CHILD_EPOCHS = 100\n",
        "\n",
        "Build controller network\n",
        "\n",
        "for i in CONTROLLER_EPOCHS:\n",
        "\n",
        "     1. Generate a child model\n",
        "     2. Train this child model for CHILD_EPOCHS\n",
        "     3. Obtain val_acc\n",
        "     4. Update controller parameters\n",
        "Get child model with the highest val_acc\n",
        "\n",
        "Train this child model for CHILD_EPOCHS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImvVE8fYetlQ"
      },
      "outputs": [],
      "source": [
        "#config.py\n",
        "# task\n",
        "# find whether the child archi given with respective child labels and child skips is already in the trained dataset of controller\n",
        "#loadcontroller = True\n",
        "#batch = 10000\n",
        "#createcsv = False\n",
        "\n",
        "\n",
        "#train.py\n",
        "#if loadcontroller:\n",
        "#load the weights\n",
        "#optimizer state\n",
        "#load the last (32) rewards and compute baseline\n",
        "\n",
        "#else:\n",
        "#controller weights initially\n",
        "#define the optimizer\n",
        "\n",
        "#if createcsv:\n",
        "#create empty csv with relevant column names\n",
        "\n",
        "\n",
        "#for b in controller epochs: #10000 - initial\n",
        "\n",
        "    #sample a batch :  randomly (32)\n",
        "\n",
        "    #if sampling a batch with random + exploited models (Unique.CSV), do a dataframe concatenation and the sample random 32\n",
        "\n",
        "    #update my controller\n",
        "\n",
        "    #exploit: sample model based on the highest probabilities in the softmaxes\n",
        "    #assume that I am saving all of these exploited ones in a csv\n",
        "\n",
        "    #populate your code\n",
        "\n",
        "    #saving my controller weights and anything necessary\n",
        "    #controller_batch.pb #optimizer_state_batch #grads.py\n",
        "    #dynamically  you can log the loss value and baseline values in a CSV (loss.CSV)\n",
        "\n",
        "    #dynamically save the 32 architectures sampled --Arch config--Rewards--- in a file called architectures.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ1Ab9nYhL8i"
      },
      "outputs": [],
      "source": [
        "#exploit: sample model based on the highest probabilities in the softmaxes\n",
        "#assume that I am saving all of these exploited ones in a csv\n",
        "\n",
        "#if batch is 1:\n",
        "   #generate and add #---ArchID---BatchID---ArchitectureConfig-----reward-(labels,etc) to the Exploit and Unique CSV dynamically\n",
        "#else:\n",
        "   #try:\n",
        "   #open the exploit CSV\n",
        "   #check if the exploited one is equal to any of the config in ArchitectureConfig IN EXPLOIT.csv\n",
        "   #if matched, I will copy the rewards from the respective entry and populate other necessary columns.\n",
        "   #if it didn't match, we will train the generated model and add #---ArchID---BatchID---ArchitectureConfig---reward---(labels,etc) to the Exploit and Unique CSV dynamically\n",
        "   #save the child weights at the end epochs and also the optimizer state and also save the history which has validation accuracy, train accuracy at each epochs\n",
        "   #model checkpoints :  save the model at the best epoch.\n",
        "\n",
        "\n",
        "\n",
        "#save the exploited model in 2 CSVs\n",
        "#1. Exploited. csv\n",
        "\n",
        "#---ArchID---BatchID---ArchitectureConfig---reward---(labels,etc)--Unique\n",
        "#2. Unique.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wQ1vUWrwdSj"
      },
      "outputs": [],
      "source": [
        "with open(exploit_csv, 'a', newline='') as exploit_file, open(unique_csv, 'a', newline='') as unique_file:\n",
        "        exploit_writer = csv.writer(exploit_file)\n",
        "        unique_writer = csv.writer(unique_file)\n",
        "if batch==1:\n",
        "  # add data to exploitcsv andupdate csv\n",
        "  exploit_writer.writerow(arch_id,batch_id,architecture_config, rewards ,labels,skips,unique)\n",
        "  unique_writer.writerow([arch_id, architecture_config])\n",
        "else:\n",
        "  try:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W19fuGwaOxJ0"
      },
      "outputs": [],
      "source": [
        "#write a function to create empty CSV\n",
        "import csv\n",
        "\n",
        "def create_csv():\n",
        "  # creating unique_csv\n",
        "  headers=['arch_ID','Batch_ID','archi_config','reward','labels','skips']\n",
        "  df = pd.DataFrame(columns=headers)\n",
        "  df.to_csv('unique.csv', index=False)\n",
        "\n",
        "  # create exploit_csv\n",
        "  headers=['arch_ID','Batch_ID','archi_config','reward','labels','skips','unique']\n",
        "  df = pd.DataFrame(columns=headers)\n",
        "  df.to_csv('exploit.csv', index=False)\n",
        "\n",
        "  # create architecture_csv\n",
        "  headers=['archi_config','reward']\n",
        "  df = pd.DataFrame(columns=headers)\n",
        "  df.to_csv('archi_config.csv', index=False)\n",
        "\n",
        "  # create loss_csv\n",
        "  headers=['loss','baseline']\n",
        "  df = pd.DataFrame(columns=headers)\n",
        "  df.to_csv('loss.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4eTQEGLofEx"
      },
      "outputs": [],
      "source": [
        "#write a function to add data to a csv in a file path dynamically\n",
        "\n",
        "def save_data_to_csv(filepath, data):\n",
        "  try:\n",
        "    with open(self.filepath, 'r', newline='') as csvfile:\n",
        "                    csv_reader = csv.reader(csvfile)\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    # Open the CSV file in append mode\n",
        "  with open(filepath, 'a', newline='') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerow(data)  # Write the data to the CSV file"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b9da4f211b84267bbf3ea264927321f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25313e6a7b5c40479fb3c6d3c981140e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25ed5e067bbc46cbaddd5528cfa986ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7692b7723ecf40fe9deacf00163e0ed3",
            "placeholder": "​",
            "style": "IPY_MODEL_1b9da4f211b84267bbf3ea264927321f",
            "value": ""
          }
        },
        "396172b2a8984d6ca3ae8bcd60aeec43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d380f50b78c44b128534c3e704e3a611",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_874bc9197d4342aeba30550926bd1b6f",
            "value": 0
          }
        },
        "483a7e73e3bc48ec831563ee70c3ab1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_25ed5e067bbc46cbaddd5528cfa986ea",
              "IPY_MODEL_c34b4c045d184044b8336a04fec81ffe",
              "IPY_MODEL_eb02dd05a3f840b79e08b24a05cdad9d"
            ],
            "layout": "IPY_MODEL_9ec3de546846451793ae9d28181482c3"
          }
        },
        "49709487ea0e42ee8b4317fff54f250b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7328629d61240f28b2ab70e5753e51f",
            "placeholder": "​",
            "style": "IPY_MODEL_5c2e2d223c8648dd90a02c54cd83b7ae",
            "value": "  0%"
          }
        },
        "5b8637b35f434425a8b9696fdc0412e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c2e2d223c8648dd90a02c54cd83b7ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6845a97ed9234f16babf40c633c9e5fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49709487ea0e42ee8b4317fff54f250b",
              "IPY_MODEL_396172b2a8984d6ca3ae8bcd60aeec43",
              "IPY_MODEL_dfee6af47a1d434f9329212841dabf9f"
            ],
            "layout": "IPY_MODEL_5b8637b35f434425a8b9696fdc0412e4"
          }
        },
        "7692b7723ecf40fe9deacf00163e0ed3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "874bc9197d4342aeba30550926bd1b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "976b8cf9b6864777bd5600e672525f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98d78a894337485f866d486340ab5db6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ec3de546846451793ae9d28181482c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7328629d61240f28b2ab70e5753e51f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c34b4c045d184044b8336a04fec81ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7389f3b0fdc4d7da3fe0bbd23e99098",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3d61e4d269c47e3aded2a75ec9123fa",
            "value": 0
          }
        },
        "c3d61e4d269c47e3aded2a75ec9123fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7389f3b0fdc4d7da3fe0bbd23e99098": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d380f50b78c44b128534c3e704e3a611": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfee6af47a1d434f9329212841dabf9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98d78a894337485f866d486340ab5db6",
            "placeholder": "​",
            "style": "IPY_MODEL_976b8cf9b6864777bd5600e672525f3c",
            "value": " 0/20 [00:16&lt;?, ?it/s]"
          }
        },
        "eb02dd05a3f840b79e08b24a05cdad9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25313e6a7b5c40479fb3c6d3c981140e",
            "placeholder": "​",
            "style": "IPY_MODEL_eb367ce15f6a4a738bd09af2235ef0d2",
            "value": " 0/? [00:16&lt;?, ?it/s]"
          }
        },
        "eb367ce15f6a4a738bd09af2235ef0d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
